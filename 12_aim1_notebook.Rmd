Analyze familiar word recognition
===========================================================================

Next steps:

- Model year over year changes.
- Download test scores and individual differences. 
- Analyze individual differences

```{r include = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
```

```{r helpers, include = FALSE}
```

## Data preparation

Earlier we cleaned the data to remove trials with excessive missing data 
and blocks of trials with too few trials. Now we prepare the data for modelling.

```{r}
opts_model <- list(
  bin_width = 3,
  start_time = 250,
  end_time = 1500
)
opts_model$bin_length <- round(opts_model$bin_width * 16.67, -1)
opts_model
```

We next downsample the data into `r opts_model$bin_length` ms (`r
opts_model$bin_width`-frame) bins in order to smooth the data. We will model the
looks from `r opts_model$start_time` to `r opts_model$end_time` ms, so we filter
down to that time window. Lastly, we aggregate looks by child, study and time,
and create orthogonal polynomials to use as time features for the model

```{r, message = FALSE, warnings = FALSE}
data <- readr::read_csv("./data/aim1-screened.csv.gz") %>% 
  select(Study, ResearchID, TrialID:GazeByImageAOI) %>% 
  assign_bins(bin_width = opts_model$bin_width, Time, TrialID)

# Compute time at center of each bin
bin_times <- data %>% 
  distinct(Time, .bin) %>% 
  group_by(.bin) %>% 
  mutate(BinTime = round(median(Time), -1)) %>% 
  ungroup()

# Attach bin times
binned <- data %>% 
  left_join(bin_times, by = c("Time", ".bin")) %>% 
  ungroup() %>% 
  select(-Time) %>% 
  rename(Time = BinTime) 

resp_def <- create_response_def(
  primary = "Target",
  others = c("PhonologicalFoil", "SemanticFoil", "Unrelated"),
  elsewhere = "tracked",
  missing = NA
)  
  
d <- binned %>% 
  aggregate_looks(resp_def, Study + ResearchID + Time ~ GazeByImageAOI)

d_m <- d %>% 
  filter(opts_model$start_time <= Time, 
         Time <= opts_model$end_time) %>% 
  polypoly::poly_add_columns(Time, degree = 3, 
                             scale_width = 1, prefix = "ot")
```

Plot the model-ready data. For this plot, we use the so-called _empirical logit_
transformation because the regular logit (log-odds) generates too extreme of
values for plotting. 

```{r spaghetti-elogit, echo = FALSE, message = FALSE, out.width = "100%", fig.height=2.5, fig.width=6}
ggplot(d_m) + 
  aes(x = Time, y = empirical_logit(Primary, Others)) + 
  geom_line(aes(group = ResearchID), alpha = .2) + 
  stat_smooth() +
  theme_grey(base_size = 9) +
  facet_grid(. ~ Study) + 
  labs(x = "Time after target onset (smoothed to 50 ms bins)", 
       y = "Emp. logit looking to target")
```

Those extreme lines indicate sparse data where there are zero-to-few looks to
the distractors compared to the target. These are the 20 most extreme bins, to 
illustrate how empirical logit tames infinite values.

```{r, echo = FALSE}
d_m %>% 
  select(Study:Time, Primary, Others) %>% 
  arrange(desc(log(Primary / Others))) %>% 
  mutate(
    logit = log(Primary / Others) %>% round(2),
    elogit = empirical_logit(Primary, Others) %>% round(2)) %>% 
  head(20) %>% 
  knitr::kable()
```


## Maximum likelihood results

Fit a maximum likelihood model as a first pass for the analysis. We won't fit
the model automatically (whenever this page is updated). It's too time
consuming. Instead, we do it manually here, and save the results.

```{r, eval = FALSE}
library(lme4)
m <- glmer(
    cbind(Primary, Others) ~
      (ot1 + ot2 + ot3) * Study +
      (ot1 + ot2 + ot3 | ResearchID/Study),
    family = binomial,
    data = d_m)
readr::write_rds(m, "./data/aim1_cubic_model.rds.gz")
```

And reload the saved model here.

```{r cubic-model-fits, out.width = "100%", fig.height=2.5, fig.width=6}
library(lme4)
m <- readr::read_rds("./data/aim1_cubic_model.rds.gz")
arm::display(m)

d_m$cubic_fit <- fitted(m)

ggplot(d_m) + 
  aes(x = Time, y = cubic_fit) + 
  geom_line(aes(group = ResearchID), alpha = .2) + 
  facet_grid(. ~ Study) + 
    labs(
      x = "Time after target onset (smoothed to 50 ms bins)",
      y = "Proportion looks to target (fitted)") +
  theme_grey(base_size = 9) 
```

### What's being captured by the random effects? 

First, let's plot just the fixed effect predictions.

```{r cubic-model-fits-fixes, out.width = "100%", fig.height=2.5, fig.width=6}
predict_y <- function(...) predict(..., type = "response")
d_m$fixef_fit <- predict_y(m, re.form = ~ 0)
d_m$subj_fit  <- predict_y(m, re.form = ~ (ot1 + ot2 + ot3 | ResearchID))
d_m$study_fit <- predict_y(m, re.form = ~ (ot1 + ot2 + ot3 | Study:ResearchID))
d_m$full_fit  <- predict_y(m, re.form = ~ (ot1 + ot2 + ot3 | Study:ResearchID) + 
                            (ot1 + ot2 + ot3 | ResearchID))

ggplot(d_m) + 
  aes(x = Time, y = fixef_fit) + 
  geom_line(aes(group = ResearchID), alpha = .2) + 
  facet_grid(. ~ Study) + 
  theme_grey(base_size = 9) +
  labs(
    x = "Time after target onset (smoothed to 50 ms bins)",
    y = "Proportion looks to target (fitted)",
    caption = "Conditioned on no random effects") 
```

Now, we condition on child level effects. 

```{r cubic-model-fits-child-efs, out.width = "100%", fig.height=2.5, fig.width=6}
ggplot(d_m) + 
  aes(x = Time, y = subj_fit) + 
  geom_line(aes(group = ResearchID), alpha = .2) + 
  facet_grid(. ~ Study) + 
  theme_grey(base_size = 9) +
  labs(
    x = "Time after target onset (smoothed to 50 ms bins)",
    y = "Proportion looks to target (fitted)",
    caption = "Conditioned on Child effects") 

ggplot(d_m) + 
  aes(x = Time, y = subj_fit - fixef_fit) + 
  geom_line(aes(group = ResearchID), alpha = .2) + 
  facet_grid(. ~ Study) + 
  theme_grey(base_size = 9) +
  labs(
    x = "Time after target onset (smoothed to 50 ms bins)",
    y = "Child-conditioned minus study means") 
```

It looks like the range of y values is
smaller in TimePoint2 and TimePoint3, but could that just be the different
numbers of participants who contribute to each study?

```{r}
d_m %>% 
  distinct(ResearchID, Study) %>% 
  count(Study) %>% 
  rename(`Num children in model` = n) %>% 
  knitr::kable()
```

Now we condition on Study x Child effects. These would be capturing the
subject-x-study variability.

```{r cubic-model-fits-ranefs, out.width = "100%", fig.height=2.5, fig.width=6}
ggplot(d_m) +
  aes(x = Time, y = study_fit) +
  geom_line(aes(group = ResearchID), alpha = .2) +
  facet_grid(. ~ Study) +
  theme_grey(base_size = 9) +
  labs(
    x = "Time after target onset (smoothed to 50 ms bins)",
    y = "Proportion looks to target (fitted)",
    caption = "Conditioned on Study x Child effects")

ggplot(d_m) +
  aes(x = Time, y = study_fit - fixef_fit) +
  geom_line(aes(group = ResearchID), alpha = .2) +
  facet_grid(. ~ Study) +
  theme_grey(base_size = 9) +
  labs(
    x = "Time after target onset (smoothed to 50 ms bins)",
    y = "Child-x-Study-conditioned minus study means")
```

Look for weak spots in the time series.

```{r cubic-model-raw-fit-corr, out.width = "50%", fig.height=3, fig.width=4}
d_corr <- d_m %>% 
  group_by(Time, Study) %>% 
  summarise(r = cor(Prop, cubic_fit)) 

ggplot(d_corr) + 
  aes(x = Time, y = r, color = Study) + 
  geom_point(shape = 1, size = 3) + 
  ylim(c(.8, 1)) + 
  labs(
    x = "Time after target onset (smoothed to 50 ms bins)",
    y = "Correlation of fitted and observed") + 
  theme_grey(base_size = 9) +
  theme(
    legend.position = c(0.025, 0.05), 
    legend.justification = c(0, 0)) 
```

Rank the participants by their growth curve parameters---that is, the growth
curve features when conditioned on child ID.

```{r}
xstudy_effects <- m %>% 
  ranef() %>% 
  getElement("ResearchID") %>% 
  tibble::rownames_to_column("ResearchID") %>% 
  as_tibble() %>% 
  select(ResearchID, intercept = `(Intercept)`, slope = ot1)

top_20 <- top_n(xstudy_effects, 20, slope)
bot_20 <- top_n(xstudy_effects, 20, -slope)
```

```{r cubic-model-fits-child-efs-ranks, out.width = "50%", fig.height=3, fig.width=3}
ggplot(d_m %>% filter(Study == "TimePoint2")) + 
  aes(x = Time, y = subj_fit) + 
  geom_line(aes(group = ResearchID), alpha = .2) +
  geom_line(aes(group = ResearchID), 
            data = semi_join(d_m, top_20) %>% filter(Study == "TimePoint2"), 
            size = .7, color = "#0074D9") + 
  geom_line(aes(group = ResearchID), 
            data = semi_join(d_m, bot_20) %>% filter(Study == "TimePoint2"), 
            size = .7, color = "#FF4136") + 
  theme_grey(base_size = 9) +
  labs(y = "TP2 fits conditioned on Child effects", 
       x = "Time after target onset (smoothed to 50 ms bins)",
       caption = "Colors: Top 20 and bottom 20 children by linear time effect")
```

Visualize the model fits for the top and bottom 20 children. This plot
illustrates that the children with strongest and weakest linear time components
overall stay clustered away from each other when looking study level
predictions. That is, the top 20 in general perform bunch together in all three
studies.

```{r ranks, out.width = "100%", fig.height=2.5, fig.width=6}
ggplot(d_m) + 
  aes(x = Time, y = cubic_fit) + 
  geom_line(aes(group = ResearchID), alpha = .2) +
  geom_line(aes(group = ResearchID), data = semi_join(d_m, top_20), 
            size = .7, color = "#0074D9") + 
  geom_line(aes(group = ResearchID), data = semi_join(d_m, bot_20), 
            size = .7, color = "#FF4136") + 
  facet_grid(. ~ Study) + 
  theme_grey(base_size = 9) +
  labs(y = "Proportion looks to target [model fits]", 
       x = "Time after target onset (smoothed to 50 ms bins)",
       caption = "Colors: Top 20 and bottom 20 children by linear time effect")
```

To confirm that this differences are not just an artifact of modeling, visualize
the ranks on the observed data.

```{r ranks-on-raw, out.width = "100%", fig.height=2.5, fig.width=6}
ggplot(d_m) + 
  aes(x = Time, y = Prop) + 
  geom_line(aes(group = ResearchID), alpha = .2) +
  geom_line(aes(group = ResearchID), data = semi_join(d_m, top_20), 
            size = .7, color = "#0074D9") + 
  geom_line(aes(group = ResearchID), data = semi_join(d_m, bot_20), 
            size = .7, color = "#FF4136") + 
  facet_grid(. ~ Study) + 
  labs(y = "Proportion looks to target", 
       x = "Time after target onset (smoothed to 50 ms bins)",
       caption = "Colors: Top 20 and bottom 20 children by linear time effect")
```

Open questions:

* How to test for stability of individual differences over time? 
  + Intuitively, I would say that the differences are unstable if the red and 
    blue lines got shuffled in each study. What stats formalize this intuition?



## Bayesian model results

Here is the code used to fit the model with Stan. It took about 24 hours to run
the model. The regression terms have the prior Normal(0, 1)

```{r, eval = FALSE}
library(rstanarm)
options(mc.cores = parallel::detectCores())

m <- stan_glmer(
  cbind(Primary, Others) ~
    (ot1 + ot2 + ot3) * Study +
    (ot1 + ot2 + ot3 | ResearchID/Study),
  family = binomial,
  prior = normal(0, 1),
  prior_intercept = normal(0, 5),
  prior_covariance = decov(2, 1, 1),
  data = d_m)
readr::write_rds(m, "./data/stan_aim1_cubic_model.rds.gz")
```

Let's try to understand our model by making some plots.

### Fixed effects plots

First, let's prepare to plot the intervals for the fixed effects.

```{r}
library(rstanarm)
library(bayesplot)
theme_set(theme_grey())
library(stringr)
library(ggstance)
parse_text <- function(x) parse(text = x)

b <- readr::read_rds("./data/stan_aim1_cubic_model.rds.gz")
b

summary(b, pars = names(fixef(b)))

prior_summary(b)
```

Below the TimePoint2, TimePoint3, Time x TimePoint2, and Time x TimePoint3 
effects confirm that children get more reliable and faster each year of the 
study. Only the Time^2^ effect is near 0, which does not matter. We mostly care
about the intercept and time terms.

```{r effects1, echo = FALSE, out.width = "80%", fig.height=4, fig.width=5}
intervals <- mcmc_intervals_data(as.data.frame(b), pars = names(fixef(b)))

# Rename to use mathematical formatting
intervals$pname <- intervals$parameter %>%
  str_replace("ot(2|3)", "Time^\\1") %>% 
  str_replace("ot(1)", "Time") %>% 
  str_replace(".Intercept.", "Intercept") %>% 
  str_replace("Study", "") %>% 
  str_replace(":", " %*% ") %>% 
  factor(., levels = rev(.))

ggplot(intervals) + 
  aes(y = pname) +
  geom_vline(xintercept = 0, size = 2, color = "white") +
  geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  geom_point(aes(x = m), size = 3, shape = 3) + 
  scale_y_discrete(labels = parse_text) + 
  labs(x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals") + 
  ggtitle("Average effects", 
          subtitle = "Dummy-coded effects with Timepoint1 as reference level")
```

Now, let's undo interactions by adding year 1 main effects to interaction 
effects and plot the effects for each year of the study. For each effect, there
appears to be a linear trend in the change from TP1 to TP2 and from TP2 to TP3.

```{r effects2, echo = FALSE, out.width = "80%", fig.height=4, fig.width=5}
# Column names will have mathematical formatting too
draws <- as.data.frame(b) %>% 
  as_tibble() %>% 
  transmute(
    `Intercept~~(TP1)` = `(Intercept)`,
    `Intercept~~(TP2)` = `(Intercept)` + StudyTimePoint2,
    `Intercept~~(TP3)` = `(Intercept)` + StudyTimePoint3,
    `Time~~(TP1)` = ot1,
    `Time~~(TP2)` = ot1 + `ot1:StudyTimePoint2`,
    `Time~~(TP3)` = ot1 + `ot1:StudyTimePoint3`,
    `Time^2~~(TP1)` = ot2,
    `Time^2~~(TP2)` = ot2 + `ot2:StudyTimePoint2`,
    `Time^2~~(TP3)` = ot2 + `ot2:StudyTimePoint3`,
    `Time^3~~(TP1)` = ot3,
    `Time^3~~(TP2)` = ot3 + `ot3:StudyTimePoint2`,
    `Time^3~~(TP3)` = ot3 + `ot3:StudyTimePoint3`)

intervals2 <- draws %>% 
  mcmc_intervals_data(prob = 0.5, prob_outer = 0.9) %>% 
  mutate(parameter = factor(parameter, levels = rev(parameter)))

ggplot(intervals2) + 
  aes(y = parameter) +
  geom_vline(xintercept = 0, size = 2, color = "white") +
  ggstance::geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  ggstance::geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  geom_point(aes(x = m), size = 3, shape = 3) + 
  scale_y_discrete(labels = parse_text) + 
  labs(x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals") + 
  ggtitle("Average effects by study")
```

Compute pairwise comparisons.

```{r pairwise-effects, echo = FALSE, out.width = "80%", fig.height=4, fig.width=5}
clean_names <- . %>% 
  stringr::str_replace_all("[()]", "") %>% 
  stringr::str_replace("~~", "_")

pairwise <- draws %>% 
  tibble::rowid_to_column(".draw") %>% 
  set_names(clean_names) %>% 
  tidyr::gather(parameter, value, -.draw) %>% 
  tidyr::separate(parameter, c("parameter", "year"), sep = "_") %>% 
  compare_pairs(year, value) %>% 
  tidyr::spread(pair, value) %>% 
  split(.$parameter) %>% 
  lapply(. %>% 
           select(-.draw, -parameter) %>% 
           mcmc_intervals_data(prob = 0.5, prob_outer = 0.9) %>% 
           rename(pair = parameter)) %>% 
  bind_rows(.id = "parameter")

ggplot(pairwise) + 
  aes(y = forcats::fct_rev(pair)) +
  geom_vline(xintercept = 0, size = 2, color = "white") +
  ggstance::geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  ggstance::geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  geom_point(aes(x = m), size = 3, shape = 3) + 
  labs(x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals") + 
  facet_wrap("parameter", ncol = 1, strip.position = "left", 
             labeller = label_parsed) + 
  theme(strip.placement = "outside", 
        strip.background = element_rect(fill = NA),
        axis.text.y = element_text(size = rel(1.2))) +
  ggtitle("Differences in average effects")
```




Bayesplot supports transformations so we could invert the log-odds measure to
see the intercepts (area under curve/average accuracy) in proportion units.

```{r intercepts, echo = FALSE,  out.width = "60%", fig.height=2.5, fig.width=4}
intervals3 <- draws %>% 
  mcmc_intervals_data(regex_pars = "Intercept", transformations = "plogis", 
                      prob = 0.5, prob_outer = 0.9) %>% 
  mutate(parameter = factor(parameter, levels = rev(parameter)))

intervals3 %>% 
  mutate_if(is.numeric, round, 3) %>% 
  select(-point_est) %>% 
  rename(outer = outer_width, inner = inner_width) %>% 
  knitr::kable()

ggplot(intervals3) + 
  aes(y = parameter) +
  geom_vline(xintercept = .25, size = 2, color = "white") +
  ggstance::geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  ggstance::geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  geom_point(aes(x = m), size = 3, shape = 3) + 
  scale_y_discrete(labels = parse_text) + 
  labs(x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals") + 
  ggtitle("Average accuracy by year")
```

We can compute differences in average accuracy as well.

```{r intercept-differences, echo = FALSE, out.width = "60%", fig.height=2.5, fig.width=4}
proportions <- b %>% 
  as.data.frame() %>%
  transmute(
    `TP1` = `(Intercept)`,
    `TP2` = `(Intercept)` + StudyTimePoint2,
    `TP3` = `(Intercept)` + StudyTimePoint3) %>% 
  tibble::rowid_to_column(".draw") %>% 
  tidyr::gather(parameter, estimate, -.draw) %>% 
  mutate(estimate = plogis(estimate)) %>% 
  as_tibble()

prop_diffs <- proportions %>% 
  compare_pairs(parameter, estimate) %>% 
  tidyr::spread(pair, value) %>% 
  select(-.draw) %>% 
  mcmc_intervals_data(prob = 0.5, prob_outer = 0.9)

ggplot(prop_diffs) + 
  aes(y = forcats::fct_rev(parameter)) +
  geom_vline(xintercept = 0, size = 2, color = "white") +
  ggstance::geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  ggstance::geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  geom_point(aes(x = m), size = 3, shape = 3) + 
  scale_y_discrete(labels = parse_text) + 
  labs(x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals") + 
  ggtitle("Differences in average accuracy")
```

```{r, include = FALSE}
pluck <- purrr::pluck

prop_list <- intervals3 %>% 
  split(.$parameter) %>% 
  set_names(str_extract, "TP.")

get_pts <- . %>% lapply(. %>% pluck("m") %>% round(3)) 
get_uis <- . %>% lapply(. %>% glue::glue_data("{round(ll,3)}--{round(hh,3)}")) 

pts <- get_pts(prop_list)
uis <- get_uis(prop_list)

diff_list <- prop_diffs %>% 
  split(.$parameter) %>% 
  set_names(str_replace, "-", "_")

d_pts <- get_pts(diff_list)
d_uis <- get_uis(diff_list)
```

The average accuracy was `r pts$TP1` [90% UI: `r uis$TP1`] for timepoint
1, `r pts$TP2` [`r uis$TP2`] for timepoint 2, and `r pts$TP3` [`r uis$TP3`]
for timepoint 3. The average accuracy increased by `r d_pts$TP2_TP1`
[`r d_uis$TP2_TP1`] from timepoint 1 to timepoint 2 and by `r d_pts$TP3_TP2`
[`r d_uis$TP3_TP2`] from timepoint 2 to timepoint 3.


### Plot the intervals for the random effect parameters

These are the parameters governing the random effect distributions. First, we
plot the standard deviations.

```{r posterior-sds, echo = FALSE, out.width = "80%", fig.height = 2.5, fig.width = 5}
sdcors <- tristan::draw_var_corr(b)
sdcors_wide <- sdcors %>% 
  select(.draw, .parameter, sdcor) %>% 
  tidyr::spread(.parameter, sdcor) %>% 
  select(-.draw)

# Create the mathematical labels for parameters
group_info <- sdcors %>% 
  select(.parameter:var2) %>% 
  distinct()
group_info$group <- group_info$grp %>% 
  stringr::str_replace("Study:ResearchID", "Child-Study") %>% 
  stringr::str_replace("ResearchID", "Child") 
group_info$r <- ifelse(is.na(group_info$var2), "", 
                       paste0(",", group_info$var2))
group_info$sym <- ifelse(is.na(group_info$var2), "sigma", "rho")
group_info$var1 <- ifelse(group_info$var1 == "(Intercept)", "Intercept", 
                          group_info$var1)
group_info$math <- sprintf("%s[list(%s%s)]", group_info$sym, 
                           group_info$var1, group_info$r)
group_info$class <- ifelse(is.na(group_info$var2), "scale", "correlation")
group_info <- group_info %>% 
  select(group, class, var1, var2, parameter = .parameter, math) %>% 
  mutate(parameter = as.factor(parameter))

intervals <- as.data.frame(sdcors_wide) %>% 
  mcmc_intervals_data() %>% 
  left_join(group_info, by = "parameter") %>% 
  mutate(math = forcats::fct_rev(math))

ggplot(intervals %>% filter(class == "scale")) + 
  aes(y = math) +
  # Draw medians with + then draw white horizontal lines over the horizontal 
  # parts of the + symbols
  geom_point(aes(x = m), size = 3, shape = 3) +
  geom_hline(aes(yintercept = as.numeric(parameter)), color = "white") +
  geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  scale_y_discrete(labels = parse_text) +
  facet_wrap("group", ncol = 1, strip.position = "left") + 
  theme(strip.placement = "outside", 
        strip.background = element_rect(fill = NA),
        axis.text.y = element_text(size = rel(1.2))) +
  labs(title = "Random effect scales", 
       x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals")
```

Then the correlations.

```{r posterior-cors, echo = FALSE, out.width = "80%", fig.height = 3, fig.width = 5}
ggplot(intervals %>% filter(class == "correlation")) + 
  aes(y = math) +
  geom_vline(xintercept = 0, size = 2, color = "white") +
  # Draw medians with + then draw white horizontal lines over the horizontal 
  # parts of the + symbols
  geom_point(aes(x = m), size = 3, shape = 3) +
  geom_hline(aes(yintercept = as.numeric(parameter)), color = "white") +
  geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  scale_y_discrete(labels = parse_text) +
  facet_wrap("group", ncol = 1, strip.position = "left") + 
  theme(strip.placement = "outside", 
        strip.background = element_rect(fill = NA),
        axis.text.y = element_text(size = rel(1.2))) +
  labs(title = "Random effect correlations", 
       x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals")
```


### Check for stable individual differences

```{r}



```





### Posterior predictive checks

Next, we let's check how well the model can simulate the observed data.

```{r post-pred, out.width = "80%", fig.height=3, fig.width=5}
rstanarm::pp_check(b, nreps = 200, seed = "09272017") + 
  labs(
    x = "Proportion of looks", 
    title = "Observed data and 200 posterior simulations") +
  guides(color = "none") +
  coord_cartesian(xlim = c(0, 1))
```


### Look at some predictions

Plot the posterior predictions for random participants. This is the model 
simulating new data for these participants.

```{r posterior-lines, out.width = "100%", fig.height=4, fig.width=5}
set.seed(09272017)

ppred <- d_m %>% 
  sample_n_of(8, ResearchID) %>% 
  tristan::augment_posterior_predict(b, newdata = ., nsamples = 100) %>% 
  mutate(trials = Primary + Others)

ggplot(ppred) + 
  aes(x = Time, y = Prop, color = Study, group = Study) + 
  geom_line(aes(y = .posterior_value / trials, 
                group = interaction(.draw, Study)), 
            alpha = .20) + 
  geom_line(size = 1, color = "grey50") + 
  facet_wrap("ResearchID") + 
  theme(
    legend.position = c(.95, 0), 
    legend.justification = c(1, 0),
    legend.margin = margin(0)) +
  guides(color = guide_legend(title = NULL, override.aes = list(alpha = 1))) +
  labs(
    title = "Observed means and 100 simulations of new data",
    x = "Time after target onset",
    y = "Proportion looks to target") 
```

Or we can plot the linear predictions. These are posterior predictions of the
log-odds of looking to target before adding binomial noise.

```{r posterior-mean-lines, out.width = "100%", fig.height=4, fig.width=5}
lpred <- d_m %>% 
  sample_n_of(8, ResearchID) %>% 
  tristan::augment_posterior_linpred(b, newdata = ., nsamples = 100)

ggplot(lpred) + 
  aes(x = Time, y = .posterior_value, color = Study) +
  geom_line(aes(group = interaction(Study, ResearchID, .draw)), 
            alpha = .1) +
  facet_wrap("ResearchID") + 
  geom_point(aes(y = qlogis(Prop)), shape = 1) + 
  theme(
    legend.position = c(.95, 0), 
    legend.justification = c(1, 0),
    legend.margin = margin(0)) +
  guides(color = guide_legend(title = NULL, override.aes = list(alpha = 1))) +
  labs(
    title = "Observed data and 100 posterior predictions",
    x = "Time after target onset",
    y = "Posterior log-odds")
```

We can consider predictions for hypothetical, new children as well.

```{r new-participants, fig.width=6, fig.height=3, out.width="80%"}
dummy_data <- d_m %>% 
  distinct(Study, Time, ot1, ot2, ot3) %>% 
  mutate(ResearchID = "NEW",
         Primary = 0, 
         Others = 0)

lpred <- dummy_data %>% 
  tristan::augment_posterior_linpred(b, newdata = ., nsamples = 1000)

ggplot(lpred) + 
  aes(x = Time, y = plogis(.posterior_value), color = Study) +
  geom_hline(yintercept = .25, size = 2, color = "white") +
  geom_line(aes(group = interaction(Study, .draw)), 
            alpha = .1, show.legend = FALSE) +
  facet_wrap("Study") + 
  guides(color = guide_legend("none")) +
  labs(
    title = "Posterior predictions for 1000 new participants",
    x = "Time after target onset",
    y = "Proportion looks to target")

ggplot(lpred) + 
  aes(x = Time, y = plogis(.posterior_value), color = Study) +
  geom_hline(yintercept = .25, size = 2, color = "white") +
  stat_summary(fun.data = median_hilow, fun.args = list(conf.int = .9),
               size = 1, geom = "linerange") + 
  stat_summary(fun.data = median_hilow, fun.args = list(conf.int = .5), 
               size = 1.5, geom = "linerange") + 
  stat_summary(fun.y = median, fun.args = list(conf.int = .5), 
               size = 2.5, geom = "point") + 
  facet_wrap("Study") + 
  guides(color = guide_legend("none")) +
  labs(
    title = "Posterior predictions for 1000 new participants",
    x = "Time after target onset",
    y = "Proportion looks to target")
```


```{r hmmm-new-participants, fig.width=6, fig.height=3, out.width="80%"}
by_draw <- lpred %>%
  group_by(Study, Time) %>%
  summarise(
    iqr = IQR(plogis(.posterior_value)),
    min = min(plogis(.posterior_value)),
    max = max(plogis(.posterior_value)),
    range = max - min)

ggplot(by_draw) +
  aes(x = Time, y = range, color = Study) +
  stat_summary(fun.data = median_hilow, fun.args = list(conf.int = .9),
               size = 1, geom = "linerange") +
  stat_summary(fun.data = median_hilow, fun.args = list(conf.int = .5),
               size = 1.5, geom = "linerange") +
  stat_summary(fun.y = median, fun.args = list(conf.int = .5),
               size = 2.5, geom = "point") +
  labs(
    title = "Ranges of predictions for 1000 new participants",
    x = "Time after target onset",
    y = "Max - min predicted value") 

ggplot(by_draw) +
  aes(x = Time, y = iqr, color = Study) +
  stat_summary(fun.data = median_hilow, fun.args = list(conf.int = .9),
               size = 1, geom = "linerange") +
  stat_summary(fun.data = median_hilow, fun.args = list(conf.int = .5),
               size = 1.5, geom = "linerange") +
  stat_summary(fun.y = median, fun.args = list(conf.int = .5),
               size = 2.5, geom = "point") +
  labs(
    title = "25%-75% ranges of predictions",
    x = "Time after target onset",
    y = "Interquartile range of predictions") + 
  ylim(0, .25)


# in_every_study <- d_m %>% 
#   distinct(Study, ResearchID) %>% 
#   split(.$Study) %>% 
#   lapply(getElement, "ResearchID") %>% 
#   Reduce(intersect, .)
# 
# d_m_every <- d_m %>% 
#   filter(ResearchID %in% in_every_study)
# 
# sims <- tristan::augment_posterior_linpred(b, d_m_every, nsamples = 1000)
# 
# ggplot(sims) + 
#   aes(x = Time, y = plogis(.posterior_value, color = Study) +
#   geom_hline(yintercept = .25, size = 2, color = "white") +
#   stat_summary(fun.data = median_hilow, fun.args = list(conf.int = .9),
#                size = 1, geom = "linerange") + 
#   stat_summary(fun.data = median_hilow, fun.args = list(conf.int = .5), 
#                size = 1.5, geom = "linerange") + 
#   stat_summary(fun.y = median, fun.args = list(conf.int = .5), 
#                size = 2.5, geom = "point") + 
#   # geom_line(aes(group = interaction(Study, ResearchID, .draw)), 
#   #           alpha = .1) +
#   # facet_wrap("ResearchID") + 
#   geom_point(aes(y = qlogis(Prop)), shape = 1) + 
#   theme(
#     legend.position = c(.95, 0), 
#     legend.justification = c(1, 0),
#     legend.margin = margin(0)) +
#   guides(color = guide_legend(title = NULL, override.aes = list(alpha = 1))) +
#   labs(
#     title = "Observed data and 100 posterior predictions",
#     x = "Time after target onset",
#     y = "Posterior log-odds")
# sds <- fits %>% 
#   group_by(Study, coef, .draw) %>% 
#   summarise(
#     mean = mean(.posterior_value),
#     min = min(.posterior_value),
#     max = max(.posterior_value),
#     range = max - min,
#     sd = sd(.posterior_value)) %>%
#   group_by(Study, coef) %>% 
#   select(-.draw) %>% 
#   do(bayesplot::mcmc_intervals_data(select(., mean:sd))) %>% 
#   ungroup()
# 
# ggplot(sds %>% filter(coef %in% c("intercept", "ot1"))) + 
#   aes(y = forcats::fct_rev(Study)) +
#   geom_vline(xintercept = 0, size = 2, color = "white") +
#   ggstance::geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
#   ggstance::geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
#   geom_point(aes(x = m), size = 3, shape = 3) + 
#   labs(x = NULL, y = NULL, caption = "90% and 50% intervals") + 
#   facet_grid(parameter ~ coef, scales = "free")
#   facet_gird("coef", ncol = 1, strip.position = "left", 
#              labeller = label_parsed, scales = "free") + 
#   theme(strip.placement = "outside", 
#         strip.background = element_rect(fill = NA),
#         axis.text.y = element_text(size = rel(1.2))) 
```


### Predicting the future

> As a consequence, individual differences in word recognition at age 3, for
example, will be more discriminating and predictive of age 5 language outcomes
than differences at age 4.


```{r bunch-of-plots, out.width = "80%", fig.height=4, fig.width=5}
fits <- readr::read_csv("./data/fits.csv.gz")
fits <- fits %>% semi_join(d_m)

point_ests <- fits %>% 
  group_by(Study, ResearchID, coef) %>% 
  summarise(point = median(.posterior_value)) %>% 
  ungroup() %>% 
  tidyr::spread(coef, point)

scores <- readr::read_csv("./data-raw/test_scores.csv") %>% 
  select(Study, ResearchID, Age, EVT_GSV, EVT_Standard, 
         PPVT_GSV, PPVT_Standard)

with_ests <- scores %>% 
  inner_join(point_ests)

ggplot(with_ests) + 
  aes(x = intercept, y = EVT_GSV, color = Study) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(with_ests) + 
  aes(x = ot1, y = EVT_GSV, color = Study) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(with_ests) + 
  aes(x = Age, y = intercept, color = Study) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(with_ests) + 
  aes(x = Age, y = ot1, color = Study) + 
  geom_point() + 
  stat_smooth(method = "lm")

widely <- with_ests %>% 
  tidyr::gather("Test", "Value", -ResearchID, -Study) %>% 
  tidyr::unite("Col", Study, Test) %>% 
  tidyr::spread(Col, Value)


ggplot(widely) + 
  aes(x = TimePoint1_intercept, y = TimePoint3_EVT_GSV) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(widely) + 
  aes(x = TimePoint2_intercept, y = TimePoint3_EVT_GSV) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(widely) + 
  aes(x = TimePoint1_ot1, y = TimePoint3_EVT_GSV) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(widely) + 
  aes(x = TimePoint2_ot1, y = TimePoint3_EVT_GSV) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(widely) + 
  aes(x = TimePoint3_ot1, y = TimePoint3_EVT_GSV) + 
  geom_point() + 
  stat_smooth(method = "lm")

```

```{r bunch-of-plots2, out.width = "80%", fig.height=4, fig.width=6}
cor_complete <- function(...) cor(..., use = "pairwise.complete")

test <- fits %>% 
  left_join(widely) %>% 
  group_by(Study, coef, .draw) %>% 
  summarise(
    r_TimePoint3_EVT_Standard = cor_complete(.posterior_value, 
                                             TimePoint3_EVT_Standard),
    r_TimePoint3_EVT_GSV = cor_complete(.posterior_value, 
                                        TimePoint3_EVT_GSV),
    r_TimePoint2_PPVT_GSV = cor_complete(.posterior_value, 
                                         TimePoint2_PPVT_GSV),
    r_TimePoint2_PPVT_Standard = cor_complete(.posterior_value, 
                                              TimePoint2_PPVT_Standard))

c_intervals <- test %>% 
  do(bayesplot::mcmc_intervals_data(
    select(., r_TimePoint3_EVT_Standard:r_TimePoint2_PPVT_Standard))) %>% 
  ungroup()

c_intervals %>% 
  filter(parameter == "r_TimePoint3_EVT_Standard") %>% 
  filter(coef %in% c("intercept", "ot1")) %>% 
  ggplot() + 
    aes(y = forcats::fct_rev(Study)) +
    geom_vline(xintercept = 0, size = 2, color = "white") +
    ggstance::geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
    ggstance::geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
    geom_point(aes(x = m), size = 3, shape = 3) + 
    facet_wrap("coef") +
    labs(x = NULL, y = NULL, caption = "90% and 50% intervals") + 
    ggtitle("Correlation of curve features and TP3 EVT Standard")

c_intervals %>% 
  filter(parameter == "r_TimePoint2_PPVT_Standard") %>% 
  filter(coef %in% c("intercept", "ot1")) %>% 
  filter(Study != "TimePoint3") %>% 
  ggplot() + 
    aes(y = forcats::fct_rev(Study)) +
    geom_vline(xintercept = 0, size = 2, color = "white") +
    ggstance::geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
    ggstance::geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
    geom_point(aes(x = m), size = 3, shape = 3) + 
    facet_wrap("coef") +
    labs(x = NULL, y = NULL, caption = "90% and 50% intervals") + 
    ggtitle("Correlation of curve features and TP2 PPVT Standard")

# test %>% 
#   filter(coef == "intercept") %>%
#   ggplot() + 
#   aes(x = c1) + 
#   geom_histogram() + 
#   facet_grid(Study ~ coef)
# 
# test %>% 
#   filter(coef == "ot1") %>%
#   ggplot() + 
#   aes(x = c1) + 
#   geom_histogram() + 
#   facet_grid(Study ~ coef)
# 
# test %>% 
#   filter(coef == "ot2") %>%
#   ggplot() + 
#   aes(x = c1) + 
#   geom_histogram() + 
#   facet_grid(Study ~ coef)

widely %>% tidy_correlation(ends_with("EVT_GSV"))

widely %>% 
  tidy_correlation(TimePoint3_EVT_GSV, ends_with("intercept"), ends_with("ot1")) %>% 
  filter(column1 == "TimePoint3_EVT_GSV")

widely %>% 
  tidy_correlation(TimePoint2_PPVT_GSV, TimePoint1_ot1, TimePoint2_ot1) %>% 
  filter(column1 == "TimePoint2_PPVT_GSV")

widely %>% 
  tidy_correlation(TimePoint2_PPVT_GSV, TimePoint1_ot1, TimePoint2_ot1,
            TimePoint1_intercept, TimePoint2_intercept) %>% 
  filter(column1 == "TimePoint2_PPVT_GSV")
```







### Relationship with child-level variables

> Vocabulary size and lexical processing will be tightly correlated such that
large year-over-year gains in one measure will predict large year-over-years
gains in the other measure.

```{r, eval = FALSE, include = FALSE}
scores <- readr::read_csv("./data-raw/test_scores.csv") %>% 
  select(Study, ResearchID, Age, EVT_GSV, EVT_Standard, 
         PPVT_GSV, PPVT_Standard)

changes <- scores %>% 
  tidyr::gather("Score", "Value", -Study, -ResearchID) %>% 
  tidyr::spread(Study, Value) %>% 
  mutate(TP3_Change = TimePoint3 - TimePoint2, 
         TP2_Change = TimePoint2 - TimePoint1) %>% 
  select(-TimePoint1, -TimePoint2, -TimePoint3) %>% 
  tidyr::gather("Change", "Value", TP3_Change, TP2_Change) %>% 
  tidyr::unite(Col, Change, Score) %>% 
  tidyr::spread(Col, Value)

ggplot(changes) + 
  aes(x = TP2_Change_PPVT_Standard) + 
  geom_histogram()

bot_20_ppvt_changes <- changes %>% top_n(20, TP2_Change_PPVT_Standard)
bot_20_ppvt_changes <- changes %>% top_n(20, -TP2_Change_PPVT_Standard)


d_avg <- binned %>% 
  filter(250 <= Time, Time <= 1500) %>% 
  aggregate_looks(resp_def, Study + ResearchID ~ GazeByImageAOI)

with_prop_changes <- d_avg %>% 
  select(Study, ResearchID, Prop) %>% 
  tidyr::spread(Study, Prop) %>% 
  mutate(TP2_Change_Prop = TimePoint2 - TimePoint1, 
         TP3_Change_Prop = TimePoint3 - TimePoint2) %>% 
  select(ResearchID, TP2_Change_Prop, TP3_Change_Prop) %>% 
  inner_join(changes, by = "ResearchID")


long_changes <- with_prop_changes %>% 
  tidyr::gather("Var", "Value", -ResearchID) %>% 
  mutate(when = ifelse(str_detect(Var, "TP2_Change"), "TP2", "TP3"),
         Var = str_replace(Var, "TP._Change_", "")) %>% 
  tidyr::spread(Var, Value) %>% 
  tidyr::gather("Var", "Change", -ResearchID, -when, -Prop)

ggplot(long_changes %>% filter(when == "TP2")) + 
  aes(x = Change, y = Prop) + 
  geom_point() + 
  facet_wrap("Var", scales = "free_x") +
  stat_smooth(method = "lm")
ggplot(long_changes %>% filter(when == "TP3")) + 
  aes(x = Change, y = Prop) + 
  geom_point() + 
  facet_wrap("Var", scales = "free_x") +
  stat_smooth(method = "lm")

cor(with_prop_changes$TP2_Change_PPVT_Standard,
    with_prop_changes$TP2_Change_Prop,
    use = "pairwise.complete.obs")

cor(with_prop_changes$TP3_Change_Age,
    with_prop_changes$TP3_Change_Prop,
    use = "pairwise.complete.obs")

cor(with_prop_changes$TP2_Change_Age,
    with_prop_changes$TP2_Change_Prop,
    use = "pairwise.complete.obs")

cor(with_prop_changes$TP2_Change_EVT_Standard,
    with_prop_changes$TP2_Change_Prop,
    use = "pairwise.complete.obs")

cor(with_prop_changes$TP3_Change_EVT_Standard,
    with_prop_changes$TP3_Change_Prop,
    use = "pairwise.complete.obs")
```



