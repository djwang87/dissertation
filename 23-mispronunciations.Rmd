Sensitivity to mispronunciations
=======================================================================

```{r, include = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r helpers, message = FALSE, warning = FALSE}
```

```{r, include = FALSE}
# knitr::opts_chunk$set(cache = TRUE)
```

```{r}
d_raw <- readr::read_csv("./data/aim2-model-ready.csv.gz") %>% 
  select(-starts_with("ot"))

d <- d_raw %>% 
  select(-starts_with("ot")) %>% 
  filter(Condition == "MP", !is.na(Bias_Fam), 300 <= Time) %>% 
  mutate(Trials = Target + Distractor) %>% 
  polypoly::poly_add_columns(
    Time, degree = 3, scale_width = 1, prefix = "ot")

study_child_with_empty_cells <- d %>% 
  filter(Trials < 4) %>% 
  distinct(Study, ResearchID, Bias_Fam)

d <- d %>% 
  anti_join(study_child_with_empty_cells)

d_u <- d %>% filter(Bias_Fam == "Unfamiliar")
d_f <- d %>% filter(Bias_Fam == "Familiar")

library(brms)

# Fit a hierarchical logistic regression model
formula <- bf(
  Target | trials(Trials) ~ 
    (1 + ot1 + ot2 + ot3) * Study + 
    (1 + ot1 + ot2 + ot3 | ResearchID/Study), 
  family = binomial)

priors <- c(
  set_prior(class = "Intercept", "normal(0, 1)"),
  set_prior(class = "b", "normal(0, 1)"),
  set_prior(class = "b", coef = "ot1", "normal(0, 2)"),
  set_prior(class = "cor", "lkj(2)"),
  set_prior(class = "sd", "student_t(7, 0, 2)"))

mp_unfam <- brm(
  formula = formula,
  data = d_u,
  prior = priors,
  chains = 4,
  cores = 4,
  # Run extra iterations to get a higher effective sample size
  iter = 3000,
  control = list(
    adapt_delta = .995, 
    max_treedepth = 15))

# Save the output
readr::write_rds(mp_unfam, "./data/aim2-mp-unfam.rds.gz")

mp_fam <- brm(
  formula = formula,
  data = d_f,
  prior = priors,
  chains = 4,
  cores = 4,
  control = list(
    adapt_delta = .99, 
    max_treedepth = 15))

# Save the output
readr::write_rds(mp_fam, "./data/aim2-mp-fam.rds.gz")
```

