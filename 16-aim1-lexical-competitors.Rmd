Effects of phonological and semantic competitors {#lex-competitors}
=======================================================================

```{r include = FALSE, warning = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
```

```{r helpers, include = FALSE}
```

```{r aim1-gam-load-looks, message = FALSE}
data <- readr::read_csv("./data/aim1-screened.csv.gz")

constants$cap_model_mean_data_mean_se <-
  "Lines: Model fits. Points: Obs. means ± SE"

# How to aggregate looks to the images
resp_def <- create_response_def(
  primary = "Target",
  others = c("PhonologicalFoil", "SemanticFoil", "Unrelated"),
  elsewhere = "tracked",
  missing = NA
)

# Create alternative aggregation rules for the two foils
semy_defs <- cycle_response_def(resp_def) %>%
  purrr::keep(~ .x$primary %in% c("Target", "SemanticFoil"))

phon_defs <- cycle_response_def(resp_def) %>%
  purrr::keep(~ .x$primary %in% c("Target", "PhonologicalFoil"))
```

```{r separate-strong-vs-weak-foils, message = FALSE, echo = FALSE}
# In @RWLPaper, we ignored trials for certain items where we didn't think the
# phonological or semantic similarity was strong enough.

trial_info <- bind_rows(
  readr::read_csv("data-raw/rwl_timepoint1_trials.csv.gz"),
  readr::read_csv("data-raw/rwl_timepoint2_trials.csv.gz"),
  readr::read_csv("data-raw/rwl_timepoint3_trials.csv.gz")) %>%
  select(
    Study,
    TrialID,
    Target = WordTarget,
    PhonologicalFoil = WordPhonologicalFoil,
    SemanticFoil = WordSemanticFoil,
    Unrelated = WordUnrelated)

## There was a block at year one where the wrong unrelated was used.
## See the items with 15 trials each. We will exclude them.
trials_to_drop <- trial_info %>%
  count(Study, Target, PhonologicalFoil, SemanticFoil, Unrelated) %>%
  filter(n <= 15)

words <- trial_info %>%
  distinct(Target, PhonologicalFoil, SemanticFoil, Unrelated) %>%
  anti_join(
    trials_to_drop,
     by = c("Target", "PhonologicalFoil", "SemanticFoil", "Unrelated"))

# aim1_stim$good_phon is a constant defined in helpers.R
phono_foils <- split(words, words$Target %in% aim1_stim$good_phon) %>%
  lapply(arrange, Target) %>%
  setNames(c("weak_foil", "strong_foil"))

# aim1_stim$good_semy is a constant defined in helpers.R
semy_foils <- split(words, words$Target %in% aim1_stim$good_semy) %>%
  lapply(arrange, Target) %>%
  setNames(c("weak_foil", "strong_foil"))

strong_phon_looks <- trial_info %>%
  semi_join(phono_foils$strong_foil) %>%
  inner_join(data) %>%
  mutate(PhonFoil = "Strong")

strong_semy_looks <- trial_info %>%
  semi_join(semy_foils$strong_foil) %>%
  inner_join(data) %>%
  mutate(SemyFoil = "Strong")

n_phon <- phono_foils$strong_foil$Target %>%
  unique() %>%
  length()

n_semy <- semy_foils$strong_foil$Target %>%
  unique() %>%
  length()
```

```{r gam-modeling-options, echo = FALSE, results = "hide"}
opts_model <- list(
  bin_width = 3,
  phon_start_time = 0,
  phon_end_time = 1500,
  semy_start_time = 250,
  semy_end_time = 1800)

opts_model$bin_length <- round(opts_model$bin_width * 16.67, -1)
opts_model$semy_longer <- opts_model$semy_end_time - opts_model$phon_end_time
```




Looks to the phonological competitor
------------------------------------------------------------------------

```{r create-phon-data, include = FALSE}
data <- strong_phon_looks %>%
  select(Study, ResearchID, TrialID:GazeByImageAOI) %>%
  assign_bins(bin_width = opts_model$bin_width, Time, TrialID)

# Compute time at center of each bin
bin_times <- data %>%
  distinct(Time, .bin) %>%
  group_by(.bin) %>%
  mutate(BinTime = round(median(Time), -1)) %>%
  ungroup()

# Attach bin times
binned <- data %>%
  left_join(bin_times, by = c("Time", ".bin")) %>%
  ungroup() %>%
  select(-Time) %>%
  rename(Time = BinTime)

d <- binned %>%
  aggregate_looks(phon_defs, Study + ResearchID + Time ~ GazeByImageAOI)

phon_d <- d %>%
  filter(
    opts_model$phon_start_time <= Time,
    Time <= opts_model$phon_end_time) %>%
  rename(Focus = .response_def)

phon_d <- phon_d %>%
  mutate(
    S = factor(Study, c("TimePoint2", "TimePoint1", "TimePoint3")),
    R = as.factor(ResearchID),
    SR = interaction(S, R),
    elog = lookr::empirical_logit(PhonologicalFoil, Unrelated))

# Include intercepts and smooths for studies
phon_d$S2 <- as.ordered(phon_d$S)
contrasts(phon_d$S2) <- "contr.treatment"
contrasts(phon_d$S2)
```

```{r create-semy-data, include = FALSE}
semy_data <- strong_semy_looks %>%
  select(Study, ResearchID, TrialID:GazeByImageAOI) %>%
  assign_bins(bin_width = opts_model$bin_width, Time, TrialID)

# Compute time at center of each bin
bin_times <- semy_data %>%
  distinct(Time, .bin) %>%
  group_by(.bin) %>%
  mutate(BinTime = round(median(Time), -1)) %>%
  ungroup()

# Attach bin times
binned <- semy_data %>%
  left_join(bin_times, by = c("Time", ".bin")) %>%
  ungroup() %>%
  select(-Time) %>%
  rename(Time = BinTime)

semy_d <- binned %>%
  aggregate_looks(semy_defs, Study + ResearchID + Time ~ GazeByImageAOI)

semy_d <- semy_d %>%
  filter(
    opts_model$semy_start_time <= Time,
    Time <= opts_model$semy_end_time) %>%
  rename(Focus = .response_def)

semy_d <- semy_d %>%
  mutate(
    S = factor(Study, c("TimePoint2", "TimePoint1", "TimePoint3")),
    R = as.factor(ResearchID),
    SR = interaction(S, R),
    elog = lookr::empirical_logit(SemanticFoil, Unrelated))

# Include intercepts and smooths for studies
semy_d$S2 <- as.ordered(semy_d$S)
contrasts(semy_d$S2) <- "contr.treatment"
contrasts(semy_d$S2)
```

The next question I asked was how children's sensitivity to the
phonological competitors changed over developmental time. Following our
approach in @RWLPaper, I only examined trials for which the phonological
foil and the noun shared the same syllable onset. For example, this
criterion included trials with *dress*–*drum*, *fly*–*flag*, or
*horse*–*heart*, but it excluded trials *kite*–*gift* (phonetic
feature difference), *bear*–*bread* (onset difference), and
*ring*–*swing* (rimes). I kept `r n_phon` of the 24 trials.
[Appendix \@ref(vw-experiment-items)](#vw-experiment-items) provides a
complete list of trials used.

The outcome measure for these analyses was the log-odds of fixating on
the phonological competitor versus the unrelated word. Because children
looked more to the target word with each year of the study, they
necessarily looked less to the three distractors each year. 
Figure \@ref(fig:declining-phon-props) illustrates how the proportions
of looks to the phonological foils declined each year. Therefore, I
examined the effect of the phonological foil in comparison to the
unrelated foil. For example, on the trials where the target is *fly*, we
can study the effect of the phonological foil *flag* by looking at when
and to what degree the children fixate on *flag* more than the
unrelated image *pen*. If a window of time of shows a consistent
advantage for the phonological foil over the unrelated image, we
conclude that the children were sensitive to the phonological foil
during that window. By studying the time course of fixations to the
phonological competitor versus the unrelated word, we can identify when the
phonological competitor affected word recognition most significantly.



(ref:declining-phon-props) Because children looked more to the target as they grew older, they numerically looked less the foils too. This effect is why I evaluated the phonological and semantic foils by comparing them against the unrelated image.

(ref:declining-phon-props-scap) Because children looked more to the target as they grew older, they numerically looked less the foils too.

```{r declining-phon-props, fig.cap = "(ref:declining-phon-props)", fig.scap = "(ref:declining-phon-props-scap)", echo = FALSE, message = FALSE, out.width = out_tex80_else50, fig.width = 5, fig.height = 3.5}
data_labs <- tibble::tribble(
  ~Focus, ~Time, ~Prop, ~Study,
  "Target", 1400, .8, "Age 5",
  "Target", 1400, .7, "Age 4",
  "Target", 1400, .575, "Age 3",
  "PhonologicalFoil", 1180, .04, "Age 5",
  "PhonologicalFoil", 1400, .18, "Age 3") %>% 
  mutate(
    Focus = factor(
      Focus, c("Target", "PhonologicalFoil"),
      c("Target", "Phonological foil"))) 

# test_theme <- theme_grey(base_size = 14) %+replace%
#     theme(
#       axis.title = element_text(hjust = 1), 
#       strip.text = element_text(hjust = 0), 
#       strip.text.x = element_text(margin = margin(14/2, 14/2, 14/2, 14/2)),
#       strip.text.y = element_text(margin = margin(14/2, 14/2, 14/2, 14/2)))

phon_d %>%
  mutate(
    Focus = factor(
      Focus, c("Target", "PhonologicalFoil"),
      c("Target", "Phonological foil")),
    Study = convert_study_to_age(Study)) %>%
  ggplot() +
    aes(x = Time, y = Prop, color = Study) +
    geom_hline(yintercept = .25, color = "white", size = 2) +
    stat_summary(fun.y = "mean", geom = "line", size = 1) +
    geom_text(
      aes(label = Study), 
      data = data_labs, 
      size = 4, 
      family = "Lato Semibold") +
    facet_wrap("Focus") +
    scale_color_study() +
    labs(
      x = "Time after target onset [ms]",
      y = "Mean proportion looking to image") +
    guides(color = FALSE)
```

As in the models from the previous chapter, I downsampled the data into
`r opts_model$bin_length`-ms (`r opts_model$bin_width`-frame) bins in
order to smooth the data. For these trials, I modeled the looks
from `r opts_model$phon_start_time` to `r opts_model$phon_end_time` ms,
and I aggregated looks by child, year and time bin.
To account for the sparseness of the data, I used the empirical log-odds
(or empirical logit) transformation [@Barr2008]. This transformation
adds .5 to the looking counts. For example, a time-frame with 4 looks to
the phonological foil and 1 look to the unrelated image has a
conventional log-odds of log(4/1) = 1.39 and empirical log-odds of
log(4.5/1.5) = 1.10. This transformation fills in bins with 0 looks with
.5/.5 (avoiding 0/0 problems), and it dampens the extremeness of
some probabilities that arise in sparse count data.

```{r load-phon-model, echo = FALSE, message = FALSE, include = FALSE, out.width = out_tex100_else80, fig.width = 6}
library(mgcv)
library(itsadug)

phon_by_year <- "./data/aim1-phon-random-smooths.rds.gz"

if (file.exists(phon_by_year)) {
  b2r <- readr::read_rds(phon_by_year)
} else {
  b2r <- bam(
    elog ~ S2 +
      s(Time) + s(Time, by = S2) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = phon_d)
  readr::write_rds(b2r, phon_by_year)
}
```

To model these data, I fit a generalized additive model with fast
restricted maximum likelihood estimation [@Wood2017; @Winter2016;
see @Soskuthy2017 for a tutorial for linguists]. Box 2 provides a brief
overview of these models. I used the mgcv R package
[vers. `r packageVersion("mgcv")`; @Wood2017] with support from the
tools in the itsadug R package [vers. `r packageVersion("itsadug")`;
@itsadug].[^gca-fail] [Appendix \@ref(aim1-gca-models)](#aim1-gca-models)
contains the R code used to fit these models along with a description of 
the specifications represented by the model syntax.

[^gca-fail]: Initially, I tried to use Bayesian polynomial growth
  curve models, as in the earlier analysis of the looks to the target
  image. These models however did not converge, even when strong priors
  were placed on the parameters. In principle, I could have used Bayesian
  generalized additive models, but the software ecosystem and available
  tools for model criticism and inference are currently rather limited.





\Begin{infobox}
<div class = "infobox">

**Box 2: Intuition behind generalized additive models**.

In these analyses, the outcome of interest is a value that changes over
time in a nonlinear way. We model these time series by building a set of
features to represent time values. In the growth curve analyses of
familiar word recognition, I used a set of polynomial features which
expressed time as the weighted sum of a linear trend, a quadratic trend
and cubic trend. That is:

$$
\text{log odds}(\text{looking}) = 
  \alpha + 
  \beta_1\text{Time}^1 + 
  \beta_2\text{Time}^2 + 
  \beta_3\text{Time}^3
$$

But another way to think about the polynomial terms is as *basis
functions*: A set of features that combine to approximate some nonlinear
function of time. Under this framework, the model can be expressed as:

$$
\text{log odds}(\text{looking}) = 
  \alpha + f(\text{Time})
$$

This is the idea behind generalized additive models and their *smooth
terms*. These smooths fit nonlinear functions of data by weighting and
adding simple functions together. The figures below show 9 basis
functions from a "thin-plate spline" and how they can be weighted and
summed to fit a growth curve.

```{r infobox-1-figs, message = FALSE, echo = FALSE, out.width = out_tex80_else66, fig.width = 6, fig.height = 3, fig.align = "center"}
t1_fam <- structure(
  list(
    Time = c(
      250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900,
      950, 1000, 1050, 1100, 1150, 1200, 1250, 1300, 1350, 1400, 1450, 1500),
    Prop = c(
      0.252, 0.255, 0.257, 0.261, 0.265, 0.275, 0.286, 0.298, 0.311, 0.315,
      0.329, 0.342, 0.365, 0.392, 0.407, 0.422, 0.446, 0.464, 0.479, 0.497,
      0.514, 0.524, 0.532, 0.545, 0.549, 0.555)),
  .Names = c("Time", "Prop"),
  class = c("tbl_df", "tbl", "data.frame"),
  row.names = c(NA, -26L))

times <- modelr::seq_range(t1_fam$Time, 80)
newdata <- data.frame(Time = times)
t1_gam <- gam(Prop ~ s(Time), data = t1_fam)

t1_gam <- gam(Prop ~ s(Time, bs = "tp", k = 10), data = t1_fam)
basis_matrix <- predict(t1_gam, newdata, type = "lpmatrix")[, 2:10]

basis <- polypoly::poly_melt(basis_matrix) %>%
  mutate(observation = as.numeric(observation)) %>%
  left_join(
    data.frame(Time = times, observation = seq_along(times)),
    by = "observation")

p1 <- ggplot(basis) +
  aes(x = Time, y = value) +
  geom_line(aes(color = degree)) +
  ylim(c(-2, 2)) +
  guides(color = FALSE) +
  ggtitle("Basis functions (time features)") +
  labs(
    x = constants$x_time,
    y = NULL) +
  theme_teej(base_size = 9) +
  theme(
    plot.background = element_rect(
      fill = constants$col_infobox_blue,
      colour = constants$col_infobox_blue),
    panel.background = element_rect(fill = constants$col_infobox_plot_bg))

weighted <- (basis_matrix %*% diag(coef(t1_gam)[-1])) %>%
  polypoly::poly_melt() %>%
  mutate(observation = as.numeric(observation)) %>%
  left_join(
    data.frame(Time = times, observation = seq_along(times)),
    by = "observation")

p2 <- ggplot(weighted) +
  aes(x = Time, y = value) +
  geom_line(aes(color = factor(degree))) +
  stat_summary(
    fun.y = sum,
    color = constants$col_blue_highlight,
    geom = "line",
    size = 1.25) +
  annotate("text",
    label = "sum", 
    x = 1350, 
    y = .175, 
    color = constants$col_blue_highlight,
    size = 4,
    family = "Lato Semibold") +
  ylim(c(-.2, .2)) +
  guides(color = FALSE) +
  ggtitle("Weighted basis functions") +
  labs(
    x = constants$x_time,
    y = NULL) +
  theme_teej(base_size = 9)  +
  theme(
    plot.background = element_rect(
      fill = constants$col_infobox_blue,
      colour = constants$col_infobox_blue),
    panel.background = element_rect(fill = constants$col_infobox_plot_bg))


## Analagous plot for GCA polynomials

# t1_poly <- lm(Prop ~ poly(Time, 3), data = t1_fam)
#
# poly_basis <- polypoly::poly_melt(poly(t1_fam$Time, 3)) %>%
#   mutate(observation = as.numeric(observation)) %>%
#   left_join(
#     data.frame(Time = times, observation = seq_along(times)),
#     by = "observation")

# p1_poly <- ggplot(poly_basis) +
#   aes(x = Time, y = value) +
#   geom_line(aes(color = degree)) +
#   # ylim(c(-2, 2)) +
#   guides(color = FALSE) +
#   ggtitle("Basis functions (time features)") +
#   labs(
#     x = constants$x_time,
#     y = NULL) +
#   theme_grey(base_size = 9)

# poly_weighted <- (poly(t1_fam$Time, 3) %*% diag(coef(t1_poly)[-1])) %>%
#   polypoly::poly_melt() %>%
#   mutate(observation = as.numeric(observation)) %>%
#   left_join(
#     data.frame(Time = times, observation = seq_along(times)),
#     by = "observation")

# p2_poly <- ggplot(poly_weighted) +
#   aes(x = Time, y = value) +
#   geom_line(aes(color = factor(degree))) +
#   stat_summary(
#     fun.y = sum,
#     color = constants$col_blue_highlight,
#     geom = "line",
#     size = 1.25) +
#   ylim(c(-.2, .2)) +
#   guides(color = FALSE) +
#   ggtitle("Weighted basis functions") +
#   labs(
#     x = constants$x_time,
#     y = NULL) +
#   theme_grey(base_size = 9)
#
# p3_poly <- cowplot::plot_grid(p1_poly, p2_poly)

p3 <- cowplot::plot_grid(p1, p2)
print(p3)
# ggsave("./misc/basis-raw.png", p1,  width = 3, height = 3)
# ggsave("./misc/basis-weighted.png", p2, width = 3, height = 3)
# cowplot::ggsave("./misc/basis-both.png", p3, width = 6, height = 3)
# cowplot::ggsave("./misc/basis-both.png", p3, width = 6, height = 3)
```

Each of these basis functions is weighted by a model coefficient, but
the individual basis functions are not a priori meaningful. Rather, it
is the whole set of functions that approximate the curvature of the
data---i.e., *f*(Time)---so we statistically evaluate the whole batch
of coefficients simultaneously. This joint testing is similar to how one
might test a batch of effects in an ANOVA. If the batch of effects
jointly improve model fit, we infer that there is a significant smooth
or shape effect at play.

Smooth terms come with an estimated degrees of freedom (EDF). These
values provide a sense of how many degrees of freedom the smooth
consumed. An EDF of 1 is a perfectly straight line, indicating no
smoothing. Higher EDF values indicate that the smooth term captured more
curvature from the data.

<!-- The other important thing to know about generalized additive models is that -->
<!-- wigglyness is penalized. With so many functions, one might worry about -->
<!-- overfitting the data and including incidental wiggliness into *f*(Time). These -->
<!-- models, however, include a smoothing parameter that -->
</div>
\End{infobox}




The model included main effects of study year. These *parametric* terms
work like conventional regression effects and determined the growth
curve's average values. The model used age 4 as the reference year, so
the intercept represented the average looking probability at
age 4. The year effects represented differences
between age 4 vs. age 3 and age 4 vs. age 5.

The model also included *smooth* terms to represent the time course of
the data. As with the parametric effects, age 4 served as the reference
year. The model estimated a smooth for age 4 and it estimated
*difference smooths* to capture how the curvature at age 3 and age 5
differed from the age-4 curvature. Each of these year-level smooths
used 10 knots (9 basis functions). I also included child-level *random
smooths* to represent child-level variation in growth curve shapes.
Because there is much less data at the child level than at the year
level, these random smooths only included 5 knots (4 basis functions).
We can think of these simpler splines as coarse adjustments in growth
curve shape to capture child-level variation from limited data.
Altogether, the model contained the following terms:

`r insert_html_math()`
\small
\begin{align*}
   \text{emp. log odds}(\text{phon. vs. unrelated}) =\
   & \alpha + \beta_1\text{Age3} + \beta_2\text{Age5} +\ &\text{[growth curve averages]} \\
   & f_1(\text{Time}, \text{Age4})\ +                    &\text{[reference smooth]} \\
   & f_2(\text{Time}, \text{Age4} - \text{Age3})\ +      &\text{[difference smooths]} \\
   & f_3(\text{Time}, \text{Age4} - \text{Age5})\ +      & \\
   & f_i(\text{Time}, \text{Child}_i)                    &\text{[by-child random smooths]} \\
\end{align*}
\normalsize
`r insert_html_math()`

```{r stats-from-phon-gamms}
b2r_summary <- summary.gam(b2r)

tp2_est <- get_para_estimate(b2r_summary, "(Intercept)")
tp3_est <- get_para_estimate(b2r_summary, "S2TimePoint3")

tp2 <- tp2_est %>%
  printy::fmt_fix_digits(2)

tp3 <- (tp2_est + tp3_est) %>%
  printy::fmt_fix_digits(2)

tp2_prop <- tp2_est %>%
  plogis() %>%
  printy::fmt_fix_digits(2) %>%
  printy::fmt_leading_zero()

tp3_prop <- (tp2_est + tp3_est) %>%
  plogis() %>%
  printy::fmt_fix_digits(2) %>%
  printy::fmt_leading_zero()

tp1_p <- get_para_pvalue(b2r_summary, "S2TimePoint1", digits = 2)
tp3_p <- get_para_pvalue(b2r_summary, "S2TimePoint3")

# # itsadug::report_stats(b2r, b2r_summary)
# smooths <- b2r_summary$s.table %>%
#   as.data.frame() %>%
#   setNames(c("edf", "Ref.df", "F", "p.value")) %>%
#   tibble::rownames_to_column("term")

s_tp2_edf <- get_smooth_edf(b2r_summary, term = "s(Time)")
s_tp1_edf <- get_smooth_edf(b2r_summary, term = "s(Time):S2TimePoint1")
s_tp3_edf <- get_smooth_edf(b2r_summary, term = "s(Time):S2TimePoint3")

s_tp2_p <- get_smooth_pvalue(b2r_summary, "s(Time)")
s_tp1_p <- get_smooth_pvalue(b2r_summary, "s(Time):S2TimePoint1")
s_tp3_p <- get_smooth_pvalue(b2r_summary, "s(Time):S2TimePoint3")
```

```{r phon-peaks, include = FALSE}
avg <- b2r %>%
  get_predictions(
    cond = list(
      Time = unique(phon_d$Time),
      S2 = unique(phon_d$S2)),
    rm.ranef = TRUE,
    print.summary = FALSE) %>%
  left_join(recode_studies, by = c("S2"))

# what and when is the peak value
peaks <- avg %>% 
  group_by(Age) %>% 
  filter(fit == max(fit)) %>% 
  ungroup() %>% 
  mutate(
    prop = plogis(fit) %>% 
      printy::fmt_fix_digits(2) %>% 
      printy::fmt_leading_zero()) %>% 
  split(.$S)
```


The model’s fitted values are shown in
Figure \@ref(fig:phon-vs-unre-fits). These are the average empirical
log-odds of fixating on the phonological foil versus the unrelated image
for each year of the study. The model captured the trend for increased
looks to the competitor image with each year of the study. At age 4 and
age 5, the shape rises from a baseline to the peak around 800 ms. These
curves slope downwards and eventually fall beneath the initial baseline.
The shape at age 3 does not have a steady rise from baseline and shows a
small peak around 800 ms. The peak proportions of looks to the
phonological competitor versus the unrelated word were
`r peaks$TimePoint1$prop` at `r peaks$TimePoint1$Time` ms for age 3,
`r peaks$TimePoint2$prop` at `r peaks$TimePoint2$Time` ms for age 4, and
`r peaks$TimePoint3$prop` at `r peaks$TimePoint3$Time` ms for age 5.

(ref:phon-vs-unre-fits) With each year of the study, children looked more to the phonological competitor (relative to the unrelated image) during and after the target noun. Both figures show means for each year estimated by the generalized additive model. The left panel compares model estimates to observed means and standard errors, and the right panel visualizes estimated means and their 95% confidence intervals.

(ref:phon-vs-unre-fits-scap) With each year of the study, children looked more to the phonological competitor (relative to the unrelated image) during and after the target noun.

```{r phon-vs-unre-fits, fig.cap = "(ref:phon-vs-unre-fits)", fig.scap = "(ref:phon-vs-unre-fits-scap)", warning = FALSE, message = FALSE, out.width = out_tex100_else80, fig.width = 6, fig.height = 4, results = "hide"}
labs_fit_obs <- labs(
  color = constants$lab_study,
  fill = constants$lab_study,
  x = constants$x_time,
  caption = constants$cap_model_mean_data_mean_se)

# Data for direct labeling of lines
study_labs <- data.frame(
  Age = c("Age 3", "Age 4", "Age 5"),
  x = c(775, NA, 750),
  y = c(.07, NA, .80)
)

p1 <- phon_d %>%
  left_join(recode_studies, by = c("Study", "S", "S2")) %>%
  ggplot() +
    aes(x = Time, y = fitted_elogit, color = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    stat_summary(aes(y = elog), fun.data = mean_se, alpha = .7) +
    geom_line(aes(y = fit), data = avg, size = 1) +
    geom_text(
      aes(label = Age, x = x, y = y), 
      data = study_labs,
      size = 5,
      family = "Lato Semibold") +
    coord_cartesian(ylim = c(-.35, .85)) +
    labs_fit_obs +
    labs(y = constants$y_elog_phon) +
    guides(color = FALSE) +
    scale_color_study()


labs_model_ci <- labs(
  color = constants$lab_study,
  fill = constants$lab_study,
  x = constants$x_time,
  y = NULL,
  caption = constants$cap_mean_95)

p2 <- b2r %>%
  get_predictions(
    cond = list(
      Time = unique(phon_d$Time),
      S2 = unique(phon_d$S2)),
    rm.ranef = TRUE,
    print.summary = FALSE) %>%
  left_join(recode_studies) %>%
  ggplot() +
    aes(x = Time, y = fit, fill = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
    geom_line(aes(color = Age), size = 1) +
    geom_text(
      aes(label = Age, color = Age, x = x, y = y), 
      data = study_labs, 
      size = 5,
      family = "Lato Semibold") +
    coord_cartesian(ylim = c(-.35, .85)) +
    labs_model_ci +
    guides(color = FALSE, fill = FALSE) +
    scale_color_study() + 
    scale_fill_study() 

p3 <- cowplot::plot_grid(p1, p2)
print(p3)
```

```{r, eval = FALSE}
labs_fit_obs <- labs(
  color = constants$lab_study,
  fill = constants$lab_study,
  x = constants$x_time,
  caption = constants$cap_model_mean_data_mean_se)

# Data for direct labeling of lines
study_labs <- data.frame(
  Age = c("Age 3", "Age 4", "Age 5"),
  x = c(775, NA, 750),
  y = c(.15, NA, .78)
)

library(extrafont)
loadfonts()

p1 <- phon_d %>%
  left_join(recode_studies, by = c("Study", "S", "S2")) %>%
  ggplot() +
    aes(x = Time, y = fitted_elogit, color = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    stat_summary(aes(y = elog), fun.data = mean_se, alpha = .7) +
    geom_line(aes(y = fit), data = avg, size = 1) +
    geom_text(
      aes(label = Age, x = x, y = y), 
      data = study_labs, 
      size = 6, family = "Lato") +
    coord_cartesian(ylim = c(-.35, .85)) +
    labs_fit_obs +
    labs(y = "Log-odds (phonological vs. unrelated)") +
    guides(color = FALSE) + 
    theme_grey(
      base_size = 18, base_family = "Lato") + 
    theme(
      axis.title = element_text(hjust = 1))


labs_model_ci <- labs(
  color = constants$lab_study,
  fill = constants$lab_study,
  x = constants$x_time,
  y = NULL,
  caption = constants$cap_mean_95)

p2 <- b2r %>%
  get_predictions(
    cond = list(
      Time = unique(phon_d$Time),
      S2 = unique(phon_d$S2)),
    rm.ranef = TRUE,
    print.summary = FALSE) %>%
  left_join(recode_studies) %>%
  ggplot() +
    aes(x = Time, y = fit, fill = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
    geom_line(aes(color = Age), size = 1) +
    geom_text(
      aes(label = Age, color = Age, x = x, y = y), 
      data = study_labs, size = 6, family = "Lato") +
    coord_cartesian(ylim = c(-.35, .85)) +
    labs_model_ci +
    guides(color = FALSE, fill = FALSE) + 
  theme_grey(
      base_size = 18, base_family = "Lato") + 
    theme(
      axis.title = element_text(hjust = 1),
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank())

library(patchwork)
p1 + p2
    

tjmisc::ggpreview(height = 5, width = 7.5, dpi = 600)
```


The early peaks occur when one would expect if children are acting on
partial phonological information. The similarity between the
phonological competitor and the target noun occurs early on in the
trial. Suppose a child acts on the first 400 ms of the phonological
competitor. Assuming a 200--300 ms overhead to execute an eye movement
in response to speech, the child would reach the phonological foil
around 600--700 ms. This window is slightly before the observed peaks
at 750--800 ms, but the age 4 and age 5 curves both are on the rise away
from baseline during this window. 

The average looks to the phonological foil over the unrelated image for
age 4 was `r tp2` emp. log-odds, `r tp2_prop` proportion units. The
averages for age 3 and age 4 did not significantly differ, `r tp1_p`,
but the average value was significantly greater at age 5, `r tp3` emp.
log-odds, `r tp3_prop` proportion units, `r tp3_p`. Visually, this
effect shows up in the almost constant height difference between the
age-4 and the age-5 curves.

There was a significant smooth term for time at age 4, estimated degrees
of freedom (EDF) = `r s_tp2_edf`, `r s_tp2_p`.
Figure \@ref(fig:phon-diff-curves) visualizes how and when the smooths
from other ages differed from the age-4 smooth.

(ref:phon-diff-curves) Differences in the average looks to the phonological competitor versus the unrelated image between age 4 and the other ages. Plotted line is estimated difference and the shaded region is the 95% confidence interval around that difference. Boxes highlight regions where the 95% interval excludes zero. From age 3 to age 4, children become more sensitive to the phonological foil during and after the target noun. The linear difference curve for age 4 versus age 5 indicates that the two years largely have the same curvature, but they steadily diverge over the course of the trial.

(ref:phon-diff-curves-scap) Differences in average looks to the phonological competitor versus the unrelated image between age 4 and the other ages.


```{r phon-diff-curves, fig.cap = "(ref:phon-diff-curves)", fig.scap = "(ref:phon-diff-curves-scap)", message = FALSE, out.width = out_tex100_else80, fig.width = 5, fig.height = 3.5, results = "hide"}
age5_age4 <- b2r %>%
  get_difference(
    comp = list(S2 = c("TimePoint3", "TimePoint2")),
    cond = list(Time = unique(phon_d$Time)),
    rm.ranef = TRUE,
    print.summary = FALSE) %>%
  mutate(comparison = "Age 5 − Age 4")

age4_age3 <- b2r %>%
  get_difference(
    comp = list(S2 = c("TimePoint2", "TimePoint1")),
    cond = list(Time = unique(phon_d$Time)),
    rm.ranef = TRUE,
    print.summary = FALSE) %>%
  mutate(comparison = "Age 4 − Age 3")

rle_lengths <- function(xs) rle(xs)[["lengths"]]

differences <- bind_rows(age5_age4, age4_age3) %>%
  rename(fit = difference) %>%
  mutate(
    upper = fit + CI,
    lower = fit - CI,
    no_zero = 0 > upper | 0 < lower) %>%
  group_by(comparison) %>%
  arrange(comparison, Time) %>%
  mutate(
    streak = rep(seq_along(rle_lengths(no_zero)), rle_lengths(no_zero))) %>%
  ungroup()

sig_regions <- differences %>%
  filter(no_zero) %>%
  group_by(comparison, streak) %>%
  summarize(min = min(Time), max = max(Time)) %>%
  ungroup()

ggplot(differences) +
  aes(x = Time, y = fit) +
  geom_hline(size = 2, yintercept = 0, color = "white") +
  geom_vline(
    aes(xintercept = min), data = sig_regions,
    color = constants$col_blue_highlight, linetype = "dashed") +
  geom_vline(
    aes(xintercept = max), data = sig_regions,
    color = constants$col_blue_highlight, linetype = "dashed") +
  geom_segment(
      aes(x = min, xend = max, group = streak), y = -Inf, yend = -Inf,
      data = sig_regions, color = constants$col_blue_highlight,
      size = 1) +
  geom_segment(
      aes(x = min, xend = max, group = streak), y = Inf, yend = Inf,
      data = sig_regions, color = constants$col_blue_highlight,
      size = 1.1) +
  geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
  geom_line(size = 1) +
  labs(
    color = constants$lab_study,
    fill = constants$lab_study,
    x = constants$x_time,
    y = constants$y_elog_diff_phon,
    caption = constants$cap_diff_95,
    title = "Changes in phonological competitor effect") +
  facet_wrap("comparison")
```

The age-3 and age-4 curves significantly differed, EDF = `r s_tp1_edf`,
`r s_tp1_p`. In particular, the curves are significantly different
from 500 to 1050 ms. This result confirms that the looks to the
phonological foil increased from age 3 and age 4 during the time window
immediately following presentation of the noun and that children became
more sensitive to the phonological similarities between the competitor
and the target from age 3 to age 4.

The age-3 and age-4 curves also differed significantly after 1250 ms, so
that at age 4 children looked less to the competitor compared to age 3.
The effect reflects how the looks to phonological competitor decrease as
a trial progresses. After an incorrect look to the foil, the children on
average corrected their gaze and looked even less to the phonological
foil. We do not observe this degree of correction during age 3,
because children at age 3 looked less overall to the phonological
foil early on.

The age-4 and age-5 smooths also significantly differed, EDF =
`r s_tp3_edf`, `r s_tp3_p`, although the low EDF values indicates that
the shape of the difference was a flat line. Thus, the difference
between the age-4 and age-5 smooths is driven primarily by the intercept
difference and a linear diverging trend---that is, the distance between
the two grows slowly over time. The same general curvature was
observed for the two age smooths, suggesting the same general looking
behavior at both time points: Children showed an early increase in looks
to the phonological foil relative to the unrelated image but after
receiving disqualifying information from the rest of the word, the looks
to the phonological foil rapidly decrease. The primary difference
between age-4 and age-5 is that the competitor effect becomes more
pronounced at age 5.

**Summary**. Children looked more to the phonological competitor than the
unrelated image early on in the trials. The advantage of the phonological
competitor peaked on average around 800 ms after target onset, and the
early timing indicates that children were shifting their gaze in
response to the fleeting phonological similarity of the competitor to
the target noun. The peak was small at age 3 but increased in height
with each year of the study. Children became more sensitive to the
phonological cohort competitors as they grew older.




Looks to the semantic competitor
------------------------------------------------------------------------

I asked how children's sensitivity to the semantic competitor changed
as they grew older. As in @RWLPaper, I only examined trials for
which the semantic foil and the noun were part of the same category. For
example, I included trials with *bee*–*fly*, *shirt*–*dress*, and
*spoon*–*pan*, but I excluded trials where the similarity was perceptual
(*sword*–*pen*) or too abstract (*swan*–*bee*). This criterion kept
`r n_semy` of the 24 trials.
[Appendix \@ref(vw-experiment-items)](#vw-experiment-items) provides a
complete list of trials used.

For these trials, I used the same modeling technique as the one used for
phonological competitors: Generalized additive models with year effects
and a time smooth, time-by-year difference smooths, and time-by-child
random smooths. I modeled the looks
from `r opts_model$semy_start_time` to `r opts_model$semy_end_time` ms.
This window was `r opts_model$semy_longer` ms longer than the one used
for the phonological competitors in order to capture late-occurring
semantic effects.

```{r semy-models, message = FALSE, results = "hide"}
semy_by_year <- "./data/aim1-semy-random-smooths.rds.gz"

if (file.exists(semy_by_year)) {
  s2r <- readr::read_rds(semy_by_year)
} else {
  s2r <- bam(
    elog ~ S2 +
      s(Time) + s(Time, by = S2) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = semy_d)
  readr::write_rds(s2r, semy_by_year)
}
```

```{r stats-from-semy-gamms}
s2r_summary <- summary.gam(s2r)

sem_para <- s2r_summary$p.table %>%
  as.data.frame() %>%
  tibble::rownames_to_column("term") %>%
  rename(estimate = Estimate, p.value = `Pr(>|t|)`)

sem_tp2_est <- get_para_estimate(s2r_summary, "(Intercept)")
sem_tp1_est <- get_para_estimate(s2r_summary, "S2TimePoint1")
sem_tp3_est <- get_para_estimate(s2r_summary, "S2TimePoint3")

sem_tp2 <- sem_tp2_est %>%
  printy::fmt_fix_digits(2)

sem_tp2_prop <- sem_tp2_est %>%
  plogis() %>%
  printy::fmt_fix_digits(2) %>%
  printy::fmt_leading_zero()

sem_tp1_elog <- (sem_tp2_est + sem_tp1_est) %>%
  printy::fmt_fix_digits(2)

sem_tp1_prop <- (sem_tp2_est + sem_tp1_est) %>%
  plogis() %>%
  printy::fmt_fix_digits(2) %>%
  printy::fmt_leading_zero()

sem_tp3_elog <- (sem_tp2_est + sem_tp3_est) %>%
  printy::fmt_fix_digits(2)

sem_tp3_prop <- (sem_tp2_est + sem_tp3_est) %>%
  plogis() %>%
  printy::fmt_fix_digits(2) %>%
  printy::fmt_leading_zero()

sem_tp1_p <- get_para_pvalue(s2r_summary, "S2TimePoint1", digits = 3)
sem_tp3_p <- get_para_pvalue(s2r_summary, "S2TimePoint3", digits = 3)

sem_s_tp2_edf <- get_smooth_edf(s2r_summary, term = "s(Time)")
sem_s_tp1_edf <- get_smooth_edf(s2r_summary, term = "s(Time):S2TimePoint1")
sem_s_tp3_edf <- get_smooth_edf(s2r_summary, term = "s(Time):S2TimePoint3")

sem_s_tp2_p <- get_smooth_pvalue(s2r_summary, "s(Time)")
sem_s_tp1_p <- get_smooth_pvalue(s2r_summary, "s(Time):S2TimePoint1")
sem_s_tp3_p <- get_smooth_pvalue(s2r_summary, "s(Time):S2TimePoint3")
```

```{r semy-peaks, include = FALSE}
avg <- s2r %>%
  get_predictions(
    cond = list(
      Time = unique(semy_d$Time),
      S2 = unique(semy_d$S2)),
    rm.ranef = TRUE,
    print.summary = FALSE) %>%
  left_join(recode_studies, by = c("S2"))

# what and when is the peak value
peaks <- avg %>% 
  group_by(Age) %>% 
  filter(fit == max(fit)) %>% 
  ungroup() %>% 
  mutate(
    prop = plogis(fit) %>% 
      printy::fmt_fix_digits(2) %>% 
      printy::fmt_leading_zero()) %>% 
  split(.$S)
```


The model’s fitted values are shown in
Figure \@ref(fig:semy-vs-unre-fits). The average empirical log-odds of
fixating on the semantic competitor versus the unrelated word increased with
each year of the study. All three years show the same general time
course of effects: Looks begin to increase from a baseline around 750 ms
and peak around 1300 ms. The peak proportions of looks to the
semantic competitor versus the unrelated word increased as children grew
older: The peaks were `r peaks$TimePoint1$prop` at
`r peaks$TimePoint1$Time` ms for age 3, `r peaks$TimePoint2$prop` at
`r peaks$TimePoint2$Time` ms for age 4, and `r peaks$TimePoint3$prop` at
`r peaks$TimePoint3$Time` ms for age 5. Moreover, the semantic competitor
shows a decisive advantage over the unrelated image at age 3, in contrast
to the limited advantage of the phonological competitor at age 3.

(ref:semy-vs-unre-fits) With each year of the study, children looked more to the semantic foil (relative to the unrelated image) with peak looking occurring after the target noun. Both figures show means for each year estimated by the generalized additive model. The left panel compares model estimates to observed means and standard errors, and the right panel visualizes estimated means and their 95% confidence intervals.

(ref:semy-vs-unre-fits-scap) With each year of the study, children looked more to the semantic foil (relative to the unrelated image) with peak looking occurring after the target noun.

```{r semy-vs-unre-fits, fig.cap = "(ref:semy-vs-unre-fits)", fig.scap = "(ref:semy-vs-unre-fits-scap)", warning = FALSE, message = FALSE, out.width = out_tex100_else80, fig.width = 6, fig.height = 4, results = "hide"}
# Data for direct labeling of lines
study_labs <- data.frame(
  Age = c("Age 3", "Age 4", "Age 5"),
  x = c(1400, NA, 1330),
  y = c(.40, NA, 1.1)
)

p1 <- semy_d %>%
  left_join(recode_studies, by = c("Study", "S", "S2")) %>%
  ggplot() +
    aes(x = Time, y = fitted_elogit, color = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    stat_summary(aes(y = elog), fun.data = mean_se, alpha = .7) +
    geom_line(aes(y = fit), data = avg, size = 1) +
    geom_text(
      aes(x = x, y = y, label = Age), 
      data = study_labs, 
      family = "Lato Semibold", 
      size = 5) +
    coord_cartesian(ylim = c(-.25, 1.1)) +
    guides(color = FALSE) + 
    labs_fit_obs +
    labs(y = constants$y_elog_semy) +
    theme_teej() + 
    scale_color_study()

p2 <- s2r %>%
  get_predictions(
    cond = list(
      Time = unique(semy_d$Time),
      S2 = unique(semy_d$S2)),
    rm.ranef = TRUE,
    print.summary = FALSE) %>%
  left_join(recode_studies) %>%
  ggplot() +
    aes(x = Time, y = fit, fill = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
    geom_line(aes(color = Age), size = 1) +
    geom_text(
      aes(x = x, y = y, color = Age, label = Age), 
      data = study_labs,      
      family = "Lato Semibold", 
      size = 5) +
    coord_cartesian(ylim = c(-.25, 1.1)) +
    labs_model_ci +
    theme_teej() + 
    guides(color = FALSE, fill = FALSE)  + 
    scale_color_study()  + 
    scale_fill_study()


p3 <- cowplot::plot_grid(p1, p2)
print(p3)

# semy_peaks <- s2r %>%
#   get_predictions(
#     cond = list(
#       Time = unique(semy_d$Time),
#       S2 = unique(semy_d$S2)),
#     rm.ranef = TRUE,
#     print.summary = FALSE) %>%
#   group_by(S2) %>%
#   top_n(5, fit) %>%
#   summarise(
#     fit = median(fit),
#     fit_prop = plogis(fit) %>%
#       printy::fmt_fix_digits(2) %>%
#       printy::fmt_leading_zero()) %>%
#   split(.$S2)
```

```{r, eval = FALSE}
labs_fit_obs <- labs(
  color = constants$lab_study,
  fill = constants$lab_study,
  x = constants$x_time,
  caption = constants$cap_model_mean_data_mean_se)

# Data for direct labeling of lines
study_labs <- data.frame(
  Age = c("Age 3", "Age 4", "Age 5"),
  x = c(1400, NA, 1330),
  y = c(.42, NA, 1.1)
)

library(extrafont)
loadfonts()

p1 <- semy_d %>%
  left_join(recode_studies, by = c("Study", "S", "S2")) %>%
  ggplot() +
    aes(x = Time, y = fitted_elogit, color = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    stat_summary(aes(y = elog), fun.data = mean_se, alpha = .7) +
    geom_line(aes(y = fit), data = avg, size = 1) +
    geom_text(
      aes(label = Age, x = x, y = y), 
      data = study_labs, 
      size = 6, family = "Lato") +
    coord_cartesian(ylim = c(-.25, 1.1)) +
    labs_fit_obs +
    labs(y = "Log-odds (semantic vs. unrelated)") +
    guides(color = FALSE) + 
    theme_grey(
      base_size = 18, base_family = "Lato") + 
    theme(
      axis.title = element_text(hjust = 1))

p1
labs_model_ci <- labs(
  color = constants$lab_study,
  fill = constants$lab_study,
  x = constants$x_time,
  y = NULL,
  caption = constants$cap_mean_95)

p2 <- s2r %>%
  get_predictions(
    cond = list(
      Time = unique(semy_d$Time),
      S2 = unique(semy_d$S2)),
    rm.ranef = TRUE,
    print.summary = FALSE) %>%
  left_join(recode_studies) %>%
  ggplot() +
    aes(x = Time, y = fit, fill = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
    geom_line(aes(color = Age), size = 1) +
    geom_text(
      aes(label = Age, color = Age, x = x, y = y), 
      data = study_labs, size = 6, family = "Lato") +
    coord_cartesian(ylim = c(-.25, 1.1)) +
    labs_model_ci +
    guides(color = FALSE, fill = FALSE) + 
  theme_grey(
      base_size = 18, base_family = "Lato") + 
    theme(
      axis.title = element_text(hjust = 1),
      axis.text.y = element_blank(), 
      axis.ticks.y = element_blank())
library(patchwork)
p1 + p2
```



The average looks to the semantic foil over the unrelated image for
age 4 was `r sem_tp2` emp. log-odds, `r sem_tp2_prop` proportion units.
Children looked significantly less to the semantic foil on average at
age 3, `r sem_tp1_elog` emp. log-odds, `r sem_tp1_prop` proportion
units, `r sem_tp1_p`, and they looked significantly more to the semantic
foil at age 5, `r sem_tp3_elog` emp. log-odds, `r sem_tp3_prop`
proportion units, `r sem_tp3_p`. 

There was a significant smooth term for time at age 4, estimated degrees
of freedom (EDF) = `r sem_s_tp2_edf`, `r sem_s_tp2_p`.
Figure \@ref(fig:semy-diff-curves) visualizes the time course of the
differences between the smooths from each year.

(ref:semy-diff-curves) Differences in the average looks to the semantic competitor versus the unrelated word between age 4 and the other ages. Plotted line is estimated difference and the shaded region is the 95% confidence interval around that difference. Boxes highlight regions where the 95% interval excludes zero. The flat line on the left reflects how the shape of the growth curves remained the same from age 3 to age 4 and only differed in average height. From age 4 to age 5, the lines quickly diverge and the age-5 curve reaches a higher peak value.

(ref:semy-diff-curves-scap) Differences in average looks to the semantic competitor versus the unrelated word between age 4 and the other ages. 

```{r semy-diff-curves, fig.cap = "(ref:semy-diff-curves)", fig.scap = "(ref:semy-diff-curves-scap)", out.width = out_tex100_else80, fig.width = 5, fig.height = 3.5}
age5_age4 <- s2r %>%
  get_difference(
    comp = list(S2 = c("TimePoint3", "TimePoint2")),
    cond = list(Time = unique(semy_d$Time)),
    rm.ranef = TRUE,
    print.summary = FALSE) %>%
  mutate(comparison = "Age 5 − Age 4")

age4_age3 <- s2r %>%
  get_difference(
    comp = list(S2 = c("TimePoint2", "TimePoint1")),
    cond = list(Time = unique(semy_d$Time)),
    rm.ranef = TRUE,
    print.summary = FALSE) %>%
  mutate(comparison = "Age 4 − Age 3")

rle_lengths <- function(xs) rle(xs)[["lengths"]]

differences <- bind_rows(age5_age4, age4_age3) %>%
  rename(fit = difference) %>%
  mutate(
    upper = fit + CI,
    lower = fit - CI,
    no_zero = 0 > upper | 0 < lower) %>%
  group_by(comparison) %>%
  arrange(comparison, Time) %>%
  mutate(
    streak = rep(seq_along(rle_lengths(no_zero)), rle_lengths(no_zero))) %>%
  ungroup()

sig_regions <- differences %>%
  filter(no_zero) %>%
  group_by(comparison, streak) %>%
  summarize(min = min(Time), max = max(Time)) %>%
  ungroup()

ggplot(differences) +
  aes(x = Time, y = fit) +
  geom_hline(size = 2, yintercept = 0, color = "white") +
  geom_vline(
    aes(xintercept = min), data = sig_regions,
    color = constants$col_blue_highlight, linetype = "dashed") +
  geom_vline(
    aes(xintercept = max), data = sig_regions,
    color = constants$col_blue_highlight ,linetype = "dashed") +
  geom_segment(
      aes(x = min, xend = max, group = streak), y = -Inf, yend = -Inf,
      data = sig_regions, color = constants$col_blue_highlight,
      size = 1) +
  geom_segment(
      aes(x = min, xend = max, group = streak), y = Inf, yend = Inf,
      data = sig_regions, color = constants$col_blue_highlight,
      size = 1.1) +
  geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
  geom_line(size = 1) +
  labs(
    color = constants$lab_study,
    fill = constants$lab_study,
    x = constants$x_time,
    y = constants$y_elog_diff_semy,
    caption = constants$cap_diff_95,
    title = "Changes in semantic competitor effect") +
  facet_wrap("comparison")
```

The shapes of the age-3 and age-4 curves did not significantly differ,
EDF = `r sem_s_tp1_edf`, `r sem_s_tp1_p`. The age-3 curve begins to rise
about 100 ms later, and it reaches a shallower peak value than the age-4
curve. These two features create a nearly constant height difference
between the two curves, and thus the two curves show the same overall
shape.

The age-4 and age-5 smooths significantly differed, EDF = `r sem_s_tp3_edf`,
`r sem_s_tp3_p`. The differences are greatest after the end of the target
noun, in the window from 750 to 1500 ms. The two curves start from a
similar baseline but quickly diverge as the age-5 curve reaches a higher
peak value. After 1500 ms, the age-5 curve turns downwards to overlap
with the age-4 curve. Children looked more to the semantic foil
relative to the unrelated image, but they were also quicker to correct
and look away from it.

**Summary.** Children became more sensitive to the semantic competitor,
compared to the unrelated word, with each year of the study. The
semantic foils clearly influenced looking patterns at age 3, in contrast
to the muted effect observed for the phonological foils. The semantic
effect also occurred when we would expect: After the end of the target
noun, following the lexical activation of the target noun and its
semantic neighbors.




Child-level differences in competitor sensitivity at age 3
------------------------------------------------------------------------

Next, I asked whether children differed reliably in their sensitivity to
the phonological and semantic foils based on speech perception and
vocabulary measures collected at age 3.

As a measure of speech perception, I used scores from a minimal pair
discrimination experiment administered during the first year of the
study. The task [based on @ProtoMinPair] is essentially an ABX
discrimination task: A picture of a familiar object is shown and labeled
(e.g., "car"), another object is shown and labeled ("jar"), and then
both images are shown and one of the two is named. The child then
indicated which word they heard by tapping on the image on a
touch-screen.

I derived speech perception scores by fitting a hierarchical
item-response model. This logistic regression model estimates the
probability of child *i* correctly choosing word *j* on word-pair *k*.
The equation below provides a term-by-term description of the model. The
model's intercept term represents the average participant's probability
of correctly answering for an average item. By-child random intercepts
capture a child's deviation from the overall average, so they estimate
the child's *ability*. By-word and by-word-in-pair random intercepts
capture the relative *difficulty* of particular items on the experiment.
The by-word-in-pair effects were necessary because four words appeared
in more than one word pair (e.g., *juice*--*goose* and
*juice*--*moose*). The model also controlled for the children's ages and
receptive vocabulary scores (PPVT-4 growth scale values). These
predictors were transformed to have mean 0 and standard deviation 1, so
the model's intercept reflected a child of an average age and an
average vocabulary level. Therefore, the by-child intercepts
reflect a child's ability after controlling for age and receptive
vocabulary.

`r insert_html_math()`
\small
\begin{align*}
   \text{log odds}(\text{choose target}) =\
   & \alpha\ +                  &\text{[average child ability]} \\
   & \alpha_i\ +                &\text{[difference of child}\ i
                                       \text{'s ability from average]} \\
   & \alpha_j\ +                &\text{[word}\ j\text{'s difficulty]} \\
   & \alpha_{j,k}\ +            &\text{[word}\ j
                                       \text{'s difficulty in word-pair}\ k] \\
   & \beta_{1}\text{Age}\ +     &\text{[child-level predictors]} \\
   & \beta_{2}\text{Vocabulary} & \\
\end{align*}
\normalsize
`r insert_html_math()`

I tested whether phonemic discrimination ability at age 3 predicted
looks to the phonological competitor over the unrelated image by
modifying the generalized additive model from earlier. In particular, I
included a smooth term for the phonemic discrimination ability score and
a "smooth interaction" between the smooth of time and phonemic ability.
These smooth interaction terms are analogous to interaction terms in
linear models. In this case, the interaction term allows the ability
score to change the shape of the time trend. The additive model was
therefore:

`r insert_html_math()`
\small
\begin{align*}
   \text{emp. log odds}(\text{phon. vs. unrelated}) =\
   & \alpha\ +\ &\text{[growth curve average]} \\
   & f_1(\text{Time})\ +                    &\text{[time smooth]} \\
   & f_2(\text{Ability})\ +                 &\text{[ability smooth]} \\
   & f_3(\text{Time} * \text{Ability})\ +   &\text{[interaction smooth]} \\
   & f_i(\text{Time}, \text{Child}_i)       &\text{[by-child random smooths]} \\
\end{align*}
\normalsize
`r insert_html_math()`

```{r load-test-scores, include = FALSE}
ppvt <- readr::read_csv(file = "./data-raw/test_scores.csv") %>%
  filter(Study == "TimePoint1") %>%
  select(ResearchID, PPVT_Age, PPVT_GSV, EVT_Age, PPVT_GSV)

minp <- readr::read_csv(file = "./data-raw/age3-minpair-fits.csv") %>%
  filter(Model == "base + age + ppvt") %>%
  left_join(ppvt) %>%
  mutate(PPVT_Age = ifelse(is.na(PPVT_Age), MinPair_Age, PPVT_Age))

minp <- minp %>%
  modelr::add_residuals(
    model = lm(PPVT_GSV ~ PPVT_Age + fitted, .),
    var = "PPVT_GSV_Adj")

phon_d_minp <- phon_d %>%
  filter(S == "TimePoint1") %>%
  inner_join(minp, by = "ResearchID") %>%
  mutate(
    ability = as.vector(scale(coef)),
    ppvt = as.vector(scale(PPVT_GSV_Adj)))

semy_d_minp <- semy_d %>%
  filter(S == "TimePoint1") %>%
  inner_join(minp, by = "ResearchID") %>%
  mutate(
    ability = as.vector(scale(coef)),
    ppvt = as.vector(scale(PPVT_GSV_Adj)))
```

```{r fit-phon-minp-model}
phon_base <- "./data/aim1-phon-gamm-age3-base.rds.gz"
phon_minp <- "./data/aim1-phon-gamm-age3-minp.rds.gz"
phon_ppvt <- "./data/aim1-phon-gamm-age3-ppvt.rds.gz"
phon_ppvt_para <- "./data/aim1-phon-gamm-age3-ppvt-para.rds.gz"

b2_age3 <- if (file.exists(phon_base)) {
  readr::read_rds(phon_base)
} else {
  bam(
    elog ~ s(Time) + s(Time, R, bs = "fs", m = 1, k = 5),
    data = phon_d_minp) %>%
  readr::write_rds(phon_base)
}

b2_age3_minp <- if (file.exists(phon_minp)) {
  readr::read_rds(phon_minp)
} else {
  bam(
    elog ~ s(Time) +
      s(ability) +
      ti(Time, ability) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = phon_d_minp) %>%
  readr::write_rds(phon_minp)
}

b2_age3_ppvt <- if (file.exists(phon_ppvt)) {
  readr::read_rds(phon_ppvt)
} else {
  bam(
    elog ~ s(Time) +
      s(ppvt) +
      ti(Time, ppvt) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = phon_d_minp) %>%
  readr::write_rds(phon_ppvt)
}

b2_age3_ppvt_0 <- if (file.exists(phon_ppvt_para)) {
  readr::read_rds(phon_ppvt_para)
} else {
  bam(
    elog ~ ppvt +
      s(Time) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = phon_d_minp) %>%
  readr::write_rds(phon_ppvt_para)
}

n_phon_minp <- phon_d_minp %>%
  pull(ResearchID) %>%
  unique() %>%
  length()

minp_summary <- summary(b2_age3_minp)
phon_minp_edf <- get_smooth_edf(minp_summary, "s(ability)")
phon_minp_p <- get_smooth_pvalue(minp_summary, "s(ability)")

phon_minp_time_edf <- get_smooth_edf(minp_summary, "ti(Time,ability)")
phon_minp_time_p <- get_smooth_pvalue(minp_summary, "ti(Time,ability)")

ppvt_summary <- summary(b2_age3_ppvt)
phon_ppvt_edf <- get_smooth_edf(ppvt_summary, "s(ppvt)")
phon_ppvt_p <- get_smooth_pvalue(ppvt_summary, "s(ppvt)")

phon_ppvt_time_edf <- get_smooth_edf(ppvt_summary, "ti(Time,ppvt)")
phon_ppvt_time_p <- get_smooth_pvalue(ppvt_summary, "ti(Time,ppvt)")

comparison <- compareML(b2_age3, b2_age3_minp, print.output = FALSE)
chi_phon <- format_chi_squared(comparison)
# compareML(b2_age3, b2_age3_minp,  suggest.report = TRUE)
```

The model included data from `r n_phon_minp` participants; these were
children with eyetracking data, receptive vocabulary and phonemic
discrimination data at age 3. There was not a significant smooth effect
for discrimination ability, EDF = `r phon_minp_edf`, `r phon_minp_p` or
for an interaction smooth between time and ability, EDF =
`r phon_minp_time_edf`, `r phon_minp_time_p`.

```{r fit-semy-minp-model, echo = FALSE}
semy_base <- "./data/aim1-semy-gamm-age3-base.rds.gz"
semy_ppvt <- "./data/aim1-semy-gamm-age3-ppvt.rds.gz"
semy_minp <- "./data/aim1-semy-gamm-age3-minp.rds.gz"
semy_ppvt_para <- "./data/aim1-semy-gamm-age3-ppvt-para.rds.gz"
semy_minp_para <- "./data/aim1-semy-gamm-age3-minp-para.rds.gz"

semy_age3 <- if (file.exists(semy_base)) {
  readr::read_rds(semy_base)
} else {
  bam(
    elog ~ s(Time) + s(Time, R, bs = "fs", m = 1, k = 5),
    data = semy_d_minp) %>%
  readr::write_rds(semy_base)
}

semy_age3_ppvt <- if (file.exists(semy_ppvt)) {
  readr::read_rds(semy_ppvt)
} else {
  bam(
    elog ~ s(Time) +
      s(ppvt) +
      ti(Time, ppvt) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = semy_d_minp) %>%
  readr::write_rds(semy_ppvt)
}

semy_age3_minp <- if (file.exists(semy_minp)) {
  readr::read_rds(semy_minp)
} else {
  bam(
    elog ~ s(Time) +
      s(ability) +
      ti(Time, ability) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = semy_d_minp) %>%
  readr::write_rds(semy_minp)
}

# parametric ppvt effect
semy_age3_ppvt_0 <- if (file.exists(semy_ppvt_para)) {
  readr::read_rds(semy_ppvt_para)
} else {
  bam(
    elog ~ s(Time) +
      ppvt +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = semy_d_minp) %>%
  readr::write_rds(semy_ppvt_para)
}

# parametric minpair effect
semy_age3_minp_0 <- if (file.exists(semy_minp_para)) {
  readr::read_rds(semy_minp_para)
} else {
  bam(
    elog ~ s(Time) +
      ability +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = semy_d_minp) %>%
  readr::write_rds(semy_minp_para)
}
```

To test the role of receptive vocabulary, I also fit analogous models
using growth scale value scores from the PPVT-4, a receptive vocabulary
test. I first adjusted these scores in a regression model to control
for--that is, to partial out the effects of---age and predicted accuracy
on the discrimination task. There was not a significant
smooth effect for receptive vocabulary, EDF = `r phon_ppvt_edf`,
`r phon_ppvt_p`, or a significant interaction smooth between time and
receptive vocabulary, EDF = `r phon_ppvt_time_edf`,
`r phon_ppvt_time_p`. Receptive vocabulary therefore was not related to
looks to the phonological foil at age 3.

I tested the same two predictors on looks to the semantic foil at age 3.
These child-level factors did not show any significant parametric
effects, smooth effects or smooth interactions with time. Thus,
children's looks to the semantic foil were not reliably related to
phonemic discrimination or receptive vocabulary.

**Summary**. These models tested whether two child-level
factors---minimal-pair discrimination ability and receptive
vocabulary---predicted looks to the phonological and semantic
competitors at age 3. No significant effects were observed for 
all cases. 




Discussion
------------------------------------------------------------------------

In the preceding analyses, I examined children's fixation patterns to
the phonological and semantic competitors and how these fixation
patterns changed over developmental time. With each year of the study,
children looked more to the target overall, so they consequently looked
less to the competitor images each year. To account for this fact, these
analyses examined the ratio of looks to the competitors versus the
unrelated word. This ratio measured the relative advantage of a
competitor over the unrelated word.


### Immediate activation of phonological neighbors

Developmentally, children became more sensitive to the phonological
competitors with each year of the study. These words shared the same
syllable onset as the target noun---for example, the pairs
*dress*–*drum* or *fly*–*flag*. The competitors affected word
recognition early on, with relative looks to the phonological foils
peaking around 800 ms. The target nouns were approximately 800 ms in duration
at age 3 and 550--800 ms at later ages. Assuming a 200–300 ms overhead
for executing an eye movement in response to speech, this timing
indicates that children shifted their gaze immediately, based on partial
information. Moreover, the tendency to act on partial information became
stronger with age, because the early advantage of the phonological
competitor increased with each year of the study.

When children looked to the phonological competitor, they fixated on the
wrong image and had to revise their interpretation of the noun. At
ages 4 and 5, the early peaks of looks to the phonological competitor
were followed by a steep, monotonic decrease in looks: Children rejected
their initial interpretation of the word and considered other images. At
age 3, the average pattern showed more wiggliness, suggesting that
children were less decisive in rejecting the phonological competitor.
The shapes of the looking patterns at age 4 and age 5 were essentially
the same. In particular, the older children were not any faster in the
rejecting the phonological competitor on average.

We can interpret these findings in terms of lexical processing dynamics.
Under this view, incoming speech activates phonetic and phonemic and
lexical representations. The word with the strongest activation is the
favored interpretation and the object of the child's fixations. The
early looks to the phonological competitors reflect immediate
activation of lexical units: Children activate words on the basis of
partial acoustic information. This result is a hallmark of spoken word
recognition. The activation of phonologically plausible words becomes
stronger with age, as reflected in children's increasing sensitivity to
the phonological competitors. Some mechanisms that may explain this
developmental pattern include changes in lexical organization so that
neighborhoods of phonologically similar words coactivate and changes in
lexical representation so that partial information can more eagerly
activate compatible words.[^connectionism]

[^connectionism]: I am not too committed to any particular mechanisms
  of *representation* or *organization*. Under a connectionist framework
  with distributed representations, for instance, a 
  word is represented as a pattern of activation distributed over many shared 
  units. (I think of numbers on a digital clock where seven lines turn on or 
  off to make ten digits but exponentially more complicated.) In that
  case, representation and organization are inseparable, and it would make
  more sense to talk about the strength and number of connections instead.
  My point here is that the lexical mechanisms involved should be ones
  that enable stronger immediate activations as a result of learning more
  words.

Children at age 4 and age 5 did not show any changes in how quickly they
rejected the phonological foil, and this result suggests that lexical
inhibition may not change over the preschool years. The reasoning is as
follows: If children developed stronger lexical inhibition with age, so
that lexical competition resolves more quickly, then we would expect
activation of the phonological competitors to decay more quickly and for
children to reject the phonological competitor more quickly. But this
pattern is not what we observed in the growth curve
analyses.[^decay-rates] The developmental trajectory here is one of
increased activation, of children learning words and learning
similarities among them so that phonological similar words participate
in word recognition.

[^decay-rates]: Granted, there might be some subtle nonlinear effect
  at play where higher peak activations require a greater degree of
  inhibition to overcome, so changes in inhibition could be a plausible
  part of the developmental story. But there is no compelling reason from 
  the data to make that assertion.


### Late activation of semantic neighbors

The semantic competitors were from the same category as the target noun:
for example, *bee*–*fly* or *shirt*–*dress*. Children showed
year-over-year increases in their sensitivity to the semantic
competitor, compared to the unrelated image. Looks the semantic foils
started rising steadily 500--700 ms after target onset and peaked late
in the trial, around 1300 ms. This time-course is more protracted than
the immediate peaks observed for the phonological competitor.

In terms of lexical processing, this late timing is consistent with
cascading activation: Spoken words immediately activate phonological
neighborhoods with activation cascading onto semantically related words.
As a particular word is favored, its semantic relatives receive more
secondary activation. For example, children hear "find the shirt",
activate the target *shirt*, but also activate other pieces of clothing
including *dress*. The late timing of looks to the semantic competitor
therefore reflects late, secondary activation of the spoken word's semantic
relatives. In other words, the activation of a semantic neighbor (like
*dress*) is greatest when the activation of the spoken word (*shirt*) is
greatest which happens relatively late, once the competition among
phonological alternatives resolves.

Under this account, children hear a word, activate it, and become
increasingly likely to fixate on the semantic competitor, compared to
the unrelated image. The late looks probably reflect a combination of 
behaviors: children considering the semantically related image to check
their initial interpretation as well as children looking to the wrong image
because of confusion, lack of knowledge, overriding activation from
the semantic competitor, or lack of interest in the target. 

Initially, I had subscribed to a confusion or lack-of-knowledge
interpretation of the semantic competitor's advantage. That is, children
look to the semantic competitor because they do not know the difference
between the target and the semantic competitor. After all, my thinking
went, these were young children and decisions like *bee* vs. *fly* or
*goat* vs. *sheep* can be difficult. But there are two objections to
that line of reasoning. First, our lab piloted the set of words in
preschool classrooms, so we confirmed that children could reliably and
correctly point to *bee* even when *fly* is an alternative. Second, we
would a priori expect that children's confusion among words to be
greatest when they are youngest and have much less experience with these
semantic categories. (Indeed, children at age 3 looked less to the
target overall, so in general, they were less successful at recognizing
the target word.) 

The late looks to the semantic competitor, relative to the unrelated
image, however, were greatest at age 5. Children's looks became more
selective with age: They looked more to the semantic competitor because
they had discovered the semantic connections among words. They had
learned the similarity between *bee* and *fly* or *shirt* and *dress*.
Put another way, to demonstrate confusion between two choices, children
must learn some association that connects the two; they must use or
activate some information that induces warranted uncertainty. Rather
than confusion about the meaning of nouns, the late looks likely reflect
a confirmatory behavior where children give some consideration to the
semantic alternative. This is especially the case at age 5, where the
advantage of semantic competitor quickly decreases after its peak,
indicating rejection of the semantic competitor.


### Lexical competitors and child-level predictors

I asked whether offline child-level measures predicted sensitivity to
the phonological and semantic competitors at age 3. I used children's
ability scores from a minimal-pair discrimination task as a measure of
phonemic speech perception, and I also used scores from a receptive
vocabulary test. For the phonological competitor, I expected that
children with better phonemic discrimination would show increased
looks to the phonological competitor because they had more detailed
phonemic representations that would activate phonological neighborhoods
more quickly. For the semantic competitor, I likewise expected children
with larger receptive vocabularies to show increased looks to the
semantic competitor because these children knew more words and likely
developed more semantic connections among the words. I tested these
effects by using the scores as parametric effects to see if they
predicted average looks to the competitor, and alternatively, by using
the scores for smooth effects to see if they influenced the time course
of looks to the foils.

None of these expectations held: Neither of the child-level measures
predicted average sensitivity to the phonological or semantic
competitors at age 3. Part of the result may be artifactual: The
data---looks to a subset of images on a subset of trials---may be too
limited at the individual level for the models to pick up on child-level
effects. Part of the result may be developmental too: Children were
least sensitive to the competitors at age 3, so individual differences
may be too small for the data or models to capture. Further work, with
different experimental designs, may elaborate on whether offline
measures can reliably detect differences in sensitivity to lexical
competitors during word recognition. 

