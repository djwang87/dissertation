(PART\*) Synthesis  {#part-end .unnumbered}
=======================================================================


General discussion
=======================================================================

In this chapter, I integrate results from the two studies. First, I describe the mechanisms underlying children's word recognition. Next, I review some clinical implications of this research.


Mechanisms of word recognition
-----------------------------------------------------------------------

What cognitive or word-recognitions mechanisms can account for the data
observed from these two studies? These are the essential findings that
the model needs to account for:

* Developmental improvements in familiar word recognition
* Early advantage of phonologically similar words (over unrelated words)
* Late advantage of semantically similar words (over unrelated words)
* Developmental changes in the advantage of these similar words
* Disrupted processing of onset-mispronunciations
* Easy processing of unambiguous nonwords
* Individual differences in familiar word recognition

As a baseline for word recognition mechanisms, I would start with 1) a
continuous activation model 2) that uses different levels of
representation---in other words, TRACE [@TRACE]. In my preceding
interpretations of the data from Aim 1 and Aim 2 I have assumed a
TRACE-like archecture, so it is helpful to briefly review what this
model does.

TRACE interprets an input pattern by spreading energy (activation)
through a network of processing units. The pattern of activation over
the network is its interpretation of the input signal, so that more
active units represent more likely interpretations. Over many processing
cycles, the network propagates energy among its connections until it
settles into a stable pattern of activation. (Activation also decays
over cycles so that the model can start and return a resting state.)
This activation process is *continuous*; the model's interpretation
evolves continuously. We can ask at any point during (or after)
presentation of a word what the model's interpretation of that word is.
Thus, the listener does not need to hear a whole word to generate a
plausible guess for that word [e.g., @Fernald2001].

The model involves three levels of representation: perceptual/phonetic
features, phoneme units and lexical units. The input for TRACE is a
mock-speech signal that activates the perceptual feature-detectors.
These units respond to phonetic features like voicing or vocalic
resonance. The perceptual units activate phoneme units, and the phoneme
units activate lexical word units. For example, the bundle of features
representing a /b/ would activate /b/ but to a lesser extent also
activate the phonetically similar /d/ (different place), /p/ (voice),
/v/ (manner), or /m/ (nasality). The initial /b/ sound activates a
neighborhood of words containing /b/, and the phonetically similar sound
also activate matching similar words, albeit to a weaker extent. 

The combination of continuous processing and levels of representation
means that ambiguities can arise during word recognition. After /b/, the
sound /i/ arrives, activating a set of phoneme units and in turn
activating words containing /i/. The sequence of /bi/ favors a
particular neighborhood of cohorts: *be*, *bee*, *beam*, *beak*, *beat*,
*beetle*, etc. At this point, however, the signal is ambiguous. Any of
the words in the cohort are plausible interpretations and more
information is needed to refine the interpretation.
In @Swingley1999, 24-month-olds were slower to respond to trials of
*doggie* versus *doll*, compared to *doggie*--*tree* or *doll*--*truck*
trials, where the delay reflected the brief ambiguity from the words
sharing an onset and vowel.

<!-- phonological effect -->

The mechanisms described thus far can account for the advantage of the
phonological competitors over unrelated words from the first study. The
initial phoneme in a word activates a cohort of words that share that
sound, so that the cohorts briefly represent more plausible
interpretations of the target than words that are not phonologically
related. A child can act on that early information and shift their gaze
to the phonological competitor.

Words in TRACE compete with each other through lateral inhibition, so
that an active word will dampen the activation of other competitors.
Inhibition allows the model to reinforce or revise an interpretation. In
the earlier example, the arrival of /m/ after /bi/ would strongly favor
*beam* as the most plausible interpretation of the word, and *beam* will
inhibit the other candidates like *beak* or *beat* so that it can be the
decisive interpreation of the word. The transient effect of the
phonological competitor suggests lateral inhibition: The advantage of
the phonological competitor over the unrelated word is short-lived
because the target word builds up activation and inhibits the
phonological competitor. 

<!-- semantic effect and cascading activation -->

To account for the effect of the semantic competitor, we need to make a
few more assumptions. Semantic information is not explicitly included as
a part of TRACE but we can stipulate that semantic information is part
of a word's lexical representation. We also need a way for semantically
related words to co-activate, so that hearing *bee* will generate some
spurious looks to *fly*. In this case, we can assume that there are
excitatory connections between semantically related words, so that
hearing a word also activates its semantic relatives. In my earlier
discussions, I used the term *cascading activation* to describe this
arrangement. For children to generate looks to the semantic competitor,
they first to need to build up activation of the word and that
activation would cascade over to semantic relatives. The time course of
activation here is consistent with the late effects of the semantic
competitor. The semantic competitor can exerts an advantage over the
unrelated word after semantic information comes online.

The relative advantage of the phonological and semantic competitors
increased each year, as did children's overall recognition of the
familiar word. In other words, children became better at activating the
target and the words related to the target. In Chapter XX, I argued that
these developmental changes in the first study reflected stronger
phoneme--word connections (for greater activation of the target and
phonological competitors) and stronger semantic connections between
words. I did not observe any developmental changes in inhibition, so I 
favored an interpretation that focused on stronger connections.


<!-- mispronunciations -->

One prediction of TRACE is that rhymes and rimes (one-syllable rhymes)
can affect word recognition. But these rhymes are at a disadvantage. Early
in the processing of a word, all of the action is in the bottom-up
connections from the phonetic features to the phonological units onto
the words. Cohorts show an early advantage in word recognition because
they receive activation before lexical units start to inhibit each
other. The rhyme mismatch the input from the start of the word, so they
undergo inhibition early on. But as the word unfolds, subsequent
phonemes can build up activation of the rhyme word and the word can
overcome the initial disadvantage. @Allopenna1998 found similarity
between TRACE activation patterns and adult listeners' looking pattern.
Namely, adults hear *beaker* and look to the word, but they also
generate spurious early looks to a cohort *beetle* and late looks to a 
rhyme *speaker*. (Anecdotally, my name is Tristan, but in grade school,
I always snapped to attention whenever Kristen's name was called.)

The mechanisms that predict how rhymes can engage in the lexical
competition also explain the disruptive mispronunciation effects. An
initial *s* in *suze* sends the listener down a lexical garden path,
activating /s/-initial words. The arrival of the rest of the word,
*shoes*, plus the image of the shoes onscreen, supports *shoes* as an
interpretation of the word. But there is much less certainty in this
situation. At age 3, we observed 50% looking for *suze* and 80% looking
for *shoes*. There was a small developmental improvement for
mispronunciation conditions and the real word condition. For example, at
age 5, *suze* reaches 60% looking and *shoes* reaches 87% looking.
Developmentally, children became more likely to activation the target
when given a mispronunciation, and this change reflects like general
improvements in activation efficiency.


Footnote? It should be noted that these mispronunciations were all
one-syllable words, so they did not have phonological substance that
could overlap with the target. If the mispronunciation-target pairs were
longer like a *beaker*--*speaker* rhyme, we would predict more segments
would overlap, leading to greater activation of the mispronounced
target. 

<!-- nonwords -->

What about the effortless processing of the unambiguous nonwords?
Surely, children do not have a lexical item *geeve* to activate the
first time they hear the word. (Perhaps not.) On these trials, however, the
children did know *sock* and know that *geeve* was not the name for the sock,
so they looked to the trolley instead. For @McMurray2012, the problem
facing a child is reference selection: Children have to select a visual
referent for a spoken word. In that model, all words can refer to all visual
referents initially and the model has to prune away unnecessary
connections to build up selective word recognition. Development of the
*sock*-sock pairing pruned away other visual referents or words from
activating *sock*. Thus, "geeve" is not likely to activate *sock* so
the viability of the *geeve*-trolley pairing allow the child to select
the correct referent for the nonword. In TRACE simulations,
@TRACE_Mispro simulated this situation by treating the nonword as a
low-frequency word. In both of these situations, the novel nonword is
recognized because it is not affected by lexical competition from any
other plausible alternatives. 

This framework also allows us to account for the differences in
retention for the nonwords and mispronunciations at age 5. In
@McMurray2012, learning was associative. Developed connections between
spoken words, lexical items, and visual referents when spoken words and
visual referents occurred together, and each co-occurence build up the
connections. On the mispronunciation trial from the second study, a
child heard a mispronunciation of a familiar word and also saw an image
of mispronounced word. On average, they tended to interpret the
mispronunciation as the familiar word. Thus, the familar word competed
with the mispronunciation, leading the child to develop a weaker
association between the novel object and mispronunciation. The effect of
looking behavior, where children who looked more to the familiar image
on mispronunciation trials showed poor retention, shows how the familiar
image could impede the association of the mispronunciation and the novel
objet. In contrast, for unambiguous nonword trials, children could
associate the novel object and novel word more strongly. This difference
in lexical competition manifested in the retention performance where
children demonstrated that children were better able to retain nonwords
than mispronunciations. 

<!-- individual differences -->

So far, I have described a general framework of word recognition and I
claimed children's developmental changes in word recognition reflect
more efficient representations and activation pathways. I now describe
task differences and individual differences under this framework.

Word learning is a matter of degree. I like to draw a distinction
between "shallow" receptive knowledge and "deeper" expressive knowledge,
based on the idea that recognition is easier than generation. But we can
imagine an even finer continuum with degrees of recognition ability. For
example, a word can be recognized in one situation but may not be
recognized in a more challenging situation. For example, @McMurray2012
tested a word-learning model's comprehension by simulating
alternative-forced choice (AFC) tasks where a target was pitted against
competitors. The model showed graded performance, with better
comprehension on a 3-AFC (2 competitor) tests than 5-AFC tests, and
better performance on 5-AFC tests than 10-AFC tests. Thus, the 4-AFC
task in my first study provided a more challenging word-recognition than
the 2-AFC task in the second study. For example, children demonstrated
ceiling performance on the nonword condition at age 4, whereas children
had room to develop each year in the 4-AFC task.

Individual differences in word recognition reflect differences in
children's lexicons and their representations. Although all the words on
the 4-AFC were familiar to children, children differed in their peak
looking probabilities and rate of fixating on the target. In lexical
processing terms, children differed in their peak activation and the
rate at which activation reached the target word. Differences in word
recognition were stable from year to year. Even though all of the
children became faster, more reliable and more certain during word
recognition with age, the children who faster and more reliable at age 3
were also faster and more reliable at age 5. The children who performed
better at age 3 had more experience and more reliable representations of
the words---thus, they had a head start and they built on top of that
advantage. This interpretation can also account for how word recognition
performance at age 3 correlated with vocabulary scores at later ages.









and this suggests that children improved on their representations




The mapping between fixation probabilities and word activations in @Allopenna1998 allow us to interpret differences in fixation probabilities as differences in word activations.






Given this backdrop, how do we account for individual differences in word recognition? Vocabulary size is a reliably predictor of word recognition performance [@MPPaper], so that suggest differences in lexical processing are the result of differences in lexical representation.





We know that children can recognize words before they can name them, and this principles makes sense from a computational perspective: 


The ability quickly associate a novel word to a novel object reveals a disconnect between lexical knowledge and lexical performance. 
My first study with four-images is a 4-AFC task, and the second study is a 2-AFC task. 






"a dissociation between what a model 'knows' (the associative connections), and what it 'does' (performance on comprehension tasks"




So far I have suggested that word recognition in preschoolers draws on mechanisms of 
continuous activation, multiple levels of representation, cascading activation, and lexical competition through bottom-up activation and lateral inhibition. I have taken for granted that children learn words by developing lexical representations. These representations are phonetically well detailed so that children are sensitive to mispronunciations and phonological competitors. 






"Crucially, the suppression or pruning of the irrelevant weights is the dominant factor—the bulk of word learning may consist of learning which objects and words do not go together"

When a child knows
answer is  argues that children do not need one in the moment either. 

Cohorts exhibit a strong effect on word recognition because they


so that an early cohort competitor is suppressed

Other word recognition models, say Cohort xxx, emphasize the importance of initial sounds activating a 


My reasoning was that 

To recognize the target word more quickly, children need to build up activation to the target more quickly.


<!-- Alternatively, we could assume there is a layer of semantic representations outside of lexical representations, so that word form and word meaning are separated. -->



This arrangement predicts that semantic information will enter into word recognition relatively late, as it requires activation of the word. 





and this mechanism accounts for the phonological competitors

The immediate activation of phonologically similar words provides the mechanism




These mechanisms are enough to account for the mispronunciation effect from the second study.




The results from the first study are consistent with a continuous activation model with different levels of representation. 



(yes, ham / hamster)

This is the baseline. Now the question is how the results from the two
studies fit inside this model.


There are two implications from this set up. The first is the cohort effect. And the second is the mispronunciation penalty.

The combination of continuous activation and levels of representation
has a few implications. For example



In order to account for the mispronunciation penalty, we need the phonetic features.


This is a *continuous activation* model.


I would start
with a continuous activation model of word recognition with different levels of representation. 






The input for TRACE is a mock-speech signal that activates perceptual feature-detectors. These units respond to phonetic features like voicing or vocalic resonance. The perceptual units activate phoneme units, and the phoneme units activate lexical word units, as shown below.


<!-- Units within a level (phonetic, phonemic, lexical) compete through lateral inhibition, so that more active units can suppress less active units. This inhibition allows the network to rule out possible units and narrow its interpretations over time. There are also top-down connections so that word units in the lexical layer can reinforce the sound units that make up those words. One consequence of this feature is that the network can resolve ambiguous phonemes, as in Xift where X is a sound between /k/ and /g/ and top-down influence supports gift rather than kift¬. Lastly, activation in units gradually decays over time, and the network will eventually “forget” it input pattern to return to a resting state. -->

<!-- The model parameters that govern how activation propagates through the network map onto psychological processing constructs. For instance, the phoneme inhibition strength parameter controls how decisively (or categorically) the network interprets speech sounds. Phoneme-to-word activation strength reflects how quickly speech sounds begin to activate words. Decay parameters control the model’s temporary memory for different kinds of representations.  -->

The TRACE model of speech perception and word recognition [@TRACE] is well suited for this kind of simulation work. TRACE can simulate a dozen or so empirical results from speech perception literature (Strauss, Harris, & Magnuson, 2007, Table 1), and it has been used to simulate word-recognition data from adults (Allopenna, Magnuson, & Tanenhaus, 1998), and adults with aphasia (Mirman, Yee, Blumstein, & Magnuson, 2011), and toddlers (Mayor & Plunkett, 2014). 

@jTRACE

McMurray, Samelson, Lee, and Bruce Tomblin (2010) used TRACE to simulate word recognition results from adolescents with specific language impairment (SLI). They mapped certain theories about SLI onto different model parameters. For example, to test the theory that listeners with SLI have impairments in acoustic perception, they varied three of the model’s parameters: amount of noise added to the model’s mock-speech input, temporal spread of acoustic features in the input (temporal resolution), and rate of decay in the model’s acoustic feature detectors (perceptual memory). Other theories of SLI (and other model parameters) provided a closer fit to the observed data than the perceptual deficit theory. Specifically, lexical decay—“the ability to maintain words in memory” (p. 23)—was the most important model parameter, implying that individual differences in word recognition for listeners with SLI are rooted in lexical processes (and not perceptual or phonological ones). 

This example shows how simulations with TRACE recast word recognition performance in terms of psychological processes. For this project, I will use TRACE to describe how cognitive processes and representations need to change to simulate the development of word recognition in preschoolers.


Clinical implications
----------------------------------------------------------------------

The results of the first study remind us that words
are not simply acquired---they are learned and *integrated*. In the first
study, children's recognition of very familiar words improved each year.
Children's representations of familiar words continue to develop, even
if they ostenisbly *know* the word. One might attribute this development
change to improvements in visual processing and sensory processing or
some other nonlinguistic factor. This study cannot rule out those
explanations. The increasing effect of the phonological and semantic
competitors, however, suggests that changes in lexical representations
can explain these results.

Word recognition predicts later outcomes, and one common conclusion from this research is that word recognition may provide an early screening tool: "[t]ime-course measures of comprehension in very young language learners could ultimately prove useful in improving early identification of children at risk for persistent language disorders" [@Fernald2012, p. 219]. The developmental results here stress that such a tool has to be developmentally appropriate. Children's processing of real words on the two-image task did not predict language outcomes, but the slightly more challenging nonword condition did yield a small predictive effect. For the more difficult four-image task, individual differences were greatest and most predictive at age 3 and the range of variability decreased with age.


For a recent example, XXX found that reaction time on a 2-AFC word recognition task at 18-months predicted vocabulary and non-verbal language outcomes at 54 months in children born preterm. 

Future directions
----------------------------------------------------------------------

There are two open questions from this research. First, how does lexical inhibition change over this developmental window? The results from the first study show that phonologically and semantically similar words become more relevant during word recognition as children grow older, but I did not observe any clear changes in how quickly those words are *rejected* as possible interpretations of the input.

When does inhibition come online?

When does a new word begin to participate in lexical competition?
When would a cohort nonword start to affect processing of a known word?


Contributions
----------------------------------------------------------------------

What has this project established?





A needle in a self-organizing haystack
=======================================================================

When I give my "elevator pitch" for word recognition research, I
sometimes employ a cheeky analogy of a needle in a haystack. Imagine,
for the sake of discussion, that the information processing mechanism
behind word recognition were just a naïve table search. Think of
autocomplete on a phone or a spellchecker. Over the course of
development, children's lexicons grow larger in size and yet they get
*better* at recognizing words. Children with larger lexicons have to
find a needle in a larger haystack—yet this apparent liability is an
advantage. That is why the search analogy is naïve. Children become
better at recognizing words as they learn more words because they
extract regularities and discover similarities among words and develop
more efficient lexical representations. The haystack develops regularity
and becomes easier to search. In fact, try to pull out a single needle
and a tangle of other very similar needles come with it.

The vagueness of the phrase "more efficient lexical representations" is
something of a trap. For example, we might think like the one efficient
way to store lexical items is to posit that children lazily encode
lexical information on demand. That *underspecification* hypothesis has
been discredited by children's sensitivities to mispronunciations and
with their ability to use part-word information during word recognition.

Let us take for granted that children know the words they know in full
phonetic detail. How might learning more words make word recognition
search problem even easier? On the basis of the two studies in this
project, I think the distinction by @Leach2007 between *lexical
configuration* and *lexical engagement* is crucial. If we adopt the
analogy that the lexicon is a mental dictionary, a word's configuration
is the information found in its dictionary entry: sound, meaning,
syntactic roles, and orthography. A word's engagement is its connection
to other words, like competitors or cohorts or semantic relatives. We
know from the research into representations that a word's phonetic
configuration should be generally well-specified. What children develop
and what turns an increase in words into an advantage is lexical
engagement. The development of word recognition for preschoolers is
about engagement, children learning the connections among related words
and harnessing those similarities to their advantage.



Mechanisms
	- Start with a baseline of lexical processing: Continuous, incremental activation of candidates and cascading activation to related words.
	- Become more sensitive to similar words
		○ More lexical engagement
	- Referent selection
	- Known words
	- Why does early differences matter?
		○ Differences in associative representations (later learning is refinement) are greatest early on.
		○ Specify that we are talkinga bout familiarity with these words

Implications

	- Aim 1
		○ Children do not stop learning words.
			§ It's linguistic because of the foils.
			§ Representations of highly familiar words continue to develop.
		○ Continue to develop during preschool years.
		○ Everyone gets faster.
		○ Early differences matter more than later ones.
	- Aim 2
		○ Mastery of referent selection in a two-image format by age 4
		○ Still sensitive to mispronunciations
			§ Early penalty from mismatching information
			§ This si like a rime effect or the inverse of cohort effect
			§ Age 5 more like to treat the mispronunciation as a real word.
			§ Take advantage of rest of syllable, better at using rest of word.
			
		○ Poorer retention of mispronunciations as new words than nonwords
		○ New words that sound like known words and are presented in contexts with the known word are really hard to passively learn.
			§ Known words interfere.

Next steps
CI users and SLI users


