(PART\*) Summary
===================

My favorite analogy for word recognition is as a strange
needle-in-a-haystack problem. Let's imagine, for the sake of discussion,
that the information processing mechanism behind word recognition were
just a naïve table search. Over the course of development, children's
lexicons grow larger in size and yet they get better at recognizing
words. Children with larger lexicons have to find a needle in a larger
haystack—yet this apparent liability is an advantage. That is why the
search analogy is naïve. One explanation follows from an idea of graded
word learning: Children become better at recognizing words as they learn
more words because they extract regularities and discover similarities
among words and develop more efficient lexical representations—the
haystack develops regularity and becomes easier to search.

But there's a trap here. One promising route to efficient lexical representations is to have children lazily encode lexical information on demand. That's the idea of holistic or underspecified representations, and it is safe to say that it has been discredited by mispronunciation studies and word recognition studies. So how we take for granted that lexical representations are well specified. 

I occasionally like to describe word recognition or lexical access. 

Suppose . Then this finding is somewhat puzzling: 
Except over the course of development, children grow larger lexicons and have to find a needle in a larger haystack—yet this apparent
liability is an advantage. That is why the search analogy is naïve. One
explanation follows from the earlier described idea about graded word
learning: Children become better at recognizing words as they learn more
words because they extract regularities and discover similarities among
words and develop more efficient lexical representations—the haystack
develops regularity and becomes easier to search.
