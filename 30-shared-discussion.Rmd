(PART\*) Afterword
===================

A needle in a self-organizing haystack
=======================================================================

When I give my sales pitch for word recognition research, I sometimes
employ a cheeky analogy of a needle in a haystack. Imagine, for the sake
of discussion, that the information processing mechanism behind word
recognition were just a naïve table search. Think of autocomplete on a
phone or search engine text field. Over the course of development,
children's lexicons grow larger in size and yet they get *better* at
recognizing words. Children with larger lexicons have to find a needle
in a larger haystack—yet this apparent liability is an advantage. That
is why the search analogy is naïve. Children become better at
recognizing words as they learn more words because they extract
regularities and discover similarities among words and develop more
efficient lexical representations. The haystack develops regularity and
becomes easier to search. Try to pull out a single needle and a tangled
mess of related needles come with it.

But there's a trap here. One promising route to efficient lexical representations is to have children lazily encode lexical information on demand. That's the idea of holistic or underspecified representations, and it is safe to say that it has been discredited by mispronunciation studies and word recognition studies. So how we take for granted that lexical representations are well specified. 

How to proceed?

Leach and Samuel (2007) make a distinction between *lexical configuration* and *lexical engagement*. If we adopt the analogy that the lexicon is a mental dictionary, a word's configuration is the information found in its dictionary entry: sound, meaning, syntactic roles, and orthography. A word's engagement is its connection to other words, like competitors or cohorts or semantic relatives. Children's words are well-configured for the earliest stages of development.
