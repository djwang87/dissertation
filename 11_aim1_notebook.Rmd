Prepare and explore the data
===========================================================================

First, let's load in all the data and plot the data from each year.

```{r include = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
```

```{r helpers, message = FALSE, warnings = FALSE}
```

```{r, message = FALSE, warnings = FALSE}
looks1 <- readr::read_csv("./data-raw/rwl_timepoint1_looks.csv.gz")
looks2 <- readr::read_csv("./data-raw/rwl_timepoint2_looks.csv.gz")
looks3 <- readr::read_csv("./data-raw/rwl_timepoint3_looks.csv.gz")
looks <- bind_rows(looks1, looks2, looks3) %>% 
  filter(Version == "Standard")

resp_def <- create_response_def(
  primary = "Target",
  others = c("PhonologicalFoil", "SemanticFoil", "Unrelated"),
  elsewhere = "tracked",
  missing = NA
)

# Keep only frames from -500 to 2000 plus or minus any frames to make the 
# number of frames divisible by 3 (for binning)
times_to_keep <- looks %>% 
  distinct(Time) %>% 
  trim_to_bin_width(3, time_var = Time, key_time = 0, key_position = 2, 
                    min_time = -500, max_time = 2000) %>% 
  pull(Time) %>% 
  range()

raw_data <- looks %>% 
  filter(between(Time, times_to_keep[1], times_to_keep[2])) %>% 
  aggregate_looks(resp_def, Study + ResearchID + Time ~ GazeByImageAOI)
```

Make some plots of overall averages.

```{r raw-aim1, out.width = "50%", fig.show='hold', fig.height=3, fig.width=3}
ggplot(raw_data) + 
  aes(x = Time, y = Prop, color = Study) +
  geom_hline(size = 2, color = "white", yintercept = .25) +
  stat_summary() +
  labs(x = "Time after target onset [ms]",
       y = "Proportion looks to target",
       caption = "Mean +/- SE") +
  theme_grey(base_size = 9) +
  theme(legend.position = c(0.05, 0.95), 
        legend.justification = c(0, 1))

ggplot(raw_data) + 
  aes(x = Time, y = Prop, color = Study) +
  geom_hline(size = 2, color = "white", yintercept = .25) +
  stat_smooth() +
  labs(x = "Time after target onset [ms]",
       y = "Proportion looks to target",
       caption = "GAM Smooth") +
  theme_grey(base_size = 9) +
  theme(legend.position = c(0.05, 0.95), 
        legend.justification = c(0, 1))
```

The raw data plainly confirm hypothesis 1:

> Childrenâ€™s accuracy and efficiency of recognizing words will improve each year.

Look at a spaghetti plot...

```{r spaghetti-aim1, out.width = "100%", fig.height=2.5, fig.width=6}
ggplot(raw_data) + 
  aes(x = Time, y = Prop, group = ResearchID) +
  geom_hline(size = 2, color = "white", yintercept = .25) +
  geom_line(alpha = .15) +
  facet_grid(~ Study) +
  theme_grey(base_size = 9) +
  labs(x = "Time after target onset [ms]",
       y = "Proportion looks to target",
       caption = "Lines: Individual participants") +
  theme(legend.position = c(0.05, 0.95), 
        legend.justification = c(0, 1))
```



## Data cleaning

We use the following options for data screening.

```{r}
rules <- list(
  screening_window = c(0, 2020),
  missing_data_limit = .5,
  min_trials = 12
)
```

That is:

* Filter out bad trials. These have at least 
  `r rules$missing_data_limit * 100`% missing data between 
  `r rules$screening_window[1]` to `r rules$screening_window[2]`ms. 
* Filter out bad blocks. These have fewer than `r rules$min_trials` trials.

These are the default conventions four lab on these eyetracking experiments.

```{r}
# offset to catch frame before and after window 
# (to reflect binning boundaries)
screening_times <- looks %>% 
  distinct(Time) %>% 
  trim_to_bin_width(3, 0, 2, Time, min_time = rules$screening_window[1], 
                    max_time = rules$screening_window[2]) %>% 
  pull(Time) %>% 
  range()
screening_times

missing_data_by_trial <- looks %>% 
  filter(screening_times[1] <= Time, Time <= screening_times[2]) %>% 
  aggregate_looks(
    resp_def, 
    Study + Version + ResearchID + Basename + TrialNo ~ GazeByImageAOI) %>% 
  mutate(BadTrial = rules$missing_data_limit <= PropNA)

bad_trial_counts <- missing_data_by_trial %>% 
  count(Study, ResearchID, Basename, BadTrial) %>% 
  tidyr::spread(BadTrial, n) %>% 
  rename(n_bad = `TRUE`, n_good = `FALSE`) %>% 
  # Replace NAs with 0, in case there were 0 good trials in a block or 
  # 0 bad trials in a block
  mutate(n_bad = coalesce(n_bad, 0L),
         n_good = coalesce(n_good, 0L),
         trials = n_good + n_bad,
         prop_bad = round(n_bad / trials, 2)) 

blocks_to_drop <- bad_trial_counts %>% 
  filter(.5 <= prop_bad)
blocks_to_drop

leftover_bad_trials <- missing_data_by_trial %>% 
  anti_join(blocks_to_drop, by = c("Study", "ResearchID", "Basename")) %>% 
  filter(.5 <= PropNA)

clean_looks <- looks %>% 
  anti_join(blocks_to_drop, by = c("Study", "ResearchID", "Basename")) %>% 
  anti_join(leftover_bad_trials)
```

Do some head counts.

```{r}
screening_results <- list(Screened = clean_looks, Raw = looks) %>% 
  bind_rows(.id = "Dataset") %>% 
  distinct(Dataset, Study, ResearchID, TrialID) %>% 
  group_by(Dataset, Study) %>% 
  summarise(
    `Num Children` = n_distinct(ResearchID),
    `Num Trials` = n_distinct(TrialID))

screening_results %>% 
  knitr::kable(caption = "Eyetracking data before and after data screening")
```

Plot the data after partial data screening.

```{r}
data <- clean_looks %>% 
  filter(between(Time, times_to_keep[1], times_to_keep[2])) %>% 
  readr::write_csv("./data/aim1-screened.csv.gz") 

agg_data <- data %>% 
  aggregate_looks(resp_def, Study + ResearchID + Time ~ GazeByImageAOI)
```

We include the curves from the earlier plots in gray. The data-cleaning process 
slightly increases the average accuracy during the plateau-ed portion of the
growth curve.

```{r clean-aim1, out.width = "50%", fig.show='hold', fig.height=3, fig.width=3}
ggplot(agg_data) + 
  aes(x = Time, y = Prop, color = Study) +
  geom_hline(size = 2, color = "white", yintercept = .25) +
  stat_summary(aes(group = Study), data = raw_data, 
               color = "gray70") +
  stat_summary() +
  labs(x = "Time after target onset [ms]",
       y = "Proportion looks to target",
       caption = "Mean +/- SE") +
  theme_grey(base_size = 9) +
  theme(legend.position = c(0.05, 0.95), 
        legend.justification = c(0, 1))

ggplot(agg_data) + 
  aes(x = Time, y = Prop, color = Study) +
  geom_hline(size = 2, color = "white", yintercept = .25) +
  stat_smooth(aes(group = Study), data = raw_data, 
              color = "gray70") +
  stat_smooth() +
  labs(x = "Time after target onset [ms]",
       y = "Proportion looks to target",
       caption = "GAM smooth on partially screened data") +
  theme_grey(base_size = 9) +
  theme(legend.position = c(0.05, 0.95), 
        legend.justification = c(0, 1))
```

### Add a note about the bad version of the experiment

(_Skip for now._)

### Special case data screening

(_Skip for now._ This is where I review the participant notes and will remove 
children who have to be excluded for other reasons, like being diagnosed with a 
language disorder at TimePoint 3.)


```{r}
# stub for saving the final-final data
```


### Interim summary

* Visual evidence that group averages get faster and more reliable at looking 
  to target each year. 
  
