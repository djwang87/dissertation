@article {RWLPaper,
  author  = {Law, II, Franzo and Mahr, Tristan and Schneeberg, Alissa and Edwards, Jan R.},
  title   = {Vocabulary size and auditory word recognition in preschool children},
  journal = {Applied Psycholinguistics},
  year    = {2016},
  doi     = {10.1017/S0142716416000126},
}

@article {MPPaper,
  title   = {Effects of Vocabulary Size on Online Lexical Processing by Preschoolers},
  author  = {Law, II, Franzo and Edwards, Jan R.},
  journal = {Language Learning and Development},
  year    = {2015},
  doi     = {10.1080/15475441.2014.961066},
  volume  = {11},
  number  = {4},
  pages   = {331--355},
}

@article {Barr2008,
  author   = {Barr, Dale J.},
  title    = {Analyzing ‘visual world' eyetracking data using multilevel
              logistic regression},
  journal  = {Journal of Memory and Language},
  year     = {2008},
  doi      = {10.1016/j.jml.2007.09.002},
  number   = {4},
  pages    = {457--474},
  volume   = {59},
  abstract = {A new framework is offered that uses multilevel logistic
              regression (MLR) to analyze data from ‘visual world' eyetracking
              experiments used in psycholinguistic research. The MLR framework
              overcomes some of the problems with conventional analyses, making
              it possible to incorporate time as a continuous variable and gaze
              location as a categorical dependent variable. The multilevel
              approach minimizes the need for data aggregation and thus
              provides a more statistically powerful approach. With MLR, the
              researcher builds a mathematical model of the overall response
              curve that separates the response into different temporal
              components. The researcher can test hypotheses by examining the
              impact of independent variables and their interactions on these
              components. A worked example using MLR is provided.},
}


@book {Mirman2014,
  author    = {Mirman, Daniel},
  title     = {Growth Curve Analysis and Visualization Using {R}},
  address   = {Boca Raton, FL},
  publisher = {Chapman \& Hall/CRC},
  year      = {2014},
}

@article {Weisleder2013,
  author   = {Weisleder, Adriana and Fernald, Anne},
  title    = {Talking to children matters: early language experience strengthens processing and builds vocabulary},
  doi      = {10.1177/0956797613488145},
  journal  = {Psychological science},
  number   = {11},
  pages    = {2143--52},
  volume   = {24},
  year     = {2013},
  abstract = {Infants differ substantially in their rates of language
              growth, and slow growth predicts later academic difficulties. In this
              study, we explored how the amount of speech directed to infants in
              Spanish-speaking families low in socioeconomic status influenced the
              development of children's skill in real-time language processing and
              vocabulary learning. All-day recordings of parent-infant interactions at
              home revealed striking variability among families in how much speech
              caregivers addressed to their child. Infants who experienced more
              child-directed speech became more efficient in processing familiar words
              in real time and had larger expressive vocabularies by the age of 24
              months, although speech simply overheard by the child was unrelated to
              vocabulary outcomes. Mediation analyses showed that the effect of
              child-directed speech on expressive vocabulary was explained by infants'
              language-processing efficiency, which suggests that richer language
              experience strengthens processing skills that facilitate language
              growth.},
}

@article {WhiteMorgan2008,
  author   = {White, Katherine S. and Morgan, James L.},
  title    = {Sub-segmental detail in early lexical representations},
  year     = {2008},
  doi      = {10.1016/j.jml.2008.03.001},
  journal  = {Journal of Memory and Language},
  number   = {1},
  pages    = {114--132},
  volume   = {59},
}

@article {Swingley2002,
  author   = {Swingley, Daniel and Aslin, Richard N.},
  title    = {Lexical Neighborhoods and the Word-Form Representations of 14-Month-Olds},
  doi      = {10.1111/1467-9280.00485},
  year     = {2002},
  journal  = {Psychological Science},
  number   = {5},
  pages    = {480--484},
  volume   = {13},
  abstract = {The degree to which infants represent phonetic detail in
              words has been a source of controversy in phonology and developmental
              psychology. One prominent hypothesis holds that infants store words in a
              vague or inaccurate form until the learning of similar-sounding
              neighbors forces attention to subtle phonetic distinctions. In the
              experiment reported here, we used a visual fixation task to assess word
              recognition. We present the first evidence indicating that, in fact, the
              lexical representations of 14- and 15-month-olds are encoded in fine
              detail, even when this detail is not functionally necessary for
              distinguishing similar words in the infant's vocabulary. Exposure to
              words is sufficient for well-specified lexical representations, even
              well before the vocabulary spurt. These results suggest developmental
              continuity in infants' representations of speech: As infants begin to
              build a vocabulary and learn word meanings, they use the perceptual
              abilities previously demonstrated in tasks testing the discrimination
              and categorization of meaningless syllables.},
}

@article {Swingley2000,
  author   = {Swingley, Daniel and Aslin, Richard N.},
  title    = {Spoken word recognition and lexical representation in very young children},
  doi      = {10.1016/S0010-0277(00)00081-0},
  journal  = {Cognition},
  number   = {2},
  pages    = {147--66},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/10856741},
  volume   = {76},
  year     = {2000},
  abstract = {Although children's knowledge of the sound patterns of
              words has been a focus of debate for many years, little is known about
              the lexical representations very young children use in word recognition.
              In particular, researchers have questioned the degree of specificity
              encoded in early lexical representations. The current study addressed
              this issue by presenting 18-23-month-olds with object labels that were
              either correctly pronounced, or mispronounced. Mispronunciations
              involved replacement of one segment with a similar segment, as in
              'baby-vaby'. Children heard sentences containing these words while
              viewing two pictures, one of which was the referent of the sentence.
              Analyses of children's eye movements showed that children recognized the
              spoken words in both conditions, but that recognition was significantly
              poorer when words were mispronounced. The effects of mispronunciation on
              recognition were unrelated to age or to spoken vocabulary size. The
              results suggest that children's representations of familiar words are
              phonetically well-specified, and that this specification may not be a
              consequence of the need to differentiate similar words in production.},
}



@article {TRACE_Mispro,
  author   = {Mayor, Julien and Plunkett, Kim},
  title    = {Infant word recognition: Insights from {TRACE} simulations},
  year     = {2014},
  doi      = {10.1016/j.jml.2013.09.009},
  journal  = {Journal of Memory and Language},
  number   = {1},
  pages    = {89--123},
  volume   = {71},
  abstract = {The TRACE model of speech perception (McClelland \& Elman,
              1986) is used to simulate results from the infant word recognition
              literature, to provide a unified, theoretical framework for interpreting
              these findings. In a first set of simulations, we demonstrate how TRACE
              can reconcile apparently conflicting findings suggesting, on the one
              hand, that consonants play a pre-eminent role in lexical acquisition
              (Nespor, Pe\~{n}a \& Mehler, 2003; Nazzi, 2005), and on the other, that
              there is a symmetry in infant sensitivity to vowel and consonant
              mispronunciations of familiar words (Mani \& Plunkett, 2007). In a
              second series of simulations, we use TRACE to simulate infants' graded
              sensitivity to mispronunciations of familiar words as reported by White
              and Morgan (2008). An unexpected outcome is that TRACE fails to
              demonstrate graded sensitivity for White and Morgan's stimuli unless the
              inhibitory parameters in TRACE are substantially reduced. We explore the
              ramifications of this finding for theories of lexical development.
              Finally, TRACE mimics the impact of phonological neighbourhoods on early
              word learning reported by Swingley and Aslin (2007). TRACE offers an
              alternative explanation of these findings in terms of mispronunciations
              of lexical items rather than imputing word learning to infants. Together
              these simulations provide an evaluation of Developmental (Jusczyk, 1993)
              and Familiarity (Metsala, 1999) accounts of word recognition by infants
              and young children. The findings point to a role for both theoretical
              approaches whereby vocabulary structure and content constrain infant
              word recognition in an experience-dependent fashion, and highlight the
              continuity in the processes and representations involved in lexical
              development during the second year of life.},
}

@article {McMurray2010,
  title     = {Individual differences in online spoken word recognition: Implications for {SLI}},
  author    = {McMurray, Bob and Samelson, Vicki M and Lee, Sung Hee and Tomblin, J. Bruce},
  doi       = {10.1016/j.cogpsych.2009.06.003},
  journal   = {Cognitive Psychology},
  year      = {2010},
  volume    = {60},
  number    = {1},
  pages     = {1--39},
  publisher = {Elsevier Inc.},
}


@article {Allopenna1998,
  title   = {Tracking the Time Course of Spoken Word Recognition Using Eye Movements: Evidence for Continuous Mapping Models},
  author  = {Allopenna, Paul D. and Magnuson, James S. and Tanenhaus, Michael K.},
  year    = {1998},
  journal = {Journal of Memory and Language},
  doi     = {10.1006/jmla.1997.2558},
  volume  = {38},
  number  = {4},
  pages   = {419--439},
}


@article{Mirman2011,
abstract = {We used eye-tracking to investigate lexical processing in aphasic participants by examining the fixation time course for rhyme (e.g., carrot-. parrot) and cohort (e.g., beaker-. beetle) competitors. Broca's aphasic participants exhibited larger rhyme competition effects than age-matched controls. A re-analysis of previously reported data (Yee, Blumstein, {\&} Sedivy, 2008) confirmed that Wernicke's aphasic participants exhibited larger cohort competition effects. Individual-level analyses revealed a negative correlation between rhyme and cohort competition effect size across both groups of aphasic participants. Computational model simulations were performed to examine which of several accounts of lexical processing deficits in aphasia might account for the observed effects. Simulation results revealed that slower deactivation of lexical competitors could account for increased cohort competition in Wernicke's aphasic participants; auditory perceptual impairment could account for increased rhyme competition in Broca's aphasic participants; and a perturbation of a parameter controlling selection among competing alternatives could account for both patterns, as well as the correlation between the effects. In light of these simulation results, we discuss theoretical accounts that have the potential to explain the dynamics of spoken word recognition in aphasia and the possible roles of anterior and posterior brain regions in lexical processing and cognitive control. ?? 2011 Elsevier Inc.},
author = {Mirman, Daniel and Yee, Eiling and Blumstein, Sheila E. and Magnuson, James S.},
doi = {10.1016/j.bandl.2011.01.004},
journal = {Brain and Language},
number = {2},
pages = {53--68},
title = {{Theories of spoken word recognition deficits in Aphasia: Evidence from eye-tracking and computational modeling}},
volume = {117},
year = {2011}
}


@article {TRACE,
abstract = {We describe a model called the TRACE model of speech perception. The model is based on the principles of interactive activation. Information processing takes place through the excitatory and inhibitory interactions of a large number of simple processing units, each working continuously to update its own activation on the basis of the activations of other units to which it is connected. The model is called the TRACE model because the network of units forms a dynamic pro- cessing structure called “the Trace,” which serves at once as the perceptual processing mechanism and as the system's working memory. The model is in- stantiated in two simulation programs. TRACE 1. described in detail elsewhere. deals with short segments of real speech, and suggests a mechanism for coping with the fact that the cues to the identity of phonemes vary as a function of context. TRACE II, the focus of this article, simulates a large number of empirical findings on the perception of phonemes and words and on the interactions of phoneme and word perception. At the phoneme level, TRACE II simulates the influence of lexical information on the identification of phonemes and accounts for the fact that lexical effects are found under certain conditions but not others. The model also shows how knowledge of phonological constraints can be em- bodied in particular lexical items but can still be used to influence processing of novel, nonword utterances. The model also exhibits categorical perception and The the ability to trade cues off against each other in phoneme identification. At the word level, the model captures the major positive feature of Marslen-Wilson's COHORT model of speech perception, in that it shows immediate sensitivity to information favoring one word or set of words over others. At the same time, it overcomes a difftculty with the COHORT model: it can recover from underspec- itication or mispronunciation of a word's beginning. TRACE II also uses lexical information to segment a stream of speech into a sequence of words and to find word beginnings and endings, and it simulates a number of recent findings related to these points. The TRACE model has some limitations, but we believe it is a step toward a psychologically and computationally adequate model of the process of speech perception.},
author = {McClelland, James L. and Elman, Jeffrey L.},
doi = {10.1016/0010-0285(86)90015-0},
journal = {Cognitive Psychology},
number = {1},
pages = {1--86},
title = {{The TRACE model of speech perception}},
volume = {18},
year = {1986}
}

@article{Morgan2015,
abstract = {Data were analyzed from a population-based, longitudinal sample of 8,650 U.S. children to (a) identify factors associated with or predictive of oral vocabulary size at 24 months of age and (b) evaluate whether oral vocabulary size is uniquely predictive of academic and behavioral functioning at kindergarten entry. Children from higher socioeconomic status households, females, and those experiencing higher quality parenting had larger oral vocabularies. Children born with very low birth weight or from households where the mother had health problems had smaller oral vocabularies. Even after extensive covariate adjustment, 24-month-old children with larger oral vocabularies displayed greater reading and mathematics achievement, increased behavioral self-regulation, and fewer externalizing and internalizing problem behaviors at kindergarten entry.},
author = {Morgan, Paul L. and Farkas, George and Hillemeier, Marianne M. and Hammer, Carol Scheffner and Maczuga, Steve},
doi = {10.1111/cdev.12398},



journal = {Child Development},
number = {5},
pages = {1351--1370},

title = {{24-Month-Old Children With Larger Oral Vocabularies Display Greater Academic and Behavioral Functioning at Kindergarten Entry}},
volume = {86},
year = {2015}
}

@article{Marslen-Wilson1989,
abstract = {Approaches to spoken word recognition differ in the importance they assign to word onsets during lexical access. This research contrasted the hypothesis that lexical access is strongly directional with the hypothesis that word onsets are less important than the overall goodness of fit between input and lexical form. A cross-modal priming technique was used to investigate the extent to which a rhyme prime (a prime that differs only in its first segment from the word that is semantically associated with the visual probe) is as effective a prime as the original word itself. Earlier research had shown that partial primes that matched from word onset were very effective cross-modal primes. The present results show that, irrespective of whether the rhyme prime was a real word or not, and irrespective of the amount of overlap between the rhyme prime and the original word, the rhymes are much less effective primes than the full word. In fact, no overall priming effect could be detected at all except under conditions in which the competitor environment was very sparse. This suggests that word onsets do have a special status in the lexical access of spoken words.},
author = {Marslen-Wilson, William D. and Zwitserlood, Pienie},
doi = {10.1037/0096-1523.15.3.576},



journal = {Journal of Experimental Psychology: Human Perception and Performance},
number = {3},
pages = {576--585},
title = {{Accessing spoken words: The importance of word onsets.}},
volume = {15},
year = {1989}
}

@incollection {Magnuson2013,
  author = {Magnuson, James S. and Mirman, Daniel and Myers, Emily},
  booktitle = {The Oxford Handbook of Cognitive Psychology},
  doi = {10.1093/oxfordhb/9780195376746.013.0027},
  editor = {Daniel Reisberg},
  publisher = {Oxford University Press},
  title = {Spoken Word Recognition},
  year = {2013}
}

@incollection{Magnuson2012_Models,
  address = {Cambridge},
  author = {Magnuson, James S. and Mirman, Daniel and Harris, Harlan D.},
  booktitle = {The Cambridge Handbook of Psycholinguistics},
  chapter = {5},
  editor = {Spivey, Michael J. and McRae, Ken and Joanisse, Marc F.},
  pages = {76--103},
  publisher = {Cambridge University Press},
  series = {Cambridge Handbooks in Psychology},
  title = {Computational Models of Spoken Word Recognition},
  year = {2012}
}



@article {jTRACE,
abstract = {This article describes jTRACE, a freely available, cross-platform Java reimplementation of the TRACE model of spoken word recognition. The goal of the reimplementation is to facilitate the use of simulations by researchers who may not have the skills or time necessary to use or extend the original C implementation. In this article, we report a large-scale validation project, in which we have replicated a number of important previous simulations, and then we describe several new features in jTRACE designed to help researchers conduct original TRACE research, as well as to replicate earlier findings. These features include visualization tools, powerful scripting, built-in data graphing, adjustable levels of external and internal noise, and adjustable lexical characteristics, such as frequency of occurrence. Functions for saving and reloading entire simulations facilitate archiving, sharing, and replication and also make jTRACE ideal for educational use, since it comes bundled with several important simulations. jTRACE can be downloaded from magnuson.psy.uconn.edu/jtrace.},
author = {Strauss, Ted J. and Harris, Harlan D. and Magnuson, James S.},
doi = {10.3758/BF03192840},



journal = {Behavior Research Methods},
number = {1},
pages = {19--30},

title = {{jTRACE}: A reimplementation and extension of the {TRACE} model of speech perception and spoken word recognition},
volume = {39},
year = {2007}
}

@article {MarchmanFernald2008,
  author   = {Marchman, Virginia A. and Fernald, Anne},
  title    = {Speed of word recognition and vocabulary knowledge in infancy predict cognitive and language outcomes in later childhood},
  doi      = {10.1111/j.1467-7687.2008.00671.x},
  journal  = {Developmental Science},
  number   = {3},
  pages    = {F9--16},
  volume   = {11},
  year     = {2008},
  abstract = {The nature of predictive relations between early language
              and later cognitive function is a fundamental question in research on
              human cognition. In a longitudinal study assessing speed of language
              processing in infancy, Fernald, Perfors and Marchman (2006) found that
              reaction time at 25 months was strongly related to lexical and
              grammatical development over the second year. In this follow-up study,
              children originally tested as infants were assessed at 8 years on
              standardized tests of language, cognition, and working memory. Speed of
              spoken word recognition and vocabulary size at 25 months each accounted
              for unique variance in linguistic and cognitive skills at 8 years,
              effects that were attributable to strong relations between both infancy
              measures and working memory. These findings suggest that processing
              speed and early language skills are fundamental to intellectual
              functioning, and that language development is guided by learning and
              representational principles shared across cognitive and linguistic
              domains.},
}

@article {Fernald2012,
  author   = {Fernald, Anne and Marchman, Virginia A.},
  title    = {Individual differences in lexical processing at 18 months predict
              vocabulary growth in typically developing and late-talking toddlers},
  doi      = {10.1111/j.1467-8624.2011.01692.x},
  journal  = {Child Development},
  number   = {1},
  pages    = {203--222},
  volume   = {83},
  year     = {2012},
  abstract = {Using online measures of familiar word recognition in the
              looking-while-listening procedure, this prospective longitudinal study
              revealed robust links between processing efficiency and vocabulary
              growth from 18 to 30 months in children classified as typically
              developing (n= 46) and as "late talkers" (n= 36) at 18 months. Those
              late talkers who were more efficient in word recognition at 18 months
              were also more likely to "bloom," showing more accelerated vocabulary
              growth over the following year, compared with late talkers less
              efficient in early speech processing. Such findings support the emerging
              view that early differences in processing efficiency evident in infancy
              have cascading consequences for later learning and may be continuous
              with individual differences in language proficiency observed in older
              children and adults.},
}

@article {Swingley1999,
  title    = {Continuous processing in word recognition at 24 months},
  author   = {Swingley, Daniel and Pinto, John P and Fernald, Anne},
  doi      = {10.1016/S0010-0277(99)00021-9},
  journal  = {Cognition},
  number   = {2},
  pages    = {73--108},
  volume   = {71},
  year     = {1999},
  abstract = {Speech processing in adults in continuous: as
              acoustic-phonetic information is heard, listeners' interpretation of the
              speech is updated incrementally. The present studies used a visual
              fixation technique to examine whether young children also interpret
              speech continuously. In Experiments 1 and 2, 24-month-old children
              looked at visual displays while hearing sentences. Sentences each
              contained a target word labeling one of the two displayed pictures.
              Children's latency to fixate the labeled picture was measured.
              Children's responses were delayed when the competing distractor
              picture's label overlapped phonetically with the target at onset
              (dog-doll), but not when the pictures' labels rhymed (ball-doll),
              showing that children monitored the speech stream incrementally for
              acoustic-phonetic information specifying the correct picture. In
              Experiment 3, adults' responses in the same task were found to be very
              similar to those of the 24-month-olds. This research shows that by 24
              months, children can interpret speech continuously.},
}

@article {Fernald2001,
  title    = {When half a word is enough: infants can recognize spoken words using partial phonetic information},
  author   = {Fernald, Anne and Swingley, Daniel and Pinto, John P.},
  doi      = {10.1111/1467-8624.00331},
  journal  = {Child development},
  number   = {4},
  pages    = {1003--15},
  volume   = {72},
  year     = {2001},
  abstract = {Adults process speech incrementally, rapidly identifying
              spoken words on the basis of initial phonetic information sufficient to
              distinguish them from alternatives. In this study, infants in the second
              year also made use of word-initial information to understand fluent
              speech. The time course of comprehension was examined by tracking
              infants' eye movements as they looked at pictures in response to
              familiar spoken words, presented both as whole words in intact form and
              as partial words in which only the first 300 ms of the word was heard.
              In Experiment 1, 21-month-old infants (N = 32) recognized partial words
              as quickly and reliably as they recognized whole words; in Experiment 2,
              these findings were replicated with 18-month-old infants (N = 32).
              Combining the data from both experiments, efficiency in spoken word
              recognition was examined in relation to level of lexical development.
              Infants with more than 100 words in their productive vocabulary were
              more accurate in identifying familiar words than were infants with less
              than 60 words. Grouped by response speed, infants with faster mean
              reaction times were more accurate in word recognition and also had
              larger productive vocabularies than infants with slower response
              latencies. These results show that infants in the second year are
              capable of incremental speech processing even before entering the
              vocabulary spurt, and that lexical growth is associated with increased
              speed and efficiency in understanding spoken language.},
}

@article {Mahr2015,
  title    = {Anticipatory coarticulation facilitates word recognition
              in toddlers},
  author   = {Mahr, Tristan and McMillan, Brianna T. M. and Saffran, Jenny R.
              and {Ellis Weismer}, Susan and Edwards, Jan},
  year     = {2015},
  journal  = {Cognition},
  pages    = {345--350},
  volume   = {142},
  doi      = {10.1016/j.cognition.2015.05.009},
  url      = {http://doi.org/10.1016/j.cognition.2015.05.009},
  abstract = {Children learn from their environments and their caregivers.
              To capitalize on learning opportunities, young children have to
              recognize familiar words efficiently by integrating contextual
              cues across word boundaries. Previous research has shown that
              adults can use phonetic cues from anticipatory coarticulation
              during word recognition. We asked whether 18--24 month-olds (n=29)
              used coarticulatory cues on the word "the" when recognizing the
              following noun. We performed a looking-while-listening eyetracking
              experiment to examine word recognition in neutral versus
              facilitating coarticulatory conditions. Participants looked to the
              target image significantly sooner when the determiner contained
              facilitating coarticulatory cues. These results provide the first
              evidence that novice word-learners can take advantage of
              anticipatory sub-phonemic cues during word recognition.}
}

@article{Lew-Williams2007,
abstract = {All nouns in Spanish have grammatical gender, with obligatory gender marking on preceding articles (e.g., la and el, the feminine and masculine forms of "the," respectively). Adult native speakers of languages with grammatical gender exploit this cue in on-line sentence interpretation. In a study investigating the early development of this ability, Spanish-learning children (34-42 months) were tested in an eye-tracking procedure. Presented with pairs of pictures with names of either the same grammatical gender (la pelota, "ball [feminine]"; la galleta, "cookie [feminine]") or different grammatical gender (la pelota; el zapato, "shoe [masculine]"), they heard sentences referring to one picture (Encuentra la pelota, "Find the ball"). The children were faster to orient to the referent on different-gender trials, when the article was potentially informative, than on same-gender trials, when it was not, and this ability was correlated with productive measures of lexical and grammatical competence. Spanish-learning children who can speak only 500 words already use gender-marked articles in establishing reference, a processing advantage characteristic of native Spanish-speaking adults.},
author = {Lew-Williams, Casey and Fernald, Anne},
doi = {10.1111/j.1467-9280.2007.01871.x},


journal = {Psychological Science},


number = {3},
pages = {193--8},

title = {Young children learning {Spanish} make rapid use of grammatical gender in spoken word recognition},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3206966{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {18},
year = {2007}
}


@article{McMurray2012,
abstract = {Classic approaches to word learning emphasize referential ambiguity: In naming situations, a novel word could refer to many possible objects, properties, actions, and so forth. To solve this, researchers have posited constraints, and inference strategies, but assume that determining the referent of a novel word is isomorphic to learning. We present an alternative in which referent selection is an online process and independent of long-term learning. We illustrate this theoretical approach with a dynamic associative model in which referent selection emerges from real-time competition between referents and learning is associative (Hebbian). This model accounts for a range of findings including the differences in expressive and receptive vocabulary, cross-situational learning under high degrees of ambiguity, accelerating (vocabulary explosion) and decelerating (power law) learning, fast mapping by mutual exclusivity (and differences in bilinguals), improvements in familiar word recognition with development, and correlations between speed of processing and learning. Together it suggests that (a) association learning buttressed by dynamic competition can account for much of the literature; (b) familiar word recognition is subserved by the same processes that identify the referents of novel words (fast mapping); (c) online competition may allow the children to leverage information available in the task to augment performance despite slow learning; (d) in complex systems, associative learning is highly multifaceted; and (e) learning and referent selection, though logically distinct, can be subtly related. It suggests more sophisticated ways of describing the interaction between situation- and developmental-time processes and points to the need for considering such interactions as a primary determinant of development. (PsycINFO Database Record (c) 2012 APA, all rights reserved).},
author = {McMurray, Bob and Horst, Jessica S. and Samuelson, Larissa K.},
doi = {10.1037/a0029872},
journal = {Psychological Review},
number = {4},
pages = {831--877},
title = {Word learning emerges from the interaction of online referent selection and slow associative learning},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23088341 http://doi.apa.org/getdoi.cfm?doi=10.1037/a0029872},
volume = {119},
year = {2012}
}

@article {Huang2011,
  title     = {Cascading activation across levels of representation in children's lexical processing},
  author    = {Huang, Yi Ting and Snedeker, Jesse},
  journal   = {Journal of Child Language},
  volume    = {38},
  number    = {03},
  pages     = {644--661},
  year      = {2011},
  publisher = {Cambridge Univ Press},
  doi       = {10.1017/S0305000910000206},
}

@article {EllisWeismer2016,
  author = {{Ellis Weismer}, Susan and Haebig, Eileen and Edwards, Jan R. and Saffran, Jenny R. and Venker, Courtney E.},
  doi = {10.1007/s10803-016-2926-y},
  journal = {Journal of Autism and Developmental Disorders},
  number = {12},
  pages = {3755--3769},
  publisher = {Springer US},
  title = {Lexical Processing in Toddlers with {ASD}: Does Weak Central Coherence Play a Role?},
  volume = {46},
  year = {2016}
}


@article {Mani2010,
abstract = {Do infants implicitly name visually fixated objects whose names are known, and does this information influence their preference for looking at other objects? We presented 18-month-old infants with a picture-based phonological priming task and examined their recognition of named targets in primed (e.g., dog-door) and unrelated (e.g., dog-boat) trials. Infants showed better recognition of the target object in primed than in unrelated trials across three measures. As the prime image was never explicitly named during the experiment, the only explanation for the systematic influence of the prime image on target recognition is that infants, like adults, can implicitly name visually fixated images and that these implicitly generated names can prime infants' subsequent responses in a paired visual-object spoken-word-recognition task.},
author = {Mani, Nivedita and Plunkett, Kim},
doi = {10.1177/0956797610373371},
journal = {Psychological Science},
number = {7},
pages = {908--913},
title = {In the infant's mind's ear: evidence for implicit naming in 18-month-olds},
volume = {21},
year = {2010}
}


@article {Mani2012,
abstract = {What are the processes underlying word recognition in the toddler lexicon? Work with adults suggests that, by 5-years of age, hearing a word leads to cascaded activation of other phonologically, semantically and phono-semantically related words (Huang {\&} Snedeker, 2010; Marslen-Wilson {\&} Zwitserlood, 1989). Given substantial differences in children's sensitivity to phonological and semantic relationships between words in the first few years of life (Arias-Trejo {\&} Plunkett, 2010; Newman, Samuelson, {\&} Gupta, 2009; Storkel {\&} Hoover, 2012), the current set of experiments investigated whether children younger than five also show such phono-semantic priming. Using a picture-priming task, Experiments 1 and 2 presented 2-year-olds with phono-semantically related prime-target pairs, where the label for the prime image is phonologically related (Experiment 1 – onset CV overlap, Experiment 2 – rhyme VC overlap) to a semantic associate of the target label. Across both experiments, toddlers recognised a word faster when this was preceded by a phono- semantically related prime relative to an unrelated prime. Overall, the results provide strong evidence that word recognition involves cascaded processing of phono-semantically related words by 2-years of age. ?},
author = {Mani, Nivedita and Durrant, Samantha and Floccia, Caroline},
doi = {10.1016/j.jml.2012.03.003},
journal = {Journal of Memory and Language},
number = {4},
pages = {612--622},
publisher = {Elsevier Inc.},
title = {Activation of phonological and semantic codes in toddlers},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0749596X12000253},
volume = {66},
year = {2012}
}

@article {Kapnoula2015,
abstract = {It is well known that familiar words inhibit each other during spoken word recognition. However, we do not know how and under what circumstances newly learned words become integrated with the lexicon in order to engage in this competition. Previous work on word learning has highlighted the importance of offline consolidation (Gaskell {\&} Dumay, 2003) and meaning (Leach {\&} Samuel, 2007) to establish this integration. In two experiments we test the necessity of these factors by examining the inhibition between newly learned items and familiar words immediately after learning. Participants learned a set of nonwords without meanings in active (Experiment 1) or passive (Experiment 2) exposure paradigms. After training, participants performed a visual world paradigm task to assess inhibition from these newly learned items. An analysis of participants' fixations suggested that the newly learned words were able to engage in competition with known words without any consolidation.},
author = {Kapnoula, Efthymia C. and Packard, Stephanie and Gupta, Prahlad and McMurray, Bob},
doi = {10.1016/j.cognition.2014.09.007},
journal = {Cognition},
pages = {85--99},
publisher = {Elsevier B.V.},
title = {Immediate lexical integration of novel word forms},
url = {http://dx.doi.org/10.1016/j.cognition.2014.09.007},
volume = {134},
year = {2015}
}

@article {Cristia2014_Review,
  title   = {Predicting individual variation in language from infant speech perception measures},
  author  = {Cristia, Alejandrina and Seidl, Amanda and Junge, Caroline and Soderstrom, Melanie and Hagoort, Peter},
  journal = {Child Development},
  volume  = {85},
  number  = {4},
  pages   = {1330--1345},
  year    = {2014},
  doi     = {10.1111/cdev.12193}
}

@book {HartRisley,
  title     = {Meaningful differences in the everyday experience of young {American} children},
  author    = {Hart, Betty and Risley, Todd R.},
  year      = {1995},
  address   = {Baltimore},
  publisher = {P.H. Brookes},
}

@article {Hoff2003,
  title     = {The specificity of environmental influence: Socioeconomic status affects early vocabulary development via maternal speech},
  author    = {Hoff, Erika},
  journal   = {Child Development},
  volume    = {74},
  number    = {5},
  pages     = {1368--1378},
  year      = {2003},
  url       = {http://dx.doi.org/10.1111/1467-8624.00612},
  doi       = {10.1111/1467-8624.00612},
  publisher = {Blackwell Publishing},
  abstract  = {The hypothesis was tested that children whose families
               differ in socioeconomic status (SES) differ in their rates of productive
               vocabulary development because they have different language-learning
               experiences. Naturalistic interaction between 33 high-SES and 30 mid-SES
               mothers and their 2-year-old children was recorded at 2 time points 10
               weeks apart. Transcripts of these interactions provided the basis for
               estimating the growth in children's productive vocabularies between the
               first and second visits and properties of maternal speech at the first
               visit. The high-SES children grew more than the mid-SES children in the
               size of their productive vocabularies. Properties of maternal speech
               that differed as a function of SES fully accounted for this difference.
               Implications of these findings for mechanisms of environmental influence
               on child development are discussed.},
}


@article{Tsao2004,
  title    = {Speech perception in infancy predicts language development in the
              second year of life: a longitudinal study},
  author   = {Tsao, Feng-Ming and Liu, Huei-Mei and Kuhl, Patricia K.},
  year     = {2004},
  doi      = {10.1111/j.1467-8624.2004.00726.x},
  journal  = {Child Development},
  volume   = {75},
  number   = {4},
  pages    = {1067--1084},
  abstract = {Infants' early phonetic perception is hypothesized to play
              an important role in language development. Previous studies
              have not assessed this potential link in the first 2 years
              of life. In this study, speech discrimination was measured
              in 6-month-old infants using a conditioned head-turn task.
              At 13, 16, and 24 months of age, language development
              was assessed in these same children using the MacArthur
              Communicative Development Inventory. Results demonstrated
              significant correlations between speech perception at 6
              months of age and later language (word understanding, word
              production, phrase understanding). The finding that speech
              perception performance at 6 months predicts language at 2
              years supports the idea that phonetic perception may play an
              important role in language acquisition.},
}

@article {Kuhl2008,
  title    = {Phonetic learning as a pathway to language: new data and native
              language magnet theory expanded ({NLM-e})},
  author   = {Kuhl, Patricia K. and Conboy, B T and Coffey-Corina, S and
              Padden, D and Rivera-Gaxiola, M and Nelson, T},
  year     = {2008},
  doi      = {10.1098/rstb.2007.2154},
  journal  = {Philosophical Transactions of the Royal Society B: Biological
              Sciences},
  volume   = {363},
  number   = {1493},
  pages    = {979--1000},
  abstract = {Infants' speech perception skills show a dual change
              towards the end of the first year of life. Not only does
              non-native speech perception decline, as often shown, but
              native language speech perception skills show improvement,
              reflecting a facilitative effect of experience with native
              language. The mechanism underlying change at this point
              in development, and the relationship between the change in
              native and non-native speech perception, is of theoretical
              interest. As shown in new data presented here, at the cusp
              of this developmental change, infants' native and non-native
              phonetic perception skills predict later language ability,
              but in opposite directions. Better native language skill
              at 7.5 months of age predicts faster language advancement,
              whereas better non-native language skill predicts slower
              advancement. We suggest that native language phonetic
              performance is indicative of neural commitment to the
              native language, while non-native phonetic performance
              reveals uncommitted neural circuitry. This paper has three
              goals: (i) to review existing models of phonetic perception
              development, (ii) to present new event-related potential
              data showing that native and non-native phonetic perception
              at 7.5 months of age predicts language growth over the next
              2 years, and (iii) to describe a revised version of our
              previous model, the native language magnet model, expanded
              (NLM-e). NLM-e incorporates five new principles. Specific
              testable predictions for future research programmes are
              described.},
}



@misc {OSF_Statement,
  title     = {Standard Reviewer Statement for Disclosure of Sample, Conditions, Measures, and Exclusions},
  author    = {Nosek, Brian A. and Simonsohn, Uri and Moore, Don A. and
               Nelson, Leif D. and Simmons, Joseph P. and Sallans, Andrew and
               LeBel, Etienne P.},
  year      = {2014},
  month     = {Feb},
  url       = {https://osf.io/hadz3},
  publisher = {Open Science Framework},
}


@Manual {eyetrackingR,
  title  = {{eyetrackingR}},
  author = {Jacob Dink and Brock Ferguson},
  year   = {2016},
  note   = {{R} package version 0.1.6},
  url    = {http://www.eyetracking-R.com},
}



@article {Oleson2015,
  title={Detecting time-specific differences between temporal nonlinear curves: Analyzing data from the visual world paradigm},
  author={Oleson, Jacob J. and Cavanaugh, Joseph .E and McMurray, Bob and Brown, Grant},
  journal={Statistical methods in medical research},
  doi     = {10.1177/0962280215607411},
  year={2015},
}

@book {EVT2,
  author    = {Williams, Kathleen T},
  title     = {{Expressive Vocabulary Test, Second Edition}},
  year      = {2007},
  publisher = {Pearson Education},
  address   = {San Antonio, TX},
}

@book {PPVT4,
  author    = {Dunn, Lloyd M and Dunn, Douglas M},
  title     = {{Peabody Picture Vocabulary Test, Fourth Edition}},
  year      = {2007},
  publisher = {Pearson Education},
  address   = {San Antonio, TX},
}

@article {ProtoMinPair,
  title   = {Factors Affecting Articulation Skills In Children With
             Velocardiofacial Syndrome and Children With Cleft Palate or
             Velopharyngeal Dysfunction: A Preliminary Report},
  author  = {Adriane L. Baylis and Benjamin Munson and Karlind T. Moller},
  journal = {The Cleft Palate-Craniofacial Journal},
  volume  = {45},
  number  = {2},
  pages   = {193-207},
  year    = {2008},
  doi     = {10.1597/06-012.1},
}

@article {Rvachew2006,
  title     = {Longitudinal predictors of implicit phonological awareness
               skills},
  author    = {Rvachew, Susan},
  journal   = {American Journal of Speech-Language Pathology},
  volume    = {15},
  number    = {2},
  pages     = {165--176},
  year      = {2006},
  publisher = {ASHA},
  doi       = {10.1044/1058-0360(2006/016)}
}

@book {CTOPP2,
  title     = {{Comprehensive Test of Phonological Processing, Second Edition}},
  author    = {Richard Wagner and Joseph Torgesen and Carol Rashotte and
               Nils A. Pearson},
  year      = {2013},
  publisher = {PRO-ED},
  address   = {Austin, TX},
}

@book {GFTA2,
  author    = {Goldman, Ronald and Fristoe, Macalyne},
  title     = {{Goldman-Fristoe Test of Articulation, Second Edition}},
  year      = {2000},
  publisher = {Pearson},
  address   = {Minneapolis, MN},
}

@book{RethinkingBook,
  title={Statistical Rethinking: A {Bayesian} Course with Examples in {R} and {Stan}},
  author    = {Richard McElreath},
  year      = {2016},
  publisher = {CRC Press/Taylor \& Francis Group},
  address   = {Boca Raton, FL},
}

@book {GelmanHill,
  title={Data Analysis Using Regression and Multilevel/Hierarchical Models},
  author    = {Gelman, Andrew and Hill, Jennifer},
  year      = {2007},
  publisher = {Cambridge University Press},
  address   = {New York},
}

@book {kruschke2015doing,
  title={Doing {Bayesian} Data Analysis: A Tutorial with {R}, {JAGS}, and {Stan}},
  year      = {2015},
  publisher = {Academic Press},
  author={Kruschke, John K.},
  address   = {Amsterdam},
  edition={2},
}

@book {Luce1959,
  author    =  {Luce, R. Duncan},
  title     = {Individual choice behavior},
  year      = {1959},
  publisher = {Wiley},
  address   = {New York},
}

@article {Luce2008,
  author  = {Luce, R. Duncan},
  title   = {{L}uce's choice axiom},
  year    = {2008},
  JOURNAL = {Scholarpedia},
  VOLUME  = {3},
  NUMBER  = {12},
  PAGES   = {8077},
  DOI     = {10.4249/scholarpedia.8077},
  NOTE    = {revision \#121550}
}

@article{Soskuthy2017,
abstract = {This is a hands-on introduction to Generalised Additive Mixed Models (GAMMs) in the context of linguistics with a particular focus on dynamic speech analysis (e.g. formant contours, pitch tracks, diachronic change, etc.). The main goal is to explain some of the main ideas underlying GAMMs, and to provide a practical guide to frequentist significance testing using these models. The introduction covers a range of topics including basis functions, the smoothing penalty, random smooths, difference smooths, smooth interactions, model comparison and autocorrelation. It is divided into two parts. The first part looks at what GAMMs are, how they work and why/when we should use them. Although the reader can replicate some of the example analyses in this section, this is not essential. The second part is a tutorial introduction that illustrates the process of fitting and evaluating GAMMs in the R statistical software environment, and the reader is strongly encouraged to work through the examples on their own machine.},
  archivePrefix = {arXiv},
  arxivId       = {1703.05339},
author = {S{\'{o}}skuthy, M{\'{a}}rton},
  eprint        = {1703.05339},
title = {{Generalised additive mixed models for dynamic analysis in linguistics: a practical introduction}},
url = {http://arxiv.org/abs/1703.05339},
year = {2017}
}

@book {Wood2017,
  title     = {Generalized Additive Models: An Introduction with {R}},
  author    = {Wood, Simon N.},
  edition   = {2},
  series    = {Chapman \& Hall/CRC Texts in Statistical Science},
  year={2017},
  publisher={CRC Press}
}

@misc {itsadug,
  title  = {{itsadug}: Interpreting Time Series and Autocorrelated
            Data Using GAMMs},
  author = {Jacolien {van Rij} and Martijn Wieling and R. Harald
    Baayen and Hedderik {van Rijn}},
  year   = {2017},
  note = {R package version 2.3},
}
