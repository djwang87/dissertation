Development of referent selection {#real-nonword-selection}
=======================================================================

```{r, include = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r helpers, message = FALSE, warning = FALSE}
```

```{r, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)
```



```{r load-aim2-nw-data, include = FALSE}
constants$cap_emp_and_draw <- 
  "Intervals: Empirical mean ± SE. Lines: 100 posterior means."

d <- readr::read_csv("./data/aim2-model-ready.csv.gz") %>% 
  filter(!is.na(Bias_Fam)) %>% 
  filter(300 <= Time) %>% 
  select(-starts_with("ot")) %>% 
  polypoly::poly_add_columns(
    Time, degree = 3, scale_width = 1, prefix = "ot")

# Flip things so that the nonword and real-word curves go upward
d_r_ui <- d %>% 
  filter(Condition == "real", Bias_Fam == "Unfamiliar") %>% 
  mutate(elog = empirical_logit(Target, Distractor))

d_bias_target <- tibble::tribble(
  ~Condition, ~Bias_Fam,   ~Bias_Target,
  "nonsense", "Familiar",   "Distractor",
  "nonsense", "Unfamiliar", "Target",
  "real",     "Familiar",   "Target",
  "real",     "Unfamiliar", "Distractor")

d_r_nw_vs <- d %>% 
  select(-Primary, -.response_def, -Prop, -PropSE) %>% 
  filter(Condition != "MP") %>% 
  rename(Unfamiliar = Distractor, Familiar = Target) %>% 
  mutate(
    Target = ifelse(Condition == "nonsense", Unfamiliar, Familiar), 
    Distractor = ifelse(Condition == "nonsense", Familiar, Unfamiliar),
    Trials = Target + Distractor) %>% 
  left_join(d_bias_target) %>% 
  mutate(elog = empirical_logit(Target, Distractor))

d_r_nw_dis <- d_r_nw_vs %>% 
  filter(Bias_Target == "Distractor")

study_child_with_empty_cells <- d_r_nw_dis %>% 
  filter(Trials < 4) %>% 
  distinct(Study, ResearchID)

study_counts <- study_child_with_empty_cells %>% 
  count(Study) %>% 
  split(.$Study) %>% 
  lapply(pull, n) %>% 
  set_names(stringr::str_replace, "TimePoint", "T")

d_r_nw_dis <- d_r_nw_dis %>% 
  anti_join(study_child_with_empty_cells)
```

```{r load-aim2-nw-models, include = FALSE}
library(brms)
library(bayesplot)
theme_set(theme_teej())

d_r_nw_dis <- readr::read_rds("./data/aim2-real-vs-nw-modeled-data.rds.gz") 

d_tp1 <- d_r_nw_dis %>%
  filter(Study == "TimePoint1") 

d_tp2 <- d_r_nw_dis %>%
  filter(Study == "TimePoint2") 

d_tp3 <- d_r_nw_dis %>%
  filter(Study == "TimePoint3") 

m_tp1 <- readr::read_rds("./data/aim2-real-vs-nw-tp1.rds.gz")
m_tp2 <- readr::read_rds("./data/aim2-real-vs-nw-tp2.rds.gz")
m_tp3 <- readr::read_rds("./data/aim2-real-vs-nw-tp3.rds.gz")

peaks <- readr::read_rds("./data/aim2-real-vs-nw-all-peaks.rds.gz")
```

```{r}
effects <- list(tp1 = m_tp1, tp2 = m_tp2, tp3 = m_tp3) %>% 
  lapply(as.matrix) %>% 
  purrr::map_df(
    mcmc_intervals_data, 
    pars = c("b_Intercept", "b_ot1", "b_Conditionreal", "b_ot1:Conditionreal"), 
    prob = 0.5, 
    prob_outer = 0.9, 
    .id = "model")

r_ot0_uis <- effects %>% 
  filter(parameter == "b_Conditionreal") %>% 
  split(.$model) %>% 
  fmt_inline_median_interval() %>% 
  add_ui_slug_to_first("90%&nbsp;UI: ")

r_ot1_uis <- effects %>% 
  filter(parameter == "b_ot1:Conditionreal") %>% 
  split(.$model) %>% 
  fmt_inline_median_interval()
```

```{r}
percent_diff <- function(new, old) {
  # A change from 100 to 80 is (80 - 100) / 100 = -20 / 100 = -20% change
  (new - old) / old
}

# m_tp1
pull_samples <- . %>% 
  posterior_samples(pars = "^b_") %>% 
  transmute(
    b_Nonword_Intercept = b_Intercept,
    b_Real_Intercept = b_Intercept + b_Conditionreal,
    b_Nonword_ot1 = b_ot1,
    b_Real_ot1 = b_ot1 + `b_ot1:Conditionreal`,
    b_Nonword_ot2 = b_ot2,
    b_Real_ot2 = b_ot2 + `b_ot2:Conditionreal`,
    b_Nonword_ot3 = b_ot3,
    b_Real_ot3 = b_ot3 + `b_ot3:Conditionreal`,
    b_Nonword_Intercept_Prop = plogis(b_Nonword_Intercept),
    b_Real_Intercept_Prop = plogis(b_Real_Intercept),
    d_NonwordvReal_Prop = b_Nonword_Intercept_Prop - b_Real_Intercept_Prop,
    neg_d_NonwordvReal_Prop = d_NonwordvReal_Prop * -1,
    per_d_NonwordvReal_Prop = percent_diff(
      b_Nonword_Intercept_Prop, 
      b_Real_Intercept_Prop),
    d_NonwordvReal_ot1 = b_Nonword_ot1 - b_Real_ot1,
    neg_d_NonwordvReal_ot1 = d_NonwordvReal_ot1 * -1,
    per_d_NonwordvReal_ot1 = percent_diff(b_Nonword_ot1, b_Real_ot1),
    neg_per_d_NonwordvReal_ot1 = -percent_diff(b_Nonword_ot1, b_Real_ot1),
    d_NonwordvReal_ot2 = b_Nonword_ot2 - b_Real_ot2,
    neg_d_NonwordvReal_ot2 = d_NonwordvReal_ot2 * -1,
    per_d_NonwordvReal_ot2 = percent_diff(b_Nonword_ot2, b_Real_ot2),
    neg_per_d_NonwordvReal_ot2 = -percent_diff(b_Nonword_ot2, b_Real_ot2),
    d_NonwordvReal_ot3 = b_Nonword_ot3 - b_Real_ot3,
    neg_d_NonwordvReal_ot3 = d_NonwordvReal_ot3 * -1,
    per_d_NonwordvReal_ot3 = percent_diff(b_Nonword_ot3, b_Real_ot3),
    neg_per_d_NonwordvReal_ot3 = -percent_diff(b_Nonword_ot3, b_Real_ot3)) %>% 
  as_tibble()

age3 <- m_tp1 %>% pull_samples()
age4 <- m_tp2 %>% pull_samples()
age5 <- m_tp3 %>% pull_samples()

# mcmc_intervals(age3, regex_pars = "Prop")
# mcmc_intervals(data.frame(x = mp_fam_fixef$per_d_ot1_Age4))
# mcmc_intervals(data.frame(x = mp_fam_fixef$b_Intercept_Prop_Age3))
# mcmc_intervals(mp_fam_fixef,  regex_pars = "Intercept_Prop")
# mcmc_intervals_data(mp_fam_fixef,  regex_pars = "Intercept_Prop")

pull_props <- . %>% 
  mcmc_intervals_data(regex_pars = "Prop") %>% 
  mutate(
    parameter = parameter %>% 
      stringr::str_replace("_?Intercept_Prop_?", "") %>% 
      stringr::str_replace("_?Prop_?", "")) %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  add_ui_slug_to_first("90% UI: ") %>% 
  lapply(fmt_remove_leading_zeros_in_text)

props3 <- age3 %>% pull_props()
props4 <- age4 %>% pull_props()
props5 <- age5 %>% pull_props()

pull_time1 <- . %>% 
  mcmc_intervals_data(regex_pars = "ot1") %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  purrr::map_at(
    .at = c("per_d_NonwordvReal_ot1", "neg_per_d_NonwordvReal_ot1"), 
    .f = fmt_convert_prop_to_percent)

time1_3 <- age3 %>% pull_time1()
time1_4 <- age4 %>% pull_time1()
time1_5 <- age5 %>% pull_time1()
```



## Nonwords versus familiar words

I asked whether the recognition of familiar words differed from the
fast selection of referents for nonwords. I fit a Bayesian, mixed effects
logistic regression, growth curve model, as in
[Chapter \@ref(fam-rec)](#fam-rec). For the real word and nonword
conditions, there is a well-defined target image: the familiar image for
real words and the novel/unfamiliar image for nonwords. The outcome
measures were the probabilities of fixating to the target image in each
condition:

  - P(look to familiar image | hear a real word)
  - P(look to unfamiliar image | hear a nonword)

Both the real word and nonword conditions measure referent selection as
the probability of fixating on the appropriate referent when presented
with a label. The important analytic question is whether and to what
degree these two probabilities differ. The growth curve model is similar
to the one in [Chapter \@ref(fam-rec)](#fam-rec) with linear, quadratic
and cubic time features but it adds a condition effect which interacts
with these features. The linear model was:

`r insert_html_math()`
\small
\begin{align*}
   \text{log\,odds}(\text{looking}) =\
    &\beta_0 + 
      \beta_1\text{Time}^1 + 
      \beta_2\text{Time}^2 + 
      \beta_3\text{Time}^3\ + 
      &\text{[nonword curve]} \\
    (&\gamma_0 + 
      \gamma_1\text{Time}^1 + 
      \gamma_2\text{Time}^2 +
      \gamma_3\text{Time}^3)*\text{Condition} \
      &\text{[real words]} \\
\end{align*}
\normalsize
`r insert_html_math()`

I fit a separate model for each year of the study.
[Appendix \@ref(aim2-gca-models)](#aim2-gca-models) contains the R code
used to fit these models along with a description of the specifications
represented by the model syntax. The mixed model included by-child and
by-child-by-condition random effects to allow some of a
child's growth curve features to be similar between conditions
(by-child effects) and to differ between conditions
(by-child-by-condition effects).

For these analyses, I limited focus to distractor-initial trials, and
modeled the data from `r min(d$Time)` to `r max(d$Time)` ms after target
onset. I removed any Age × Child levels if a child had fewer than 4
fixations in a single time bin. In other words, children had to have at
least 4 looks to one of the images in every 50 ms time bin. This
screening removed `r study_counts$T1` children at age 3,
`r study_counts$T2` at age 4, and `r study_counts$T3` at age 5.

Figure \@ref(fig:aim2-real-nonword-means) shows the group averages of the growth
curves. For each condition and age, I computed the empirical growth
curve for each participant, and I averaged the participants' growth
curves together to obtain group averages. I also applied this process
to 100 model-estimated growth curves.

(ref:aim2-real-nonword-means) Averages of participants' growth curves in each condition and age. The lines represent 100 posterior predictions of the group average. 

(ref:aim2-real-nonword-means-scap) Averages of participants' growth curves in each condition and age.

```{r aim2-real-nonword-means, fig.cap = "(ref:aim2-real-nonword-means)", fig.scap = "(ref:aim2-real-nonword-means-scap)", out.width = out_tex100_else80, fig.height = 4, fig.width = 6}
theme_set(theme_teej())
# m_tp1
# m_tp2
# m_tp3
# m_tp3

# Sets for predictions
n_tp1_all <- d_tp1 %>%
  distinct(Study, ResearchID, Condition, Time, ot1, ot2, ot3) %>%
  mutate(Trials = 30)

n_tp2_all <- d_tp2 %>%
  distinct(Study, ResearchID, Condition, Time, ot1, ot2, ot3) %>%
  mutate(Trials = 30)

n_tp3_all <- d_tp3 %>%
  distinct(Study, ResearchID, Condition, Time, ot1, ot2, ot3) %>%
  mutate(Trials = 30)

# re_formula <- NA
re_formula <- NULL

tp1_fits <- augment_linpred(
  m_tp1, n_tp1_all, allow_new_levels = TRUE,
  re_formula = re_formula, nsamples = 100)

tp2_fits <- augment_linpred(
  m_tp2, n_tp2_all, allow_new_levels = TRUE,
  re_formula = re_formula, nsamples = 100)

tp3_fits <- augment_linpred(
  m_tp3, n_tp3_all, allow_new_levels = TRUE,
  re_formula = re_formula, nsamples = 100)

all_fits <- bind_rows(tp1_fits, tp2_fits, tp3_fits) %>% 
  mutate(
    Study = convert_study_to_age(Study),
    Condition = convert_condition_to_name(Condition))

all_data <- bind_rows(d_tp1, d_tp2, d_tp3) %>% 
  mutate(
    Study = convert_study_to_age(Study),
    Condition = convert_condition_to_name(Condition)) 

# emp_diffs <- all_data %>% 
#   mutate(Prop = Target / Trials) %>% 
#   select(Study, ResearchID, Prop, Condition, Time) %>% 
#   tidyr::spread(Condition, Prop) %>% 
#   mutate(
#     nonword_prop = nonwords, 
#     real_prop = `real words`,
#     `nonword - real` = nonword_prop - real_prop) %>% 
#   select(Study, ResearchID, Time, nonword_prop, real_prop, `nonword - real`)

# curve_diffs <- all_fits %>% 
#   select(Study, .draw, ResearchID, .posterior_value, Condition, Time) %>% 
#   tidyr::spread(Condition, .posterior_value) %>% 
#   mutate(
#     nonsense_prop = plogis(nonsense), 
#     real_prop = plogis(real),
#     `nonsense - real` = nonsense_prop - real_prop) %>% 
#   select(
#     Study, .draw, ResearchID, Time, 
#     nonsense_prop, real_prop, `nonsense - real`)

# some_curve_diffs <- curve_diffs %>% 
#   tjmisc::sample_n_of(100, .draw) 

some_fits <- all_fits %>% 
  tjmisc::sample_n_of(100, .draw)

ant_0 <- data.frame(
  Condition = c("nonsense", "real"),
  Study = c("Age 4"), 
  Time = c(300, 900), 
  y = c(.83, .60)) %>% 
  mutate(Condition = convert_condition_to_name(Condition))

ggplot(some_fits) + 
  aes(x = Time, y = plogis(.posterior_value), color = Condition) + 
  geom_hline(yintercept = .5, size = 2, color = "white") +
  stat_summary(
    aes(group = interaction(.draw, Condition)),
    geom = "line",
    fun.y = mean,
    alpha = .05) +
  stat_summary(
    aes(y = Target / Trials), 
    data = all_data,
    fun.data = mean_se,
    geom = "pointrange") +
  geom_text(
    aes(label = Condition, y = y),
    data = ant_0,
    hjust = 0,
    size = 3.5,
    family = "Lato Semibold") + 
  geom_text(
    aes(label = label, y = Prop),
    data = data_frame(
      Study = "Age 3",
      Time = 600, 
      Prop = .15, 
      label = "Trials starting on distractor" %>% 
        strwrap(width = 20) %>% 
        paste0(collapse = "\n")),
    size = 3, 
    hjust = 0,
    color = constants$col_off_black,
    family = "Lato") +
  facet_wrap("Study") +
  guides(color = FALSE) +
  labs(
    x = constants$x_time, 
    y = constants$y_prop_target,
    caption = constants$cap_emp_and_draw) + 
  scale_color_real_non()
```

In [Chapter \@ref(fam-rec)](#fam-rec), I claim that for these growth
curve models only the intercept and linear time terms are behaviorally
meaningful model parameters. The intercept measures the average growth
curve value so it reflects overall *looking reliability*, and the linear
time term measures the overall steepness of the growth so it reflects
*lexical processing efficiency*. I also derived a measure of peak
looking probability by taking the median of top five points in a growth
curve, and this peak provides a measure of *word recognition certainty*.
Higher peaks indicate less uncertainty about a word.

I evaluated the general condition effects by looking at how the
population-level ("fixed") effects differed in each condition. Due to
ceiling effects, where children's growth curves saturated 100% looking
probabilities, the population-level average growth curve outperformed
the observed group averages in Figure \@ref(fig:aim2-real-nonword-means).
The condition differences described by these population-level effects,
however, do qualitatively match the patterns in the group averages.

The two conditions did not reliably differ at age 3. The
population-level average proportion of looks to the target for nonwords
was `r props3$b_Nonword`, compared to `r props3$b_Real` for real
words---a difference (nonword advantage) of `r props3$d_NonwordvReal`. For the
linear time feature, the nonword slope increases by
`r time1_3$neg_per_d_NonwordvReal_ot1` in the real word condition. Both
these 90% intervals include 0 as a plausible estimate for the condition
difference, so there is uncertainty about the sign of the effect. I
therefore conclude that the conditions did not credibly differ on
average at age 3.

There was an advantage for the nonword condition at age 4 and age 5. The
population-level average proportion of looks for the nonwords was
`r props4$b_Nonword`, compared to `r props4$b_Real` for real words. On
average, children looked less to target for the real words than the
nonwords. There was a suggestive linear time effect where the
nonword curve was `r time1_4$per_d_NonwordvReal_ot1` steeper than the real word
one. The curve for real words was probably less steep at age 4 but small
values near 0 remain plausible. At age 5, only the average probability
difference was credible, `r props5$b_Nonword` for nonwords compared to
`r props5$b_Real` for real words. In general, children performed better in
the nonword condition than the real word condition at age 4 and age 5.
This difference shows up in the growth curve model through intercept
effects, although it is plausible that children's nonword growth curves
were steeper than the real word curves at age 4.





```{r}
do_it_1 <- peaks %>%
  group_by(Study, ResearchID) %>%
  summarise_at(vars(nonsense:diff), funs(mean, sd)) %>%
  rename(nonsense = nonsense_mean, real = real_mean, diff = diff_mean) %>% 
  ungroup()

# do_it_1 %>% 
#   group_by(Study) %>% 
#   summarise(
#     real_ceiling = sum(real >= .99),
#     real_ceiling_prop = real_ceiling / n(),
#     nonsense_ceiling = sum(nonsense >= .99),
#     nonsense_ceiling_prop = nonsense_ceiling / n(), 
#     n = n())

ceilings <- peaks %>% 
  group_by(Study, .draw) %>% 
  summarise(
    real = sum(real >= .99),
    nonsense = sum(nonsense >= .99)) %>% 
  ungroup() %>% 
  select(Study, real, nonsense) %>%
  tidyr::nest(-Study) %>% 
  mutate(intervals = data %>% purrr::map(mcmc_intervals_data)) %>% 
  select(-data) %>% 
  tidyr::unnest(intervals) %>% 
  mutate(
    Study = stringr::str_replace(Study, "TimePoint", "TP"),
    parameter = stringr::str_replace(parameter, "nonsense", "nons"))

nons_ceilings <- ceilings  %>% 
  filter(parameter == "nons") %>% 
  split(.$Study) %>% 
  fmt_inline_median_interval(0) %>% 
  add_ui_slug_to_first(slug = "90%&nbsp;UI: ")

real_ceilings <- ceilings  %>% 
  filter(parameter == "real") %>% 
  split(.$Study) %>% 
  fmt_inline_median_interval(0)
# peaks %>% 
#   mutate(Study = convert_study_to_age(Study)) %>% 
#   group_by(Study, ResearchID) %>% 
#   summarise_at(vars(nonsense:diff), mean) %>% 
#   select(-diff) %>%
#   tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
#   ungroup() 
```

I analyzed the children's model-estimated growth curve peaks. Each
posterior sample of the model represents a plausible set of growth curve
parameters for the data, so for each of these samples, I calculated the
growth curves for each child and the peaks of the growth curves.
Figure \@ref(fig:aim2-gca-peaks) shows the posterior averages of the
growth curves peaks for each participant.

(ref:aim2-gca-peaks) Growth curve peaks by child, condition and year of the study. The movement of the medians conveys how the nonword peaks effect increased from age 3 to age 4 and the real word peaks increased from age 4 to age 5. The piling of points near the 1.0 line depicts how children reached ceiling performance on this task.

(ref:aim2-gca-peaks-scap) Growth curve peaks by child, condition and year of the study.

```{r aim2-gca-peaks, fig.cap = "(ref:aim2-gca-peaks)", fig.scap = "(ref:aim2-gca-peaks-scap)", out.width = out_tex80_else66, fig.height = 3, fig.width = 4.5}
# Count up participants in each study for the x axis
study_peak_counts <- peaks %>%
  distinct(Study, ResearchID) %>%
  mutate(
    Study = Study %>% convert_study_to_age(),
    StudyCounts = Study %>% fct_add_counts()) %>%
  distinct(Study, StudyCounts)

x_levels <- setNames(
  as.character(study_peak_counts$StudyCounts), 
  as.character(study_peak_counts$Study))

condition_means <- peaks %>% 
  mutate(Study = Study %>% convert_study_to_age()) %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(nonsense:diff), mean) %>% 
  select(-diff) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  ungroup() %>% 
  mutate(Condition = convert_condition_to_name(Condition))

ggplot(condition_means) + 
  aes(x = Study, y = Peak, color = Condition) + 
  geom_hline(yintercept = .5, size = 2, color = "white") + 
  geom_text(
    aes(label = Condition),
    data = data_frame(
      Peak = 1.06, 
      label = c("nonwords", "real words"),
      Condition = convert_condition_to_name(c("nonsense", "real")),
      Study = "Age 3"), 
    position = position_dodge(width = 1.15), 
    size = 3, 
    family = "Lato Medium") +
  geom_point(
    position = position_jitterdodge(jitter.width = 0.25, dodge.width = 1.05), 
    alpha = .5, 
    shape = 1) +
  geom_boxplot(
    width = .2, 
    position = position_dodge(width = .3), 
    outlier.alpha = 0)  +
  guides(color = FALSE) +
  labs(
    title = "Growth curve peaks",
    x = NULL,
    y = NULL,
    caption = "Points: Participant posterior means.") + 
  scale_x_discrete(labels = x_levels) +
  scale_y_continuous(
    minor_breaks = c(.1, .3, .5, .7, .9),
    breaks = c(0, .2, .4, .6, .8, 1)) +
  scale_color_real_non() 
```


```{r}
meds_by_year <- do_it_1 %>% 
  group_by(Study) %>% 
  summarise(nonsense = median(nonsense), real = median(real))

tp1_non_med <- meds_by_year %>% 
  filter(Study == "TimePoint1") %>% 
  pull(nonsense) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

tp1_r_med <- meds_by_year %>% 
  filter(Study == "TimePoint1") %>% 
  pull(real) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

tp2_non_med <- meds_by_year %>% 
  filter(Study == "TimePoint2") %>% 
  pull(nonsense) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

tp3_non_med <- meds_by_year %>% 
  filter(Study == "TimePoint3") %>% 
  pull(nonsense) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

tp2_r_med <- meds_by_year %>% 
  filter(Study == "TimePoint2") %>% 
  pull(real) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

tp3_r_med <- meds_by_year %>% 
  filter(Study == "TimePoint3") %>% 
  pull(real) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()
```

Descriptive statistics reveal the developmental trends for this task. At
age 3, the median peak values were similar for the two conditions:
`r tp1_non_med` for nonwords and `r tp1_r_med` for real words. The peaks
increased for the nonword condition in the following year with a median
value of `r tp2_non_med`. It is worth emphasizing what this statistic
tells us: At age 4, half of the children had a peak looking probability
of `r tp2_non_med` *or greater*. In other words, half the children
performed near the ceiling on this task by age 4. At age 5, the median
nonword peak was `r tp3_non_med`, essentially unchanged from age 4. For
the real words, the median peak increased from `r tp2_r_med` at age 4 to
`r tp3_r_med` at age 5.

To quantify the degree of ceiling performance, I calculated the number
of children per condition with a growth curve peak greater than or equal
to .99 over the posterior distribution. For the nonword condition, there
were `r nons_ceilings$TP1` children who performed at ceiling at age 3,
`r nons_ceilings$TP2` at age 4, `r nons_ceilings$TP3` and at age 5. For
the real word condition, the number of children attaining ceiling
performance was more uneven: there were `r real_ceilings$TP1`
ceiling-performers at age 3, `r real_ceilings$TP2` at age 4, and
`r real_ceilings$TP3` at age 5.


```{r, echo = FALSE}
rw_peak_lme_tp2 <- do_it_1 %>%
  select(Study, ResearchID, nonsense, real) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  mutate(Condition = forcats::fct_rev(Condition)) %>%
  mutate(Study = factor(Study, c("TimePoint2", "TimePoint1", "TimePoint3"))) %>% 
  lme4::lmer(Peak ~ Condition * Study + (1 | ResearchID/Study), .) %>%
  broom::tidy("fixed")

nw_peak_lme_tp1 <- do_it_1 %>% 
  select(Study, ResearchID, nonsense, real) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  lme4::lmer(Peak ~ Condition * Study + (1 | ResearchID/Study), .) %>%
  broom::tidy("fixed")

nw_peak_lme_tp2 <- do_it_1 %>% 
  select(Study, ResearchID, nonsense, real) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  mutate(Study = factor(Study, c("TimePoint2", "TimePoint1", "TimePoint3"))) %>% 
  lme4::lmer(Peak ~ Condition * Study + (1 | ResearchID/Study), .) %>%
  broom::tidy("fixed")

nw_peak_lme_tp3 <- do_it_1 %>% 
  select(Study, ResearchID, nonsense, real) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  mutate(Study = factor(Study, c("TimePoint3", "TimePoint1", "TimePoint2"))) %>% 
  lme4::lmer(Peak ~ Condition * Study + (1 | ResearchID/Study), .) %>%
  broom::tidy("fixed")

# x <- emmeans::emmeans(nw_peak_lme_tp3, "Condition")
# pairs(emmeans::emmeans(nw_peak_lme_tp3, "Condition", by = "Study"))

pull_effect_est <- function(output, effect, flip = FALSE) {
  flip_sign <- function(x) if (flip) x * - 1 else x
  
  b <- output %>% 
    filter(term == effect) %>%
    pull(estimate) %>% 
    flip_sign() %>% 
    printy::fmt_fix_digits(2) %>% 
    printy::fmt_leading_zero()
  
  t <- output %>% 
  filter(term == effect) %>%
  pull(statistic) %>% 
  flip_sign() %>% 
  printy::fmt_fix_digits(2)
  
  list(b = b, t = t)
}

t2_real <- pull_effect_est(nw_peak_lme_tp2, "Conditionreal", TRUE)
t1_real <- pull_effect_est(nw_peak_lme_tp1, "Conditionreal", FALSE)
t3_real <- pull_effect_est(nw_peak_lme_tp3, "Conditionreal", TRUE)

t2_t1 <- pull_effect_est(nw_peak_lme_tp2, "StudyTimePoint1", TRUE)
t2_t3 <- pull_effect_est(nw_peak_lme_tp2, "StudyTimePoint3", FALSE)

t2_t3_real <- pull_effect_est(rw_peak_lme_tp2, "StudyTimePoint3", FALSE)
```

To compare peaks looking probabilities between ages, I fit a linear
mixed effects model with restricted maximum likelihood via the lme4 R
package [vers. `r packageVersion("lme4")`; @lme4]. I regressed the
children's average growth curve peaks onto experimental condition, age
group, and the age × condition interaction. The model included randomly
varying intercepts for child and child × age. This modeling software does
not provide *p*-values for its effects estimates, so for these
comparisons, I decided that an effect was significant when the *t*
statistic for a population-level ("fixed") effect had an absolute value
of 2 or greater. In practical terms, this convention interprets an
effect as "significant" when its estimate is at least 2 standard errors
away from 0. [@GelmanHill use this approach with mixed models.]

At age 3, the two conditions did not significantly differ,
*B*~real−nonword~ = `r t1_real$b`, *t* = `r t1_real$t`. At
age 4, nonword peaks were on average `r t2_real$b` proportion units
greater than the real word peaks, *t* = `r t2_real$t`, and at age 5, the
nonword peaks were `r t3_real$b` proportion units greater than the real
word peaks, *t* = `r t3_real$t`. For the nonword condition there was a
significant increase in the peaks from age 3 to age 4,
*B*~4−3~ = `r t2_t1$b`, *t* = `r t2_t1$t`, whereas there was
no improvement from age 4 to age 5, *t* = `r t2_t3$t`. In the real word
condition, there was only a significant improvement from age 4 to age 5,
*B*~5−4~ = `r t2_t3_real$b`, *t* = `r t2_t3_real$t`.




<!-- [pvalues]: The lme4 package does not provide *p*-values because it is -->
<!-- unclear what number to use for the degrees of freedom with hierarchical -->
<!-- or repeated measures data. One approach is the so-called "normal -->
<!-- approximation" which treats t-values like z-scores---i.e., drawn from a -->
<!-- normal distribution with mean 0 and standard deviation 1. Under this -->
<!-- approach, conventional significance obtains when is greater than or -->
<!-- equal to 1.96 in magnitude. I use 2 as the cutoff because I find significance thresholds are arbitrary. -->

<!-- > As in Chapter XX, I calculated the posterior distribution of growth -->
<!-- curves for each child x condition x year. To measure children's -->
<!-- lexical processing, I used the peak value each growth curve by taking -->
<!-- the median of the top 5 model fits. For each child, I calculated the -->
<!-- difference between the peak of the real word and the nonword growth -->
<!-- curves. This difference in peak values conveys the *condition advantage* -->
<!-- for a child. The figure below visualizes the condition advantages. -->


```{r aim2-gca-diffs, out.width = out_tex80_else50, fig.height = 3, fig.width = 4, eval = FALSE}
ant <- data_frame(
  diff = -.6, 
  Study = "Age 3", 
  label = "Real word curves had higher peaks")

ant2 <- data_frame(
  diff = .6, 
  Study = "Age 3", 
  label = "Nonword curves had higher peaks")

peaks %>% 
  mutate(Study = convert_study_to_age(Study)) %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(nonsense:diff), mean) %>% 
    ggplot() + 
      aes(x = Study, y = diff) + 
      geom_hline(yintercept = 0, size = 2, color = "white") + 
      geom_boxplot(width = .4, fill = NA, outlier.alpha = 0) +
      geom_point(position = position_jitter(width = .2), alpha = .3, shape = 1) +
      geom_text(
        aes(label = label), 
        data = bind_rows(ant, ant2), nudge_x = -.45, hjust = 0, 
        color = "grey10", size = 3, family = "Lato Medium") +
      labs(
        title = "Differences in growth curve peaks",
        x = NULL,
        y = "Nonword - real word",
        caption = "Points: Participant posterior means.") + 
  theme_teej()
```


```{r}
scores <- readr::read_csv("./data-raw/test_scores.csv")
tp1 <- scores %>% filter(Study == "TimePoint1")
tp2 <- scores %>% filter(Study == "TimePoint2")
tp3 <- scores %>% filter(Study == "TimePoint3")

peaks_and_vocabs <- peaks %>% 
  mutate(Study = convert_study_to_age(Study)) %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(nonsense:diff), mean) %>% 
  ungroup() 

peaks_and_vocabs_w <- peaks_and_vocabs %>% 
  left_join(
    scores %>% mutate(Study = convert_study_to_age(Study))) 

peaks_and_vocabs_l <- peaks_and_vocabs %>% 
  tidyr::gather("Condition", "Peak", -ResearchID, -Study) %>% 
  left_join(
    scores %>% mutate(Study = convert_study_to_age(Study))) 
```


Finally, I asked whether expressive vocabulary size correlated with peak
looking performance on the two conditions. Correlations among real word
peaks, nonword peaks, expressive vocabulary and receptive vocabulary are
given in Table \@ref(tab:table-peak-cor). At all three years, children with larger vocabularies
had higher nonword peak looking values. At age 3 and age 4, vocabulary
positively correlated with real-word looking performance.
Figure \@ref(fig:peak-concurrent-vocab-cors) illustrates the relationship
between the peaks and expressive vocabulary. When there is more
variability in the peaks, as at age 3, the vocabulary effect on the
nonwords is strongest. 


```{r table-peak-cor}
p_stars <- function(pv) {
  Signif <- symnum(pv, corr = FALSE, na = FALSE, 
         cutpoints = c(0, 0.001, 0.01, 0.05, 1), 
         symbols = c("***", "**", "*", " "))
  format(Signif)
}

md_table <- peaks_and_vocabs_w %>%
  group_by(Study) %>%
  tidy_correlation(EVT_Standard, PPVT_Standard, nonsense, real) %>%
  ungroup() %>%
  rename(r = estimate, p = p.value) %>% 
  mutate(
    r = r %>% 
      printy::fmt_fix_digits(2) %>% 
      printy::fmt_leading_zero() %>% 
      printy::fmt_minus_sign(),
    p_stars = p_stars(p),
    line = glue::glue("*r*({n}) = {r}{p_stars}") %>% as.character()) %>% 
  anti_join(data_frame(Study = "Age 5", column1 = "PPVT_Standard")) %>% 
  anti_join(data_frame(Study = "Age 5", column2 = "PPVT_Standard")) %>% 
  select(Study, column1, column2, line) %>%
  tidyr::spread(column2, line) %>%
  mutate(
    column1 = 
      factor(
        column1, 
        levels = c("nonsense", "PPVT_Standard", "EVT_Standard"), 
        labels = c("Nonword peak", "PPVT-4 standard", "EVT-2 standard"))) %>%
  mutate_at(vars(-Study, -column1), ~ ifelse(is.na(.x), "&nbsp;", .x)) %>% 
  arrange(Study, column1) %>%
  select(Study, column1, real, nonsense, PPVT_Standard) %>% 
  rename(
    `Real word peak` = real, 
    `Nonword peak` = nonsense, 
    `PPVT-4 standard` = PPVT_Standard,
    `&nbsp;` = column1) %>% 
  mutate(
    Study = Study %>% as.character() %>% replace_if_same_as_last("&nbsp;")) 

tscap <- "Correlations between curve peaks and vocabulary measures."

if (knitr::is_latex_output()) {
  tcap <- glue::glue(
    "
    {{tscap}} \\
    Vocbulary measures are standard scores for receptive vocabulary \\
    (PPVT-4) and expressive vocabulary (EVT-2). \\
    Significance conventions: \\
    \\textit{p} $\\leq$ .05*, \\
    \\textit{p} $\\leq$ .01**, \\
    \\textit{p} $\\leq$ .001***.
    ", 
    .open = "{{", 
    .close = "}}") %>% 
  glue::glue_collapse() %>% 
  as.character()
    
  to_print <- md_table %>% 
    mutate_all(
      . %>% 
        stringr::str_replace_all("&minus;", "$-$") %>% 
        stringr::str_replace_all("&nbsp;", " ") %>%
        stringr::str_replace_all("([*]r[*])", "\\\\textit{r}") %>% 
        stringr::str_replace_all("([*]+)[$]$", "\\\\text{\\1}$") %>% 
        stringr::str_replace_all(" standard", "")) %>% 
    rename(` ` = `&nbsp;`) %>% 
    rename(`  ` = `Study`) %>% 
    rename(`PPVT-4` = `PPVT-4 standard`) %>% 
    knitr::kable(
      align = c("lllll"),
      format = "latex",
      booktabs = TRUE,
      escape = FALSE,
      linesep = c("", "", "\\addlinespace"),
      caption.short = tscap,
      caption = tcap)
} else {
  tcap <- glue::glue(
    "
    {{tscap}} \\
    Significance conventions: \\
    *p*&nbsp;&le; .05\\*, *p*&nbsp;&le; .01\\*\\*, *p*&nbsp;&le; .001\\*\\*\\*.
    ", 
    .open = "{{", 
    .close = "}}") %>% 
    as.character()
  
  to_print <- md_table %>% 
    knitr::kable(
      align = c("lllll"),
      caption = tcap)
}

to_print

# peaks_and_vocabs_l %>% 
#   filter(Condition != "diff") %>% 
#   group_by(Study, Condition) %>% 
#   tidy_correlation(EVT_Standard, Peak) %>% 
#   ungroup() %>% 
#   mutate(Condition = convert_condition_to_name(Condition)) %>% 
#   select(Study, Condition, n, r = estimate, p = p.value) %>% 
#   mutate(
#     r = r %>% 
#       printy::fmt_fix_digits(2) %>% 
#       printy::fmt_leading_zero() %>% 
#       printy::fmt_minus_sign(),
#     p = printy::fmt_p_value(p)) %>% 
#   knitr::kable(
#     align = c("llrrr"),
#     caption = "Correlation between EVT-2 standard scores and curve peaks")
```

(ref:peak-concurrent-vocab-cors) Relationships between expressive vocabulary and growth curve peaks at each age.

```{r peak-concurrent-vocab-cors, fig.cap = "(ref:peak-concurrent-vocab-cors)", out.width = out_tex100_else80, fig.width = 6, fig.height = 3}
theme_set(theme_teej())

to_plot <- peaks_and_vocabs_l %>% 
  filter(Condition != "diff") %>% 
  group_by(Condition) %>% 
  mutate(Study = fct_add_counts(Study)) %>% 
  ungroup() 

ggplot(to_plot) + 
  aes(x = EVT_Standard, y = Peak, color = Condition) + 
  geom_point(
    alpha = .8, 
    shape = 1) + 
  facet_wrap("Study") + 
  stat_smooth(method = "lm") + 
  geom_text(
    aes(label = label),
    data = data_frame(
      Study = stringr::str_subset(to_plot$Study, "Age 3")[1],
      Peak = .45,
      EVT_Standard = 37,
      Condition = "nonsense",
      label = c("Nonwords")), 
    hjust = 0,
    family = "Lato Semibold", 
    size = 3) + 
  geom_text(
    aes(label = label),
    data = data_frame(
      Study = stringr::str_subset(to_plot$Study, "Age 4")[1],
      Peak = .92,
      EVT_Standard = 40,
      Condition = "nonsense",
      label = c("Nonwords")), 
    hjust = 0,
    family = "Lato Semibold", 
    size = 3) + 
  geom_text(
    aes(label = label),
    data = data_frame(
      Study = stringr::str_subset(to_plot$Study, "Age 5")[1],
      Peak = .72,
      EVT_Standard = 42,
      Condition = "nonsense",
      label = c("Nonwords")), 
    hjust = 0,
    family = "Lato Semibold", 
    size = 3) + 
  scale_color_manual(
    values = c("#f7882f", "#6b7a8f")) +
  labs(
    x = "Concurrent expressive vocabulary (EVT-2 standard)",
    y = "Growth curve peak",
    caption = "Lines: Regression fit ± SE") + 
  guides(color = FALSE)
```

```{r}
  # 
  # col_real = "#6b7a8f",
  # col_nonword = "#f7882f",
  # col_mispronunciation = "#cyan4"

# peaks_and_vocabs_l %>% 
#   filter(Condition != "diff") %>% 
#   filter(Study == "Age 3") %>% 
#   lmer(Peak ~ scale(EVT_Standard) * Condition + (1 | ResearchID), .) %>% 
#   summary()
# 
# peaks_and_vocabs_l %>% 
#   filter(Condition != "diff") %>% 
#   filter(Study == "Age 4") %>% 
#   lmer(Peak ~ scale(EVT_Standard) * Condition + (1 | ResearchID), .) %>% 
#   summary()
# 
# peaks_and_vocabs_l %>% 
#   filter(Condition != "diff") %>% 
#   filter(Study == "Age 5") %>% 
#   lmer(Peak ~ scale(EVT_Standard) * Condition + (1 | ResearchID), .) %>% 
#   summary()

# peaks_and_vocabs_w %>% 
#   filter(Study == "Age 3") %>% 
#   lm(nonsense ~ scale(EVT_Standard) * scale(real), .) %>% 
#   summary()
# 
# peaks_and_vocabs_w %>% 
#   filter(Study == "Age 4") %>% 
#   lm(nonsense ~ scale(EVT_Standard) * scale(real), .) %>% 
#   summary()
# 
# peaks_and_vocabs_w %>% 
#   filter(Study == "Age 5") %>% 
#   lm(nonsense ~ scale(EVT_Standard) * scale(real), .) %>% 
#   summary()

peak_corrs <- peaks_and_vocabs_w %>% 
  group_by(Study) %>% 
  tidy_correlation(nonsense, real) %>% 
  ungroup() 

# peaks_and_vocabs %>% 
#   ggplot() + 
#     aes(x = EVT_GSV, y = nonsense) + 
#     geom_point() + 
#     facet_wrap("Study") + 
#     stat_smooth(method = "lm")
# 
# peaks_and_vocabs %>% 
#   ggplot() + 
#     aes(x = EVT_GSV, y = nonsense) + 
#     geom_point() + 
#     facet_wrap("Study") + 
#     stat_smooth(method = "lm")
```

**Summary**. Children performed similarly for real words and nonwords
at age 3. Children's processing of nonwords improved at age 4. At this
age, performance also began to saturate with the group average for peak
looking probability greater than .9 for the nonword condition.
Consequently, children did not improve in processing of nonwords from
age 4 to age 5. For the real word condition, children's performance did
not change from age 3 to age 4 but it did improve from age 4 to age 5.
At both age 4 and age 5, there was a decisive advantage for the nonword
condition. Finally, children with larger expressive vocabularies looked
more to the nonwords compared to children with smaller vocabularies. A
comparable effect for real words was observed at age 3 and age 4 but
only reliably observed at age 4.


## Does age-3 referent selection better predict age-5 vocabulary?

I hypothesized that performance on the nonword condition would be a
better predictor of future vocabulary size than the real word condition.
This hypothesis follows from the assumption that fast referent
selection, as opposed to familiar word recognition, is a more relevant
skill for word-learning. Put another way, a child's ability to quickly
map a novel word to a referent is more closely related to the demands of
in the moment word-learning than familiar word recognition.

In [Chapter \@ref(fam-rec)](#fam-rec), I found that peak looking
probability at age 3 positively correlated with age 5 vocabulary.
Pairing this finding with my hypothesis, I predicted that the growth
curve peaks in the nonword condition at age 3 would be better predictors
of vocabulary at age 5 than the real word peaks at age 3.

```{r, include = FALSE}
w_evt <- scores %>% 
  filter(Study != "TimePoint2") %>% 
  select(ResearchID, Study, EVT_Standard) %>% 
  tidyr::spread(Study, EVT_Standard) %>% 
  inner_join(do_it_1 %>% filter(Study == "TimePoint1")) %>% 
  modelr::add_residuals(
    lm(TimePoint3 ~ TimePoint1, .), 
    "EVT_Residualized")

evt_t1_z <- lm(scale(TimePoint3) ~ scale(TimePoint1), w_evt)
evt_t1 <- lm(TimePoint3 ~ scale(TimePoint1), w_evt)

evt_t1_z_nonsense <- lm(scale(TimePoint3) ~ scale(TimePoint1) + nonsense, w_evt)
evt_t1_nonsense <- lm(TimePoint3 ~ TimePoint1 + nonsense, w_evt)

w_evt$both <- (w_evt$nonsense + w_evt$real) / 2

evt_t1_z_both <- lm(scale(TimePoint3) ~ scale(TimePoint1) + both + diff, w_evt)
evt_t1_both <- lm(TimePoint3 ~ TimePoint1 + both + diff, w_evt)
summary(evt_t1_z_both)

evt_t1_z_nonsense <- lm(scale(TimePoint3) ~ scale(TimePoint1) + nonsense, w_evt)
evt_t1_nonsense <- lm(TimePoint3 ~ TimePoint1 + nonsense, w_evt)

evt_t1_z_real <- lm(scale(TimePoint3) ~ scale(TimePoint1) + real, w_evt)

p_real <- evt_t1_z_real %>% 
  broom::tidy(conf.int = TRUE) %>%
  filter(term == "real") %>% 
  pull(p.value) %>% 
  printy::fmt_p_value(digits = 2) 

p_nonsense <- evt_t1_z_nonsense %>% 
  broom::tidy(conf.int = TRUE) %>%
  filter(term == "nonsense") %>% 
  pull(p.value) %>% 
  printy::fmt_p_value() 

evt_z_nonsense <- lm(scale(TimePoint3) ~ nonsense, w_evt)
evt_nonsense <- lm(TimePoint3 ~  nonsense, w_evt)

for_pred <- na.omit(w_evt)

adj_rsquare <- function(model) {
  summary(model)[["adj.r.squared"]]
}

t1_sd <- round(sd(for_pred$TimePoint1))
t3_sd_change <- evt_t1_z$coef[2] %>% round(2)
t3_change <- round(coef(evt_t1)[2])


nonsense_change <- {coef(evt_t1_nonsense)["nonsense"] / 10} %>% 
  printy::fmt_fix_digits(1)

z_nonsense_change <- {coef(evt_t1_z_nonsense)["nonsense"] / 10} %>% 
  printy::fmt_fix_digits(2)

base_r2 <- evt_t1 %>% 
  adj_rsquare() %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

nonsense_delta <- adj_rsquare(evt_t1_z_nonsense) - adj_rsquare(evt_t1)
nonsense_delta <- nonsense_delta %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()


diff_change <- {coef(evt_t1_both)["diff"] / 10} %>% 
  printy::fmt_fix_digits(1)

z_diff_change <- {coef(evt_t1_z_both)["diff"] / 10} %>% 
  printy::fmt_fix_digits(2)

p_both <- evt_t1_z_both %>% 
  broom::tidy(conf.int = TRUE) %>%
  filter(term == "both") %>% 
  pull(p.value) %>% 
  printy::fmt_p_value(digits = 2) 

p_diff <- evt_t1_z_both %>% 
  broom::tidy(conf.int = TRUE) %>%
  filter(term == "diff") %>% 
  pull(p.value) %>% 
  printy::fmt_p_value() 
```


For these analyses, I regressed age-5 expressive vocabulary (EVT-2)
standard scores onto age-3 expressive vocabulary score and onto age-3
real word peaks or age-3 nonword peaks. There were `r nobs(evt_t1)`
children with data available for this analysis. There was an expectedly
strong relationship between age 3 and age 5 vocabulary, *R*^2^ =
`r base_r2`. A 1-SD (`r t1_sd`-point) increase in vocabulary at age 3
predicted an `r t3_sd_change`-SD (`r t3_change`-point) increase at
age 5. There was no effect of age-3 real-word peak over and above age-3
vocabulary, *p* = `r p_real`. There was a significant effect of the
nonword peak, *p* = `r p_nonsense`, *ΔR*^2^ = `r nonsense_delta`, over
and above age-3 vocabulary. A .1 increase in nonword peak probability
predicted a `r z_nonsense_change`-SD (`r nonsense_change`-point)
increase in age-5 vocabulary. Figure \@ref(fig:age-5-from-peaks) depicts
the difference between the two conditions with a flat line for the real
condition and small slope for the nonword condition.

(ref:age-5-from-peaks) Marginal effects of age-3 referent selection measures on age-5 expressive vocabulary standard scores. The vocabulary scores were adjusted (residualized) to control for age-3 vocabulary, so these regression lines show the effects of the predictors over and above age-3 vocabulary.

(ref:age-5-from-peaks-scap) Marginal effects of age-3 referent selection measures on age-5 expressive vocabulary standard scores.

```{r age-5-from-peaks, fig.cap = "(ref:age-5-from-peaks)", fig.scap = "(ref:age-5-from-peaks-scap)", out.width = out_tex100_else60, fig.height = 5, fig.width = 5}
w_l <- w_evt %>% 
  select(ResearchID, EVT_Residualized, nonsense, real, diff, both) %>% 
  rename(
    `Nonword peak` = nonsense,
    `Real word peak` = real,
    # `Condition average` = (nonsense + real) / 2,
    `Condition average` = both,
    `Nonword advantage` = diff) %>% 
  tidyr::gather("var", "value", -ResearchID, -EVT_Residualized) %>% 
  mutate(
    var = factor(
      var, 
      c("Real word peak", "Nonword peak", 
        "Condition average", "Nonword advantage")))

fmt_axis_props <- function(xs) {
  ifelse(xs == 0, "0", printy::fmt_leading_zero(xs)) 
}

step_by_25 <- function(x) {
  steps <- (x %/% .25)
  seq(from = steps[1] - 1, to = steps[2] + 1) * .25
}

theme_set(theme_teej())

w_l %>%
  # add dummy point to real word peaks so that panel has the same range and
  # width as the nonword peaks
  tibble::add_row(
    ResearchID = "1", EVT_Residualized = NA, 
    var = "Real word peak", value = .01) %>% 
  ggplot() +
    aes(x = value, y = EVT_Residualized) +
    geom_hline(yintercept = 0, color = "white",  size = 2) + 
    geom_point(color = "grey40", shape = 1) +
    stat_smooth(method = "lm", color = constants$col_blue_highlight) + 
    facet_wrap("var", scales = "free_x") +
    # scale_x_continuous(labels = fmt_axis_props) +
    # scale_x_continuous(breaks = step_by_25, labels = fmt_axis_props) +
    labs(
      x = "Age 3 measures", 
      y = "Age 5 EVT-2 (Adj.)",
      caption = "Line: Regression estimate with standard error")
```

Finally, I tested whether the difference between nonword and real word
peaks within children predicted vocabulary growth. By themselves,
differences do not convey much information about how well the child
performed: A difference of 0 can happen if a child has peaks of .1 in
both conditions or .9 in both conditions. To control for general
referent selection performance, therefore, I also included the
within-child averages of the two peaks. The model predicted age-5
vocabulary using the within-child average of the peaks, the nonword
advantage, and age-3 vocabulary. In this case, condition-averaged
performance did not significantly predict age-5 vocabulary, *p* =
`r p_both`. The condition differences did predict age-5 vocabulary: A
.1 increase in the nonword condition advantage predicted a
`r z_diff_change`-SD (`r diff_change`-point) increase in age-5
vocabulary, *p* = `r p_diff`

**Summary**. A child's performance in the nonword condition at age 3
positively predicted expressive vocabulary size at age 5. This effect
held even when controlling age-3 vocabulary size, and the effect emerged
when using the absolute growth curve peak or using the relative
advantage of the nonword condition over the real word condition.
Although the effects were significant, the effect sizes were small. The
EVT-2 is normed to have an IQ-like scale with a mean of 100 and standard
deviation of 15. An increase of .1 in age-3 growth curve peak predicted
an increase in age-5 vocabulary of `r nonsense_change`, approximately one
tenth of the test norms' standard deviation.


## Discussion

Children showed developmental improvements in referent selection for the
real word and nonword trials. The changes were not consistent
year-over-year improvements however. Nonword processing improved from
age 3 to age 4 and real word recognition improved from age 4 and to
age 5. One reason for these limited improvements is that the two-image
word recognition task was too easy. At age 4, approximately 25% of
children had nonword growth curve peaks of .99 or greater.

Despite the presence of ceiling effects, vocabulary size had a
small-to-medium positive correlation with nonword growth curve peaks at
all three ages. Children who knew more words had a higher probability of
looking to the novel object when presented with a nonword. This
replicates the vocabulary advantage in processing nonwords observed by
@Bion2013 and @MPPaper. This effect is probably bidirectional with
larger vocabularies making fast referent selection easier, and fast
referent selection being a crucial mechanism for word-learning. To
further examine the direction of effect, I tested whether nonword
performance at age 3 predicted expressive vocabulary size at age 5.
There was a small predictive effect where children with high
nonword peaks had a larger vocabulary size two years later. Although
real word and nonword performance had a small-to-medium positive
correlation, children's processing of the real words had no predictive
value. Real word peaks did not predict vocabulary, nor did the average
of real word and nonword peaks have an effect over and above the
difference of the peaks. This result was unexpected, given how lexical
processing can predict future language outcomes as in
[Chapter \@ref(fam-rec)](#fam-rec). On the other hand, familiar word
recognition with a familiar object and novel object is probably not
demanding enough for individual differences to predict future vocabulary size

For these two conditions, I hypothesized that word recognition in the real word
condition would be easier than in the nonword condition, or failing
that, the two conditions would not reliably differ. I had discounted a
third possibility of any overall advantage for nonwords over real words.
The advantage of nonwords at age 4 and age 5 over real words was therefore
an unexpected result.

Why might children perform better on the nonword trials than the real
words? The results are consistent with a novelty bias in referent
selection [@Horst2011; @Mather2012]. An additional factor may be the
presence of the mispronunciation trials---reported in
[Chapter \@ref(sensitivity-to-mispronunciations)](#sensitivity-to-mispronunciations).
The mispronunciations may undermine familiar word recognition. For
one-third of the trials, children hear an imperfect version of a
familiar word, and they show more uncertain responses to them. This
environment may cause children to downweight the syllable-initial
sounds. Such an adaptation would lead to lower overall activation of the
real words. This possibility is a limitation of this study: A design
with just real words and nonwords would provide a better comparison of
the two kinds of words. Alternatively, the novelty bias could interfere
with processing of familiar words. For some trials, children could have
ignored the familiar word and focused attention on the novel object due
to a novelty bias.
