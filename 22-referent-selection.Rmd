Development of referent selection
=======================================================================

```{r, include = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r helpers, message = FALSE, warning = FALSE}
```

```{r, include = FALSE}
# knitr::opts_chunk$set(cache = TRUE)
```



```{r load-aim2-nw-data, include = FALSE}
d <- readr::read_csv("./data/aim2-model-ready.csv.gz") %>% 
  filter(!is.na(Bias_Fam)) %>% 
  filter(300 <= Time) %>% 
  select(-starts_with("ot")) %>% 
  polypoly::poly_add_columns(
    Time, degree = 3, scale_width = 1, prefix = "ot")

# Flip things so that the nonword and real-word curves go upward
d_r_ui <- d %>% 
  filter(Condition == "real", Bias_Fam == "Unfamiliar") %>% 
  mutate(elog = empirical_logit(Target, Distractor))

d_bias_target <- tibble::tribble(
  ~Condition, ~Bias_Fam,   ~Bias_Target,
  "nonsense", "Familiar",   "Distractor",
  "nonsense", "Unfamiliar", "Target",
  "real",     "Familiar",   "Target",
  "real",     "Unfamiliar", "Distractor")

d_r_nw_vs <- d %>% 
  select(-Primary, -.response_def, -Prop, -PropSE) %>% 
  filter(Condition != "MP") %>% 
  rename(Unfamiliar = Distractor, Familiar = Target) %>% 
  mutate(
    Target = ifelse(Condition == "nonsense", Unfamiliar, Familiar), 
    Distractor = ifelse(Condition == "nonsense", Familiar, Unfamiliar),
    Trials = Target + Distractor) %>% 
  left_join(d_bias_target) %>% 
  mutate(elog = empirical_logit(Target, Distractor))

d_r_nw_dis <- d_r_nw_vs %>% 
  filter(Bias_Target == "Distractor")

study_child_with_empty_cells <- d_r_nw_dis %>% 
  filter(Trials < 4) %>% 
  distinct(Study, ResearchID)

study_counts <- study_child_with_empty_cells %>% 
  count(Study) %>% 
  split(.$Study) %>% 
  lapply(pull, n) %>% 
  set_names(stringr::str_replace, "TimePoint", "T")

d_r_nw_dis <- d_r_nw_dis %>% 
  anti_join(study_child_with_empty_cells)
```

```{r load-aim2-nw-models, include = FALSE}
library(brms)
theme_set(theme_teej())

d_r_nw_dis <- readr::read_rds("./data/aim2-real-vs-nw-modeled-data.rds.gz") 

d_tp1 <- d_r_nw_dis %>%
  filter(Study == "TimePoint1") 

d_tp2 <- d_r_nw_dis %>%
  filter(Study == "TimePoint2") 

d_tp3 <- d_r_nw_dis %>%
  filter(Study == "TimePoint3") 

m_tp1 <- readr::read_rds("./data/aim2-real-vs-nw-tp1.rds.gz")
m_tp2 <- readr::read_rds("./data/aim2-real-vs-nw-tp2.rds.gz")
m_tp3 <- readr::read_rds("./data/aim2-real-vs-nw-tp3.rds.gz")

peaks <- readr::read_rds("./data/aim2-real-vs-nw-all-peaks.rds.gz")
```

```{r}
effects <- list(tp1 = m_tp1, tp2 = m_tp2, tp3 = m_tp3) %>% 
  lapply(as.matrix) %>% 
  purrr::map_df(
    bayesplot::mcmc_intervals_data, 
    pars = c("b_Intercept", "b_ot1", "b_Conditionreal", "b_ot1:Conditionreal"), 
    prob = 0.5, 
    prob_outer = 0.9, 
    .id = "model")

r_ot0_uis <- effects %>% 
  filter(parameter == "b_Conditionreal") %>% 
  split(.$model) %>% 
  fmt_inline_median_interval() %>% 
  add_ui_slug_to_first("90%&nbsp;UI: ")

r_ot1_uis <- effects %>% 
  filter(parameter == "b_ot1:Conditionreal") %>% 
  split(.$model) %>% 
  fmt_inline_median_interval()
```




## Nonwords versus familiar words

I asked whether the recognition of familiar words differed from the
fast-selecting of referents for nonwords. I fit a Bayesian mixed-effects
logistic regression growth-curve model, as in
[Chapter \@ref(fam-rec)](#fam-rec). For the real word and nonword
conditions, there is a well-defined target image: the familar image for
real words and the novel/unfamiliar image for nonwords. Under these
assumptions, the outcome measures were the probabilities of fixating to
the target image in each condition:

  - P(Look to familiar image | Hear a real word)
  - P(Look to unfamiliar image | Hear a nonword)

Both the real word and nonword conditions measure referent selection as
the probability of fixating on the appropriate referent when presented
with a label. The important analytic question is whether and to what
degree these two probabilities differ. The growth curve model is similar
to the one in [Chapter @ref(fam-rec)](#fam-rec) with cubic polynomial
but it adds a condition effect which interacts with time features. Thus,
the basic model is:

`r insert_html_math()`
\small
\begin{align*}
   \text{log-odds}(\mathit{looking\,}) =\
    &\beta_0 + 
      \beta_1\text{Time}^1 + 
      \beta_2\text{Time}^2 + 
      \beta_3\text{Time}^3\ + 
      &\text{[nonword growth curve]} \\
    (&\gamma_0 + 
      \gamma_1\text{Time}^1 + 
      \gamma_2\text{Time}^2 +
      \gamma_3\text{Time}^3)*\text{Condition} \
      &\text{[adjustments for real words]} \\
\end{align*}
`r insert_html_math()`

I fit a separate model for each year of the study.
[Appendix \@ref(aim2-gca-models)](#aim2-gca-models) contains the R code
used to fit these models along with a description of the specifications
represented by the model syntax. The mixed model included by-child and
by-child-by-condition random effects so that it captured how some of a
child's growth curve features may be similar between the conditions and
may differ between conditions.

For these analyses, I limited focus to distractor-initial trials, and
modeled the data from `r min(d$Time)` to `r max(d$Time)` ms after target
onset. I removed any Age × Child levels if a child had fewer than 4
fixations in a single time bin. In other words, children had to have at
least 4 looks to one of the images in every 50 ms time bin. This
screening removed `r study_counts$T1` children from age 3,
`r study_counts$T2` from age 4, and `r study_counts$T3` from age 5.

Figure \@ref(fig:aim2-real-nonword-means) shows the group averages of the growth
curves. For each condition and age, I computed the empirical growth
curve for each participant, and I averaged the participants' growth
curves together to obtain group averages. I also applied this process
to 100 model-estimated growth curves.

(ref:aim2-real-nonword-means) Averages of participants' growth curves in
each condition and age. The lines represent 100 posterior predictions of
the group average. 

```{r aim2-real-nonword-means, fig.cap = "(ref:aim2-real-nonword-means)", out.width = "80%", fig.height = 4, fig.width = 6}
theme_set(theme_teej())
# m_tp1
# m_tp2
# m_tp3
# m_tp3

# Sets for predictions
n_tp1_all <- d_tp1 %>%
  distinct(Study, ResearchID, Condition, Time, ot1, ot2, ot3) %>%
  mutate(Trials = 30)

n_tp2_all <- d_tp2 %>%
  distinct(Study, ResearchID, Condition, Time, ot1, ot2, ot3) %>%
  mutate(Trials = 30)

n_tp3_all <- d_tp3 %>%
  distinct(Study, ResearchID, Condition, Time, ot1, ot2, ot3) %>%
  mutate(Trials = 30)

tp1_fits <- augment_linpred(
  m_tp1, n_tp1_all, allow_new_levels = TRUE,
  re_formula = NULL, nsamples = 100)

tp2_fits <- augment_linpred(
  m_tp2, n_tp2_all, allow_new_levels = TRUE,
  re_formula = NULL, nsamples = 100)

tp3_fits <- augment_linpred(
  m_tp3, n_tp3_all, allow_new_levels = TRUE,
  re_formula = NULL, nsamples = 100)

all_fits <- bind_rows(tp1_fits, tp2_fits, tp3_fits) %>% 
  mutate(
    Study = convert_study_to_age(Study),
    Condition = convert_condition_to_name(Condition))

all_data <- bind_rows(d_tp1, d_tp2, d_tp3) %>% 
  mutate(
    Study = convert_study_to_age(Study),
    Condition = convert_condition_to_name(Condition)) 

emp_diffs <- all_data %>% 
  mutate(Prop = Target / Trials) %>% 
  select(Study, ResearchID, Prop, Condition, Time) %>% 
  tidyr::spread(Condition, Prop) %>% 
  mutate(
    nonword_prop = nonwords, 
    real_prop = `real words`,
    `nonword - real` = nonword_prop - real_prop) %>% 
  select(Study, ResearchID, Time, nonword_prop, real_prop, `nonword - real`)

# curve_diffs <- all_fits %>% 
#   select(Study, .draw, ResearchID, .posterior_value, Condition, Time) %>% 
#   tidyr::spread(Condition, .posterior_value) %>% 
#   mutate(
#     nonsense_prop = plogis(nonsense), 
#     real_prop = plogis(real),
#     `nonsense - real` = nonsense_prop - real_prop) %>% 
#   select(
#     Study, .draw, ResearchID, Time, 
#     nonsense_prop, real_prop, `nonsense - real`)

# some_curve_diffs <- curve_diffs %>% 
#   tjmisc::sample_n_of(100, .draw) 

some_fits <- all_fits %>% 
  tjmisc::sample_n_of(100, .draw)

ant_0 <- data.frame(
  Condition = c("nonsense", "real"),
  Study = c("Age 4"), 
  Time = c(300, 900), 
  y = c(.83, .60)) %>% 
  mutate(Condition = convert_condition_to_name(Condition))

ggplot(some_fits) + 
  aes(x = Time, y = plogis(.posterior_value), color = Condition) + 
  stat_summary(
    aes(group = interaction(.draw, Condition)),
    geom = "line",
    fun.y = mean,
    alpha = .05) +
  stat_summary(
    aes(y = Target / Trials), 
    data = all_data,
    fun.data = mean_se,
    geom = "pointrange") +
  geom_text(
    aes(label = Condition, y = y),
    data = ant_0,
    hjust = 0,
    size = 3.5,
    family = "Lato Semibold") + 
  geom_text(
    aes(label = label, y = Prop),
    data = data_frame(
      Study = "Age 3",
      Time = 600, 
      Prop = .15, 
      label = constants$note_unfam %>% 
        strwrap(width = 20) %>% paste0(collapse = "\n")),
    size = 3, 
    hjust = 0,
    color = constants$col_off_black,
    family = "Lato") +
  facet_wrap("Study") +
  guides(color = FALSE) +
  labs(
    x = constants$x_time, 
    y = constants$y_prop_target,
    caption = "Intervals: Empirical mean ± SE. Lines: 100 posterior means.") + 
  scale_color_real_non()
```

In [Chapter \@ref(fam-rec)](#fam-rec), I claim that for these growth
curve models that only the intercept and linear time terms to be
behaviorally meaningful model parameters. The intercept measures overall
the average growth curve value so it reflects *looking reliability*, and
the linear time term measures the overall stepness of the growth so it
reflects *lexical processing efficiency*. I also derived a measure of
peak looking probability by taking the median of top five points in a
growth curve, and this peak provides a measure of *word recognition
certainty*. Higher peaks indicate less uncertainty about a word.

I evaluated the condition effects by looking at the effect of the real
word condition on the intercept and linear time terms. The two
conditions did not reliably differ at age 3. The real-word condition
effect on the intercept was `r r_ot0_uis$tp1` and its interaction with
the linear time term was `r r_ot1_uis$tp1`. Both these 90% intervals
include 0 as a plausible estimate for the condition difference, so there
is uncertainty about the sign of the effect. I therefore conclude
that the conditions did not credibly differ on average at age 3.

There was an advantage for the nonword condition at age 4 and age 5. The
real-word effect was negative at age 4, `r r_ot0_uis$tp2`, so that on
average, children looked less to target for the real words than the
nonwords. There was a suggestive effect linear time effect at
age 4, `r r_ot1_uis$tp2`. The curve for real words was probably less
steep at age 4 but values near 0 remain plausible. At age 5, only the
intercept difference was credible, `r r_ot0_uis$tp3`. In general,
children performed better in the nonword condition than the real word
condition at age 4 and age 5. This difference shows up in the growth
curve model through intercept effects, although it is plausible that
children's nonword growth curves were steeper than the real word curves
at age 4.


```{r}
do_it_1 <- peaks %>%
  group_by(Study, ResearchID) %>%
  summarise_at(vars(nonsense:diff), funs(mean, sd)) %>%
  rename(nonsense = nonsense_mean, real = real_mean, diff = diff_mean) %>% 
  ungroup()

# do_it_1 %>% 
#   group_by(Study) %>% 
#   summarise(
#     real_ceiling = sum(real >= .99),
#     real_ceiling_prop = real_ceiling / n(),
#     nonsense_ceiling = sum(nonsense >= .99),
#     nonsense_ceiling_prop = nonsense_ceiling / n(), 
#     n = n())

ceilings <- peaks %>% 
  group_by(Study, .draw) %>% 
  summarise(
    real = sum(real >= .99),
    nonsense = sum(nonsense >= .99)) %>% 
  ungroup() %>% 
  select(Study, real, nonsense) %>%
  tidyr::nest(-Study) %>% 
  mutate(intervals = data %>% purrr::map(bayesplot::mcmc_intervals_data)) %>% 
  select(-data) %>% 
  tidyr::unnest(intervals) %>% 
  mutate(
    Study = stringr::str_replace(Study, "TimePoint", "TP"),
    parameter = stringr::str_replace(parameter, "nonsense", "nons"))

nons_ceilings <- ceilings  %>% 
  filter(parameter == "nons") %>% 
  split(.$Study) %>% 
  fmt_inline_median_interval(0) %>% 
  add_ui_slug_to_first(slug = "90%&nbsp;UI: ")

real_ceilings <- ceilings  %>% 
  filter(parameter == "real") %>% 
  split(.$Study) %>% 
  fmt_inline_median_interval(0)
# peaks %>% 
#   mutate(Study = convert_study_to_age(Study)) %>% 
#   group_by(Study, ResearchID) %>% 
#   summarise_at(vars(nonsense:diff), mean) %>% 
#   select(-diff) %>%
#   tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
#   ungroup() 
theme_set(theme_teej())
```

Next, I analyzed the children's model-estimated growth curve peaks. Each
posterior sample of the model represents a plausible set of growth curve
parameters for the data, so for each of these samples, I calculated the
growth curves for each child and the peaks of the growth curves.
Figure \@ref(fig:aim2-gca-peaks) shows the the posterior averages of the
growth curves peaks for each participant.


(ref:aim2-gca-peaks) Growth curve peaks by child, condition and year of
the study. The movement of the medians conveys how the nonword peaks
effect increased from age 3 to age 4 and the real word peaks increased
from age 4 to age 5. The piling of points near the 1.0 line depicts how
children reached ceiling performance on this task.

```{r aim2-gca-peaks, fig.cap = "(ref:aim2-gca-peaks)", out.width = "66%", fig.height = 3, fig.width = 4.5}
# Count up participants in each study for the x axis
study_peak_counts <- peaks %>%
  distinct(Study, ResearchID) %>%
  mutate(
    Study = Study %>% convert_study_to_age(),
    StudyCounts = Study %>% fct_add_counts()) %>%
  distinct(Study, StudyCounts)

x_levels <- setNames(
  as.character(study_peak_counts$StudyCounts), 
  as.character(study_peak_counts$Study))

condition_means <- peaks %>% 
  mutate(Study = Study %>% convert_study_to_age()) %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(nonsense:diff), mean) %>% 
  select(-diff) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  ungroup() %>% 
  mutate(Condition = convert_condition_to_name(Condition))

ggplot(condition_means) + 
  aes(x = Study, y = Peak, color = Condition) + 
  geom_text(
    aes(label = Condition),
    data = data_frame(
      Peak = 1.06, 
      label = c("nonwords", "real words"),
      Condition = convert_condition_to_name(c("nonsense", "real")),
      Study = "Age 3"), 
    position = position_dodge(width = 1.15), 
    size = 3, 
    family = "Lato Medium") +
  geom_point(
    position = position_jitterdodge(jitter.width = 0.25, dodge.width = 1.05), 
    alpha = .5, 
    shape = 1) +
  geom_boxplot(
    width = .2, 
    position = position_dodge(width = .3), 
    outlier.alpha = 0)  +
  guides(color = FALSE) +
  labs(
    title = "Growth curve peaks",
    x = NULL,
    y = NULL,
    caption = "Points: Participant posterior means.") + 
  scale_x_discrete(labels = x_levels) +
  scale_y_continuous(
    minor_breaks = c(.1, .3, .5, .7, .9),
    breaks = c(0, .2, .4, .6, .8, 1)) +
  scale_color_real_non() 
```


```{r}
meds_by_year <- do_it_1 %>% 
  group_by(Study) %>% 
  summarise(nonsense = median(nonsense), real = median(real))
tp2_non_med <- meds_by_year %>% 
  filter(Study == "TimePoint2") %>% 
  pull(nonsense) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()
```

Descriptive statistics help reveal the developmental trends for this
task. At age 3, the median peak values are similar for the two
conditions, both around .83. The peaks increase for the nonword
condition in the following year with a median value of `r tp2_non_med`.
It is worth emphasizing what this statistic tells us: At age 4, half of
the children had a peak looking probability of `r tp2_non_med` *or
greater*. In other words, children are performing near the ceiling on
this task by age 4. 

To quantify the degree of ceiling performance, I calculated the number
of children per condition with a growth curve peak greater than or equal
to .99 over the posterior distribution. For the nonword condition, there
were `r nons_ceilings$TP1` children who performed at ceiling at age 3,
`r nons_ceilings$TP2` at age 4, `r nons_ceilings$TP3` and at age 5. For
the real word condition, the number of children attaining ceiling
performance was more uneven: there were `r real_ceilings$TP1`
ceiling-performers at age 3, `r real_ceilings$TP2` at age 4, and
`r real_ceilings$TP2` at age 5.


```{r, echo = FALSE}
rw_peak_lme_tp2 <- do_it_1 %>%
  select(Study, ResearchID, nonsense, real) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  mutate(Condition = forcats::fct_rev(Condition)) %>%
  mutate(Study = factor(Study, c("TimePoint2", "TimePoint1", "TimePoint3"))) %>% 
  lme4::lmer(Peak ~ Condition * Study + (1 | ResearchID/Study), .) %>%
  broom::tidy("fixed")

nw_peak_lme_tp1 <- do_it_1 %>% 
  select(Study, ResearchID, nonsense, real) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  lme4::lmer(Peak ~ Condition * Study + (1 | ResearchID/Study), .) %>%
  broom::tidy("fixed")

nw_peak_lme_tp2 <- do_it_1 %>% 
  select(Study, ResearchID, nonsense, real) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  mutate(Study = factor(Study, c("TimePoint2", "TimePoint1", "TimePoint3"))) %>% 
  lme4::lmer(Peak ~ Condition * Study + (1 | ResearchID/Study), .) %>%
  broom::tidy("fixed")

nw_peak_lme_tp3 <- do_it_1 %>% 
  select(Study, ResearchID, nonsense, real) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  mutate(Study = factor(Study, c("TimePoint3", "TimePoint1", "TimePoint2"))) %>% 
  lme4::lmer(Peak ~ Condition * Study + (1 | ResearchID/Study), .) %>%
  broom::tidy("fixed")

# x <- emmeans::emmeans(nw_peak_lme_tp3, "Condition")
# pairs(emmeans::emmeans(nw_peak_lme_tp3, "Condition", by = "Study"))

pull_effect_est <- function(output, effect, flip = FALSE) {
  flip_sign <- function(x) if (flip) x * - 1 else x
  
  b <- output %>% 
    filter(term == effect) %>%
    pull(estimate) %>% 
    flip_sign() %>% 
    printy::fmt_fix_digits(2) %>% 
    printy::fmt_leading_zero()
  
  t <- output %>% 
  filter(term == effect) %>%
  pull(statistic) %>% 
  flip_sign() %>% 
  printy::fmt_fix_digits(2)
  
  list(b = b, t = t)
}

t2_real <- pull_effect_est(nw_peak_lme_tp2, "Conditionreal", TRUE)
t1_real <- pull_effect_est(nw_peak_lme_tp1, "Conditionreal", FALSE)
t3_real <- pull_effect_est(nw_peak_lme_tp3, "Conditionreal", TRUE)

t2_t1 <- pull_effect_est(nw_peak_lme_tp2, "StudyTimePoint1", TRUE)
t2_t3 <- pull_effect_est(nw_peak_lme_tp2, "StudyTimePoint3", FALSE)

t2_t3_real <- pull_effect_est(rw_peak_lme_tp2, "StudyTimePoint3", FALSE)
```

To compare peaks looking probabilities between ages, I fit a linear
mixed effects model with restricted maximum likelihood via the lme4 R
package [vers. `r packageVersion("lme4")`; @lme4]. I regressed the
children's average growth curve peaks onto experimental condition, age
group, and the age × condition interaction. The model included randomly
varying intercepts for child and child-year. This modeling software does
not provide *p*-values for its effects estimates, so for these
comparisons, I decided that an effect was significant when the *t*
statistic for a model fixed effect has an absolute value of 2 or
greater. In practical terms, this convention interprets an effect as
"significant" when its estimate is at least 2 standard errors away
from 0. (@GelmanHill use this approach when with mixed models.)

At age 3, the two conditions did not significantly differ,
B<sub>real-nonword</sub> = `r t1_real$b`, *t* = `r t1_real$t`. At age 4,
nonword peaks were on average `r t2_real$b` proportion units greater
than the real word peaks, *t* = `r t2_real$t`, and at age 5, the nonword
peaks were `r t3_real$b` proportion units greater than the real word
peaks, *t* = `r t3_real$t`. For the nonword condition there was a
significant increase in the peaks from age 3 to age 4, *B*<sub>4-3</sub>
= `r t2_t1$b`, *t* = `r t2_t1$t`, whereas there was no improvement from
age 4 to age 5, *t* = `r t2_t3$t`. In the real word condition, there was
only a significant improvement from age 4 to age 5, *B*<sub>5-4</sub> =
`r t2_t3_real$b`, *t* = `r t2_t3_real$t`.


<!-- [pvalues]: The lme4 package does not provide *p*-values because it is -->
<!-- unclear what number to use for the degrees of freedom with hierarchical -->
<!-- or repeated measures data. One approach is the so-called "normal -->
<!-- approximation" which treats t-values like z-scores---i.e., drawn from a -->
<!-- normal distribution with mean 0 and standard deviation 1. Under this -->
<!-- approach, conventional significance obtains when is greater than or -->
<!-- equal to 1.96 in magnitude. I use 2 as the cutoff because I find significance thresholds are arbitrary. -->

<!-- > As in Chapter XX, I calculated the posterior distribution of growth -->
<!-- curves for each child x condition x year. To measure children's -->
<!-- lexical processing, I used the peak value each growth curve by taking -->
<!-- the median of the top 5 model fits. For each child, I calculated the -->
<!-- difference between the peak of the real word and the nonword growth -->
<!-- curves. This difference in peak values conveys the *condition advantage* -->
<!-- for a child. The figure below visualizes the condition advantages. -->


```{r aim2-gca-diffs, out.width = "50%", fig.height = 3, fig.width = 4, eval = FALSE}
ant <- data_frame(
  diff = -.6, 
  Study = "Age 3", 
  label = "Real word curves had higher peaks")

ant2 <- data_frame(
  diff = .6, 
  Study = "Age 3", 
  label = "Nonword curves had higher peaks")

theme_set(theme_teej())

peaks %>% 
  mutate(Study = convert_study_to_age(Study)) %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(nonsense:diff), mean) %>% 
    ggplot() + 
      aes(x = Study, y = diff) + 
      geom_hline(yintercept = 0, size = 2, color = "white") + 
      geom_boxplot(width = .4, fill = NA, outlier.alpha = 0) +
      geom_point(position = position_jitter(width = .2), alpha = .3, shape = 1) +
      geom_text(
        aes(label = label), 
        data = bind_rows(ant, ant2), nudge_x = -.45, hjust = 0, 
        color = "grey10", size = 3, family = "Lato Medium") +
      labs(
        title = "Differences in growth curve peaks",
        x = NULL,
        y = "Nonword - real word",
        caption = "Points: Participant posterior means.") + 
  theme_teej()

```


**Summary**. There is a decisive advantage for the nonword condition
after age 3. Performance begins to saturate at age 4 with the group
averages for peak looking probabilities over 90%. The real word
condition is more anomalous with performance only showing average
increases from age 4 to age 5.




## Does age 3 referent selection better predicts age 5 vocabulary?

I hypothesized that performance on the nonword condition would be a
better predictor of future vocabulary size than the real word condition.
This hypothesis follows from the assumption that fast referent
selection, as opposed to familiar word recognition, is a more relevant
skill for word-learning. Put another way, a child's ability to quickly
map a novel word to a referent is more closely related to the demands of
in the moment word-learning than familiar word recognition.

In [Chapter \@ref(fam-rec)](#fam-rec), I found that peak looking probability at age 3 positively
correlated with age 5 vocabulary. Pairing this finding with my
hypothesis, I predicted that the growth curve peaks in the nonword
condition at age 3 would be better predictors of vocabulary at age 5
than the real word peaks at age 3.

```{r}
scores <- readr::read_csv("./data-raw/test_scores.csv")
tp1 <- scores %>% filter(Study == "TimePoint1")
tp2 <- scores %>% filter(Study == "TimePoint2")
tp3 <- scores %>% filter(Study == "TimePoint3")

w_evt <- scores %>% 
  filter(Study != "TimePoint2") %>% 
  select(ResearchID, Study, EVT_Standard) %>% 
  tidyr::spread(Study, EVT_Standard) %>% 
  inner_join(do_it_1 %>% filter(Study == "TimePoint1")) %>% 
  modelr::add_residuals(
    lm(TimePoint3 ~ TimePoint1, .), 
    "EVT_Residualized")

evt_t1_z <- lm(scale(TimePoint3) ~ scale(TimePoint1), w_evt)
evt_t1 <- lm(TimePoint3 ~ scale(TimePoint1), w_evt)

evt_t1_z_nonsense <- lm(scale(TimePoint3) ~ scale(TimePoint1) + nonsense, w_evt)
evt_t1_nonsense <- lm(TimePoint3 ~ TimePoint1 + nonsense, w_evt)

w_evt$both <- (w_evt$nonsense + w_evt$real) / 2

evt_t1_z_both <- lm(scale(TimePoint3) ~ scale(TimePoint1) + both + diff, w_evt)
evt_t1_both <- lm(TimePoint3 ~ TimePoint1 + both + diff, w_evt)


evt_t1_z_nonsense <- lm(scale(TimePoint3) ~ scale(TimePoint1) + nonsense, w_evt)
evt_t1_nonsense <- lm(TimePoint3 ~ TimePoint1 + nonsense, w_evt)

evt_t1_z_real <- lm(scale(TimePoint3) ~ scale(TimePoint1) + real, w_evt)

p_real <- evt_t1_z_real %>% 
  broom::tidy(conf.int = TRUE) %>%
  filter(term == "real") %>% 
  pull(p.value) %>% 
  printy::fmt_p_value(digits = 2) 

p_nonsense <- evt_t1_z_nonsense %>% 
  broom::tidy(conf.int = TRUE) %>%
  filter(term == "nonsense") %>% 
  pull(p.value) %>% 
  printy::fmt_p_value() 

evt_z_nonsense <- lm(scale(TimePoint3) ~ nonsense, w_evt)
evt_nonsense <- lm(TimePoint3 ~  nonsense, w_evt)

for_pred <- na.omit(w_evt)

adj_rsquare <- function(model) {
  summary(model)[["adj.r.squared"]]
}

t1_sd <- round(sd(for_pred$TimePoint1))
t3_sd_change <- evt_t1_z$coef[2] %>% round(2)
t3_change <- round(coef(evt_t1)[2])


nonsense_change <- {coef(evt_t1_nonsense)["nonsense"] / 10} %>% 
  printy::fmt_fix_digits(1)

z_nonsense_change <- {coef(evt_t1_z_nonsense)["nonsense"] / 10} %>% 
  printy::fmt_fix_digits(2)

base_r2 <- evt_t1 %>% 
  adj_rsquare() %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

nonsense_delta <- adj_rsquare(evt_t1_z_nonsense) - adj_rsquare(evt_t1)
nonsense_delta <- nonsense_delta %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()


diff_change <- {coef(evt_t1_both)["diff"] / 10} %>% 
  printy::fmt_fix_digits(1)

z_diff_change <- {coef(evt_t1_z_both)["diff"] / 10} %>% 
  printy::fmt_fix_digits(2)

p_both <- evt_t1_z_both %>% 
  broom::tidy(conf.int = TRUE) %>%
  filter(term == "both") %>% 
  pull(p.value) %>% 
  printy::fmt_p_value(digits = 2) 

p_diff <- evt_t1_z_both %>% 
  broom::tidy(conf.int = TRUE) %>%
  filter(term == "diff") %>% 
  pull(p.value) %>% 
  printy::fmt_p_value() 
```


For these analyses, I regressed age-5 expressive vocabulary standard
scores onto the age-3 expressive vocabulary score and onto age-3 real
word peaks or age-3 nonword peaks. There were `r nobs(evt_t1)` children
with data available for this analysis. There was an expected strong
relationship between age 3 and age 5 vocabulary, *R*^2^ = `r base_r2`.
A 1-SD (`r t1_sd`-point) increase in vocabulary at age 3 predicted an
`r t3_sd_change`-SD (`r t3_change`-point) increase at age 5. There was
no effect of age-3 peak over and above age-3 vocabulary, *p* = `p_real`.
There was a significant effect of the nonword peak, *p* =
`r p_nonsense`, *ΔR*^2^ = `r nonsense_delta`, over and above age-3
vocabulary. A .1 increase in nonword peak probability predicted a
`r z_nonsense_change`-SD (`r nonsense_change`-point) increase in age-5
vocabulary. Figure \@ref(fig:age-5-from-peaks) depicts the difference
between the two conditions with a flat line for the real condition and
small slope for the nonword condition.

(ref:age-5-from-peaks) Marginal effects of age-3 referent selection
measures on age-5 expressive vocabulary standard scores. The vocabulary
scores were adjusted (residualized) to control for age-3 vocabulary, so
these regression lines show the effects of the predictors over and above
age-3 vocabulary.

```{r age-5-from-peaks, fig.cap = "(ref:age-5-from-peaks)", out.width = "100%", fig.height = 2.5, fig.width = 6}
w_l <- w_evt %>% 
  select(ResearchID, EVT_Residualized, nonsense, real, diff) %>% 
  rename(
    `Nonword peak` = nonsense,
    `Real word peak` = real,
    `Nonword advantage` = diff) %>% 
  tidyr::gather("var", "value", -ResearchID, -EVT_Residualized) %>% 
  mutate(
    var = factor(var, c("Real word peak", "Nonword peak", "Nonword advantage")))

fmt_axis_props <- function(xs) {
  ifelse(xs == 0, "0", printy::fmt_leading_zero(xs)) 
}

step_by_25 <- function(x) {
  steps <- (x %/% .25)
  seq(from = steps[1] - 1, to = steps[2] + 1) * .25
}

w_l %>%
  # add dummy point to real word peaks so that panel has the same range and
  # width as the nonword peaks
  tibble::add_row(
    ResearchID = "1", EVT_Residualized = NA, 
    var = "Real word peak", value = .01) %>% 
  ggplot() +
    aes(x = value, y = EVT_Residualized) +
    geom_hline(yintercept = 0, color = "white",  size = 2) + 
    geom_point(color = "grey40") +
    stat_smooth(method = "lm", color = constants$col_blue_highlight) + 
    facet_wrap("var", scales = "free_x") +
    # scale_x_continuous(labels = fmt_axis_props) +
    # scale_x_continuous(breaks = step_by_25, labels = fmt_axis_props) +
    labs(
      x = "Age 3 measures", 
      y = "Age 5 EVT-2 (Adj.)",
      caption = "Line: Regression estimate with standard error")
```

Finally, I tested whether the difference between nonword and real word
peaks within children predicted vocabulary growth. The differences do
not convey much information about how well the child performed: A
difference of 0 can happen if a child has peaks of .1 in both conditions
or .9 in both conditions. To control for general performance, I also
included the within-child averages of the two peaks. The model predicted
age-5 vocabulary using the within-child averages of peaks, the nonword
advantage, and age-3 vocabulary. In this case, condition-averaged
performance did not significantly predict age-5 vocabulary, *p* =
`p_both`. The condition differences did predict age-5 vocabulary: A .1
increase in the nonword condition advantage predicted a
`r z_diff_change`-SD (`r diff_change`-point) increase in age-5
vocabulary, *p* = `p_both`

**Summary**. A child's performance in the nonword condition at age 3
positively predicted expressive vocabulary size at age 5. This effect
held even when controlling age-3 vocabulary size, and the effect emerged
when using the absolute growth curve peak or using the relative
advantage of the nonword condition over the real word condition.
Although the effects were significant, the effect size were small. The
EVT-2 is normed to have an IQ-like scale with a mean of 100 and standard
deviation of 15. An increase of .1 in age-3 growth curve peak predicted
an increase in age-5 vocabulary of `r nonsense_change`, appromately one
tenth of the test norm's standard deviations.




### Points for discussion

The advantage of nonwords over real words was an unexpected. My
pre-analysis hypotheses were that word recognition in the real word
condition would be easier than in the nonword condition, or failing
that, the two conditions would not reliably differ. I had discounted the
possibility of an overall advantage for nonwords over real words.


The results are consistent however with a novelty bias in reference selection
[@Horst2011].

Children hit ceiling performanceo on this task.

<!-- For this task, I will model how the looks to the familiar image differ -->
<!-- in each condition (real words, mispronunciations, nonwords) and how the -->
<!-- growth curves for each condition change year over year. This model will -->
<!-- use growth curve model described in [Growth Curve Analysis](#growth-curve-analysis) but -->
<!-- augmented with Condition effects. -->

<!-- I will examine whether and when any dissociation is observed for word -->
<!-- recognition in the real word and nonword conditions. @McMurray2012 argue that  -->
<!-- familiar word recognition and fast -->
<!-- association for novel words reflect the same cognitive process: referent -->
<!-- selection. Data from this task would support with this hypothesis when -->
<!-- the growth curves for looks to the familiar image are symmetrical for -->
<!-- the real word and nonword conditions. Figure \@ref(fig:le-means), showing data -->
<!-- from @MPPaper [, _n_\ =\ 34 children, 30-46 months old], shows some -->
<!-- symmetry for the real word and nonword conditions. -->

<!-- I tested whether the two measures ever dissociate by computing the -->
<!-- posterior predicted difference between the growth curves. This approach -->
<!-- is similar to the bootstrap-based divergence analyses used in some word -->
<!-- recognition experiments [e.g., @Oleson2015; @eyetrackingR]. The -->
<!-- essential question is when—at which specific time points—do two growth -->
<!-- curves differ from one another. The bootstrap approach -->
<!-- uses resampling to get an estimate, whereas I use posterior -->
<!-- predicted samples to estimate these differences. -->

<!-- Specifically, I will compute the posterior-predicted looks to the -->
<!-- familiar object in the real word condition, P(Familiar | Real Word, Time -->
<!-- *t*, Child *i*) and the analogous looks to the unfamiliar object in the -->
<!-- nonword condition, P(Unfamiliar | Nonword, Time *t*, Child *i*). The -->
<!-- difference between these two probabilities estimates how the time course -->
<!-- of word recognition differs between these two conditions, and I can use -->
<!-- 50% and 90% uncertainty intervals to determine during which time points -->
<!-- the curves credibly differ from each other. -->


