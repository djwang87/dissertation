Development of referent selection
=======================================================================

```{r, include = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r helpers, message = FALSE, warning = FALSE}
```

```{r, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)
```



```{r load-aim2-nw-data, include = FALSE}
constants$cap_emp_and_draw <- 
  "Intervals: Empirical mean ± SE. Lines: 100 posterior means."

d <- readr::read_csv("./data/aim2-model-ready.csv.gz") %>% 
  filter(!is.na(Bias_Fam)) %>% 
  filter(300 <= Time) %>% 
  select(-starts_with("ot")) %>% 
  polypoly::poly_add_columns(
    Time, degree = 3, scale_width = 1, prefix = "ot")

# Flip things so that the nonword and real-word curves go upward
d_r_ui <- d %>% 
  filter(Condition == "real", Bias_Fam == "Unfamiliar") %>% 
  mutate(elog = empirical_logit(Target, Distractor))

d_bias_target <- tibble::tribble(
  ~Condition, ~Bias_Fam,   ~Bias_Target,
  "nonsense", "Familiar",   "Distractor",
  "nonsense", "Unfamiliar", "Target",
  "real",     "Familiar",   "Target",
  "real",     "Unfamiliar", "Distractor")

d_r_nw_vs <- d %>% 
  select(-Primary, -.response_def, -Prop, -PropSE) %>% 
  filter(Condition != "MP") %>% 
  rename(Unfamiliar = Distractor, Familiar = Target) %>% 
  mutate(
    Target = ifelse(Condition == "nonsense", Unfamiliar, Familiar), 
    Distractor = ifelse(Condition == "nonsense", Familiar, Unfamiliar),
    Trials = Target + Distractor) %>% 
  left_join(d_bias_target) %>% 
  mutate(elog = empirical_logit(Target, Distractor))

d_r_nw_dis <- d_r_nw_vs %>% 
  filter(Bias_Target == "Distractor")

study_child_with_empty_cells <- d_r_nw_dis %>% 
  filter(Trials < 4) %>% 
  distinct(Study, ResearchID)

study_counts <- study_child_with_empty_cells %>% 
  count(Study) %>% 
  split(.$Study) %>% 
  lapply(pull, n) %>% 
  set_names(stringr::str_replace, "TimePoint", "T")

d_r_nw_dis <- d_r_nw_dis %>% 
  anti_join(study_child_with_empty_cells)
```

```{r load-aim2-nw-models, include = FALSE}
library(brms)
library(bayesplot)
theme_set(theme_teej())

d_r_nw_dis <- readr::read_rds("./data/aim2-real-vs-nw-modeled-data.rds.gz") 

d_tp1 <- d_r_nw_dis %>%
  filter(Study == "TimePoint1") 

d_tp2 <- d_r_nw_dis %>%
  filter(Study == "TimePoint2") 

d_tp3 <- d_r_nw_dis %>%
  filter(Study == "TimePoint3") 

m_tp1 <- readr::read_rds("./data/aim2-real-vs-nw-tp1.rds.gz")
m_tp2 <- readr::read_rds("./data/aim2-real-vs-nw-tp2.rds.gz")
m_tp3 <- readr::read_rds("./data/aim2-real-vs-nw-tp3.rds.gz")

peaks <- readr::read_rds("./data/aim2-real-vs-nw-all-peaks.rds.gz")
```

```{r}
effects <- list(tp1 = m_tp1, tp2 = m_tp2, tp3 = m_tp3) %>% 
  lapply(as.matrix) %>% 
  purrr::map_df(
    mcmc_intervals_data, 
    pars = c("b_Intercept", "b_ot1", "b_Conditionreal", "b_ot1:Conditionreal"), 
    prob = 0.5, 
    prob_outer = 0.9, 
    .id = "model")

r_ot0_uis <- effects %>% 
  filter(parameter == "b_Conditionreal") %>% 
  split(.$model) %>% 
  fmt_inline_median_interval() %>% 
  add_ui_slug_to_first("90%&nbsp;UI: ")

r_ot1_uis <- effects %>% 
  filter(parameter == "b_ot1:Conditionreal") %>% 
  split(.$model) %>% 
  fmt_inline_median_interval()
```

```{r}
percent_diff <- function(new, old) {
  # A change from 100 to 80 is (80 - 100) / 100 = -20 / 100 = -20% change
  (new - old) / old
}

# m_tp1
pull_samples <- . %>% 
  posterior_samples(pars = "^b_") %>% 
  transmute(
    b_Nonword_Intercept = b_Intercept,
    b_Real_Intercept = b_Intercept + b_Conditionreal,
    b_Nonword_ot1 = b_ot1,
    b_Real_ot1 = b_ot1 + `b_ot1:Conditionreal`,
    b_Nonword_ot2 = b_ot2,
    b_Real_ot2 = b_ot2 + `b_ot2:Conditionreal`,
    b_Nonword_ot3 = b_ot3,
    b_Real_ot3 = b_ot3 + `b_ot3:Conditionreal`,
    b_Nonword_Intercept_Prop = plogis(b_Nonword_Intercept),
    b_Real_Intercept_Prop = plogis(b_Real_Intercept),
    d_NonwordvReal_Prop = b_Nonword_Intercept_Prop - b_Real_Intercept_Prop,
    neg_d_NonwordvReal_Prop = d_NonwordvReal_Prop * -1,
    per_d_NonwordvReal_Prop = percent_diff(
      b_Nonword_Intercept_Prop, 
      b_Real_Intercept_Prop),
    d_NonwordvReal_ot1 = b_Nonword_ot1 - b_Real_ot1,
    neg_d_NonwordvReal_ot1 = d_NonwordvReal_ot1 * -1,
    per_d_NonwordvReal_ot1 = percent_diff(b_Nonword_ot1, b_Real_ot1),
    neg_per_d_NonwordvReal_ot1 = -percent_diff(b_Nonword_ot1, b_Real_ot1),
    d_NonwordvReal_ot2 = b_Nonword_ot2 - b_Real_ot2,
    neg_d_NonwordvReal_ot2 = d_NonwordvReal_ot2 * -1,
    per_d_NonwordvReal_ot2 = percent_diff(b_Nonword_ot2, b_Real_ot2),
    neg_per_d_NonwordvReal_ot2 = -percent_diff(b_Nonword_ot2, b_Real_ot2),
    d_NonwordvReal_ot3 = b_Nonword_ot3 - b_Real_ot3,
    neg_d_NonwordvReal_ot3 = d_NonwordvReal_ot3 * -1,
    per_d_NonwordvReal_ot3 = percent_diff(b_Nonword_ot3, b_Real_ot3),
    neg_per_d_NonwordvReal_ot3 = -percent_diff(b_Nonword_ot3, b_Real_ot3)) %>% 
  as_tibble()


age3 <- m_tp1 %>% pull_samples()
age4 <- m_tp2 %>% pull_samples()
age5 <- m_tp3 %>% pull_samples()
# mcmc_intervals(age3, regex_pars = "Prop")
# mcmc_intervals(data.frame(x = mp_fam_fixef$per_d_ot1_Age4))
# mcmc_intervals(data.frame(x = mp_fam_fixef$b_Intercept_Prop_Age3))
# mcmc_intervals(mp_fam_fixef,  regex_pars = "Intercept_Prop")
# mcmc_intervals_data(mp_fam_fixef,  regex_pars = "Intercept_Prop")
pull_props <- . %>% 
  mcmc_intervals_data(regex_pars = "Prop") %>% 
  mutate(
    parameter = parameter %>% 
      stringr::str_replace("_?Intercept_Prop_?", "") %>% 
      stringr::str_replace("_?Prop_?", "")) %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  add_ui_slug_to_first("90% UI: ") %>% 
  lapply(fmt_remove_leading_zeros_in_text)

props3 <- age3 %>% pull_props()
props4 <- age4 %>% pull_props()
props5 <- age5 %>% pull_props()

pull_time1 <- . %>% 
  mcmc_intervals_data(regex_pars = "ot1") %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  purrr::map_at(
    .at = c("per_d_NonwordvReal_ot1", "neg_per_d_NonwordvReal_ot1"), 
    .f = fmt_convert_prop_to_percent)

time1_3 <- age3 %>% pull_time1()
time1_4 <- age4 %>% pull_time1()
time1_5 <- age5 %>% pull_time1()

```



## Nonwords versus familiar words

I asked whether the recognition of familiar words differed from the
fast selection of referents for nonwords. I fit a Bayesian mixed-effects
logistic regression growth-curve model, as in
[Chapter \@ref(fam-rec)](#fam-rec). For the real word and nonword
conditions, there is a well-defined target image: the familiar image for
real words and the novel/unfamiliar image for nonwords. The outcome
measures were the probabilities of fixating to the target image in each
condition:

  - P(look to familiar image | hear a real word)
  - P(look to unfamiliar image | hear a nonword)

Both the real word and nonword conditions measure referent selection as
the probability of fixating on the appropriate referent when presented
with a label. The important analytic question is whether and to what
degree these two probabilities differ. The growth curve model is similar
to the one in [Chapter \@ref(fam-rec)](#fam-rec) with linear, quadratic
and cubic time features but it adds a condition effect which interacts
with these features. The linear model was:

`r insert_html_math()`
\small
\begin{align*}
   \text{log-odds}(\mathit{looking\,}) =\
    &\beta_0 + 
      \beta_1\text{Time}^1 + 
      \beta_2\text{Time}^2 + 
      \beta_3\text{Time}^3\ + 
      &\text{[nonword growth curve]} \\
    (&\gamma_0 + 
      \gamma_1\text{Time}^1 + 
      \gamma_2\text{Time}^2 +
      \gamma_3\text{Time}^3)*\text{Condition} \
      &\text{[adjustments for real words]} \\
\end{align*}
`r insert_html_math()`

I fit a separate model for each year of the study.
[Appendix \@ref(aim2-gca-models)](#aim2-gca-models) contains the R code
used to fit these models along with a description of the specifications
represented by the model syntax. The mixed model included by-child and
by-child-by-condition random effects to allow some of a
child's growth curve features to be similar between conditions
(by-child effects) and to differ between conditions
(by-child-by-condition effects).

For these analyses, I limited focus to distractor-initial trials, and
modeled the data from `r min(d$Time)` to `r max(d$Time)` ms after target
onset. I removed any Age × Child levels if a child had fewer than 4
fixations in a single time bin. In other words, children had to have at
least 4 looks to one of the images in every 50 ms time bin. This
screening removed `r study_counts$T1` children at age 3,
`r study_counts$T2` at age 4, and `r study_counts$T3` at age 5.

Figure \@ref(fig:aim2-real-nonword-means) shows the group averages of the growth
curves. For each condition and age, I computed the empirical growth
curve for each participant, and I averaged the participants' growth
curves together to obtain group averages. I also applied this process
to 100 model-estimated growth curves.

(ref:aim2-real-nonword-means) Averages of participants' growth curves in each condition and age. The lines represent 100 posterior predictions of the group average. 

```{r aim2-real-nonword-means, fig.cap = "(ref:aim2-real-nonword-means)", out.width = "80%", fig.height = 4, fig.width = 6}
theme_set(theme_teej())
# m_tp1
# m_tp2
# m_tp3
# m_tp3

# Sets for predictions
n_tp1_all <- d_tp1 %>%
  distinct(Study, ResearchID, Condition, Time, ot1, ot2, ot3) %>%
  mutate(Trials = 30)

n_tp2_all <- d_tp2 %>%
  distinct(Study, ResearchID, Condition, Time, ot1, ot2, ot3) %>%
  mutate(Trials = 30)

n_tp3_all <- d_tp3 %>%
  distinct(Study, ResearchID, Condition, Time, ot1, ot2, ot3) %>%
  mutate(Trials = 30)

# re_formula <- NA
re_formula <- NULL

tp1_fits <- augment_linpred(
  m_tp1, n_tp1_all, allow_new_levels = TRUE,
  re_formula = re_formula, nsamples = 100)

tp2_fits <- augment_linpred(
  m_tp2, n_tp2_all, allow_new_levels = TRUE,
  re_formula = re_formula, nsamples = 100)

tp3_fits <- augment_linpred(
  m_tp3, n_tp3_all, allow_new_levels = TRUE,
  re_formula = re_formula, nsamples = 100)

all_fits <- bind_rows(tp1_fits, tp2_fits, tp3_fits) %>% 
  mutate(
    Study = convert_study_to_age(Study),
    Condition = convert_condition_to_name(Condition))

all_data <- bind_rows(d_tp1, d_tp2, d_tp3) %>% 
  mutate(
    Study = convert_study_to_age(Study),
    Condition = convert_condition_to_name(Condition)) 

# emp_diffs <- all_data %>% 
#   mutate(Prop = Target / Trials) %>% 
#   select(Study, ResearchID, Prop, Condition, Time) %>% 
#   tidyr::spread(Condition, Prop) %>% 
#   mutate(
#     nonword_prop = nonwords, 
#     real_prop = `real words`,
#     `nonword - real` = nonword_prop - real_prop) %>% 
#   select(Study, ResearchID, Time, nonword_prop, real_prop, `nonword - real`)

# curve_diffs <- all_fits %>% 
#   select(Study, .draw, ResearchID, .posterior_value, Condition, Time) %>% 
#   tidyr::spread(Condition, .posterior_value) %>% 
#   mutate(
#     nonsense_prop = plogis(nonsense), 
#     real_prop = plogis(real),
#     `nonsense - real` = nonsense_prop - real_prop) %>% 
#   select(
#     Study, .draw, ResearchID, Time, 
#     nonsense_prop, real_prop, `nonsense - real`)

# some_curve_diffs <- curve_diffs %>% 
#   tjmisc::sample_n_of(100, .draw) 

some_fits <- all_fits %>% 
  tjmisc::sample_n_of(100, .draw)

ant_0 <- data.frame(
  Condition = c("nonsense", "real"),
  Study = c("Age 4"), 
  Time = c(300, 900), 
  y = c(.83, .60)) %>% 
  mutate(Condition = convert_condition_to_name(Condition))

ggplot(some_fits) + 
  aes(x = Time, y = plogis(.posterior_value), color = Condition) + 
  geom_hline(yintercept = .5, size = 2, color = "white") +
  stat_summary(
    aes(group = interaction(.draw, Condition)),
    geom = "line",
    fun.y = mean,
    alpha = .05) +
  stat_summary(
    aes(y = Target / Trials), 
    data = all_data,
    fun.data = mean_se,
    geom = "pointrange") +
  geom_text(
    aes(label = Condition, y = y),
    data = ant_0,
    hjust = 0,
    size = 3.5,
    family = "Lato Semibold") + 
  geom_text(
    aes(label = label, y = Prop),
    data = data_frame(
      Study = "Age 3",
      Time = 600, 
      Prop = .15, 
      label = constants$note_unfam %>% 
        strwrap(width = 20) %>% paste0(collapse = "\n")),
    size = 3, 
    hjust = 0,
    color = constants$col_off_black,
    family = "Lato") +
  facet_wrap("Study") +
  guides(color = FALSE) +
  labs(
    x = constants$x_time, 
    y = constants$y_prop_target,
    caption = constants$cap_emp_and_draw) + 
  scale_color_real_non()
```

In [Chapter \@ref(fam-rec)](#fam-rec), I claim that for these growth
curve models only the intercept and linear time terms are behaviorally
meaningful model parameters. The intercept measures the average growth
curve value so it reflects overall *looking reliability*, and the linear
time term measures the overall steepness of the growth so it reflects
*lexical processing efficiency*. I also derived a measure of peak
looking probability by taking the median of top five points in a growth
curve, and this peak provides a measure of *word recognition certainty*.
Higher peaks indicate less uncertainty about a word.

I evaluated the general condition effects by looking at how the
population-level ("fixed") effects differed in each condition. Due to
ceiling effects, where children's growth curves saturated 100% looking
probabilities, the population-level average growth curve outperformed
the observed group averages in Figure \@ref(fig:aim2-real-nonword-means).
The condition differences described by these population-level effects,
however, do qualitatively match the patterns in the group averages.

The two conditions did not reliably differ at age 3. The
population-level average proportion of looks to the target for nonwords
was `r props3$b_Nonword`, compared to `r props3$b_Real` for real
words---a difference (nonword advantage) of `r props3$d_NonwordvReal`. For the
linear time feature, the nonword slope increases by
`r time1_3$neg_per_d_NonwordvReal_ot1` in the real word condition. Both
these 90% intervals include 0 as a plausible estimate for the condition
difference, so there is uncertainty about the sign of the effect. I
therefore conclude that the conditions did not credibly differ on
average at age 3.

There was an advantage for the nonword condition at age 4 and age 5. The
population-level average proportion of looks for the nonwords was
`r props4$b_Nonword`, compared to `props4$b_Real` for real words. On
average, children looked less to target for the real words than the
nonwords. There was a suggestive effect linear time effect where the
nonword curve was `r time1_4$per_d_NonwordvReal_ot1` steeper than the real word
one. The curve for real words was probably less steep at age 4 but small
values near 0 remain plausible. At age 5, only the average probability
difference was credible, `r props5$b_Nonword` for nonwords compared to
`props5$b_Real` for real words. In general, children performed better in
the nonword condition than the real word condition at age 4 and age 5.
This difference shows up in the growth curve model through intercept
effects, although it is plausible that children's nonword growth curves
were steeper than the real word curves at age 4.





```{r}
do_it_1 <- peaks %>%
  group_by(Study, ResearchID) %>%
  summarise_at(vars(nonsense:diff), funs(mean, sd)) %>%
  rename(nonsense = nonsense_mean, real = real_mean, diff = diff_mean) %>% 
  ungroup()

# do_it_1 %>% 
#   group_by(Study) %>% 
#   summarise(
#     real_ceiling = sum(real >= .99),
#     real_ceiling_prop = real_ceiling / n(),
#     nonsense_ceiling = sum(nonsense >= .99),
#     nonsense_ceiling_prop = nonsense_ceiling / n(), 
#     n = n())

ceilings <- peaks %>% 
  group_by(Study, .draw) %>% 
  summarise(
    real = sum(real >= .99),
    nonsense = sum(nonsense >= .99)) %>% 
  ungroup() %>% 
  select(Study, real, nonsense) %>%
  tidyr::nest(-Study) %>% 
  mutate(intervals = data %>% purrr::map(mcmc_intervals_data)) %>% 
  select(-data) %>% 
  tidyr::unnest(intervals) %>% 
  mutate(
    Study = stringr::str_replace(Study, "TimePoint", "TP"),
    parameter = stringr::str_replace(parameter, "nonsense", "nons"))

nons_ceilings <- ceilings  %>% 
  filter(parameter == "nons") %>% 
  split(.$Study) %>% 
  fmt_inline_median_interval(0) %>% 
  add_ui_slug_to_first(slug = "90%&nbsp;UI: ")

real_ceilings <- ceilings  %>% 
  filter(parameter == "real") %>% 
  split(.$Study) %>% 
  fmt_inline_median_interval(0)
# peaks %>% 
#   mutate(Study = convert_study_to_age(Study)) %>% 
#   group_by(Study, ResearchID) %>% 
#   summarise_at(vars(nonsense:diff), mean) %>% 
#   select(-diff) %>%
#   tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
#   ungroup() 
```

I analyzed the children's model-estimated growth curve peaks. Each
posterior sample of the model represents a plausible set of growth curve
parameters for the data, so for each of these samples, I calculated the
growth curves for each child and the peaks of the growth curves.
Figure \@ref(fig:aim2-gca-peaks) shows the the posterior averages of the
growth curves peaks for each participant.

(ref:aim2-gca-peaks) Growth curve peaks by child, condition and year of the study. The movement of the medians conveys how the nonword peaks effect increased from age 3 to age 4 and the real word peaks increased from age 4 to age 5. The piling of points near the 1.0 line depicts how children reached ceiling performance on this task.

```{r aim2-gca-peaks, fig.cap = "(ref:aim2-gca-peaks)", out.width = "66%", fig.height = 3, fig.width = 4.5}
# Count up participants in each study for the x axis
study_peak_counts <- peaks %>%
  distinct(Study, ResearchID) %>%
  mutate(
    Study = Study %>% convert_study_to_age(),
    StudyCounts = Study %>% fct_add_counts()) %>%
  distinct(Study, StudyCounts)

x_levels <- setNames(
  as.character(study_peak_counts$StudyCounts), 
  as.character(study_peak_counts$Study))

condition_means <- peaks %>% 
  mutate(Study = Study %>% convert_study_to_age()) %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(nonsense:diff), mean) %>% 
  select(-diff) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  ungroup() %>% 
  mutate(Condition = convert_condition_to_name(Condition))

ggplot(condition_means) + 
  aes(x = Study, y = Peak, color = Condition) + 
  geom_hline(yintercept = .5, size = 2, color = "white") + 
  geom_text(
    aes(label = Condition),
    data = data_frame(
      Peak = 1.06, 
      label = c("nonwords", "real words"),
      Condition = convert_condition_to_name(c("nonsense", "real")),
      Study = "Age 3"), 
    position = position_dodge(width = 1.15), 
    size = 3, 
    family = "Lato Medium") +
  geom_point(
    position = position_jitterdodge(jitter.width = 0.25, dodge.width = 1.05), 
    alpha = .5, 
    shape = 1) +
  geom_boxplot(
    width = .2, 
    position = position_dodge(width = .3), 
    outlier.alpha = 0)  +
  guides(color = FALSE) +
  labs(
    title = "Growth curve peaks",
    x = NULL,
    y = NULL,
    caption = "Points: Participant posterior means.") + 
  scale_x_discrete(labels = x_levels) +
  scale_y_continuous(
    minor_breaks = c(.1, .3, .5, .7, .9),
    breaks = c(0, .2, .4, .6, .8, 1)) +
  scale_color_real_non() 
```


```{r}
meds_by_year <- do_it_1 %>% 
  group_by(Study) %>% 
  summarise(nonsense = median(nonsense), real = median(real))

tp1_non_med <- meds_by_year %>% 
  filter(Study == "TimePoint1") %>% 
  pull(nonsense) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

tp1_r_med <- meds_by_year %>% 
  filter(Study == "TimePoint1") %>% 
  pull(real) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

tp2_non_med <- meds_by_year %>% 
  filter(Study == "TimePoint2") %>% 
  pull(nonsense) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

tp3_non_med <- meds_by_year %>% 
  filter(Study == "TimePoint3") %>% 
  pull(nonsense) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

tp2_r_med <- meds_by_year %>% 
  filter(Study == "TimePoint2") %>% 
  pull(real) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

tp3_r_med <- meds_by_year %>% 
  filter(Study == "TimePoint3") %>% 
  pull(real) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()
```

Descriptive statistics reveal the developmental trends for this task. At
age 3, the median peak values were similar for the two conditions:
`r tp1_non_med` for nonwords and `r tp1_r_med` for real words. The peaks
increased for the nonword condition in the following year with a median
value of `r tp2_non_med`. It is worth emphasizing what this statistic
tells us: At age 4, half of the children had a peak looking probability
of `r tp2_non_med` *or greater*. In other words, half the children
performed near the ceiling on this task by age 4. At age 5, the median
nonword peak was `r tp3_non_med`, essentially unchanged from age 4. For
the real words, the median peak increased from `r tp2_r_med` at age 4 to
`r tp3_r_med` at age 5.

To quantify the degree of ceiling performance, I calculated the number
of children per condition with a growth curve peak greater than or equal
to .99 over the posterior distribution. For the nonword condition, there
were `r nons_ceilings$TP1` children who performed at ceiling at age 3,
`r nons_ceilings$TP2` at age 4, `r nons_ceilings$TP3` and at age 5. For
the real word condition, the number of children attaining ceiling
performance was more uneven: there were `r real_ceilings$TP1`
ceiling-performers at age 3, `r real_ceilings$TP2` at age 4, and
`r real_ceilings$TP2` at age 5.


```{r, echo = FALSE}
rw_peak_lme_tp2 <- do_it_1 %>%
  select(Study, ResearchID, nonsense, real) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  mutate(Condition = forcats::fct_rev(Condition)) %>%
  mutate(Study = factor(Study, c("TimePoint2", "TimePoint1", "TimePoint3"))) %>% 
  lme4::lmer(Peak ~ Condition * Study + (1 | ResearchID/Study), .) %>%
  broom::tidy("fixed")

nw_peak_lme_tp1 <- do_it_1 %>% 
  select(Study, ResearchID, nonsense, real) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  lme4::lmer(Peak ~ Condition * Study + (1 | ResearchID/Study), .) %>%
  broom::tidy("fixed")

nw_peak_lme_tp2 <- do_it_1 %>% 
  select(Study, ResearchID, nonsense, real) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  mutate(Study = factor(Study, c("TimePoint2", "TimePoint1", "TimePoint3"))) %>% 
  lme4::lmer(Peak ~ Condition * Study + (1 | ResearchID/Study), .) %>%
  broom::tidy("fixed")

nw_peak_lme_tp3 <- do_it_1 %>% 
  select(Study, ResearchID, nonsense, real) %>%
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  mutate(Study = factor(Study, c("TimePoint3", "TimePoint1", "TimePoint2"))) %>% 
  lme4::lmer(Peak ~ Condition * Study + (1 | ResearchID/Study), .) %>%
  broom::tidy("fixed")

# x <- emmeans::emmeans(nw_peak_lme_tp3, "Condition")
# pairs(emmeans::emmeans(nw_peak_lme_tp3, "Condition", by = "Study"))

pull_effect_est <- function(output, effect, flip = FALSE) {
  flip_sign <- function(x) if (flip) x * - 1 else x
  
  b <- output %>% 
    filter(term == effect) %>%
    pull(estimate) %>% 
    flip_sign() %>% 
    printy::fmt_fix_digits(2) %>% 
    printy::fmt_leading_zero()
  
  t <- output %>% 
  filter(term == effect) %>%
  pull(statistic) %>% 
  flip_sign() %>% 
  printy::fmt_fix_digits(2)
  
  list(b = b, t = t)
}

t2_real <- pull_effect_est(nw_peak_lme_tp2, "Conditionreal", TRUE)
t1_real <- pull_effect_est(nw_peak_lme_tp1, "Conditionreal", FALSE)
t3_real <- pull_effect_est(nw_peak_lme_tp3, "Conditionreal", TRUE)

t2_t1 <- pull_effect_est(nw_peak_lme_tp2, "StudyTimePoint1", TRUE)
t2_t3 <- pull_effect_est(nw_peak_lme_tp2, "StudyTimePoint3", FALSE)

t2_t3_real <- pull_effect_est(rw_peak_lme_tp2, "StudyTimePoint3", FALSE)
```

To compare peaks looking probabilities between ages, I fit a linear
mixed effects model with restricted maximum likelihood via the lme4 R
package [vers. `r packageVersion("lme4")`; @lme4]. I regressed the
children's average growth curve peaks onto experimental condition, age
group, and the age × condition interaction. The model included randomly
varying intercepts for child and child-year. This modeling software does
not provide *p*-values for its effects estimates, so for these
comparisons, I decided that an effect was significant when the *t*
statistic for a population-level ("fixed") effect had an absolute value
of 2 or greater. In practical terms, this convention interprets an
effect as "significant" when its estimate is at least 2 standard errors
away from 0. (@GelmanHill use this approach when with mixed models.)

At age 3, the two conditions did not significantly differ,
B<sub>real-nonword</sub> = `r t1_real$b`, *t* = `r t1_real$t`. At age 4,
nonword peaks were on average `r t2_real$b` proportion units greater
than the real word peaks, *t* = `r t2_real$t`, and at age 5, the nonword
peaks were `r t3_real$b` proportion units greater than the real word
peaks, *t* = `r t3_real$t`. For the nonword condition there was a
significant increase in the peaks from age 3 to age 4, *B*<sub>4-3</sub>
= `r t2_t1$b`, *t* = `r t2_t1$t`, whereas there was no improvement from
age 4 to age 5, *t* = `r t2_t3$t`. In the real word condition, there was
only a significant improvement from age 4 to age 5, *B*<sub>5-4</sub> =
`r t2_t3_real$b`, *t* = `r t2_t3_real$t`.




<!-- [pvalues]: The lme4 package does not provide *p*-values because it is -->
<!-- unclear what number to use for the degrees of freedom with hierarchical -->
<!-- or repeated measures data. One approach is the so-called "normal -->
<!-- approximation" which treats t-values like z-scores---i.e., drawn from a -->
<!-- normal distribution with mean 0 and standard deviation 1. Under this -->
<!-- approach, conventional significance obtains when is greater than or -->
<!-- equal to 1.96 in magnitude. I use 2 as the cutoff because I find significance thresholds are arbitrary. -->

<!-- > As in Chapter XX, I calculated the posterior distribution of growth -->
<!-- curves for each child x condition x year. To measure children's -->
<!-- lexical processing, I used the peak value each growth curve by taking -->
<!-- the median of the top 5 model fits. For each child, I calculated the -->
<!-- difference between the peak of the real word and the nonword growth -->
<!-- curves. This difference in peak values conveys the *condition advantage* -->
<!-- for a child. The figure below visualizes the condition advantages. -->


```{r aim2-gca-diffs, out.width = "50%", fig.height = 3, fig.width = 4, eval = FALSE}
ant <- data_frame(
  diff = -.6, 
  Study = "Age 3", 
  label = "Real word curves had higher peaks")

ant2 <- data_frame(
  diff = .6, 
  Study = "Age 3", 
  label = "Nonword curves had higher peaks")

peaks %>% 
  mutate(Study = convert_study_to_age(Study)) %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(nonsense:diff), mean) %>% 
    ggplot() + 
      aes(x = Study, y = diff) + 
      geom_hline(yintercept = 0, size = 2, color = "white") + 
      geom_boxplot(width = .4, fill = NA, outlier.alpha = 0) +
      geom_point(position = position_jitter(width = .2), alpha = .3, shape = 1) +
      geom_text(
        aes(label = label), 
        data = bind_rows(ant, ant2), nudge_x = -.45, hjust = 0, 
        color = "grey10", size = 3, family = "Lato Medium") +
      labs(
        title = "Differences in growth curve peaks",
        x = NULL,
        y = "Nonword - real word",
        caption = "Points: Participant posterior means.") + 
  theme_teej()

```


Finally, I asked whether expressive vocabulary size correlated with peak looking performance on the two conditions. At all three years, children with larger vocabularies had higher peak looking values. At age 3 and age 4, vocabulary positively correlated with real-word looking performance, but only the age-4 correlation was significant.

```{r}
scores <- readr::read_csv("./data-raw/test_scores.csv")
tp1 <- scores %>% filter(Study == "TimePoint1")
tp2 <- scores %>% filter(Study == "TimePoint2")
tp3 <- scores %>% filter(Study == "TimePoint3")

peaks_and_vocabs <- peaks %>% 
  mutate(Study = convert_study_to_age(Study)) %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(nonsense:diff), mean) %>% 
  ungroup() 

peaks_and_vocabs_w <- peaks_and_vocabs %>% 
  left_join(
    scores %>% mutate(Study = convert_study_to_age(Study))) 

peaks_and_vocabs_l <- peaks_and_vocabs %>% 
  tidyr::gather("Condition", "Peak", -ResearchID, -Study) %>% 
  left_join(
    scores %>% mutate(Study = convert_study_to_age(Study))) 

  
peaks_and_vocabs_l %>% 
  filter(Condition != "diff") %>% 
  group_by(Study, Condition) %>% 
  tidy_correlation(EVT_Standard, Peak) %>% 
  ungroup() %>% 
  mutate(Condition = convert_condition_to_name(Condition)) %>% 
  select(Study, Condition, n, r = estimate, p = p.value) %>% 
  mutate(
    r = r %>% 
      printy::fmt_fix_digits(2) %>% 
      printy::fmt_leading_zero() %>% 
      printy::fmt_minus_sign(),
    p = printy::fmt_p_value(p)) %>% 
  knitr::kable(
    align = c("llrrr"),
    caption = "Correlation between EVT-2 standard scores and curve peaks")

library(lme4)
# peaks_and_vocabs_l %>% 
#   filter(Condition != "diff") %>% 
#   filter(Study == "Age 3") %>% 
#   lmer(Peak ~ scale(EVT_Standard) * Condition + (1 | ResearchID), .) %>% 
#   summary()
# 
# peaks_and_vocabs_l %>% 
#   filter(Condition != "diff") %>% 
#   filter(Study == "Age 4") %>% 
#   lmer(Peak ~ scale(EVT_Standard) * Condition + (1 | ResearchID), .) %>% 
#   summary()
# 
# peaks_and_vocabs_l %>% 
#   filter(Condition != "diff") %>% 
#   filter(Study == "Age 5") %>% 
#   lmer(Peak ~ scale(EVT_Standard) * Condition + (1 | ResearchID), .) %>% 
#   summary()

# peaks_and_vocabs_w %>% 
#   filter(Study == "Age 3") %>% 
#   lm(nonsense ~ scale(EVT_Standard) * scale(real), .) %>% 
#   summary()
# 
# peaks_and_vocabs_w %>% 
#   filter(Study == "Age 4") %>% 
#   lm(nonsense ~ scale(EVT_Standard) * scale(real), .) %>% 
#   summary()
# 
# peaks_and_vocabs_w %>% 
#   filter(Study == "Age 5") %>% 
#   lm(nonsense ~ scale(EVT_Standard) * scale(real), .) %>% 
#   summary()

peak_corrs <- peaks_and_vocabs_w %>% 
  group_by(Study) %>% 
  tidy_correlation(nonsense, real) %>% 
  ungroup() 

peaks_and_vocabs_l %>% 
  filter(Condition != "diff") %>% 
  ggplot() + 
    aes(x = EVT_Standard, y = Peak, color = Condition) + 
    geom_point(shape = 1) + 
    facet_wrap("Study") + 
    stat_smooth(method = "lm")
# 
# peaks_and_vocabs %>% 
#   ggplot() + 
#     aes(x = EVT_GSV, y = nonsense) + 
#     geom_point() + 
#     facet_wrap("Study") + 
#     stat_smooth(method = "lm")
# 
# peaks_and_vocabs %>% 
#   ggplot() + 
#     aes(x = EVT_GSV, y = nonsense) + 
#     geom_point() + 
#     facet_wrap("Study") + 
#     stat_smooth(method = "lm")
```

**Summary.** There is a decisive advantage for the nonword condition after age 3. Performance begins to saturate at age 4 with the group averages for peak looking probabilities over 90%. The real word condition is more anomalous with performance only showing average increases from age 4 to age 5.

**Summary**. Children performed similarly for real words and nonwords
at age 3. Children's processing of nonwords improved at age 4. At this
age, performance also began to saturate with the group average for peak
looking probability greater than .9 for the nonword condition.
Consequently, children did not improve in processing of nonwords from
age 4 to age 5. For the real word condition, children's performance did
not change from age 3 to age 4 but it did improve from age 4 to age 5.
At both age 4 and age 5, there was a decisive advantage for the nonword
condition. Finally, children with larger vocabularies looked more to the
nonwords compared to children with smaller vocabularies. A comparable effect for
real words was observed at age 3 and age 4 but only reliably observed at age 4.


## Does age 3 referent selection better predict age 5 vocabulary?

I hypothesized that performance on the nonword condition would be a
better predictor of future vocabulary size than the real word condition.
This hypothesis follows from the assumption that fast referent
selection, as opposed to familiar word recognition, is a more relevant
skill for word-learning. Put another way, a child's ability to quickly
map a novel word to a referent is more closely related to the demands of
in the moment word-learning than familiar word recognition.

In [Chapter \@ref(fam-rec)](#fam-rec), I found that peak looking
probability at age 3 positively correlated with age 5 vocabulary.
Pairing this finding with my hypothesis, I predicted that the growth
curve peaks in the nonword condition at age 3 would be better predictors
of vocabulary at age 5 than the real word peaks at age 3.

```{r, include = FALSE}
w_evt <- scores %>% 
  filter(Study != "TimePoint2") %>% 
  select(ResearchID, Study, EVT_Standard) %>% 
  tidyr::spread(Study, EVT_Standard) %>% 
  inner_join(do_it_1 %>% filter(Study == "TimePoint1")) %>% 
  modelr::add_residuals(
    lm(TimePoint3 ~ TimePoint1, .), 
    "EVT_Residualized")

evt_t1_z <- lm(scale(TimePoint3) ~ scale(TimePoint1), w_evt)
evt_t1 <- lm(TimePoint3 ~ scale(TimePoint1), w_evt)

evt_t1_z_nonsense <- lm(scale(TimePoint3) ~ scale(TimePoint1) + nonsense, w_evt)
evt_t1_nonsense <- lm(TimePoint3 ~ TimePoint1 + nonsense, w_evt)

w_evt$both <- (w_evt$nonsense + w_evt$real) / 2

evt_t1_z_both <- lm(scale(TimePoint3) ~ scale(TimePoint1) + both + diff, w_evt)
evt_t1_both <- lm(TimePoint3 ~ TimePoint1 + both + diff, w_evt)
summary(evt_t1_z_both)

evt_t1_z_nonsense <- lm(scale(TimePoint3) ~ scale(TimePoint1) + nonsense, w_evt)
evt_t1_nonsense <- lm(TimePoint3 ~ TimePoint1 + nonsense, w_evt)

evt_t1_z_real <- lm(scale(TimePoint3) ~ scale(TimePoint1) + real, w_evt)

p_real <- evt_t1_z_real %>% 
  broom::tidy(conf.int = TRUE) %>%
  filter(term == "real") %>% 
  pull(p.value) %>% 
  printy::fmt_p_value(digits = 2) 

p_nonsense <- evt_t1_z_nonsense %>% 
  broom::tidy(conf.int = TRUE) %>%
  filter(term == "nonsense") %>% 
  pull(p.value) %>% 
  printy::fmt_p_value() 

evt_z_nonsense <- lm(scale(TimePoint3) ~ nonsense, w_evt)
evt_nonsense <- lm(TimePoint3 ~  nonsense, w_evt)

for_pred <- na.omit(w_evt)

adj_rsquare <- function(model) {
  summary(model)[["adj.r.squared"]]
}

t1_sd <- round(sd(for_pred$TimePoint1))
t3_sd_change <- evt_t1_z$coef[2] %>% round(2)
t3_change <- round(coef(evt_t1)[2])


nonsense_change <- {coef(evt_t1_nonsense)["nonsense"] / 10} %>% 
  printy::fmt_fix_digits(1)

z_nonsense_change <- {coef(evt_t1_z_nonsense)["nonsense"] / 10} %>% 
  printy::fmt_fix_digits(2)

base_r2 <- evt_t1 %>% 
  adj_rsquare() %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

nonsense_delta <- adj_rsquare(evt_t1_z_nonsense) - adj_rsquare(evt_t1)
nonsense_delta <- nonsense_delta %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()


diff_change <- {coef(evt_t1_both)["diff"] / 10} %>% 
  printy::fmt_fix_digits(1)

z_diff_change <- {coef(evt_t1_z_both)["diff"] / 10} %>% 
  printy::fmt_fix_digits(2)

p_both <- evt_t1_z_both %>% 
  broom::tidy(conf.int = TRUE) %>%
  filter(term == "both") %>% 
  pull(p.value) %>% 
  printy::fmt_p_value(digits = 2) 

p_diff <- evt_t1_z_both %>% 
  broom::tidy(conf.int = TRUE) %>%
  filter(term == "diff") %>% 
  pull(p.value) %>% 
  printy::fmt_p_value() 
```


For these analyses, I regressed age-5 expressive vocabulary (EVT-2)
standard scores onto age-3 expressive vocabulary score and onto age-3
real word peaks or age-3 nonword peaks. There were `r nobs(evt_t1)`
children with data available for this analysis. There was an expectedly
strong relationship between age 3 and age 5 vocabulary, *R*^2^ =
`r base_r2`. A 1-SD (`r t1_sd`-point) increase in vocabulary at age 3
predicted an `r t3_sd_change`-SD (`r t3_change`-point) increase at
age 5. There was no effect of age-3 real-word peak over and above age-3
vocabulary, *p* = `r p_real`. There was a significant effect of the
nonword peak, *p* = `r p_nonsense`, *ΔR*^2^ = `r nonsense_delta`, over
and above age-3 vocabulary. A .1 increase in nonword peak probability
predicted a `r z_nonsense_change`-SD (`r nonsense_change`-point)
increase in age-5 vocabulary. Figure \@ref(fig:age-5-from-peaks) depicts
the difference between the two conditions with a flat line for the real
condition and small slope for the nonword condition.

(ref:age-5-from-peaks) Marginal effects of age-3 referent selection measures on age-5 expressive vocabulary standard scores. The vocabulary scores were adjusted (residualized) to control for age-3 vocabulary, so these regression lines show the effects of the predictors over and above age-3 vocabulary.

```{r age-5-from-peaks, fig.cap = "(ref:age-5-from-peaks)", out.width = "100%", fig.height = 4, fig.width = 4}
w_l <- w_evt %>% 
  select(ResearchID, EVT_Residualized, nonsense, real, diff, both) %>% 
  rename(
    `Nonword peak` = nonsense,
    `Real word peak` = real,
    # `Condition average` = (nonsense + real) / 2,
    `Condition average` = both,
    `Nonword advantage` = diff) %>% 
  tidyr::gather("var", "value", -ResearchID, -EVT_Residualized) %>% 
  mutate(
    var = factor(
      var, 
      c("Real word peak", "Nonword peak", 
        "Condition average", "Nonword advantage")))

fmt_axis_props <- function(xs) {
  ifelse(xs == 0, "0", printy::fmt_leading_zero(xs)) 
}

step_by_25 <- function(x) {
  steps <- (x %/% .25)
  seq(from = steps[1] - 1, to = steps[2] + 1) * .25
}

w_l %>%
  # add dummy point to real word peaks so that panel has the same range and
  # width as the nonword peaks
  tibble::add_row(
    ResearchID = "1", EVT_Residualized = NA, 
    var = "Real word peak", value = .01) %>% 
  ggplot() +
    aes(x = value, y = EVT_Residualized) +
    geom_hline(yintercept = 0, color = "white",  size = 2) + 
    geom_point(color = "grey40") +
    stat_smooth(method = "lm", color = constants$col_blue_highlight) + 
    facet_wrap("var", scales = "free_x") +
    # scale_x_continuous(labels = fmt_axis_props) +
    # scale_x_continuous(breaks = step_by_25, labels = fmt_axis_props) +
    labs(
      x = "Age 3 measures", 
      y = "Age 5 EVT-2 (Adj.)",
      caption = "Line: Regression estimate with standard error")
```

Finally, I tested whether the difference between nonword and real word
peaks within children predicted vocabulary growth. By themselves,
differences do not convey much information about how well the child
performed: A difference of 0 can happen if a child has peaks of .1 in
both conditions or .9 in both conditions. To control for general
referent selection performance, therefore, I also included the
within-child averages of the two peaks. The model predicted age-5
vocabulary using the within-child average of the peaks, the nonword
advantage, and age-3 vocabulary. In this case, condition-averaged
performance did not significantly predict age-5 vocabulary, *p* =
`p_both`. The condition differences did predict age-5 vocabulary: A .1
increase in the nonword condition advantage predicted a
`r z_diff_change`-SD (`r diff_change`-point) increase in age-5
vocabulary, *p* = `p_both`

**Summary**. A child's performance in the nonword condition at age 3
positively predicted expressive vocabulary size at age 5. This effect
held even when controlling age-3 vocabulary size, and the effect emerged
when using the absolute growth curve peak or using the relative
advantage of the nonword condition over the real word condition.
Although the effects were significant, the effect sizes were small. The
EVT-2 is normed to have an IQ-like scale with a mean of 100 and standard
deviation of 15. An increase of .1 in age-3 growth curve peak predicted
an increase in age-5 vocabulary of `r nonsense_change`, approximately one
tenth of the test norms' standard deviation.




## Discussion

For this discussion, I limited discussion to the main results.

For these two conditions, I hypothesized were word recognition in the real word
condition would be easier than in the nonword condition, or failing
that, the two conditions would not reliably differ. I had discounted a
third possibility of any overall advantage for nonwords over real words.
The advantage of nonwords at age 4 and age 5 over real words was an therefore
unexpected result.

Why would children perform better for the nonword trials?
The results are consistent with a novelty bias in referent selection [@Horst2011]. Alternatively, the presense of the mispronunciation trials, analyzed in chapter XX, may undermine familiar word recognition. For one-third of the trials, children hear a bad version of a familiar word and they show more uncertain responses to them. This could make recognition of familiar words more difficult by priming children to not rely as heavily on syllable-initial sounds for recognition. In contrast, the nonword trials are unambiguous.


Children also showed limited year-over-year changes in this task. Indeed, many children obtained ceiling performance with growth curve peaks at .99 or greater. Therefore we might say that children have mastered nonword fast-referent selection in a two-alternative forced choice context by age 4.



* talk about vocab effects

The findings here replicated those of @Bion2013, namely that concurrent vocabulary size positively predicted the amount of looking to the novel object on nonword trials. 

* talk about how nonword peaks were weak predictors of growth




In this experiment, children heard more words in total (6). The 3-year-olds in our study had the same peak looking proportion for both kinds of words around .83.

CHildren's year-over-year development on this task was limited.

<!-- For this task, I will model how the looks to the familiar image differ -->
<!-- in each condition (real words, mispronunciations, nonwords) and how the -->
<!-- growth curves for each condition change year over year. This model will -->
<!-- use growth curve model described in [Growth Curve Analysis](#growth-curve-analysis) but -->
<!-- augmented with Condition effects. -->

<!-- I will examine whether and when any dissociation is observed for word -->
<!-- recognition in the real word and nonword conditions. @McMurray2012 argue that  -->
<!-- familiar word recognition and fast -->
<!-- association for novel words reflect the same cognitive process: referent -->
<!-- selection. Data from this task would support with this hypothesis when -->
<!-- the growth curves for looks to the familiar image are symmetrical for -->
<!-- the real word and nonword conditions. Figure \@ref(fig:le-means), showing data -->
<!-- from @MPPaper [, _n_\ =\ 34 children, 30-46 months old], shows some -->
<!-- symmetry for the real word and nonword conditions. -->

<!-- I tested whether the two measures ever dissociate by computing the -->
<!-- posterior predicted difference between the growth curves. This approach -->
<!-- is similar to the bootstrap-based divergence analyses used in some word -->
<!-- recognition experiments [e.g., @Oleson2015; @eyetrackingR]. The -->
<!-- essential question is when—at which specific time points—do two growth -->
<!-- curves differ from one another. The bootstrap approach -->
<!-- uses resampling to get an estimate, whereas I use posterior -->
<!-- predicted samples to estimate these differences. -->

<!-- Specifically, I will compute the posterior-predicted looks to the -->
<!-- familiar object in the real word condition, P(Familiar | Real Word, Time -->
<!-- *t*, Child *i*) and the analogous looks to the unfamiliar object in the -->
<!-- nonword condition, P(Unfamiliar | Nonword, Time *t*, Child *i*). The -->
<!-- difference between these two probabilities estimates how the time course -->
<!-- of word recognition differs between these two conditions, and I can use -->
<!-- 50% and 90% uncertainty intervals to determine during which time points -->
<!-- the curves credibly differ from each other. -->


