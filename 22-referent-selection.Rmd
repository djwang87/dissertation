```{r include=FALSE, cache=FALSE}
# ---- set-options ----
library(methods)
knitr::opts_chunk$set(
  tidy = FALSE,
  collapse = TRUE,
  comment = "#>",
  out.width = 80,
  fig.align = "center"
)

options(width = 80)


# ---- knitr-helper-functions ----
is_word_output <- function() {
  knitr::opts_knit$get("rmarkdown.pandoc.to") == "docx"
}
is_html_output <- knitr:::is_html_output
is_latex_output <- knitr:::is_latex_output

# Make a function that prints a string of characters if the output is pdf
make_latex_decorator <- function(output, otherwise) {
  function() {
    if (is_latex_output()) output else otherwise
  }
}

# insert_pause <- make_latex_decorator(". . .", "\n")
# insert_slide_break <- make_latex_decorator("----", "\n")
# insert_inc_bullet <- make_latex_decorator("> *", "*")
insert_html_math <- make_latex_decorator("", "$$")
```
Development of referent selection
=======================================================================

```{r include = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r helpers, message = FALSE, warning = FALSE}
```

```{r, include = FALSE}
library(rstanarm)
knitr::opts_chunk$set(cache = TRUE)
```



```{r, include = FALSE}
d <- readr::read_csv("./data/aim2-model-ready.csv.gz") %>% 
  filter(!is.na(Bias_Fam)) %>% 
  filter(300 <= Time) %>% 
  select(-starts_with("ot")) %>% 
  polypoly::poly_add_columns(
    Time, degree = 3, scale_width = 1, prefix = "ot")

# Flip things so that the nonword and real-word curves go upward
d_r_ui <- d %>% 
  filter(Condition == "real", Bias_Fam == "Unfamiliar") %>% 
  mutate(elog = empirical_logit(Target, Distractor))

d_bias_target <- tibble::tribble(
  ~Condition, ~Bias_Fam, ~Bias_Target,
  "nonsense", "Familiar", "Distractor",
  "nonsense", "Unfamiliar", "Target",
  "real", "Familiar", "Target",
  "real", "Unfamiliar", "Distractor")

d_r_nw_vs <- d %>% 
  select(-Primary, -.response_def, -Prop, -PropSE) %>% 
  filter(Condition != "MP") %>% 
  rename(Unfamiliar = Distractor, Familiar = Target) %>% 
  mutate(
    Target = ifelse(Condition == "nonsense", Unfamiliar, Familiar), 
    Distractor = ifelse(Condition == "nonsense", Familiar, Unfamiliar),
    Trials = Target + Distractor) %>% 
  left_join(d_bias_target) %>% 
  mutate(elog = empirical_logit(Target, Distractor))

d_r_nw_dis <- d_r_nw_vs %>% 
  filter(Bias_Target == "Distractor")

study_child_with_empty_cells <- d_r_nw_dis %>% 
  filter(Trials < 4) %>% 
  distinct(Study, ResearchID)

study_counts <- study_child_with_empty_cells %>% 
  count(Study) %>% 
  split(.$Study) %>% 
  lapply(pull, n) %>% 
  set_names(stringr::str_replace, "TimePoint", "T")

d_r_nw_dis <- d_r_nw_dis %>% 
  anti_join(study_child_with_empty_cells)
```

```{r, include = FALSE}
library(brms)
theme_set(theme_teej())

d_r_nw_dis <- readr::read_rds("./data/aim2-real-vs-nw-modeled-data.rds.gz") 

d_tp1 <- d_r_nw_dis %>%
  filter(Study == "TimePoint1") 

d_tp2 <- d_r_nw_dis %>%
  filter(Study == "TimePoint2") 

d_tp3 <- d_r_nw_dis %>%
  filter(Study == "TimePoint3") 

m_tp1 <- readr::read_rds("./data/aim2-real-vs-nw-tp1.rds.gz")
m_tp2 <- readr::read_rds("./data/aim2-real-vs-nw-tp2.rds.gz")
m_tp3 <- readr::read_rds("./data/aim2-real-vs-nw-tp3.rds.gz")

peaks <- readr::read_rds("./data/aim2-real-vs-nw-all-peaks.rds.gz")
```




## Nonwords versus real words

I asked whether the recognition of familiar words differed from the
fast-selecting of referents for a nonword. I fit a Bayesian mixed
effects logistic regression model, as in Chapter X. For the real word
and nonword conditions, there is a well-defined target image. For real
words, it is the familar image, and for nonwords, it is the novel image.
Therefore, I modeled the data under these assumptions. The outcome
measures were therefore:

* P(Look to familiar image | Hear a real word)
* P(Look to unfamiliar image | Hear a nonword )

The important analytic question is whether and to what degree these two
probabilities differ. This growth curve model is similar to the one in
Chapter X with cubic polynomial and a condition effect which interacts
with time features. Thus, the basic model is:

`r insert_html_math()`
\small
\begin{align*}
   \text{log-odds}(\mathit{looking\,}) =\
    &\beta_0 + 
      \beta_1\text{Time}^1 + 
      \beta_2\text{Time}^2 + 
      \beta_3\text{Time}^3\ + 
      &\text{[nonword growth curve]} \\
    (&\gamma_0 + 
      \gamma_1\text{Time}^1 + 
      \gamma_2\text{Time}^2 +
      \gamma_3\text{Time}^3)*\text{Condition} \
      &\text{[adjustments for real words]} \\
\end{align*}
`r insert_html_math()`

I fit a separate model for each year of the study.[^bayes-fail]
[Appendix \@ref(aim2-gca-models)](#aim2-gca-models) contains the R code
used to fit these models along with a description of the specifications
represented by the model syntax. I used moderately informative
priors---see Appendix X. For these analyses, I limited my attention to
the distractor-initial.


[^bayes-fail]: A single model containing all three years with
corresponding year effects, year-by-time interactions, and
year-by-condition-by-time conditions had difficulty converging, and even
when a working model was obtained, a bug in the modeling software
prevented me from obtaining posterior predictions. I reported the bug in
an issue for the package's source code repository. 


  - I model data from `r min(d$Time)` ms to `r max(d$Time)`.
  - I flipped the growth curve for the nonword condition so that it
    reflects the proportion of looking to the unfamiliar object when
    presented a nonword. Both the real word and nonword conditions
    measure referent selection as the probability of fixating on the
    appropriate referent when presented with a label.

I removed any Study x Child levels if a child had fewer than 4
fixations in a single time bin. Put another way, children had to
have at least 4 looks to one of the images in every 50 ms time bin.
This screening removed `r study_counts$T1` children from Age 3,
`r study_counts$T2` from Age 4, and `r study_counts$T3` from Age 5.

```{r}
effects <- list(tp1 = m_tp1, tp2 = m_tp2, tp3 = m_tp3) %>% 
  lapply(as.matrix) %>% 
  purrr::map_df(
    bayesplot::mcmc_intervals_data, 
    pars = c("b_Intercept", "b_ot1", "b_Conditionreal", "b_ot1:Conditionreal"), 
    prob = 0.5, 
    prob_outer = 0.9, 
    .id = "model")

r_ot0_uis <- effects %>% 
  filter(parameter == "b_Conditionreal") %>% 
  split(.$model) %>% 
  fmt_inline_median_interval() %>% 
  add_ui_slug_to_first("90%&nbsp;UI: ")

r_ot1_uis <- effects %>% 
  filter(parameter == "b_ot1:Conditionreal") %>% 
  split(.$model) %>% 
  fmt_inline_median_interval()
```

The figure below shows group average of growth curves---that is, I
averaged the participant's individual model-estimated or empirical
growth curves together--for each condition and age. 


```{r aim2-real-nonword-means, echo = FALSE}
# m_tp1
# m_tp2
# m_tp3
# m_tp3

# Sets for predictions
n_tp1_all <- d_tp1 %>%
  distinct(Study, ResearchID, Condition, Time, ot1, ot2, ot3) %>%
  mutate(Trials = 30)

n_tp2_all <- d_tp2 %>%
  distinct(Study, ResearchID, Condition, Time, ot1, ot2, ot3) %>%
  mutate(Trials = 30)

n_tp3_all <- d_tp3 %>%
  distinct(Study, ResearchID, Condition, Time, ot1, ot2, ot3) %>%
  mutate(Trials = 30)

tp1_fits <- augment_linpred(
  m_tp1, n_tp1_all, allow_new_levels = TRUE,
  re_formula = NULL, nsamples = 100)

tp2_fits <- augment_linpred(
  m_tp2, n_tp2_all, allow_new_levels = TRUE,
  re_formula = NULL, nsamples = 100)

tp3_fits <- augment_linpred(
  m_tp3, n_tp3_all, allow_new_levels = TRUE,
  re_formula = NULL, nsamples = 100)

all_fits <- bind_rows(tp1_fits, tp2_fits, tp3_fits) %>% 
  mutate(
    Study = convert_study_to_age(Study),
    Condition = convert_condition_to_name(Condition))

all_data <- bind_rows(d_tp1, d_tp2, d_tp3) %>% 
  mutate(
    Study = convert_study_to_age(Study),
    Condition = convert_condition_to_name(Condition)) 

emp_diffs <- all_data %>% 
  mutate(Prop = Target / Trials) %>% 
  select(Study, ResearchID, Prop, Condition, Time) %>% 
  tidyr::spread(Condition, Prop) %>% 
  mutate(
    nonword_prop = nonwords, 
    real_prop = `real words`,
    `nonword - real` = nonword_prop - real_prop) %>% 
  select(Study, ResearchID, Time, nonword_prop, real_prop, `nonword - real`)

# curve_diffs <- all_fits %>% 
#   select(Study, .draw, ResearchID, .posterior_value, Condition, Time) %>% 
#   tidyr::spread(Condition, .posterior_value) %>% 
#   mutate(
#     nonsense_prop = plogis(nonsense), 
#     real_prop = plogis(real),
#     `nonsense - real` = nonsense_prop - real_prop) %>% 
#   select(
#     Study, .draw, ResearchID, Time, 
#     nonsense_prop, real_prop, `nonsense - real`)

# some_curve_diffs <- curve_diffs %>% 
#   tjmisc::sample_n_of(100, .draw) 

some_fits <- all_fits %>% 
  tjmisc::sample_n_of(100, .draw)

ant_0 <- data.frame(
  Condition = c("nonsense", "real"),
  Study = c("Age 4"), 
  Time = c(300, 900), 
  y = c(.82, .60)) %>% 
  mutate(Condition = convert_condition_to_name(Condition))

ggplot(some_fits) + 
  aes(x = Time, y = plogis(.posterior_value), color = Condition) + 
  stat_summary(
    aes(y = Target / Trials), 
    data = all_data,
    fun.data = mean_se,
    geom = "pointrange") +
  stat_summary(
    aes(group = interaction(.draw, Condition)),
    geom = "line",
    fun.y = mean,
    alpha = .05) +
  geom_text(
    aes(label = Condition, y = y),
    data = ant_0,
    hjust = 0,
    size = 3,
    family = "Lato Medium") + 
  facet_wrap("Study") +
  guides(color = FALSE) +
  labs(
    x = constants$x_time, 
    y = "Proportion looks to target",
    caption = "Intervals: Empirical mean ± SE. Lines: 100 posterior means.")

```

Recall from earlier chapters that in these growth curve models, I
consider only the intercept and linear time terms to be behaviorally
meaningful parameters. The intercept measures overall the average growth
curve value so it reflects looking reliability, and the linear time term
measures the overall stepness of the growth so it reflects lexical
processing efficiency. I also derive a measure of peak looking
probability by taking the median of top five points in a growth curve,
and this peak provides a measure of uncertainty (higher peaks indicate
less uncertainty). 

I evaluate the condition effects by looking at the effect of the real
word condition on the intercept and linear time terms. The two
conditions did not reliable differ at age 3. The real-word condition
effect on the intercept was `r r_ot0_uis$tp1` and its interaction with
the linear time term was `r r_ot1_uis$tp1`. Both these 90% intervals
include 0 as a plausible estimate for the condition difference, so I
conclude that the conditions did not differ on average at age 3.

There was an advantage for the nonword condition at age 4 and age 5. The
real-word effect was negative at age 4, `r r_ot0_uis$tp2`, so that on
average, children looked less to target on the real words than the
nonword trials. There was a suggestive effect linear time effect at
age 4, `r r_ot1_uis$tp2`. The curve for real words was probably less
steep at age 4 but values near 0 remain plausible. At age 5, only the
intercept difference was credible, `r r_ot0_uis$tp3`. In general,
children performed better in the nonword condition than the real word
condition at age 4 and age 5. This difference shows up in the growth
curve model through intercept effects, although it is plausible that
children's nonword growth curves were steeper than the real word curves
at age 4.







The advantage of nonwords over real words was an unexpected. My
pre-analysis hypotheses were that word recognition in the real word
condition would be easier than in the nonword condition, or failing
that, the two conditions would not reliably differ. I had discounted the
possibility of an overall advantage for nonwords over real words.


<!-- To evaluate the growth curve peaks, I computed the growth curve peak for -->
<!-- each participant x study x condition in each posterior sample and -->
<!-- averaged over the posterior to get an average growth curve peak. I used -->
<!-- a linear mixed effects model to regress growth curve peak onto age group -->
<!-- and experimental condition and age x condition with randomly varying -->
<!-- intercepts for each child and each child-year. -->

The growth curve peaks follow a similar pattern of results. At age 3,
the average peak value was ... for real words and ... for nonwords. The
conditions did not significantly differ at this age. The nonword peaks
were significantly higher greater than real word peaks at age 4 [blah
vs. blah, p=value.] and at age 5 although the difference was smaller
[blah vs. blah, p=value.].

Importantly, the average real word peaks was xx at age 3 which that
children were beginning to reach ceiling performance early on. This is a
task for toddlers.













<!-- For this task, I will model how the looks to the familiar image differ -->
<!-- in each condition (real words, mispronunciations, nonwords) and how the -->
<!-- growth curves for each condition change year over year. This model will -->
<!-- use growth curve model described in [Growth Curve Analysis](#growth-curve-analysis) but -->
<!-- augmented with Condition effects. -->

<!-- I will examine whether and when any dissociation is observed for word -->
<!-- recognition in the real word and nonword conditions. @McMurray2012 argue that  -->
<!-- familiar word recognition and fast -->
<!-- association for novel words reflect the same cognitive process: referent -->
<!-- selection. Data from this task would support with this hypothesis when -->
<!-- the growth curves for looks to the familiar image are symmetrical for -->
<!-- the real word and nonword conditions. Figure \@ref(fig:le-means), showing data -->
<!-- from @MPPaper [, _n_\ =\ 34 children, 30-46 months old], shows some -->
<!-- symmetry for the real word and nonword conditions. -->

<!-- I tested whether the two measures ever dissociate by computing the -->
<!-- posterior predicted difference between the growth curves. This approach -->
<!-- is similar to the bootstrap-based divergence analyses used in some word -->
<!-- recognition experiments [e.g., @Oleson2015; @eyetrackingR]. The -->
<!-- essential question is when—at which specific time points—do two growth -->
<!-- curves differ from one another. The bootstrap approach -->
<!-- uses resampling to get an estimate, whereas I use posterior -->
<!-- predicted samples to estimate these differences. -->

<!-- Specifically, I will compute the posterior-predicted looks to the -->
<!-- familiar object in the real word condition, P(Familiar | Real Word, Time -->
<!-- *t*, Child *i*) and the analogous looks to the unfamiliar object in the -->
<!-- nonword condition, P(Unfamiliar | Nonword, Time *t*, Child *i*). The -->
<!-- difference between these two probabilities estimates how the time course -->
<!-- of word recognition differs between these two conditions, and I can use -->
<!-- 50% and 90% uncertainty intervals to determine during which time points -->
<!-- the curves credibly differ from each other. -->


