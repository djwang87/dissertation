Analyze familiar word recognition
===========================================================================

Next steps:

- Model year over year changes.
- Download test scores and individual differences. 
- Analyze individual differences

```{r include = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
```

```{r helpers, include = FALSE}
```

## Data preparation

Earlier we cleaned the data to remove trials with excessive missing data 
and blocks of trials with too few trials. Now we prepare the data for modelling.

```{r}
opts_model <- list(
  bin_width = 3,
  start_time = 250,
  end_time = 1500
)
opts_model$bin_length <- round(opts_model$bin_width * 16.67, -1)
opts_model
```

We next downsample the data into `r opts_model$bin_length` ms
(`r opts_model$bin_width`-frame) bins in order to smooth the data. We will model
the looks from `r opts_model$start_time` to `r opts_model$end_time` ms, so we
filter down to that time window. Lastly, we aggregate looks by child, study and
time, and create orthogonal polynomials to use as time features for the model

```{r, message = FALSE, warnings = FALSE}
data <- readr::read_csv("./data/aim1-screened.csv.gz") %>% 
  select(Study, ResearchID, TrialID:GazeByImageAOI) %>% 
  assign_bins(bin_width = opts_model$bin_width, Time, TrialID)

# Compute time at center of each bin
bin_times <- data %>% 
  distinct(Time, .bin) %>% 
  group_by(.bin) %>% 
  mutate(BinTime = round(median(Time), -1)) %>% 
  ungroup()

# Attach bin times
binned <- data %>% 
  left_join(bin_times, by = c("Time", ".bin")) %>% 
  ungroup() %>% 
  select(-Time) %>% 
  rename(Time = BinTime) 

resp_def <- create_response_def(
  primary = "Target",
  others = c("PhonologicalFoil", "SemanticFoil", "Unrelated"),
  elsewhere = "tracked",
  missing = NA
)  
  
d <- binned %>% 
  aggregate_looks(resp_def, Study + ResearchID + Time ~ GazeByImageAOI)

d_m <- d %>% 
  filter(opts_model$start_time <= Time, 
         Time <= opts_model$end_time) %>% 
  polypoly::poly_add_columns(Time, degree = 3, 
                             scale_width = 1, prefix = "ot")
```

Plot the model-ready data. For this plot, we use the so-called _empirical logit_
transformation because the regular logit (log-odds) generates too extreme of
values for plotting. 

```{r spaghetti-elogit, echo = FALSE, message = FALSE, out.width = "100%", fig.height=2.5, fig.width=6}
ggplot(d_m) + 
  aes(x = Time, y = empirical_logit(Primary, Others)) + 
  geom_line(aes(group = ResearchID), alpha = .2) + 
  stat_smooth() +
  theme_grey(base_size = 9) +
  facet_grid(. ~ Study) + 
  labs(x = "Time after target onset (smoothed to 50 ms bins)", 
       y = "Emp. logit looking to target")
```

Those extreme lines indicate sparse data where there are zero-to-few looks to
the distractors compared to the target. These are the 20 most extreme bins, to 
illustrate how empirical logit tames infinite values.

```{r, echo = FALSE}
d_m %>% 
  select(Study:Time, Primary, Others) %>% 
  arrange(desc(log(Primary / Others))) %>% 
  mutate(
    logit = log(Primary / Others) %>% round(2),
    elogit = empirical_logit(Primary, Others) %>% round(2)) %>% 
  head(20) %>% 
  knitr::kable()
```


## Maximum likelihood results

Fit a maximum likelihood model as a first pass for the analysis. We won't fit
the model automatically (whenever this page is updated). It's too time
consuming. Instead, we do it manually here, and save the results.

```{r, eval = FALSE}
library(lme4)
m <- glmer(
    cbind(Primary, Others) ~
      (ot1 + ot2 + ot3) * Study +
      (ot1 + ot2 + ot3 | ResearchID/Study),
    family = binomial,
    data = d_m)
readr::write_rds(m, "./data/aim1_cubic_model.rds.gz")
```

And reload the saved model here.

```{r cubic-model-fits, out.width = "100%", fig.height=2.5, fig.width=6}
library(lme4)
m <- readr::read_rds("./data/aim1_cubic_model.rds.gz")
arm::display(m)

d_m$cubic_fit <- fitted(m)

ggplot(d_m) + 
  aes(x = Time, y = cubic_fit) + 
  geom_line(aes(group = ResearchID), alpha = .2) + 
  facet_grid(. ~ Study) + 
    labs(
      x = "Time after target onset (smoothed to 50 ms bins)",
      y = "Proportion looks to target (fitted)") +
  theme_grey(base_size = 9) 
```

### What's being captured by the random effects? 

First, let's plot just the fixed effect predictions.

```{r cubic-model-fits-fixes, out.width = "100%", fig.height=2.5, fig.width=6}
predict_y <- function(...) predict(..., type = "response")
d_m$fixef_fit <- predict_y(m, re.form = ~ 0)
d_m$subj_fit  <- predict_y(m, re.form = ~ (ot1 + ot2 + ot3 | ResearchID))
d_m$study_fit <- predict_y(m, re.form = ~ (ot1 + ot2 + ot3 | Study:ResearchID))
d_m$full_fit  <- predict_y(m, re.form = ~ (ot1 + ot2 + ot3 | Study:ResearchID) + 
                            (ot1 + ot2 + ot3 | ResearchID))

ggplot(d_m) + 
  aes(x = Time, y = fixef_fit) + 
  geom_line(aes(group = ResearchID), alpha = .2) + 
  facet_grid(. ~ Study) + 
  theme_grey(base_size = 9) +
  labs(
    x = "Time after target onset (smoothed to 50 ms bins)",
    y = "Proportion looks to target (fitted)",
    caption = "Conditioned on no random effects") 
```

Now, we condition on child level effects. 

```{r cubic-model-fits-child-efs, out.width = "100%", fig.height=2.5, fig.width=6}
ggplot(d_m) + 
  aes(x = Time, y = subj_fit) + 
  geom_line(aes(group = ResearchID), alpha = .2) + 
  facet_grid(. ~ Study) + 
  theme_grey(base_size = 9) +
  labs(
    x = "Time after target onset (smoothed to 50 ms bins)",
    y = "Proportion looks to target (fitted)",
    caption = "Conditioned on Child effects") 

ggplot(d_m) + 
  aes(x = Time, y = subj_fit - fixef_fit) + 
  geom_line(aes(group = ResearchID), alpha = .2) + 
  facet_grid(. ~ Study) + 
  theme_grey(base_size = 9) +
  labs(
    x = "Time after target onset (smoothed to 50 ms bins)",
    y = "Child-conditioned minus study means") 
```

It looks like the range of y values is
smaller in TimePoint2 and TimePoint3, but could that just be the different
numbers of participants who contribute to each study?

```{r}
d_m %>% 
  distinct(ResearchID, Study) %>% 
  count(Study) %>% 
  rename(`Num children in model` = n) %>% 
  knitr::kable()
```

Now we condition on Study x Child effects. These would be capturing the
subject-x-study variability.

```{r cubic-model-fits-ranefs, out.width = "100%", fig.height=2.5, fig.width=6}
ggplot(d_m) +
  aes(x = Time, y = study_fit) +
  geom_line(aes(group = ResearchID), alpha = .2) +
  facet_grid(. ~ Study) +
  theme_grey(base_size = 9) +
  labs(
    x = "Time after target onset (smoothed to 50 ms bins)",
    y = "Proportion looks to target (fitted)",
    caption = "Conditioned on Study x Child effects")

ggplot(d_m) +
  aes(x = Time, y = study_fit - fixef_fit) +
  geom_line(aes(group = ResearchID), alpha = .2) +
  facet_grid(. ~ Study) +
  theme_grey(base_size = 9) +
  labs(
    x = "Time after target onset (smoothed to 50 ms bins)",
    y = "Child-x-Study-conditioned minus study means")
```

Look for weak spots in the time series.

```{r cubic-model-raw-fit-corr, out.width = "50%", fig.height=3, fig.width=4}
d_corr <- d_m %>% 
  group_by(Time, Study) %>% 
  summarise(r = cor(Prop, cubic_fit)) 

ggplot(d_corr) + 
  aes(x = Time, y = r, color = Study) + 
  geom_point(shape = 1, size = 3) + 
  ylim(c(.8, 1)) + 
  labs(
    x = "Time after target onset (smoothed to 50 ms bins)",
    y = "Correlation of fitted and observed") + 
  theme_grey(base_size = 9) +
  theme(
    legend.position = c(0.025, 0.05), 
    legend.justification = c(0, 0)) 
```

Rank the participants by their growth curve parameters---that is, the growth
curve features when conditioned on child ID.

```{r}
xstudy_effects <- m %>% 
  ranef() %>% 
  getElement("ResearchID") %>% 
  tibble::rownames_to_column("ResearchID") %>% 
  as_tibble() %>% 
  select(ResearchID, intercept = `(Intercept)`, slope = ot1)

top_20 <- top_n(xstudy_effects, 20, slope)
bot_20 <- top_n(xstudy_effects, 20, -slope)
```

```{r cubic-model-fits-child-efs-ranks, out.width = "50%", fig.height=3, fig.width=3}
ggplot(d_m %>% filter(Study == "TimePoint2")) + 
  aes(x = Time, y = subj_fit) + 
  geom_line(aes(group = ResearchID), alpha = .2) +
  geom_line(aes(group = ResearchID), 
            data = semi_join(d_m, top_20) %>% filter(Study == "TimePoint2"), 
            size = .7, color = "#0074D9") + 
  geom_line(aes(group = ResearchID), 
            data = semi_join(d_m, bot_20) %>% filter(Study == "TimePoint2"), 
            size = .7, color = "#FF4136") + 
  theme_grey(base_size = 9) +
  labs(y = "TP2 fits conditioned on Child effects", 
       x = "Time after target onset (smoothed to 50 ms bins)",
       caption = "Colors: Top 20 and bottom 20 children by linear time effect")
```

Visualize the model fits for the top and bottom 20 children. This plot
illustrates that the children with strongest and weakest linear time components
overall stay clustered away from each other when looking study level
predictions. That is, the top 20 in general perform bunch together in all three
studies.

```{r ranks, out.width = "100%", fig.height=2.5, fig.width=6}
ggplot(d_m) + 
  aes(x = Time, y = cubic_fit) + 
  geom_line(aes(group = ResearchID), alpha = .2) +
  geom_line(aes(group = ResearchID), data = semi_join(d_m, top_20), 
            size = .7, color = "#0074D9") + 
  geom_line(aes(group = ResearchID), data = semi_join(d_m, bot_20), 
            size = .7, color = "#FF4136") + 
  facet_grid(. ~ Study) + 
  theme_grey(base_size = 9) +
  labs(y = "Proportion looks to target [model fits]", 
       x = "Time after target onset (smoothed to 50 ms bins)",
       caption = "Colors: Top 20 and bottom 20 children by linear time effect")
```

To confirm that this differences are not just an artifact of modeling, visualize
the ranks on the observed data.

```{r ranks-on-raw, out.width = "100%", fig.height=2.5, fig.width=6}
ggplot(d_m) + 
  aes(x = Time, y = Prop) + 
  geom_line(aes(group = ResearchID), alpha = .2) +
  geom_line(aes(group = ResearchID), data = semi_join(d_m, top_20), 
            size = .7, color = "#0074D9") + 
  geom_line(aes(group = ResearchID), data = semi_join(d_m, bot_20), 
            size = .7, color = "#FF4136") + 
  facet_grid(. ~ Study) + 
  labs(y = "Proportion looks to target", 
       x = "Time after target onset (smoothed to 50 ms bins)",
       caption = "Colors: Top 20 and bottom 20 children by linear time effect")
```

Open questions:

* How to test for stability of individual differences over time? 
  + Intuitively, I would say that the differences are unstable if the red and 
    blue lines got shuffled in each study. What stats formalize this intuition?



## Bayesian model results

Here is the code used to fit the model with Stan. It took about 24 hours to run
the model. The regression terms have the prior Normal(0, 1)

```{r, eval = FALSE}
library(rstanarm)
options(mc.cores = parallel::detectCores())

m <- stan_glmer(
  cbind(Primary, Others) ~
    (ot1 + ot2 + ot3) * Study +
    (ot1 + ot2 + ot3 | ResearchID/Study),
  family = binomial,
  prior = normal(0, 1),
  prior_intercept = normal(0, 5),
  prior_covariance = decov(2, 1, 1),
  data = d_m)
readr::write_rds(m, "./data/stan_aim1_cubic_model.rds.gz")
```

Let's try to understand our model by making some plots.

### Fixed effects plots

First, let's prepare to plot the intervals for the fixed effects.

```{r}
library(rstanarm)
library(bayesplot)
theme_set(theme_grey())
library(stringr)
library(ggstance)
parse_text <- function(x) parse(text = x)

b <- readr::read_rds("./data/stan_aim1_cubic_model.rds.gz")
b

summary(b, pars = names(fixef(b)))

prior_summary(b)
```

```{r effects1, eval = FALSE, echo = FALSE, out.width = "80%", fig.height=4, fig.width=5}
intervals <- mcmc_intervals_data(as.data.frame(b), pars = names(fixef(b)))

# Rename to use mathematical formatting
intervals$pname <- intervals$parameter %>%
  str_replace("ot(2|3)", "Time^\\1") %>% 
  str_replace("ot(1)", "Time") %>% 
  str_replace(".Intercept.", "Intercept") %>% 
  str_replace("Study", "") %>% 
  str_replace(":", " %*% ") %>% 
  factor(., levels = rev(.))

order <- c("Intercept", "TimePoint2", "TimePoint3", 
  "Time", "Time %*% TimePoint2", "Time %*% TimePoint3",
  "Time^2", "Time^2 %*% TimePoint2", "Time^2 %*% TimePoint3",
  "Time^3", "Time^3 %*% TimePoint2", "Time^3 %*% TimePoint3")
   
intervals$pname <- intervals$pname %>% 
  forcats::fct_relevel(rev(order))

ggplot(intervals) + 
  aes(y = pname) +
  geom_vline(xintercept = 0, size = 2, color = "white") +
  geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  geom_point(aes(x = m), size = 3, shape = 3) + 
  scale_y_discrete(labels = parse_text) + 
  labs(x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals") + 
  ggtitle("Average effects", 
          subtitle = "Dummy-coded effects with Timepoint1 as reference level")
```

Below the intercept and time effects increase each year, confirming that
children get more reliable and faster at recognizing words as they grow older.
For each effect, there appears to be a linear trend in the change from TP1 to
TP2 and from TP2 to TP3. 

```{r effects2, echo = FALSE, out.width = "80%", fig.height=4, fig.width=5}
# Column names will have mathematical formatting too
draws <- as.data.frame(b) %>% 
  as_tibble() %>% 
  transmute(
    `Intercept~~(TP1)` = `(Intercept)`,
    `Intercept~~(TP2)` = `(Intercept)` + StudyTimePoint2,
    `Intercept~~(TP3)` = `(Intercept)` + StudyTimePoint3,
    `Time~~(TP1)` = ot1,
    `Time~~(TP2)` = ot1 + `ot1:StudyTimePoint2`,
    `Time~~(TP3)` = ot1 + `ot1:StudyTimePoint3`,
    `Time^2~~(TP1)` = ot2,
    `Time^2~~(TP2)` = ot2 + `ot2:StudyTimePoint2`,
    `Time^2~~(TP3)` = ot2 + `ot2:StudyTimePoint3`,
    `Time^3~~(TP1)` = ot3,
    `Time^3~~(TP2)` = ot3 + `ot3:StudyTimePoint2`,
    `Time^3~~(TP3)` = ot3 + `ot3:StudyTimePoint3`)

intervals2 <- draws %>% 
  mcmc_intervals_data(prob = 0.5, prob_outer = 0.9) %>% 
  mutate(parameter = factor(parameter, levels = rev(parameter)))

ggplot(intervals2) + 
  aes(y = parameter) +
  geom_vline(xintercept = 0, size = 2, color = "white") +
  ggstance::geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  ggstance::geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  geom_point(aes(x = m), size = 3, shape = 3) + 
  scale_y_discrete(labels = parse_text) + 
  labs(x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals") + 
  ggtitle("Average effects by study")
```

```{r pairwise-effects, echo = FALSE, out.width = "80%", fig.height=4, fig.width=5}
clean_names <- . %>% 
  stringr::str_replace_all("[()]", "") %>% 
  stringr::str_replace("~~", "_")

pairwise <- draws %>% 
  tibble::rowid_to_column(".draw") %>% 
  set_names(clean_names) %>% 
  tidyr::gather(parameter, value, -.draw) %>% 
  tidyr::separate(parameter, c("parameter", "year"), sep = "_") %>% 
  compare_pairs(year, value) %>% 
  tidyr::spread(pair, value) %>% 
  split(.$parameter) %>% 
  lapply(. %>% 
           select(-.draw, -parameter) %>% 
           mcmc_intervals_data(prob = 0.5, prob_outer = 0.9) %>% 
           rename(pair = parameter)) %>% 
  bind_rows(.id = "parameter")

ggplot(pairwise) + 
  aes(y = forcats::fct_rev(pair)) +
  geom_vline(xintercept = 0, size = 2, color = "white") +
  ggstance::geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  ggstance::geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  geom_point(aes(x = m), size = 3, shape = 3) + 
  labs(x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals") + 
  facet_wrap("parameter", ncol = 1, strip.position = "left", 
             labeller = label_parsed) + 
  theme(strip.placement = "outside", 
        strip.background = element_rect(fill = NA),
        axis.text.y = element_text(size = rel(1.2))) +
  ggtitle("Differences in average effects")
```




Bayesplot supports transformations so we could invert the log-odds measure to
see the intercepts (area under curve/average accuracy) in proportion units.

```{r intercepts, echo = FALSE, out.width = "60%", fig.height=2.5, fig.width=4}
intervals3 <- draws %>% 
  mcmc_intervals_data(regex_pars = "Intercept", transformations = "plogis", 
                      prob = 0.5, prob_outer = 0.9) %>% 
  mutate(parameter = factor(parameter, levels = rev(parameter)))

intervals3 %>% 
  mutate_if(is.numeric, round, 3) %>% 
  select(-point_est) %>% 
  rename(outer = outer_width, inner = inner_width) %>% 
  knitr::kable()

ggplot(intervals3) + 
  aes(y = parameter) +
  geom_vline(xintercept = .25, size = 2, color = "white") +
  ggstance::geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  ggstance::geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  geom_point(aes(x = m), size = 3, shape = 3) + 
  scale_y_discrete(labels = parse_text) + 
  labs(x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals") + 
  ggtitle("Average accuracy by year")
```

We can compute differences in average accuracy as well.

```{r intercept-differences, echo = FALSE, out.width = "60%", fig.height=2.5, fig.width=4}
proportions <- b %>% 
  as.data.frame() %>%
  transmute(
    `TP1` = `(Intercept)`,
    `TP2` = `(Intercept)` + StudyTimePoint2,
    `TP3` = `(Intercept)` + StudyTimePoint3) %>% 
  tibble::rowid_to_column(".draw") %>% 
  tidyr::gather(parameter, estimate, -.draw) %>% 
  mutate(estimate = plogis(estimate)) %>% 
  as_tibble()

prop_diffs <- proportions %>% 
  compare_pairs(parameter, estimate) %>% 
  tidyr::spread(pair, value) %>% 
  select(-.draw) %>% 
  mcmc_intervals_data(prob = 0.5, prob_outer = 0.9)

ggplot(prop_diffs) + 
  aes(y = forcats::fct_rev(parameter)) +
  geom_vline(xintercept = 0, size = 2, color = "white") +
  ggstance::geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  ggstance::geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  geom_point(aes(x = m), size = 3, shape = 3) + 
  scale_y_discrete(labels = parse_text) + 
  labs(x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals") + 
  ggtitle("Differences in average accuracy")
```

```{r, include = FALSE}
pluck <- purrr::pluck

prop_list <- intervals3 %>% 
  split(.$parameter) %>% 
  set_names(str_extract, "TP.")

get_pts <- . %>% lapply(. %>% pluck("m") %>% round(3)) 
get_uis <- . %>% lapply(. %>% glue::glue_data("{round(ll,3)}--{round(hh,3)}")) 

pts <- get_pts(prop_list)
uis <- get_uis(prop_list)

diff_list <- prop_diffs %>% 
  split(.$parameter) %>% 
  set_names(str_replace, "-", "_")

d_pts <- get_pts(diff_list)
d_uis <- get_uis(diff_list)
```

The average accuracy was `r pts$TP1` [90% UI: `r uis$TP1`] for timepoint
1, `r pts$TP2` [`r uis$TP2`] for timepoint 2, and `r pts$TP3` [`r uis$TP3`]
for timepoint 3. The average accuracy increased by `r d_pts$TP2_TP1`
[`r d_uis$TP2_TP1`] from timepoint 1 to timepoint 2 and by `r d_pts$TP3_TP2`
[`r d_uis$TP3_TP2`] from timepoint 2 to timepoint 3.






### Plot the intervals for the random effect parameters

These are the parameters governing the random effect distributions. First, we
plot the standard deviations.

```{r posterior-sds, echo = FALSE, out.width = "80%", fig.height = 2.5, fig.width = 5}
sdcors <- tristan::draw_var_corr(b)
sdcors_wide <- sdcors %>% 
  select(.draw, .parameter, sdcor) %>% 
  tidyr::spread(.parameter, sdcor) %>% 
  select(-.draw)

# Create the mathematical labels for parameters
group_info <- sdcors %>% 
  select(.parameter:var2) %>% 
  distinct()
group_info$group <- group_info$grp %>% 
  stringr::str_replace("Study:ResearchID", "Child-Study") %>% 
  stringr::str_replace("ResearchID", "Child") 
group_info$r <- ifelse(is.na(group_info$var2), "", 
                       paste0(",", group_info$var2))
group_info$sym <- ifelse(is.na(group_info$var2), "sigma", "rho")
group_info$var1 <- ifelse(group_info$var1 == "(Intercept)", "Intercept", 
                          group_info$var1)
group_info$math <- sprintf("%s[list(%s%s)]", group_info$sym, 
                           group_info$var1, group_info$r)
group_info$class <- ifelse(is.na(group_info$var2), "scale", "correlation")
group_info <- group_info %>% 
  select(group, class, var1, var2, parameter = .parameter, math) %>% 
  mutate(parameter = as.factor(parameter))

intervals <- as.data.frame(sdcors_wide) %>% 
  mcmc_intervals_data() %>% 
  left_join(group_info, by = "parameter") %>% 
  mutate(math = forcats::fct_rev(math))

ggplot(intervals %>% filter(class == "scale")) + 
  aes(y = math) +
  # Draw medians with + then draw white horizontal lines over the horizontal 
  # parts of the + symbols
  geom_point(aes(x = m), size = 3, shape = 3) +
  geom_hline(aes(yintercept = as.numeric(parameter)), color = "white") +
  geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  scale_y_discrete(labels = parse_text) +
  facet_wrap("group", ncol = 1, strip.position = "left") + 
  theme(strip.placement = "outside", 
        strip.background = element_rect(fill = NA),
        axis.text.y = element_text(size = rel(1.2))) +
  labs(title = "Random effect scales", 
       x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals")
```

Then the correlations.

```{r posterior-cors, echo = FALSE, out.width = "80%", fig.height = 3, fig.width = 5}
ggplot(intervals %>% filter(class == "correlation")) + 
  aes(y = math) +
  geom_vline(xintercept = 0, size = 2, color = "white") +
  # Draw medians with + then draw white horizontal lines over the horizontal 
  # parts of the + symbols
  geom_point(aes(x = m), size = 3, shape = 3) +
  geom_hline(aes(yintercept = as.numeric(parameter)), color = "white") +
  geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  scale_y_discrete(labels = parse_text) +
  facet_wrap("group", ncol = 1, strip.position = "left") + 
  theme(strip.placement = "outside", 
        strip.background = element_rect(fill = NA),
        axis.text.y = element_text(size = rel(1.2))) +
  labs(title = "Random effect correlations", 
       x = NULL, y = NULL, 
       caption = "Posterior median with 90% and 50% intervals")
```




### Check for stable individual differences

```{r compute-kendalls, include = FALSE}
fits <- readr::read_csv("./data/fits.csv.gz") %>%
  semi_join(d_m)

# Compute Kendall's coefficient of correspondence
tidy_kendall <- . %>%
  unclass() %>%
  as.data.frame(stringsAsFactors = FALSE)

new_coef <- fits %>%
  filter(coef == "intercept") %>%
  mutate(.posterior_value = runif(length(.posterior_value)),
         coef = "random values")

reduced_data <- fits %>%
  bind_rows(new_coef) %>%
  tidyr::spread(Study, .posterior_value) %>%
  tidyr::drop_na(TimePoint1:TimePoint3) 

n_rated <- n_distinct(reduced_data$ResearchID)

ws <- reduced_data %>%
  select(-ResearchID) %>%
  tidyr::nest(TimePoint1:TimePoint3) %>%
  mutate(ws = purrr::map(data, irr::kendall) %>% purrr::map(tidy_kendall)) %>%
  select(-data) %>%
  tidyr::unnest(ws)

posterior_w <- ws %>%
  select(.draw, coef, value) %>%
  tidyr::spread(coef, value) %>%
  rename(`random numbers` = `random values`) %>%
  select(-.draw)
```

We predicted that children would show stable individual differences such that
children who are faster and more accurate at recognizing words at age 3 remain
relatively faster and more accurate at age 5. To evaluate this hypothesis,
we used Kendall's _W_ (the coefficient of correspondence or concordance). This
nonparametric statistic measures the degree of agreement among _J_ judges who
are rating _I_ items. For our purposes, the items are the `r n_rated`
children who provided reliable eyetracking for all three years of the study.
(That is, we excluded children who only had reliable eyetracking data for one or
two years.) The judges are the sets of growth curve parameters from each year of 
study. For example, the intercept term provides three sets of ratings: The 
participants' intercept terms from year 1 are one set of ratings and the 
terms from years 2 and 3 provide two more sets of ratings. These three ratings
are the "judges" used to compute the intercept's _W_. Thus, we compute four sets
of _W_ coefficients, one for each set of growth curve features: Intercept,
Time^1^, Time^2^, and Time^3^.

(Maybe: Table X illustrates 
some sample ratings of these participants.)

```{r table-example-of-feature-ranks, echo = FALSE}
zero_pad_int <- function(xs) {
    formatter <- paste0("%0", max(nchar(xs)), "d")
    sprintf(formatter, xs)
}

val_rank <- function(xs) {
  a <- printy::fmt_minus_sign(printy::fmt_fix_digits(xs, 2))
  b <- zero_pad_int(rank(-xs))
  glue::glue("{a} ({b})")
}

reduced_data %>% 
  filter(coef == "intercept") %>% 
  group_by(ResearchID, coef) %>% 
  summarise_at(vars(starts_with("TimePoint")), median) %>% 
  ungroup() %>% 
  arrange(desc(TimePoint3)) %>% 
  mutate(
    TimePoint1 = val_rank(TimePoint1), 
    TimePoint2 = val_rank(TimePoint2), 
    TimePoint3 = val_rank(TimePoint3)) %>% 
  rename(
    `Participant ID` = ResearchID,
    `Growth curve feature` = coef,
    `Year 1` = `TimePoint1`,
    `Year 2` = `TimePoint2`,
    `Year 3` = `TimePoint3`) %>% 
  head(10) %>% 
  knitr::kable(align = c("l", "l", "r", "r", "r"))

nsamples <- nrow(as.data.frame(b))
```

Because we used a Bayesian model, we have a distribution of ratings and thus a
distribution of concordance statistics. Each sample of the posterior
distribution fits a growth curve for each child in each study, so each sample
provides a set of ratings for concordance coefficients. The distribution of
_W_'s lets us quantify our uncertainty because we can compute _W_'s for each of 
the `r nsamples` samples from the posterior distribution.

One final matter is how do we assess whether a concordance statistic is 
meaningful. To tackle this question, we also included a "null rater", a fake 
parameter that assigned each child in each year a random number. We can use the 
distribution of _W_'s generated by randomly rating children as a benchmark for 
assessing whether the other concordance statistics differ meaningfully from 
chance.

We used the `kendall()` function in the `irr` package (vers.
`r packageVersion("irr")`, CITATION) to compute concordance statistics.

(ref:kendall-stats) Uncertainty intervals for the Kendall's coefficient of
concordance. Random ratings provide a baseline of null _W_ statistics. The
intercept and linear time features are decisively non-null, indicating a
significant degree of correspondence in children's relative word recognition
reliability and efficiency over three years of study.

```{r kendall-stats, fig.cap = "(ref:kendall-stats)", echo = FALSE, out.width = "80%", fig.height = 3, fig.width = 6}
subtitle <- glue::glue(
  "Kendall's W. Raters: 3 time points. Items: {n_rated} children.")

w_intervals <- posterior_w %>% 
  rename(Intercept = `intercept`,
         `Time` = ot1, 
         `Time^2` = ot2, 
         `Time^3` = ot3,
         `Random~ratings` = `random numbers`) %>% 
  mcmc_intervals_data(prob_outer = .9, prob = .5) %>% 
  mutate(parameter = forcats::fct_rev(parameter)) 

ggplot(w_intervals) + 
  aes(y = parameter) +
  geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
  geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
  geom_point(aes(x = m), size = 3, shape = 3) + 
  scale_y_discrete(labels = parse_text) + 
  labs(
    x = NULL, 
    y = NULL, 
    title = "Concordance coefficients for growth curve features",
    caption = "Posterior median with 90% and 50% intervals",
    subtitle = subtitle)

# TODO format as correlations
w_pts <- w_intervals %>% split(.$parameter) %>% get_pts()
w_uis <- w_intervals %>% split(.$parameter) %>% get_uis()
```


Figure \@ref(fig:kendall-stats) depicts uncertainty intervals for the Kendall
_W_'s for these growth curve features. The 90% uncertainty interval of _W_
statistics from random ratings [`r w_uis[["Random~ratings"]]`] subsumes the
intervals for the Time^2^ effect [`r w_uis[["Time^2"]]`] and the Time^3^ effect
[`r w_uis[["Time^3"]]`], indicating that these values do not differentiate
children in a longitudinally stable way. That is, the Time^2^ and Time^3^
features differentiate children across studies as well as random numbers.
Earlier, we stated that only the intercept and linear terms have psychologically
meaningful interpretations and that the higher-order terms of these models serve
to capture the shape of the growth curve data. These statistics support that
assertion.

Concordance is strongest for the intercept term, _W_\ = `r w_pts[["Intercept"]]`
[`r w_uis[["Intercept"]]`], followed by the linear time term, _W_\ =
`r w_pts[["Time"]]` [`r w_uis[["Time"]]`]. Because these values are from the
statistics for random ratings, we conclude that there is a credible degree of
correspondence across studies when we rank children using their average accuracy
(the intercept) or their growth curve slope (linear time).

### Summary of this section 

Growth curve features reflect individual differences in word recognition
efficiency and accuracy. By using Kendall's _W_ to measure the degree of
concordance among growth curve features over time, we can measure whether
individual differences in lexical processing are stable over time. We found 
that the intercept and linear time terms were stable over time.







### Posterior predictive checks

Bayesian models are generative; they describe how the data could have been
generated. One way to evaluate the model is to have it simulate new
observations. If the simulated data closely resembles the observed data, then we
have some confidence that our model has learned an approximation of how the data
could have been generated. Figure \@ref(fig:post-pred) depicts the density of
the observed data from each year of the study versus 200 posterior simulations.
Because the simulations closely track the density of the observed data, we can
infer that the model has learned how to generate data from each year of the
study.

(ref:post-pred) Posterior predictive density for the observed data from each
year of the study. The _x_-axis represents the outcome measure---the proportion
of looks to the target image---and the _y_-axis is the density of those values
at year. At age 3, there is a large density of looks around chance performance
(.25) with a rightward skew (above-chance looks are common). At age 4 and age 5,
a bimodal distribution emerges, reflecting how looks start at chance and
reliably increase to above-chance performance. Each light line is a simulation
of the observed data from the model, and the thick lines are the observed data.
Because the thick line is surrounded by light lines, we visually infer that the
the model faithfully approximates the observed data.

```{r post-pred, fig.cap = "(ref:post-pred)", echo = FALSE, out.width = "80%", fig.height=3, fig.width=6}
sims <- rstanarm::posterior_predict(b, draws = 200, seed = "09272017")
n_trials <- data_frame(y_id = seq_along(b$y[, 1]), n_trials = rowSums(b$y))

bayesplot:::ppc_data(b$y[, 1], sims, group = d_m$Study) %>% 
  left_join(n_trials, by = "y_id") %>% 
  mutate(prop = value / n_trials) %>% 
  ggplot() +
    aes(x = prop) +
    stat_density(
      aes_(group = ~ rep_id),
      data = function(x) dplyr::filter(x, !.data$is_y),
      geom = "line", position = "identity", size = .25, alpha = .1, 
      color = "#0074D9") +
    stat_density(
      data = function(x) dplyr::filter(x, .data$is_y),
      geom = "line", position = "identity", size = 1) + 
    labs(x = "Proportion of looks", 
         title = "Observed data and 200 posterior simulations") + 
    coord_cartesian(xlim = c(0, 1), expand = FALSE) + 
    facet_wrap("group")
```


We can ask the model make even more specific posterior predictions. Below we
plot the posterior predictions for random participants. This is the model
simulating new data for these participants.

```{r posterior-lines, out.width = "100%", fig.height=4, fig.width=5}
set.seed(09272017)

ppred <- d_m %>% 
  sample_n_of(8, ResearchID) %>% 
  tristan::augment_posterior_predict(b, newdata = ., nsamples = 100) %>% 
  mutate(trials = Primary + Others)

ggplot(ppred) + 
  aes(x = Time, y = Prop, color = Study, group = Study) + 
  geom_line(aes(y = .posterior_value / trials, 
                group = interaction(.draw, Study)), 
            alpha = .20) + 
  geom_line(size = 1, color = "grey50") + 
  facet_wrap("ResearchID") + 
  theme(
    legend.position = c(.95, 0), 
    legend.justification = c(1, 0),
    legend.margin = margin(0)) +
  guides(color = guide_legend(title = NULL, override.aes = list(alpha = 1))) +
  labs(
    title = "Observed means and 100 simulations of new data",
    x = "Time after target onset",
    y = "Proportion looks to target") 
```

Or we can plot the linear predictions. These are posterior predictions of the
log-odds of looking to target before adding binomial noise.

```{r posterior-mean-lines, out.width = "100%", fig.height=4, fig.width=5}
lpred <- d_m %>% 
  sample_n_of(8, ResearchID) %>% 
  tristan::augment_posterior_linpred(b, newdata = ., nsamples = 100)

ggplot(lpred) + 
  aes(x = Time, y = .posterior_value, color = Study) +
  geom_line(aes(group = interaction(Study, ResearchID, .draw)), 
            alpha = .1) +
  facet_wrap("ResearchID") + 
  geom_point(aes(y = qlogis(Prop)), shape = 1) + 
  theme(
    legend.position = c(.95, 0), 
    legend.justification = c(1, 0),
    legend.margin = margin(0)) +
  guides(color = guide_legend(title = NULL, override.aes = list(alpha = 1))) +
  labs(
    title = "Observed data and 100 posterior predictions",
    x = "Time after target onset",
    y = "Posterior log-odds")
```


### Simulating data from new participants

This mixed effects model assumes that the each child's growth curve is drawn
from a distribution of related growth curves, and it tries to infer the
parameters of that distribution of growth curves (like the scale of individual
differences in the intercept term or the correlation among growth curve
features). A natural next step is to ask the model to simulate new samples from
that distribution of growth curves: That is, predict new data for a
hypothetical, unobserved child drawn from the same distribution as the `N
CHILDREN` observed children.This procedure lets us explore the range of
variability in performance at each age.

Figure \@ref(fig:new-participants) shows the posterior predictions for 1,000
simulated participants, which demonstrates how the model expects new
participants to improve longitudinally but also exhibit stable individual
differences over time. Figure \@ref(fig:new-participants-intervals) shows
uncertainty intervals for these simulations. The model has learned to predict
less accurate and more variable performance at age 3 with improving accuracy and
narrowing variability at age 4 and age 5.



(ref:new-participants) Posterior predictions for new _unobserved_ participants.
Each line represents the predicted performance for a new participant. The three
dark lines highlight predictions from one single simulated participant. The
simulated participant shows both longitudinal improvement in word recognition
and similar relative performance compared to other simulations each year,
indicating that the model would predict new children to improve year over year
and show stable individual differences over time.

```{r new-participants, echo = FALSE, fig.cap = "(ref:new-participants)", fig.width = 6, fig.height = 3, out.width = "80%"}
dummy_data <- d_m %>% 
  distinct(Study, Time, ot1, ot2, ot3) %>% 
  mutate(ResearchID = "NEW",
         Primary = 0, 
         Others = 0)

set.seed(11102017)
lpred <- dummy_data %>% 
  tristan::augment_posterior_linpred(b, newdata = ., nsamples = 1000)

ggplot(lpred) + 
  aes(x = Time, y = plogis(.posterior_value), color = Study) +
  geom_hline(yintercept = .25, size = 2, color = "white") +
  geom_line(aes(group = interaction(Study, .draw)), 
            alpha = .1, show.legend = FALSE) +
  geom_line(aes(group = interaction(Study, .draw)), 
            data = sample_n_of(lpred, 1, .draw), color = "grey20",
            show.legend = FALSE) +
  facet_wrap("Study") + 
  guides(color = guide_legend("none")) +
  labs(
    title = "Posterior predictions for 1,000 new participants",
    x = "Time after target onset",
    y = "Proportion looks to target")
```

(ref:new-participants-intervals) Uncertainty intervals for the simulated
participants. Variability is widest at age 3 and narrowest at age 5,
consistent with the prediction that children become less variable as they 
grow older.

```{r new-participants-intervals, echo = FALSE, fig.cap = "(ref:new-participants-intervals)", fig.width = 6, fig.height = 3, out.width = "80%"}
ggplot(lpred) + 
  aes(x = Time, y = plogis(.posterior_value), color = Study) +
  geom_hline(yintercept = .25, size = 2, color = "white") +
  stat_summary(fun.data = median_hilow, fun.args = list(conf.int = .9),
               size = 1, geom = "linerange") + 
  stat_summary(fun.data = median_hilow, fun.args = list(conf.int = .5), 
               size = 1.5, geom = "linerange") + 
  facet_wrap("Study") + 
  guides(color = guide_legend("none")) +
  labs(
    title = "Posterior predictions for 1,000 new participants",
    x = "Time after target onset",
    y = "Proportion looks to target",
    caption = "90% and 50% intervals")
```


One of the predictions was that children would become less variable as they
grew older and converge on a mature level of performance. We can tackle
this question by inspecting the ranges of predictions for the simulated
participants. The claim that children become less variable would imply that the
range of predictions should be narrower age 5 than for age 4 than age 3. Figure
\@ref(fig:new-ranges) depicts the range of the predictions, both in terms of the
90 percentile range (i.e., the range of the middle 90% of the data) and in terms
of the 50 percentile (interquartile) range. The ranges of performance decrease
from age 3 to age 4 to age 5, consistent with the hypothesized reduction in
variability.

(ref:new-ranges) Ranges of predictions for simulated
participants over the course of a trial. The ranges are most similar during the
first half of the trial when participants are at chance performance, and the
ranges are most different at the end of the trial as children reliably fixate on
the target image. The ranges of performance decreases with each year of the
study as children show less variability.

```{r new-ranges, echo = FALSE, fig.cap = "(ref:new-ranges)", fig.width = 6, fig.height = 3, out.width = "80%"}
by_draw <- lpred %>%
  group_by(Study, Time) %>%
  summarise(
    `95th` = quantile(plogis(.posterior_value), .95),
    `05th` = quantile(plogis(.posterior_value), .05),
    `75th` = quantile(plogis(.posterior_value), .75),
    `25th` = quantile(plogis(.posterior_value), .25),
    `95^th~vs.~05^th` = `95th` - `05th`,
    `75^th~vs.~25^th` = `75th` - `25th`) %>% 
  select(-matches("^..th$")) %>% 
  ungroup() %>% 
  tidyr::gather("range", "extent", -Study, -Time) %>% 
  mutate(range = factor(range, levels = unique(rev(sort(range))))) 
  
ggplot(by_draw) +
  aes(x = Time, y = extent, color = Study) +
  geom_point() + 
  facet_wrap("range", labeller = label_parsed) +
  labs(
    title = "Ranges of predictions for 1000 new participants",
    x = "Time after target onset",
    y = "Difference of percentiles") 
```


### Predicting the future

> As a consequence, individual differences in word recognition at age 3, for
example, will be more discriminating and predictive of age 5 language outcomes
than differences at age 4.


```{r bunch-of-plots, out.width = "80%", fig.height=4, fig.width=5}
fits <- readr::read_csv("./data/fits.csv.gz")
fits <- fits %>% semi_join(d_m)

point_ests <- fits %>% 
  group_by(Study, ResearchID, coef) %>% 
  summarise(point = median(.posterior_value)) %>% 
  ungroup() %>% 
  tidyr::spread(coef, point)

scores <- readr::read_csv("./data-raw/test_scores.csv") %>% 
  select(Study, ResearchID, Age, EVT_GSV, EVT_Standard, 
         PPVT_GSV, PPVT_Standard)

with_ests <- scores %>% 
  inner_join(point_ests)

ggplot(with_ests) + 
  aes(x = intercept, y = EVT_GSV, color = Study) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(with_ests) + 
  aes(x = ot1, y = EVT_GSV, color = Study) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(with_ests) + 
  aes(x = Age, y = intercept, color = Study) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(with_ests) + 
  aes(x = Age, y = ot1, color = Study) + 
  geom_point() + 
  stat_smooth(method = "lm")

widely <- with_ests %>% 
  tidyr::gather("Test", "Value", -ResearchID, -Study) %>% 
  tidyr::unite("Col", Study, Test) %>% 
  tidyr::spread(Col, Value)


ggplot(widely) + 
  aes(x = TimePoint1_intercept, y = TimePoint3_EVT_GSV) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(widely) + 
  aes(x = TimePoint2_intercept, y = TimePoint3_EVT_GSV) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(widely) + 
  aes(x = TimePoint1_ot1, y = TimePoint3_EVT_GSV) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(widely) + 
  aes(x = TimePoint2_ot1, y = TimePoint3_EVT_GSV) + 
  geom_point() + 
  stat_smooth(method = "lm")

ggplot(widely) + 
  aes(x = TimePoint3_ot1, y = TimePoint3_EVT_GSV) + 
  geom_point() + 
  stat_smooth(method = "lm")

```

```{r bunch-of-plots2, out.width = "80%", fig.height=4, fig.width=6}
cor_complete <- function(...) cor(..., use = "pairwise.complete")

test <- fits %>% 
  left_join(widely) %>% 
  group_by(Study, coef, .draw) %>% 
  summarise(
    r_TimePoint3_EVT_Standard = cor_complete(.posterior_value, 
                                             TimePoint3_EVT_Standard),
    r_TimePoint3_EVT_GSV = cor_complete(.posterior_value, 
                                        TimePoint3_EVT_GSV),
    r_TimePoint2_PPVT_GSV = cor_complete(.posterior_value, 
                                         TimePoint2_PPVT_GSV),
    r_TimePoint2_PPVT_Standard = cor_complete(.posterior_value, 
                                              TimePoint2_PPVT_Standard))

c_intervals <- test %>% 
  do(bayesplot::mcmc_intervals_data(
    select(., r_TimePoint3_EVT_Standard:r_TimePoint2_PPVT_Standard))) %>% 
  ungroup()

c_intervals %>% 
  filter(parameter == "r_TimePoint3_EVT_Standard") %>% 
  filter(coef %in% c("intercept", "ot1")) %>% 
  ggplot() + 
    aes(y = forcats::fct_rev(Study)) +
    geom_vline(xintercept = 0, size = 2, color = "white") +
    ggstance::geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
    ggstance::geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
    geom_point(aes(x = m), size = 3, shape = 3) + 
    facet_wrap("coef") +
    labs(x = NULL, y = NULL, caption = "90% and 50% intervals") + 
    ggtitle("Correlation of curve features and TP3 EVT Standard")

c_intervals %>% 
  filter(parameter == "r_TimePoint2_PPVT_Standard") %>% 
  filter(coef %in% c("intercept", "ot1")) %>% 
  filter(Study != "TimePoint3") %>% 
  ggplot() + 
    aes(y = forcats::fct_rev(Study)) +
    geom_vline(xintercept = 0, size = 2, color = "white") +
    ggstance::geom_linerangeh(aes(xmin = ll, xmax = hh)) + 
    ggstance::geom_linerangeh(aes(xmin = l, xmax = h), size = 2) +
    geom_point(aes(x = m), size = 3, shape = 3) + 
    facet_wrap("coef") +
    labs(x = NULL, y = NULL, caption = "90% and 50% intervals") + 
    ggtitle("Correlation of curve features and TP2 PPVT Standard")

# test %>% 
#   filter(coef == "intercept") %>%
#   ggplot() + 
#   aes(x = c1) + 
#   geom_histogram() + 
#   facet_grid(Study ~ coef)
# 
# test %>% 
#   filter(coef == "ot1") %>%
#   ggplot() + 
#   aes(x = c1) + 
#   geom_histogram() + 
#   facet_grid(Study ~ coef)
# 
# test %>% 
#   filter(coef == "ot2") %>%
#   ggplot() + 
#   aes(x = c1) + 
#   geom_histogram() + 
#   facet_grid(Study ~ coef)

widely %>% tidy_correlation(ends_with("EVT_GSV"))

widely %>% 
  tidy_correlation(TimePoint3_EVT_GSV, ends_with("intercept"), ends_with("ot1")) %>% 
  filter(column1 == "TimePoint3_EVT_GSV")

widely %>% 
  tidy_correlation(TimePoint2_PPVT_GSV, TimePoint1_ot1, TimePoint2_ot1) %>% 
  filter(column1 == "TimePoint2_PPVT_GSV")

widely %>% 
  tidy_correlation(TimePoint2_PPVT_GSV, TimePoint1_ot1, TimePoint2_ot1,
            TimePoint1_intercept, TimePoint2_intercept) %>% 
  filter(column1 == "TimePoint2_PPVT_GSV")
```







### Relationship with child-level variables

> Vocabulary size and lexical processing will be tightly correlated such that
large year-over-year gains in one measure will predict large year-over-years
gains in the other measure.

```{r, eval = FALSE, include = FALSE}
scores <- readr::read_csv("./data-raw/test_scores.csv") %>% 
  select(Study, ResearchID, Age, EVT_GSV, EVT_Standard, 
         PPVT_GSV, PPVT_Standard)

changes <- scores %>% 
  tidyr::gather("Score", "Value", -Study, -ResearchID) %>% 
  tidyr::spread(Study, Value) %>% 
  mutate(TP3_Change = TimePoint3 - TimePoint2, 
         TP2_Change = TimePoint2 - TimePoint1) %>% 
  select(-TimePoint1, -TimePoint2, -TimePoint3) %>% 
  tidyr::gather("Change", "Value", TP3_Change, TP2_Change) %>% 
  tidyr::unite(Col, Change, Score) %>% 
  tidyr::spread(Col, Value)

ggplot(changes) + 
  aes(x = TP2_Change_PPVT_Standard) + 
  geom_histogram()

bot_20_ppvt_changes <- changes %>% top_n(20, TP2_Change_PPVT_Standard)
bot_20_ppvt_changes <- changes %>% top_n(20, -TP2_Change_PPVT_Standard)


d_avg <- binned %>% 
  filter(250 <= Time, Time <= 1500) %>% 
  aggregate_looks(resp_def, Study + ResearchID ~ GazeByImageAOI)

with_prop_changes <- d_avg %>% 
  select(Study, ResearchID, Prop) %>% 
  tidyr::spread(Study, Prop) %>% 
  mutate(TP2_Change_Prop = TimePoint2 - TimePoint1, 
         TP3_Change_Prop = TimePoint3 - TimePoint2) %>% 
  select(ResearchID, TP2_Change_Prop, TP3_Change_Prop) %>% 
  inner_join(changes, by = "ResearchID")


long_changes <- with_prop_changes %>% 
  tidyr::gather("Var", "Value", -ResearchID) %>% 
  mutate(when = ifelse(str_detect(Var, "TP2_Change"), "TP2", "TP3"),
         Var = str_replace(Var, "TP._Change_", "")) %>% 
  tidyr::spread(Var, Value) %>% 
  tidyr::gather("Var", "Change", -ResearchID, -when, -Prop)

ggplot(long_changes %>% filter(when == "TP2")) + 
  aes(x = Change, y = Prop) + 
  geom_point() + 
  facet_wrap("Var", scales = "free_x") +
  stat_smooth(method = "lm")
ggplot(long_changes %>% filter(when == "TP3")) + 
  aes(x = Change, y = Prop) + 
  geom_point() + 
  facet_wrap("Var", scales = "free_x") +
  stat_smooth(method = "lm")

cor(with_prop_changes$TP2_Change_PPVT_Standard,
    with_prop_changes$TP2_Change_Prop,
    use = "pairwise.complete.obs")

cor(with_prop_changes$TP3_Change_Age,
    with_prop_changes$TP3_Change_Prop,
    use = "pairwise.complete.obs")

cor(with_prop_changes$TP2_Change_Age,
    with_prop_changes$TP2_Change_Prop,
    use = "pairwise.complete.obs")

cor(with_prop_changes$TP2_Change_EVT_Standard,
    with_prop_changes$TP2_Change_Prop,
    use = "pairwise.complete.obs")

cor(with_prop_changes$TP3_Change_EVT_Standard,
    with_prop_changes$TP3_Change_Prop,
    use = "pairwise.complete.obs")
```



