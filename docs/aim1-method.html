<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Development of word recognition in preschoolers</title>
  <meta name="description" content="Development of word recognition in preschoolers">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Development of word recognition in preschoolers" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="tjmahr/dissertation" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Development of word recognition in preschoolers" />
  
  
  

<meta name="author" content="Tristan Mahr">


<meta name="date" content="2018-04-24">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="aim1-introduction.html">
<link rel="next" href="analysis-of-familiar-word-recognition.html">
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="assets\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Word Recognition in Preschoolers</a></li>

<li class="divider"></li>
<li class="part"><span><b>Prospectus</b></span></li>
<li class="chapter" data-level="1" data-path="prospectus-preamble.html"><a href="prospectus-preamble.html"><i class="fa fa-check"></i><b>1</b> Prospectus Preamble</a><ul>
<li class="chapter" data-level="" data-path="prospectus-preamble.html"><a href="prospectus-preamble.html#about-this-document"><i class="fa fa-check"></i>About This Document</a></li>
<li class="chapter" data-level="" data-path="prospectus-preamble.html"><a href="prospectus-preamble.html#committee-members"><i class="fa fa-check"></i>Dissertation Committee Members</a></li>
<li class="chapter" data-level="" data-path="prospectus-preamble.html"><a href="prospectus-preamble.html#planned-dissertation-format"><i class="fa fa-check"></i>Planned Dissertation Format</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="specific-aims.html"><a href="specific-aims.html"><i class="fa fa-check"></i><b>2</b> Specific Aims</a><ul>
<li class="chapter" data-level="2.1" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>2.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="2.2" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>2.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="2.3" data-path="specific-aims.html"><a href="specific-aims.html#summary"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="research-hypotheses.html"><a href="research-hypotheses.html"><i class="fa fa-check"></i><b>3</b> Research Hypotheses</a><ul>
<li class="chapter" data-level="3.1" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-1-familiar-word-recognition-and-lexical-competition-1"><i class="fa fa-check"></i><b>3.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="3.2" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-2-referent-selection-and-mispronunciations-1"><i class="fa fa-check"></i><b>3.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
</ul></li>
<li class="part"><span><b>Aim 1: Familiar Word Recognition and Lexical Competition</b></span></li>
<li class="chapter" data-level="4" data-path="aim1-introduction.html"><a href="aim1-introduction.html"><i class="fa fa-check"></i><b>4</b> Familiar Word Recognition</a><ul>
<li class="chapter" data-level="4.1" data-path="aim1-introduction.html"><a href="aim1-introduction.html#lexical-processing-dynamics"><i class="fa fa-check"></i><b>4.1</b> Lexical Processing Dynamics</a></li>
<li class="chapter" data-level="4.2" data-path="aim1-introduction.html"><a href="aim1-introduction.html#individual-differences-in-word-recognition"><i class="fa fa-check"></i><b>4.2</b> Individual Differences in Word Recognition</a></li>
<li class="chapter" data-level="4.3" data-path="aim1-introduction.html"><a href="aim1-introduction.html#this-project"><i class="fa fa-check"></i><b>4.3</b> This project</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="aim1-method.html"><a href="aim1-method.html"><i class="fa fa-check"></i><b>5</b> Method</a><ul>
<li class="chapter" data-level="5.1" data-path="aim1-method.html"><a href="aim1-method.html#participants"><i class="fa fa-check"></i><b>5.1</b> Participants</a></li>
<li class="chapter" data-level="5.2" data-path="aim1-method.html"><a href="aim1-method.html#procedure"><i class="fa fa-check"></i><b>5.2</b> Procedure</a></li>
<li class="chapter" data-level="5.3" data-path="aim1-method.html"><a href="aim1-method.html#experiment-administration"><i class="fa fa-check"></i><b>5.3</b> Experiment Administration</a></li>
<li class="chapter" data-level="5.4" data-path="aim1-method.html"><a href="aim1-method.html#stimuli"><i class="fa fa-check"></i><b>5.4</b> Stimuli</a></li>
<li class="chapter" data-level="5.5" data-path="aim1-method.html"><a href="aim1-method.html#data-screening"><i class="fa fa-check"></i><b>5.5</b> Data screening</a></li>
<li class="chapter" data-level="5.6" data-path="aim1-method.html"><a href="aim1-method.html#model-preparation"><i class="fa fa-check"></i><b>5.6</b> Model preparation</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html"><i class="fa fa-check"></i><b>6</b> Analysis of familiar word recognition</a><ul>
<li class="chapter" data-level="6.1" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#growth-curve-analysis"><i class="fa fa-check"></i><b>6.1</b> Growth curve analysis</a><ul>
<li class="chapter" data-level="6.1.1" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#growth-curve-features-as-measures-of-word-recognition-performance"><i class="fa fa-check"></i><b>6.1.1</b> Growth curve features as measures of word recognition performance</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#year-over-year-changes-in-word-recognition-performance"><i class="fa fa-check"></i><b>6.2</b> Year over year changes in word recognition performance</a></li>
<li class="chapter" data-level="6.3" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#exploring-plausible-ranges-of-performance-over-time"><i class="fa fa-check"></i><b>6.3</b> Exploring plausible ranges of performance over time</a></li>
<li class="chapter" data-level="6.4" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#are-individual-differences-stable-over-time"><i class="fa fa-check"></i><b>6.4</b> Are individual differences stable over time?</a></li>
<li class="chapter" data-level="6.5" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#predicting-future-vocabulary-size"><i class="fa fa-check"></i><b>6.5</b> Predicting future vocabulary size</a></li>
<li class="chapter" data-level="6.6" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#discussion"><i class="fa fa-check"></i><b>6.6</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html"><i class="fa fa-check"></i><b>7</b> Effects of phonological and semantic competitors</a><ul>
<li class="chapter" data-level="7.1" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html#looks-to-the-phonological-competitor"><i class="fa fa-check"></i><b>7.1</b> Looks to the phonological competitor</a></li>
<li class="chapter" data-level="7.2" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html#looks-to-the-semantic-competitor"><i class="fa fa-check"></i><b>7.2</b> Looks to the semantic competitor</a></li>
<li class="chapter" data-level="7.3" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html#differences-in-competitor-sensitivity-at-age-3"><i class="fa fa-check"></i><b>7.3</b> Differences in competitor sensitivity at age 3</a></li>
<li class="chapter" data-level="7.4" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html#discussion-1"><i class="fa fa-check"></i><b>7.4</b> Discussion</a><ul>
<li class="chapter" data-level="7.4.1" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html#immediate-activation-of-phonological-neighbors"><i class="fa fa-check"></i><b>7.4.1</b> Immediate activation of phonological neighbors</a></li>
<li class="chapter" data-level="7.4.2" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html#late-activation-of-semantic-neighbors"><i class="fa fa-check"></i><b>7.4.2</b> Late activation of semantic neighbors</a></li>
<li class="chapter" data-level="7.4.3" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html#lexical-competitors-and-individual-differences"><i class="fa fa-check"></i><b>7.4.3</b> Lexical competitors and individual differences</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="general-discussion.html"><a href="general-discussion.html"><i class="fa fa-check"></i><b>8</b> General Discussion</a><ul>
<li class="chapter" data-level="8.1" data-path="general-discussion.html"><a href="general-discussion.html#how-to-improve-word-recognition"><i class="fa fa-check"></i><b>8.1</b> How to improve word recognition</a></li>
<li class="chapter" data-level="8.2" data-path="general-discussion.html"><a href="general-discussion.html#learn-words-and-learn-connections-between-words"><i class="fa fa-check"></i><b>8.2</b> Learn words and learn connections between words</a></li>
<li class="chapter" data-level="8.3" data-path="general-discussion.html"><a href="general-discussion.html#individual-differences"><i class="fa fa-check"></i><b>8.3</b> Individual differences</a></li>
</ul></li>
<li class="part"><span><b>Miscellany</b></span></li>
<li class="chapter" data-level="9" data-path="scratch-paper.html"><a href="scratch-paper.html"><i class="fa fa-check"></i><b>9</b> Scratch paper</a><ul>
<li class="chapter" data-level="9.1" data-path="scratch-paper.html"><a href="scratch-paper.html#bookdown-cheatsheet"><i class="fa fa-check"></i><b>9.1</b> Bookdown cheatsheet</a><ul>
<li class="chapter" data-level="9.1.1" data-path="scratch-paper.html"><a href="scratch-paper.html#manual-section-label-demo"><i class="fa fa-check"></i><b>9.1.1</b> Cross-references to sections</a></li>
<li class="chapter" data-level="9.1.2" data-path="scratch-paper.html"><a href="scratch-paper.html#cross-references-to-appendices"><i class="fa fa-check"></i><b>9.1.2</b> Cross-references to appendices</a></li>
<li class="chapter" data-level="9.1.3" data-path="scratch-paper.html"><a href="scratch-paper.html#cross-references-to-tables"><i class="fa fa-check"></i><b>9.1.3</b> Cross-references to tables</a></li>
<li class="chapter" data-level="9.1.4" data-path="scratch-paper.html"><a href="scratch-paper.html#figure-references-and-using-text-references-as-captions"><i class="fa fa-check"></i><b>9.1.4</b> Figure references and using text references as captions</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="scratch-paper.html"><a href="scratch-paper.html#custom-blocks"><i class="fa fa-check"></i><b>9.2</b> Custom blocks</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="quick-testing-sandbox.html"><a href="quick-testing-sandbox.html"><i class="fa fa-check"></i><b>10</b> Quick testing sandbox</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html"><i class="fa fa-check"></i><b>A</b> Computational Details for Specific Aim 1</a><ul>
<li class="chapter" data-level="A.1" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#growth-curve-analysis-models"><i class="fa fa-check"></i><b>A.1</b> Growth Curve Analysis Models</a></li>
<li class="chapter" data-level="A.2" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#additional-model-results"><i class="fa fa-check"></i><b>A.2</b> Additional model results</a><ul>
<li class="chapter" data-level="A.2.1" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#plot-the-intervals-for-the-random-effect-parameters"><i class="fa fa-check"></i><b>A.2.1</b> Plot the intervals for the random effect parameters</a></li>
<li class="chapter" data-level="A.2.2" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>A.2.2</b> Posterior predictive checks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="vw-experiment-items.html"><a href="vw-experiment-items.html"><i class="fa fa-check"></i><b>B</b> Items used in the visual world experiment</a></li>
<li class="chapter" data-level="C" data-path="mp-experiment-items.html"><a href="mp-experiment-items.html"><i class="fa fa-check"></i><b>C</b> Items used in the mispronunciation experiment</a></li>
<li class="chapter" data-level="D" data-path="related-work.html"><a href="related-work.html"><i class="fa fa-check"></i><b>D</b> Related Work</a></li>
<li class="chapter" data-level="" data-path="colophon.html"><a href="colophon.html"><i class="fa fa-check"></i>Colophon</a><ul>
<li class="chapter" data-level="D.1" data-path="colophon.html"><a href="colophon.html#debug-info"><i class="fa fa-check"></i><b>D.1</b> Debug info</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Created with bookdown</a></li>
<li><a href="https://tjmahr.github.io/" target="blank">Tristan Mahr</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Development of word recognition in preschoolers</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="aim1-method" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Method</h1>
<div id="participants" class="section level2">
<h2><span class="header-section-number">5.1</span> Participants</h2>
<p>The participants were 28–39 months-old at Age 3, 39–52 at Age 4, and 51–65 at Age 5. Approximately, 180 children participated at Age 3, 170 at Age 4, and 160 at Age 5. Of these children, approximately 20 were identified by their parents as late talkers. Prospective families were interviewed over telephone before participating in the study. Children were not scheduled for testing if a parent reported language problems, vision problems, developmental delays, or an individualized education program for the child. Recruitment and data collection occurred at two Learning to Talk lab sites—one at the University of Wisconsin–Madison and the other at the University of Minnesota.</p>
<p>Table <a href="aim1-method.html#tab:participant-info">5.1</a> summarizes the cohort of children in each year of testing. The numbers and summary statistics here are general, describing children who participated at each year, but whose data may have been excluded from the analyses. Some potential reasons for exclusion include: excessive missing data during eyetracking, experiment or technology error, developmental concerns not identified until later in study, or a failed hearing screening. Final sample sizes will depend on the measures needed for an analysis and the results from data screening checks. I disclose all measurements and data exclusions following guidelines by the Center for Open Science <span class="citation">(Nosek et al., <a href="#ref-OSF_Statement">2014</a>)</span>.</p>
<table>
<caption><span id="tab:participant-info">Table 5.1: </span> Participant characteristics. Education levels: <em>Low</em>: less than high school, or high school; <em>Middle</em>: trade school, technical or associates degree, some college, or college degree; and <em>High</em>: graduate degree.</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">Year 1 (Age 3)</th>
<th align="left">Year 2 (Age 4)</th>
<th align="left">Year 3 (Age 5)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>N</td>
<td align="left">184</td>
<td align="left">175</td>
<td align="left">160</td>
</tr>
<tr class="even">
<td>Boys, Girls</td>
<td align="left">94, 90</td>
<td align="left">89, 86</td>
<td align="left">82, 78</td>
</tr>
<tr class="odd">
<td>Maternal education: Low, Middle, High</td>
<td align="left">15, 98, 71</td>
<td align="left">12, 92, 71</td>
<td align="left">6, 90, 64</td>
</tr>
<tr class="even">
<td>Dialect: MAE, AAE</td>
<td align="left">171, 13</td>
<td align="left">163, 12</td>
<td align="left">153, 7</td>
</tr>
<tr class="odd">
<td>Parent-identified late talkers</td>
<td align="left">20</td>
<td align="left">19</td>
<td align="left">16</td>
</tr>
<tr class="even">
<td>Age (months): Mean (SD) [Range]</td>
<td align="left">33 (3) [28–39]</td>
<td align="left">45 (4) [39–52]</td>
<td align="left">57 (4) [51–66]</td>
</tr>
<tr class="odd">
<td>EVT-2 standard score: Mean (SD)</td>
<td align="left">115 (18)</td>
<td align="left">118 (16)</td>
<td align="left">118 (14)</td>
</tr>
<tr class="even">
<td>PPVT-4 standard score: Mean (SD)</td>
<td align="left">113 (17)</td>
<td align="left">120 (16)</td>
<td align="left">—</td>
</tr>
<tr class="odd">
<td>GFTA-2 standard score: Mean (SD)</td>
<td align="left">92 (13)</td>
<td align="left">—</td>
<td align="left">91 (13)</td>
</tr>
</tbody>
</table>
<!-- ### Special case data screening -->
<!-- (_Skip for now._ This is where I review the participant notes and will remove  -->
<!-- children who have to be excluded for other reasons, like being diagnosed with a  -->
<!-- language disorder at TimePoint 3.) -->
</div>
<div id="procedure" class="section level2">
<h2><span class="header-section-number">5.2</span> Procedure</h2>
<p>This experiment used a version of the Visual World Paradigm for word recognition experiments <span class="citation">(Law et al., <a href="#ref-RWLPaper">2016</a>)</span>. In eyetracking studies with toddlers, two familiar images are usually presented: a target and a distractor. This experiment is a four-image eyetracking task that was designed to provide a more demanding word recognition task for preschoolers. In this procedure, four familiar images are presented onscreen followed by a prompt to view one of the images (e.g., <em>find the bell!</em>). The four images include the target word (e.g., <em>bell</em>), a semantically related word (<em>drum</em>), a phonologically similar word (<em>bee</em>), and an unrelated word (<em>swing</em>). Figure <a href="aim1-method.html#fig:sample-vw-screen">5.1</a> shows an example of a trial’s items. This procedure measures a child’s real-time comprehension of words by capturing how the child’s gaze location changes over time in response to speech.</p>

<div class="figure" style="text-align: center"><span id="fig:sample-vw-screen"></span>
<img src="misc/rwl-screens/TimePoint1/actual/Block2_17_swing2_bell2_bee2_drum2_UpperRightImage_bell.png" alt="Example display for the target bell with the semantic foil drum, the phonological foil bee, and the unrelated swing." width="100%" />
<p class="caption">
Figure 5.1: Example display for the target <em>bell</em> with the semantic foil <em>drum</em>, the phonological foil <em>bee</em>, and the unrelated <em>swing</em>.
</p>
</div>
</div>
<div id="experiment-administration" class="section level2">
<h2><span class="header-section-number">5.3</span> Experiment Administration</h2>
<p>Children participating in the study were tested over two lab visits (on different dates). The first portion of each visit involved “watching movies”—that is, performing two blocks of eyetracking experiments. A play break or hearing screening occurred between the two eyetracking blocks, depending on the visit.</p>
<p>Each eyetracking experiment was administered as a block of trials (24 for this experiment and 38 for a two-image task—see Chapter X). Children received two different blocks of each experiment. The blocks for an experiment differed in trial ordering and other features. Experiment order and block selection were counterbalanced over children and visits. For example, a child might have received Exp. 1 Block A and Exp. 2 Block B on Visit 1 and next received Exp. 2 Block A and Exp. 1 Block B on Visit 2. The purpose of this presentation was to control possible ordering effects where a particular experiment or block benefited from consistently occurring first or second.</p>
<p>Experiments were administered using E-Prime 2.0 and a Tobii T60XL eyetracker which recorded gaze location at a rate of 60 Hz. The experiments were conducted by two examiners, one “behind the scenes” who controlled the computer running the experiment and another “onstage” who guided the child through the experiment. At the beginning of each block, the child was positioned so the child’s eyes were approximately 60 cm from the screen. The examiners calibrated the eyetracker to the child’s eyes using a five-point calibration procedure (center of screen and centers of four screen quadrants). The examiners repeated this calibration procedure if one of the five calibration points for one of the eyes did not calibrate successfully. During the experiment, the behind-the-scenes examiner monitored the child’s distance from the screen and whether the eyetracker was capturing the child’s gaze. The onstage examiner coached the child to stay fixated on the screen and repositioned the child as needed to ensure the child’s eyes were being tracked. Every six or seven trials in a block of an experiment, the experiment briefly paused with a reinforcing animation or activity. During these breaks, the onstage examiner could reposition the child if necessary before resuming the experiment.</p>
<p>We used a gaze-contingent stimulus presentation. First, the images appeared in silence on screen for 2 s as a familiarization period. The experiment then checked whether the child’s gaze was being recorded. If the experiment could continuously track the child’s gaze for 300 ms, the child’s gaze was verified and the trial continued. If the experiment could not verify the gaze after 10 s, the trial continued. This procedure guaranteed that for most trials, the child was looking to the display before presenting the carrier phrase and that the experiment was ready to record the child’s response to the carrier. During Year 1 (age 3) and Year 2 (age 4), an attention-getter (e.g., <em>check it out</em>!) played 1 s following the end of the target noun. These reinforcers were dropped in Year 3 (age 5) to streamline the experiment for older listeners.</p>
</div>
<div id="stimuli" class="section level2">
<h2><span class="header-section-number">5.4</span> Stimuli</h2>
<p>The four images on each trial consisted of a target noun, a phonological foil, a semantic foil, and an unrelated word. The phonological competitors shared a syllable onset (e.g., <em>flag</em>–<em>fly</em>, <em>bell</em>–<em>bee</em>), shared an initial consonant (<em>bread</em>–<em>bear</em>, <em>swing</em>–<em>spoon</em>), had a similar phonetically similar consonant onset (<em>kite</em>–<em>gift</em>), or shared a syllable rime (<em>van</em>–<em>pan</em>). The semantic competitors included words from the same category (e.g., <em>shirt</em>–<em>dress</em>, <em>horse</em>–<em>bear</em>), words that were perceptually similar (<em>sword</em>–<em>pen</em>, <em>flag</em>–<em>kite</em>), and words with less obvious relationships (<em>van</em>–<em>horse</em>, <em>swan</em>-<em>bee</em>). A complete list of the items used in the experiment in <a href="vw-experiment-items.html#vw-experiment-items">Appendix <a href="vw-experiment-items.html#vw-experiment-items">B</a></a>.</p>
<p>The stimuli were recorded in both Mainstream American English (MAE) and African American English (AAE), so that the experiment could accommodate the child’s home dialect. Prior to the lab visit, we made a preliminary guess about the child’s home dialect, based on the recruitment channel, address, among other factors. If we expected the dialect to be AAE, then the lab visit was led by an examiner who natively spoke AAE and could fluently dialect-shift between AAE and MAE. At the beginning of the lab visit, the examiner listened to the interactions between the child and caregiver in order to confirm the child’s home dialect. Prompts to view the target image of a trial (e.g., <em>find the girl</em>) used the carrier phrases “find the” and “see the”. These carriers were recording in the frame “find/see the egg” and cross-spliced with the target nouns to minimize coarticulatory cues on the determiner “the”. The stimuli were re-recorded after the first year of the study with the same speakers so that the average duration of the two dialect versions were more similar.</p>
<p>The images used in the experiment consisted of color photographs on gray backgrounds. These images were piloted with 30 children from two preschool classrooms to ensure that children consistently used the same label for familiar objects. The two preschool classrooms differed in their students’ SES demographics: One classroom (13 piloting students) was part of a university research center which predominantly serves higher-SES families, and the other classroom (17 piloting students) was part of Head Start center which predominantly serves lower-SES families. The images were tested by presenting four images (a target, a phonological foil, a semantic foil and an unrelated word) and having the student point to the named image. The pictures had to be recognized by at least 80% of students in each classroom.</p>
</div>
<div id="data-screening" class="section level2">
<h2><span class="header-section-number">5.5</span> Data screening</h2>
<p>To process the eyetracking data, I first mapped gaze <em>x</em>-<em>y</em> coordinates onto the onscreen images. We next performed <em>deblinking</em>. I interpolated short runs of missing gaze data (up to 150 ms) if the same image was fixated before and after the missing data run. Put differently, I classified a window of missing data as a blink if the window was brief and the gaze remained on the same image before and after the blink. I interpolated missing data from blinks using the fixated image.</p>
<p>After mapping the gaze coordinates onto the onscreen images, I performed data screening. I considered the time window from 0 to 2000 ms after target noun onset. I identified a trial as <em>unreliable</em> if at least 50% of the looks were missing during the time window. I excluded an entire block of trials if it had fewer than 12 reliable trials.</p>
<p>Table <a href="aim1-method.html#tab:screening-counts">5.2</a> shows the numbers of participants and trials at each year before and after data screening. There were more children in the second year than the first due to a timing error in the initial version of this experiment, leading to the exclusion of 27 participants from the first year.</p>
<table>
<caption><span id="tab:screening-counts">Table 5.2: </span>Eyetracking data before and after data screening. For convenience, the number of exclusions are included as Raw - Screened.</caption>
<thead>
<tr class="header">
<th align="left">Dataset</th>
<th align="left">Study</th>
<th align="right">N Children</th>
<th align="right">N Blocks</th>
<th align="right">N Trials</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Raw</td>
<td align="left">Age 3</td>
<td align="right">178</td>
<td align="right">332</td>
<td align="right">7967</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Age 4</td>
<td align="right">180</td>
<td align="right">347</td>
<td align="right">8327</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">Age 5</td>
<td align="right">163</td>
<td align="right">322</td>
<td align="right">7724</td>
</tr>
<tr class="even">
<td align="left">Screened</td>
<td align="left">Age 3</td>
<td align="right">163</td>
<td align="right">291</td>
<td align="right">5951</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">Age 4</td>
<td align="right">165</td>
<td align="right">305</td>
<td align="right">6421</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Age 5</td>
<td align="right">156</td>
<td align="right">295</td>
<td align="right">6483</td>
</tr>
<tr class="odd">
<td align="left">Raw − Screened</td>
<td align="left">Age 3</td>
<td align="right">15</td>
<td align="right">41</td>
<td align="right">2016</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Age 4</td>
<td align="right">15</td>
<td align="right">42</td>
<td align="right">1906</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">Age 5</td>
<td align="right">7</td>
<td align="right">27</td>
<td align="right">1241</td>
</tr>
</tbody>
</table>
</div>
<div id="model-preparation" class="section level2">
<h2><span class="header-section-number">5.6</span> Model preparation</h2>
<p>To prepare the data for modeling, I downsampled the data into 50-ms (3-frame) bins, reducing the eyetracker’s effective sampling rate to 20 Hz. Eye movements have durations on the order of 100 or 200 ms, so capturing data every 16.67 ms oversamples eye movements and can introduce high-frequency noise into the signal. Binning together data from neighboring frames can smooth out this noise. I modeled the looks from 250 to 1500 ms. Lastly, I aggregated looks by child, study and time, and created orthogonal polynomials to use as time features for the model.</p>
<p>Figure <a href="aim1-method.html#fig:aim1-spaghetti">5.2</a> depicts the dataset following these data screening and preparation steps. The lines start around .25 which is chance performance on four-alternative forced choice task. The lines rise as the word unfolds and peak and plateau around 1400 ms.</p>

<div class="figure" style="text-align: center"><span id="fig:aim1-spaghetti"></span>
<img src="12-aim1-methods_files/figure-html/aim1-spaghetti-1.png" alt="Empirical word recognition growth curves from each year of the study. Each line represents an individual child’s proportion of looks to the target image over time. The heavy lines are the averages of the lines for each year." width="100%" />
<p class="caption">
Figure 5.2: Empirical word recognition growth curves from each year of the study. Each line represents an individual child’s proportion of looks to the target image over time. The heavy lines are the averages of the lines for each year.
</p>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-OSF_Statement">
<p>Nosek, B. A., Simonsohn, U., Moore, D. A., Nelson, L. D., Simmons, J. P., Sallans, A., &amp; LeBel, E. P. (2014, February). Standard reviewer statement for disclosure of sample, conditions, measures, and exclusions. Open Science Framework. Retrieved from <a href="https://osf.io/hadz3" class="uri">https://osf.io/hadz3</a></p>
</div>
<div id="ref-RWLPaper">
<p>Law, F., II, Mahr, T., Schneeberg, A., &amp; Edwards, J. R. (2016). Vocabulary size and auditory word recognition in preschool children. <em>Applied Psycholinguistics</em>. doi:<a href="https://doi.org/10.1017/S0142716416000126">10.1017/S0142716416000126</a></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="aim1-introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="analysis-of-familiar-word-recognition.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["dissertation.pdf"],
"toc": {
"collapse": "subsection"
},
"split_bib": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
