<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Development of word recognition in preschoolers</title>
  <meta name="description" content="Development of word recognition in preschoolers">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Development of word recognition in preschoolers" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="tjmahr/dissertation" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Development of word recognition in preschoolers" />
  
  
  

<meta name="author" content="Tristan Mahr">


<meta name="date" content="2018-04-13">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="analysis-of-familiar-word-recognition.html">
<link rel="next" href="general-discussion.html">
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="assets\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Word Recognition in Preschoolers</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>Prospectus</b></span></li>
<li class="chapter" data-level="1" data-path="prospectus-preamble.html"><a href="prospectus-preamble.html"><i class="fa fa-check"></i><b>1</b> Prospectus Preamble</a><ul>
<li class="chapter" data-level="" data-path="prospectus-preamble.html"><a href="prospectus-preamble.html#about-this-document"><i class="fa fa-check"></i>About This Document</a></li>
<li class="chapter" data-level="" data-path="prospectus-preamble.html"><a href="prospectus-preamble.html#committee-members"><i class="fa fa-check"></i>Dissertation Committee Members</a></li>
<li class="chapter" data-level="" data-path="prospectus-preamble.html"><a href="prospectus-preamble.html#planned-dissertation-format"><i class="fa fa-check"></i>Planned Dissertation Format</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="specific-aims.html"><a href="specific-aims.html"><i class="fa fa-check"></i><b>2</b> Specific Aims</a><ul>
<li class="chapter" data-level="2.1" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>2.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="2.2" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>2.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="2.3" data-path="specific-aims.html"><a href="specific-aims.html#summary"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="significance.html"><a href="significance.html"><i class="fa fa-check"></i><b>3</b> Significance</a><ul>
<li class="chapter" data-level="3.1" data-path="significance.html"><a href="significance.html#public-health-significance"><i class="fa fa-check"></i><b>3.1</b> Public Health Significance</a></li>
<li class="chapter" data-level="3.2" data-path="significance.html"><a href="significance.html#scientific-significance"><i class="fa fa-check"></i><b>3.2</b> Scientific Significance</a><ul>
<li class="chapter" data-level="3.2.1" data-path="significance.html"><a href="significance.html#lexical-processing-dynamics"><i class="fa fa-check"></i><b>3.2.1</b> Lexical Processing Dynamics</a></li>
<li class="chapter" data-level="3.2.2" data-path="significance.html"><a href="significance.html#individual-differences-in-word-recognition"><i class="fa fa-check"></i><b>3.2.2</b> Individual Differences in Word Recognition</a></li>
<li class="chapter" data-level="3.2.3" data-path="significance.html"><a href="significance.html#summary-1"><i class="fa fa-check"></i><b>3.2.3</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="research-hypotheses.html"><a href="research-hypotheses.html"><i class="fa fa-check"></i><b>4</b> Research Hypotheses</a><ul>
<li class="chapter" data-level="4.1" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-1-familiar-word-recognition-and-lexical-competition-1"><i class="fa fa-check"></i><b>4.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="4.2" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-2-referent-selection-and-mispronunciations-1"><i class="fa fa-check"></i><b>4.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
</ul></li>
<li class="part"><span><b>Aim 1: Familiar Word Recognition and Lexical Competition</b></span></li>
<li class="chapter" data-level="5" data-path="aim1-method.html"><a href="aim1-method.html"><i class="fa fa-check"></i><b>5</b> Method</a><ul>
<li class="chapter" data-level="5.1" data-path="aim1-method.html"><a href="aim1-method.html#participants"><i class="fa fa-check"></i><b>5.1</b> Participants</a></li>
<li class="chapter" data-level="5.2" data-path="aim1-method.html"><a href="aim1-method.html#procedure"><i class="fa fa-check"></i><b>5.2</b> Procedure</a></li>
<li class="chapter" data-level="5.3" data-path="aim1-method.html"><a href="aim1-method.html#experiment-administration"><i class="fa fa-check"></i><b>5.3</b> Experiment Administration</a></li>
<li class="chapter" data-level="5.4" data-path="aim1-method.html"><a href="aim1-method.html#stimuli"><i class="fa fa-check"></i><b>5.4</b> Stimuli</a></li>
<li class="chapter" data-level="5.5" data-path="aim1-method.html"><a href="aim1-method.html#data-screening"><i class="fa fa-check"></i><b>5.5</b> Data screening</a></li>
<li class="chapter" data-level="5.6" data-path="aim1-method.html"><a href="aim1-method.html#model-preparation"><i class="fa fa-check"></i><b>5.6</b> Model preparation</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html"><i class="fa fa-check"></i><b>6</b> Analysis of familiar word recognition</a><ul>
<li class="chapter" data-level="6.1" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#growth-curve-analysis"><i class="fa fa-check"></i><b>6.1</b> Growth curve analysis</a><ul>
<li class="chapter" data-level="6.1.1" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#growth-curve-features-as-measures-of-word-recognition-performance"><i class="fa fa-check"></i><b>6.1.1</b> Growth curve features as measures of word recognition performance</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#year-over-year-changes-in-word-recognition-performance"><i class="fa fa-check"></i><b>6.2</b> Year over year changes in word recognition performance</a></li>
<li class="chapter" data-level="6.3" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#exploring-plausible-ranges-of-performance-over-time"><i class="fa fa-check"></i><b>6.3</b> Exploring plausible ranges of performance over time</a></li>
<li class="chapter" data-level="6.4" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#are-individual-differences-stable-over-time"><i class="fa fa-check"></i><b>6.4</b> Are individual differences stable over time?</a></li>
<li class="chapter" data-level="6.5" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#predicting-future-vocabulary-size"><i class="fa fa-check"></i><b>6.5</b> Predicting future vocabulary size</a></li>
<li class="chapter" data-level="6.6" data-path="analysis-of-familiar-word-recognition.html"><a href="analysis-of-familiar-word-recognition.html#discussion"><i class="fa fa-check"></i><b>6.6</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html"><i class="fa fa-check"></i><b>7</b> Effects of phonological and semantic competitors</a><ul>
<li class="chapter" data-level="7.1" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html#looks-to-the-phonological-competitor"><i class="fa fa-check"></i><b>7.1</b> Looks to the phonological competitor</a></li>
<li class="chapter" data-level="7.2" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html#looks-to-the-semantic-competitor"><i class="fa fa-check"></i><b>7.2</b> Looks to the semantic competitor</a></li>
<li class="chapter" data-level="7.3" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html#differences-in-competitor-sensitivity-at-age-3"><i class="fa fa-check"></i><b>7.3</b> Differences in competitor sensitivity at age 3</a></li>
<li class="chapter" data-level="7.4" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html#discussion-1"><i class="fa fa-check"></i><b>7.4</b> Discussion</a><ul>
<li class="chapter" data-level="7.4.1" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html#immediate-activation-of-phonological-neighbors"><i class="fa fa-check"></i><b>7.4.1</b> Immediate activation of phonological neighbors</a></li>
<li class="chapter" data-level="7.4.2" data-path="effects-of-phonological-and-semantic-competitors.html"><a href="effects-of-phonological-and-semantic-competitors.html#late-activation-of-semantic-neighbors"><i class="fa fa-check"></i><b>7.4.2</b> Late activation of semantic neighbors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="general-discussion.html"><a href="general-discussion.html"><i class="fa fa-check"></i><b>8</b> General Discussion</a></li>
<li class="part"><span><b>Miscellany</b></span></li>
<li class="chapter" data-level="9" data-path="scratch-paper.html"><a href="scratch-paper.html"><i class="fa fa-check"></i><b>9</b> Scratch paper</a><ul>
<li class="chapter" data-level="9.1" data-path="scratch-paper.html"><a href="scratch-paper.html#bookdown-cheatsheet"><i class="fa fa-check"></i><b>9.1</b> Bookdown cheatsheet</a><ul>
<li class="chapter" data-level="9.1.1" data-path="scratch-paper.html"><a href="scratch-paper.html#manual-section-label-demo"><i class="fa fa-check"></i><b>9.1.1</b> Cross-references to sections</a></li>
<li class="chapter" data-level="9.1.2" data-path="scratch-paper.html"><a href="scratch-paper.html#cross-references-to-appendices"><i class="fa fa-check"></i><b>9.1.2</b> Cross-references to appendices</a></li>
<li class="chapter" data-level="9.1.3" data-path="scratch-paper.html"><a href="scratch-paper.html#cross-references-to-tables"><i class="fa fa-check"></i><b>9.1.3</b> Cross-references to tables</a></li>
<li class="chapter" data-level="9.1.4" data-path="scratch-paper.html"><a href="scratch-paper.html#figure-references-and-using-text-references-as-captions"><i class="fa fa-check"></i><b>9.1.4</b> Figure references and using text references as captions</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="scratch-paper.html"><a href="scratch-paper.html#custom-blocks"><i class="fa fa-check"></i><b>9.2</b> Custom blocks</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="quick-testing-sandbox.html"><a href="quick-testing-sandbox.html"><i class="fa fa-check"></i><b>10</b> Quick testing sandbox</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html"><i class="fa fa-check"></i><b>A</b> Computational Details for Specific Aim 1</a><ul>
<li class="chapter" data-level="A.1" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#growth-curve-analysis-models"><i class="fa fa-check"></i><b>A.1</b> Growth Curve Analysis Models</a></li>
<li class="chapter" data-level="A.2" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#additional-model-results"><i class="fa fa-check"></i><b>A.2</b> Additional model results</a><ul>
<li class="chapter" data-level="A.2.1" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#plot-the-intervals-for-the-random-effect-parameters"><i class="fa fa-check"></i><b>A.2.1</b> Plot the intervals for the random effect parameters</a></li>
<li class="chapter" data-level="A.2.2" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>A.2.2</b> Posterior predictive checks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="vw-experiment-items.html"><a href="vw-experiment-items.html"><i class="fa fa-check"></i><b>B</b> Items used in the visual world experiment</a></li>
<li class="chapter" data-level="C" data-path="mp-experiment-items.html"><a href="mp-experiment-items.html"><i class="fa fa-check"></i><b>C</b> Items used in the mispronunciation experiment</a></li>
<li class="chapter" data-level="D" data-path="related-work.html"><a href="related-work.html"><i class="fa fa-check"></i><b>D</b> Related Work</a></li>
<li class="chapter" data-level="" data-path="colophon.html"><a href="colophon.html"><i class="fa fa-check"></i>Colophon</a><ul>
<li class="chapter" data-level="D.1" data-path="colophon.html"><a href="colophon.html#debug-info"><i class="fa fa-check"></i><b>D.1</b> Debug info</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Created with bookdown</a></li>
<li><a href="https://tjmahr.github.io/" target="blank">Tristan Mahr</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Development of word recognition in preschoolers</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="effects-of-phonological-and-semantic-competitors" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Effects of phonological and semantic competitors</h1>
<div id="looks-to-the-phonological-competitor" class="section level2">
<h2><span class="header-section-number">7.1</span> Looks to the phonological competitor</h2>
<p>Next, I asked how children’s sensitivity to the phonological foils changed over developmental time. Following our approach in <span class="citation">(Law et al., <a href="#ref-RWLPaper">2016</a>)</span>, I only examined trials for which the phonological foil and the noun shared the same syllable onset. For example, this criterion included trials with <em>dress</em>–<em>drum</em>, <em>fly</em>–<em>flag</em>, or <em>horse</em>–<em>heart</em>, but it excluded trials <em>kite</em>–<em>gift</em> (feature difference), <em>bear</em>–<em>bread</em> (onset difference), and <em>ring</em>–<em>swing</em> (rimes). I kept 13 of the 24 trials. <a href="vw-experiment-items.html#vw-experiment-items">Appendix <a href="vw-experiment-items.html#vw-experiment-items">B</a></a> provides a complete list of trials used.</p>
<p>The outcome measure for these analyses was the log-odds of fixating on the phonological foil versus the unrelated image. Because children looked more to the target word with each year of the study, they necessarily looked less to the distractors each year. Figure <a href="effects-of-phonological-and-semantic-competitors.html#fig:declining-phon-props">7.1</a> illustrates how the proportions of looks to the phonological foils declined each year. Therefore, I examined the effect of the phonological foil in comparison to the unrelated foil. For example, on the trials where the target is <em>fly</em>, we can study the effect of the phonological foil <em>flag</em> by looking at when and to what to degree the children fixate on <em>flag</em> more than the unrelated image <em>pen</em>. If a window of time of shows a consistent advantage for the phonological foil over the unrelated image, we can conclude that the children were sensitive to the phonological foil. By studying the time course of fixations to the phonological foil versus the unrelated image, we can identify when the phonological foil affected word recognition most significantly.</p>
<p>As in the previous models, I downsampled the data into 50-ms (3-frame) bins in order to smooth the data. I modeled the looks from  to  ms. Lastly, I aggregated looks by child, study and time.</p>

<div class="figure"><span id="fig:declining-phon-props"></span>
<img src="16-aim1-lexical-competitors_files/figure-html/declining-phon-props-1.png" alt="Because children looked more to the target as they grew older, they numerically looked less the foils too. This effect is why I evaluated the phonological and semantic foils by comparing them against the unrelated image." width="60%" />
<p class="caption">
Figure 7.1: Because children looked more to the target as they grew older, they numerically looked less the foils too. This effect is why I evaluated the phonological and semantic foils by comparing them against the unrelated image.
</p>
</div>
<p>To account for the sparseness of the data, I used the empirical log-odds (or empirical logit) transformation <span class="citation">(Barr, <a href="#ref-Barr2008">2008</a>)</span>. This transformation adds .5 to the looking counts. For example, a time-frame with 4 looks to the phonological foil and 1 look to the unrelated image has a conventional log-odds of log(4/1) = 1.39 and empirical log-odds of log(4.5/1.5) = 1.10. This transformation fills in 0 counts, and it dampens the extremeness of some probabilities that arise in sparse count data.</p>
<p>To model these data, I fit a generalized additive model with fast restricted maximum likelihood estimation <span class="citation">(Sóskuthy, <a href="#ref-Soskuthy2017">2017</a> for a tutorial for linguists; Wood, <a href="#ref-Wood2017">2017</a>)</span>. Box 1 provides a brief overview of these models. I used the mgcv R package <span class="citation">(vers. 1.8.23; Wood, <a href="#ref-Wood2017">2017</a>)</span> with support from the tools in the itsadug R package <span class="citation">(vers. 2.3; van Rij, Wieling, Baayen, &amp; van Rijn, <a href="#ref-itsadug">2017</a>)</span>.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>

<div class="infobox">
<p><strong>Box 1: The Intuition Behind Generalized Additive Models</strong>.</p>
<p>In these analyses, the outcome of interest is a value that changes over time in a nonlinear way. We model these time series by building a set of features to represent time values. In the growth curve analyses of familiar word recognition, I used a set of polynomial features which expressed time as the weighted sum of a linear trend, a quadratic trend and cubic trend. That is:</p>
<p><span class="math display">\[
\text{log-odds}(\mathit{looking}) =
  \alpha + \beta_1 * \textit{Time}^1 +
           \beta_2 * \textit{Time}^2 +
           \beta_3 * \textit{Time}^3
\]</span></p>
<p>But another way to think about the polynomial terms is as <em>basis functions</em>: A set of features that combine to approximate some nonlinear function of time. Under this framework, the model can be expressed as:</p>
<p><span class="math display">\[
\text{log-odds}(\mathit{looking}) =
  \alpha + f(\textit{Time})
\]</span></p>
<p>This is the idea behind generalized additive models and their <em>smooth terms</em>. These smooths fit nonlinear functions of data by weighting and adding simple functions together. The figures below show 9 basis functions from a “thin-plate spline” and how they can be weighted and summed to fit a growth curve.</p>
<p><img src="16-aim1-lexical-competitors_files/figure-html/infobox-1-figs-1.png" width="66%" style="display: block; margin: auto;" /></p>
<p>Each of these basis functions is weighted by a model coefficient, but the individual basis functions are not a priori meaningful. Rather, it is the whole set of functions that approximate the curvature of the data—i.e., <em>f</em>(Time))—so we statistically evaluate the whole batch of coefficients simultaneously. This joint testing is similar to how one might test a batch of effects in an ANOVA. If the batch of effects jointly improve model fit, we infer that there is a significant smooth or shape effect.</p>
<p>Smooth terms come with an estimated degrees of freedom (EDF). These values provide a sense of how many degrees of freedom the smooth consumed. An EDF of 1 is a perfectly straight line, indicating no smoothing. Higher EDF values indicate that the smooth term captured more curvature from the data.</p>
<!-- The other important thing to know about generalized additive models is that -->
<!-- wigglyness is penalized. With so many functions, one might worry about -->
<!-- overfitting the data and including incidental wiggliness into *f*(Time). These -->
<!-- models, however, include a smoothing parameter that -->
</div>

<p>The model included main effects of study year. These <em>parametric</em> terms work like conventional regression effects and determined the growth curve’s average values. The model used age 4 as the reference year, so the intercept represented the average looking probability at age 4. The model’s year effects therefore represented differences between age 4 vs. age 3 and age 4 vs. age 5.</p>
<p>The model also included <em>smooth</em> terms to represent the time course of the data. As with the parametric effects, age 4 served as the reference year. The model estimated a smooth for age 4 and it estimated <em>difference smooths</em> to capture how the curvature at age 3 and age 5 differed from the age-4 curvature. Each of these study-level smooths used 10 knots (9 basis functions). I also included child-level <em>random smooths</em> to represent child-level variation in growth curve shapes. Because there is much as less data at the child level than at the study level, these random smooths only included 5 knots (4 basis functions). We can think of these simpler splines as coarse adjustments in growth curve shape to capture child-level variation from limited data. Altogether, the model contained the following terms:</p>
<p><span class="math display">\[
\small
\begin{align*}
   \text{emp. log-odds}(\mathit{phon.\ vs.\ unrelated}) =\
   &amp; \alpha + \beta_1\text{Age3} + \beta_2\text{Age5} +\ &amp;\text{[growth curve averages]} \\
   &amp; f_1(\text{Time}, \text{Age4})\ +                    &amp;\text{[reference smooth]} \\
   &amp; f_2(\text{Time}, \text{Age4} - \text{Age3})\ +      &amp;\text{[difference smooths]} \\
   &amp; f_3(\text{Time}, \text{Age4} - \text{Age5})\ +      &amp; \\
   &amp; f_i(\text{Time}, \text{Child}_i)                    &amp;\text{[by-child random smooths]} \\
\end{align*}
\]</span></p>
<p>The model’s fitted values are shown in Figure <a href="effects-of-phonological-and-semantic-competitors.html#fig:phon-vs-unre-fits">7.2</a>. These are the average empirical log-odds of fixating on the phonological foil versus the unrelated image for each year of the study. The model captured the trend for increased looks to the competitor image with each year of the study. At age 4 and age 5, the shape rises from a baseline to the peak around 800 ms. These curves slope downwards and eventually fall beneath the initial baseline. The shape at age 3 does not have a steady rise from baseline and shows a very small peak around 800 ms.</p>

<div class="figure"><span id="fig:phon-vs-unre-fits"></span>
<img src="16-aim1-lexical-competitors_files/figure-html/phon-vs-unre-fits-1.png" alt="With each year of the study, children looked more to the phonological competitor, relative to the unrelated image, during and after the target noun. Both figures show means for each year estimated by the generalized additive model. The left panel compares model estimates to observed means and standard errors, and the right panel visualizes estimated means and their 95% confidence intervals." width="80%" />
<p class="caption">
Figure 7.2: With each year of the study, children looked more to the phonological competitor, relative to the unrelated image, during and after the target noun. Both figures show means for each year estimated by the generalized additive model. The left panel compares model estimates to observed means and standard errors, and the right panel visualizes estimated means and their 95% confidence intervals.
</p>
</div>
<p>The average looks to the phonological foil over the unrelated for age 4 was 0.16 emp. log-odds, .54 proportion units. The averages for age 3 and age 4 did not significantly differ, <em>p</em> = .85 but the average value was significantly greater at age 5, 0.31 emp. log-odds, .58 proportion units, <em>p</em> &lt; .001. Visually, this effect shows up in the almost constant height difference between the age-4 and the age-5 curves.</p>

<div class="figure"><span id="fig:phon-diff-curves"></span>
<img src="16-aim1-lexical-competitors_files/figure-html/phon-diff-curves-1.png" alt="Differences in the average looks to the phonological competitor versus the unrelated image between age 4 and the other ages. Plotted line is estimated difference and the shaded region is the 95% confidence interval around that difference. Blue boxes highlight regions where the 95% interval excludes zero. From age 3 to age 4, children become more sensitive to the phonological foil during and after the target noun. The curves for age 3 and age 4 have largely the same shape, but they steadily diverge over time." width="80%" />
<p class="caption">
Figure 7.3: Differences in the average looks to the phonological competitor versus the unrelated image between age 4 and the other ages. Plotted line is estimated difference and the shaded region is the 95% confidence interval around that difference. Blue boxes highlight regions where the 95% interval excludes zero. From age 3 to age 4, children become more sensitive to the phonological foil during and after the target noun. The curves for age 3 and age 4 have largely the same shape, but they steadily diverge over time.
</p>
</div>
<p>There was a significant smooth term for time at age 4, estimated degrees of freedom (EDF) = 7.28, <em>p</em> &lt; .001. Figure <a href="effects-of-phonological-and-semantic-competitors.html#fig:phon-diff-curves">7.3</a> visualizes how and when the smooths from other studies differed from the age-4 smooth.</p>
<p>The age-3 and age-4 significantly differed, EDF = 5.48, <em>p</em> &lt; .001. In particular, the curves are significantly different from 500 to 1050 ms. This result confirms that the looks to the phonological foil increased from age 3 and age 4 during the time window immediately following presentation of the noun. The similarity between the phonological foil and the target occurs early in the trial. Given the 150–300 ms time required to execute an eye movement in response to speech, the time window for these differences indicates that children became more sensitive to the phonological similarities between the foil and the target from age 3 to age 4.</p>
<p>The age-3 and age-4 curves also differed significantly after 1250 ms. The effect reflects how the looks to phonological foil decreased as the trial progresses. After an incorrect look to the foil, the children on average corrected their gaze and looked even less to the phonological foil. We do not observe this degree of correction during age 3, presumably because children at age 3 hardly looked to the phonological foil early on.</p>
<p>The age-4 and age-5 smooths also significantly differed, EDF = 1.00, <em>p</em> &lt; .001, although the low EDF values indicates that the shape of the difference was a flat line. Thus, the difference between the age-4 and age-5 smooths is driven primarily by the intercept difference and a linear diverging trend—that is, the distance between the two grows slightly over time. The same general curvature was observed for the two studies, reflecting the same general looking behavior at both time points. Children showed an early increase in looks to the phonological foil relative to the unrelated image but after receiving disqualifying information from the rest of the word, the looks to the phonological foil rapidly decrease. The primary difference between age-4 and age-5 is that the foil effect becomes more pronounced at age 5.</p>
<p><strong>Summary</strong>. Children looked more the phonological competitor than the unrelated image early in the trials. The advantage of the phonological competitor peaked on average around 800 ms after target onset. This peak was very small at age 3 but increased in height with each year of the study. Thus, children became more sensitive to the phonological cohort competitors as they grew older.</p>
</div>
<div id="looks-to-the-semantic-competitor" class="section level2">
<h2><span class="header-section-number">7.2</span> Looks to the semantic competitor</h2>
<p>I asked how children’s sensitivity to the semantic competitor changed as they grew older. As in <span class="citation">(Law et al., <a href="#ref-RWLPaper">2016</a>)</span>, I only examined trials for which the semantic foil and the noun were part of the same category. For example, I included trials with <em>bee</em>–<em>fly</em>, <em>shirt</em>–<em>dress</em>, and <em>spoon</em>–<em>pan</em>, but I excluded trials where the similarity was perceptual (<em>sword</em>–<em>pen</em>) or too abstract (<em>swan</em>–<em>bee</em>). This criterion kept 13 of the 24 trials. <a href="vw-experiment-items.html#vw-experiment-items">Appendix <a href="vw-experiment-items.html#vw-experiment-items">B</a></a> provides a complete list of trials used.</p>
<p>For these trials, I used the same modeling technique as the one used for phonological competitor: Generalized additive models with study effects and a time smooth, time-by-study difference smooths, and time-by-child random smooths. I modeled the looks from from 250 to 1800 ms. This window was 300 ms longer than the one used for the phonological competitors in order to capture late-occurring semantic effects.</p>
<p>The model’s fitted values are shown in Figure <a href="effects-of-phonological-and-semantic-competitors.html#fig:semy-vs-unre-fits">7.4</a>. The average empirical log-odds of fixating on the semantic foil versus the unrelated image increased with each year of the study. All three years show the same general time course of effects: Looks begin to increase from a baseline around 750 ms and peak around 1300 ms. The peaks of the curves increased as children grew older. The semantic foil shows a clear advantage over the unrelated image at age 3, which was not the case for the phonological foil at age 3.</p>

<div class="figure"><span id="fig:semy-vs-unre-fits"></span>
<img src="16-aim1-lexical-competitors_files/figure-html/semy-vs-unre-fits-1.png" alt="With each year of the study, children looked more to the semantic foil, relative to the unrelated image, with peak looking occurring after the target noun. Both figures show means for each year estimated by the generalized additive model. The left panel compares model estimates to observed means and standard errors, and the right panel visualizes estimated means and their 95% confidence intervals." width="80%" />
<p class="caption">
Figure 7.4: With each year of the study, children looked more to the semantic foil, relative to the unrelated image, with peak looking occurring after the target noun. Both figures show means for each year estimated by the generalized additive model. The left panel compares model estimates to observed means and standard errors, and the right panel visualizes estimated means and their 95% confidence intervals.
</p>
</div>
<p>The average looks to the semantic foil over the unrelated for age 4 was 0.44 emp. log-odds, .61 proportion units. Children looked significantly less to the semantic foil on average at age 3, 0.30 emp. log-odds, .57 proportion units, <em>p</em> &lt; .001, and they looked significantly more to the semantic foil at age 5, 0.50 emp. log-odds, .62 proportion units, <em>p</em> &lt; .001. The peaks of the growth curves, in proportion units, were .65 at age 3, .68 at age 4, and .70 at age 5.</p>
<p>There was a significant smooth term for time at age 4, estimated degrees of freedom (EDF) = 7.04, <em>p</em> &lt; .001. Figure <a href="effects-of-phonological-and-semantic-competitors.html#fig:semy-diff-curves">7.5</a> visualizes the time course of the differences between the smooths from each study.</p>

<pre><code>#&gt; Summary:
#&gt;  * Time : numeric predictor; with 32 values ranging from 250.000000 to 1800.000000. 
#&gt;  * R : factor; set to the value(s): 001L. (Might be canceled as random effect, check below.) 
#&gt;  * NOTE : The following random effects columns are canceled: s(Time,R)
#&gt; </code></pre>
<div class="figure"><span id="fig:semy-diff-curves"></span>
<img src="16-aim1-lexical-competitors_files/figure-html/semy-diff-curves-1.png" alt="Differences in the average looks to the semantic foil versus the unrelated image between age 4 and the other ages. Plotted line is estimated difference and the shaded region is the 95% confidence interval around that difference. Blue boxes highlight regions where the 95% interval excludes zero. The flat line on the left reflects how the shape of the growth curves remained the same from age 3 to age 4 and only differed in average height. From age 4 to age 5, the lines quickly diverge and the age-5 curve reaches a higher peak value." width="80%" />
<p class="caption">
Figure 7.5: Differences in the average looks to the semantic foil versus the unrelated image between age 4 and the other ages. Plotted line is estimated difference and the shaded region is the 95% confidence interval around that difference. Blue boxes highlight regions where the 95% interval excludes zero. The flat line on the left reflects how the shape of the growth curves remained the same from age 3 to age 4 and only differed in average height. From age 4 to age 5, the lines quickly diverge and the age-5 curve reaches a higher peak value.
</p>
</div>
<p>The shapes of the age-3 and age-4 curves did not significantly differ, EDF = 1.00, <em>p</em> = .535. The age-3 curve begins to rise about 100 ms later, and it reaches a shallower peak value than the age-4 curve. These two features create a nearly constant height difference between the two curves, and thus, the two curves show the same overall shape.</p>
<p>The age-4 and age-5 smooths significantly differed, EDF = 1.00, <em>p</em> &lt; .001. The differences are greatest after the end of the target noun, in the window from 750 to 1500 ms. The two curves start from a similar baseline but quickly diverge as the age-5 curve reaches a higher peak value. After 1500 ms, the age-5 curve turns downwards to overlap with the age-4 curve. Thus, children looked more to the semantic foil relative to the unrelated image, but they were also quicker to correct and look away from it.</p>
<p><strong>Summary.</strong> Children became more sensitive to the semantic competitor, compared to the unrelated image, with each year of the study. The semantic foils clearly influenced looking patterns at age 3, in contrast to the muted effect observed for the phonological foils. The semantic effect also occurred when we would expect: After the end of the target noun, following activation of the target noun and its semantic neighbors.</p>
</div>
<div id="differences-in-competitor-sensitivity-at-age-3" class="section level2">
<h2><span class="header-section-number">7.3</span> Differences in competitor sensitivity at age 3</h2>
<p>Next, I asked whether children differed reliably in their sensitivity to the phonological and semantic foils based on speech perception and vocabulary measures collected at age 3</p>
<p>As a measure of speech perception, I used scores from a minimal pair discrimination experiment administered during the first year of the study. [citations] The task is essentially an ABX discrimination task: A picture of a familiar object is shown and labeled (e.g., “car”), another object is shown and labeled (“jar”), and then both images are shown and one of the two is named. The child then indicated which word they heard by tapping on the image on a touch-screen.</p>
<p>I derived speech perception scores by fitting a hierarchical item-response model. This logistic regression model estimates the probability of child <em>i</em> correctly choosing word <em>j</em> on word-pair <em>k</em>. The equation below provides a term-by-term description of the model. The model’s intercept term represents the average participant’s probability of correctly answering for an average item. By-child random intercepts capture a child’s deviation from the overall average, so they estimate the child’s <em>ability</em>. By-word and by-word-in-pair random intercepts capture the relative difficulty of particular items on the experiment. The by-word-in-pair effects were necessary because four words appeared in more than one word pair (e.g., <em>juice</em>–<em>goose</em> and <em>juice</em>–<em>moose</em>). The model also controlled for the children’s ages and receptive vocabulary scores (PPVT-4 growth scale values). These predictors were transformed to have mean 0 and standard deviation 1, so the the model’s intercept reflected a child of an average age and an average vocabulary level. Put differently, the by-child intercepts reflect a child’s ability after controlling for age and receptive vocabulary.</p>
<p><span class="math display">\[
\small
\begin{align*}
   \text{log-odds}(\mathit{choosing\ correct\ word}) =\
   &amp; \alpha\ +                  &amp;\text{[average participant ability]} \\
   &amp; \alpha_i\ +                &amp;\text{[difference of participant}\ i
                                       \text{&#39;s ability from average]} \\
   &amp; \alpha_j\ +                &amp;\text{[word}\ j\text{&#39;s difficulty]} \\
   &amp; \alpha_{j,k}\ +            &amp;\text{[word}\ j
                                       \text{&#39;s difficulty in word-pair}\ k] \\
   &amp; \beta_{1}\text{Age}\ +     &amp;\text{[participant-level predictors]} \\
   &amp; \beta_{2}\text{Vocabulary} &amp; \\
\end{align*}
\]</span></p>
<p>I tested whether phonemic discrimination ability at age-3 predicted looks to the phonological foil over the unrelated image by modifying the generalized additive model from earlier. In particular, I included a smooth term for the phonemic discrimination ability score and a “smooth interaction” between the smooth of time and phonemic ability. These smooth interaction terms are analogous to interaction terms in linear models. In this case, the interaction term allows the ability score to change the shape of the time trend. The additive model was therefore:</p>
<p><span class="math display">\[
\small
\begin{align*}
   \text{emp. log-odds}(\mathit{phon.\ vs.\ unrelated}) =\
   &amp; \alpha +\ &amp;\text{[growth curve average]} \\
   &amp; f_1(\text{Time})\ +                    &amp;\text{[time smooth]} \\
   &amp; f_2(\text{Ability})\ +                 &amp;\text{[ability smooth]} \\
   &amp; f_3(\text{Time} * \text{Ability})\ +   &amp;\text{[interaction smooth]} \\
   &amp; f_i(\text{Time}, \text{Child}_i)       &amp;\text{[by-child random smooths]} \\
\end{align*}
\]</span></p>
<p>The model included data from 144 participants; these were children with eyetracking data, receptive vocabulary and phonological discrimination data at age 3. There was not a significant smooth effect for phonological discrimination ability, EDF = 1.00, <em>p</em> = .551 or for an interaction smooth between time and ability, EDF = 8.37, <em>p</em> = .303.</p>
<p>To test the role of receptive vocabulary, I also fit analogous models using growth scale value scores from the PPVT-4, a receptive vocabulary test. I first adjusted these scores in a regression model to control for–that is, to partial out the effects of—age and predicted accuracy on the phonological discrimination task. There was not a significant smooth effect for receptive vocabulary, EDF = 1.00, <em>p</em> = .868, or a significant interaction smooth between time and receptive vocabulary, EDF = 5.57, <em>p</em> = .610. Receptive vocabulary therefore was not related to looks to the phonological foil at age 3.</p>
<p>I tested the same two predictors on looks to the semantic foil at age 3. These child-level factors did not show any significant parametric effects, smooth effects or smooth interactions with time. Thus, children’s looks to the semantic foil were not reliably related to phonological discrimination or receptive vocabulary.</p>
<p><strong>Summary</strong>. These models tested whether two child-level factors—minimal-pair discrimination ability and receptive vocabulary—predicted looks to the phonological and semantic competitors at age 3. No significant effects were observed for all cases.</p>
</div>
<div id="discussion-1" class="section level2">
<h2><span class="header-section-number">7.4</span> Discussion</h2>
<p>In the preceding analyses, I examined children’s fixation patterns to the phonological and semantic competitors and how these fixation patterns changed over developmental time. With each year of the study, children looked more to the target overall, so they consequently looked less to the competitor images each year. To account for this fact, these analyses examined the ratio of looks to the competitors versus the unrelated word. This ratio measured the relative advantage of a competitor over the unrelated word.</p>
<!-- If we imagine a pie-chart of looks to the four images, the target piece -->
<!-- increases in size each year, overtaking area from the other three looks. -->
<!-- describe general patterns, time course and increase -->
<div id="immediate-activation-of-phonological-neighbors" class="section level3">
<h3><span class="header-section-number">7.4.1</span> Immediate activation of phonological neighbors</h3>
<p>Developmentally, children became more sensitive to the phonological competitors with each year of the study. These words shared the same syllable onset as the target noun—for example, the pairs <em>dress</em>–<em>drum</em> or <em>fly</em>–<em>flag</em>. The competitors affected word recognition early on, with relative looks to the phonological foils peaking around 800 ms. The target nouns were approximately 800 ms long at age 3 and 550–800 ms for later ages. Assuming an 150–300 ms overhead for executing an eye movement in response to speech, this timing indicates that children shifted their gaze immediately, based on partial information. This tendency to act on partial information increased with age. In terms of lexical processing, the degree of activation of the phonological competitors increased each year.</p>
<!-- Our results showed that children's activation of the target and its phonological neighbors increased with age. Children were more able to use partial information during word recognition.  -->
<p>At ages 4 and 5, these early peaks of looks to the phonological competitor were followed by a steep, monotonic decrease in looks: Children rejected their initial interpretation of the word and considered other images. At age 3, the average pattern showed more wiggliness, suggesting that the children were less decisive in rejecting the phonological competitor. The shapes of the looking patterns at age 4 and age 5 were essentially the same: In particular, the rate at which children rejected the phonological competitor did not differ between the two studies. If looks away from the phonological competitor reflect resolution of lexical competition by inhibitory mechanisms, then the lack of a difference between the age 4 and age 5 growth curve shapes indicates that children’s rate of inhibition did not change.</p>
<p>The early advantage of the phonological foil was observed to a more limited degree in the age 3 study, but still there._</p>
<p>Young children used information in an incremental fashion. This fact agrees with previous findings….</p>
<!-- I had described this earlier as children becoming "more sensitive" to the phonological competitors. -->
<p><span class="citation">Rigler et al. (<a href="#ref-Rigler2015">2015</a>)</span> provides an interesting comparison. They compared 9- and 16-year-olds on a visual-world word recognition experiment with cohort and rime competitors. The younger children in that study were slower to look to the target image and showed more looks to the competitor images. The implications are that children’s lexical processing is still developing in late childhood and that in particular, children’s inhibition of lexical competitors increases with age.</p>
<p>The current results with 3-, 4-, and 5-year-olds followed a different pattern: Relative looks to the competitor images increased with age. Taken together, the results suggest an interesting progression for the development of lexical processing. From the earliest stages, children’s word recognition demonstrates incremental processing. [cite cite] During the preschool years, children learn many, many words, and they establish phonological and semantic connections between words. These connections support immediate activation of the neighborhoods of words. For these experiments, children became more sensitive to the phonological foils because the phonological competitor achieved greater activation. Late childhood, based on the <span class="citation">Rigler et al. (<a href="#ref-Rigler2015">2015</a>)</span> findings, would be a time for refinement of those connections, so that sensitivity to the competitors decreases. This refinement could follow from more selective activation channels, increased lexical inhibition, or likely a combination of both.</p>
<p>I also asked whether child-level factors predicted sensitivity to the phonological competitors. They did not at age 3. In particular, children who can more reliably discriminate minimal pairs did not show increased sensitive to the phonological foil. This finding suggests that sensitivity to the phonological foil is somewhat removed from speech perception. PPVT: vocabulary not a factor either. Early activation dynamics different from speech perception or number of words.</p>
<p>Limitations: Change in recorded stimuli. Inclusion of two competitors on every trial.</p>
<!-- Talking points: -->
<!--   - There is hardly an effect of the phonological foil during timepoint 1. There -->
<!--     are a few ways to interpret this finding. The first may be artefactual. The -->
<!--     stimuli were re-recorded at timepoint 2 so the timepoint 1 stimuli were -->
<!--     somewhat longer on average (). -->
<!--     However, with slower stimuli, we would still expect an inflection in looks -->
<!--     to the foil as children have more time to activate the phonological -->
<!--     representations to the cohort. In other words, with more time to respond, -->
<!--     there could plausibly be an even greater effect of early phonological -->
<!--     information. -->
<!--   - Alternatively, the children in timepoint 1 may not be using the early -->
<!--     similarity of words during word recognition. That is, instead of immediate -->
<!--     incremental activation of lexical cohorts, the children may not be -->
<!--     activating the cohorts as reliably. This would imply that further study is -->
<!--     required on the evidence for when young children begin to show immediate -->
<!--     activation of cohorts. -->
</div>
<div id="late-activation-of-semantic-neighbors" class="section level3">
<h3><span class="header-section-number">7.4.2</span> Late activation of semantic neighbors</h3>
<p>The semantic competitors were from the same category as the target noun: for example, <em>bee</em>–<em>fly</em> or <em>shirt</em>–<em>dress</em>. Children also showed year-over-year increases in their sensitivity to the semantic competitor, relative to the unrelated image. Looks the semantic foil peaked late in the trial, around 1300 ms after target onset. This timing is consistent with cascading activation: Spoken words immediately activates phonological neighborhoods with activation then cascading to semantically related words. In this case, children activated the target word (<em>shirt</em>) but also other pieces of clothing (<em>shirt</em>).</p>
<p>Could it instead be the case that the late looks to the semantic foil reflect confusion or uncertainty? After all, these are young children and decisions like <em>bee</em> vs. <em>fly</em> or <em>goat</em> vs. <em>sheep</em> can be difficult.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<p>describe lexical dynamics for semantic foil</p>
<p>describe lack of individual differences at age 3</p>
<!-- Phon looks scraps. -->
<!-- semantic scraps: -->
<!-- The looking patterns---that is, the shapes of the growth curves---were largely the same for each year. The main differences were that the age-3 curve was about 100&nbsp;ms slower to rise than the age-4 curve and that the age-5 curve -->
<!--   - That the effect of the foil increases each year indicates that the -->
<!--     semantic representations of words have strengthened. -->
<!--   - Is inhibition coming online at age 5? -->
<!--   - If children were just confused between bear/horse, fly/bee, -->
<!--     goat/sheep, etc., they should be confused more at younger ages when -->
<!--     they know much less about the world. So if it were confusion or -->
<!--     guess, the semantic foil should be stronger at age 3. But they are -->
<!--     also slower at word recognition in general at younger ages, so maybe -->
<!--     these things cancel each other out? -->
<!-- Talking points : -->
<!-- * I tested whether two child-level features predicted looks to the competitor image at age 3. -->
<!-- * One a priori expectation was that looks to the phonological foil would relate to phonological discrimination ability, because children who can reliably discriminate one-feature phonetic differences between words would have richer phonological or phonetic representations that supported word recognition. -->
<!-- * The other a prior expectation was that looks to semantic foil would relate to looks to the receptive vocabulary. However, neither predicted related to looks the semantic foil. -->
<!-- What's going on here: -->
<!--   - The weak phonological foils are indeed weaker than the strong foils. -->
<!--   - The strong semantic foils appear stronger than the weak ones. The -->
<!--     strong foils show a growth curve pattern of increasing looks away -->
<!--     from baseline and there a developmental difference among the growth -->
<!--     curves for each time point. -->
<!--   - Children have a lower advantage for the target (vs unrelated) in -->
<!--     weak foil trials because... why? My reading is that if the semantic -->
<!--     or phonological foil is effective, children will look at it instead -->
<!--     of the unrelated image. Conversely, if the semantic or phonological -->
<!--     foil are less effective, children will look more to the unrelated -->
<!--     image, which pulls down the ratio of looks to target versus the -->
<!--     unrelated image. -->
<!-- Each curve is the log odds of looking to the target, phonological foil, and -->
<!-- semantic foil versus the unrelated word. Positive values mean more looks to an -->
<!-- image type than the unrelated. If you think of the _y_ axis as the image's -->
<!-- _relatedness_ to the target, you can see a time course of relatedness in each -->
<!-- panel: Here early phonological effects meaning early relatedness and later, -->
<!-- flatter semantic effects meaning late relatedness. (These effects make even more -->
<!-- sense sense if phonological representations affect processing before semantic -->
<!-- ones.) -->
<!-- This plot suggests an important finding: Children becoming more sensitive to the -->
<!-- phonological and semantic foils as they grow older. Jan and I had made -->
<!-- opposite predictions about whether this would happen. Her argument, I think, was -->
<!-- that children become better at word recognition by becoming better able to -->
<!-- inhibit interference from competing words. This plot would suggest that they -->
<!-- show increased sensitive to the target and foils words by looking less to the -->
<!-- unrelated word as they age and reapportioning those looks to the other three -->
<!-- lexically relevant words. -->

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-RWLPaper">
<p>Law, F., II, Mahr, T., Schneeberg, A., &amp; Edwards, J. R. (2016). Vocabulary size and auditory word recognition in preschool children. <em>Applied Psycholinguistics</em>. doi:<a href="https://doi.org/10.1017/S0142716416000126">10.1017/S0142716416000126</a></p>
</div>
<div id="ref-Barr2008">
<p>Barr, D. J. (2008). Analyzing ‘visual world’ eyetracking data using multilevel logistic regression. <em>Journal of Memory and Language</em>, <em>59</em>(4), 457–474. doi:<a href="https://doi.org/10.1016/j.jml.2007.09.002">10.1016/j.jml.2007.09.002</a></p>
</div>
<div id="ref-Soskuthy2017">
<p>Sóskuthy, M. (2017). Generalised additive mixed models for dynamic analysis in linguistics: a practical introduction. Retrieved from <a href="http://arxiv.org/abs/1703.05339" class="uri">http://arxiv.org/abs/1703.05339</a></p>
</div>
<div id="ref-Wood2017">
<p>Wood, S. N. (2017). <em>Generalized additive models: An introduction with R</em> (2nd ed.). CRC Press.</p>
</div>
<div id="ref-itsadug">
<p>van Rij, J., Wieling, M., Baayen, R. H., &amp; van Rijn, H. (2017). itsadug: Interpreting time series and autocorrelated data using GAMMs.</p>
</div>
<div id="ref-Rigler2015">
<p>Rigler, H., Farris-Trimble, A., Greiner, L., Walker, J., Tomblin, J. B., &amp; McMurray, B. (2015). The slow developmental time course of real-time spoken word recognition. <em>Developmental Psychology</em>, <em>51</em>(12), 1690–1703. doi:<a href="https://doi.org/10.1037/dev0000044">10.1037/dev0000044</a></p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Initially, I tried to use Bayesian polynomial growth curve models, as in the earlier analysis of the looks to the target image. These models however did not converge, even when strong priors were placed on the parameters.<a href="effects-of-phonological-and-semantic-competitors.html#fnref3">↩</a></p></li>
<li id="fn4"><p>Anecdote! I was drawn to the general confusion interpretation, partially because I grew up on a farm where we raised sheep. I can remember plenty of people, much older than preschool age, calling the sheep <em>goats</em>. Surely, a bunch of non-rural preschoolers would be in a similar situation, confusing sheep and goats, right? But naming is harder than recognition. I imagine that the goat-mislabellers could point to the right animal if I showed a picture of a goat next to a picture of a sheep.<a href="effects-of-phonological-and-semantic-competitors.html#fnref4">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="analysis-of-familiar-word-recognition.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="general-discussion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["dissertation.pdf"],
"toc": {
"collapse": "subsection"
},
"split_bib": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
