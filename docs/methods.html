<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>My dissertation</title>
  <meta name="description" content="My dissertation">
  <meta name="generator" content="bookdown 0.4.5 and GitBook 2.6.7">

  <meta property="og:title" content="My dissertation" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="tjmahr/dissertation" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="My dissertation" />
  
  
  

<meta name="author" content="Tristan Mahr">


<meta name="date" content="2017-08-18">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="research-hypotheses.html">
<link rel="next" href="outcome-measures.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="assets\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">My dissertation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Development of word recognition in preschoolers</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#updates"><i class="fa fa-check"></i>Updates</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="scratch-paper.html"><a href="scratch-paper.html"><i class="fa fa-check"></i><b>1</b> Scratch paper</a><ul>
<li class="chapter" data-level="1.1" data-path="scratch-paper.html"><a href="scratch-paper.html#bookdown-cheatsheet"><i class="fa fa-check"></i><b>1.1</b> Bookdown cheatsheet</a><ul>
<li class="chapter" data-level="1.1.1" data-path="scratch-paper.html"><a href="scratch-paper.html#manual-section-label-demo"><i class="fa fa-check"></i><b>1.1.1</b> Cross-references to sections</a></li>
<li class="chapter" data-level="1.1.2" data-path="scratch-paper.html"><a href="scratch-paper.html#cross-references-to-appendices"><i class="fa fa-check"></i><b>1.1.2</b> Cross-references to appendices</a></li>
<li class="chapter" data-level="1.1.3" data-path="scratch-paper.html"><a href="scratch-paper.html#cross-references-to-tables"><i class="fa fa-check"></i><b>1.1.3</b> Cross-references to tables</a></li>
<li class="chapter" data-level="1.1.4" data-path="scratch-paper.html"><a href="scratch-paper.html#figure-references-and-using-text-references-as-captions"><i class="fa fa-check"></i><b>1.1.4</b> Figure references and using text references as captions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="scratch-paper.html"><a href="scratch-paper.html#debug-info"><i class="fa fa-check"></i><b>1.2</b> Debug info</a></li>
</ul></li>
<li class="part"><span><b>Prospectus</b></span></li>
<li class="chapter" data-level="2" data-path="front-matter.html"><a href="front-matter.html"><i class="fa fa-check"></i><b>2</b> Front Matter</a><ul>
<li class="chapter" data-level="" data-path="front-matter.html"><a href="front-matter.html#about-this-document"><i class="fa fa-check"></i>About This Document</a></li>
<li class="chapter" data-level="" data-path="front-matter.html"><a href="front-matter.html#dissertation-committee-members"><i class="fa fa-check"></i>Dissertation Committee Members</a></li>
<li class="chapter" data-level="" data-path="front-matter.html"><a href="front-matter.html#planned-dissertation-format"><i class="fa fa-check"></i>Planned Dissertation Format</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="specific-aims.html"><a href="specific-aims.html"><i class="fa fa-check"></i><b>3</b> Specific Aims</a><ul>
<li class="chapter" data-level="3.1" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>3.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="3.2" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>3.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="3.3" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-3-computational-modeling"><i class="fa fa-check"></i><b>3.3</b> Specific Aim 3 (Computational Modeling)</a></li>
<li class="chapter" data-level="3.4" data-path="specific-aims.html"><a href="specific-aims.html#summary"><i class="fa fa-check"></i><b>3.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="significance.html"><a href="significance.html"><i class="fa fa-check"></i><b>4</b> Significance</a><ul>
<li class="chapter" data-level="4.1" data-path="significance.html"><a href="significance.html#public-health-significance"><i class="fa fa-check"></i><b>4.1</b> Public Health Significance</a></li>
<li class="chapter" data-level="4.2" data-path="significance.html"><a href="significance.html#scientific-significance"><i class="fa fa-check"></i><b>4.2</b> Scientific Significance</a><ul>
<li class="chapter" data-level="4.2.1" data-path="significance.html"><a href="significance.html#lexical-processing-dynamics"><i class="fa fa-check"></i><b>4.2.1</b> Lexical Processing Dynamics</a></li>
<li class="chapter" data-level="4.2.2" data-path="significance.html"><a href="significance.html#individual-differences-in-word-recognition"><i class="fa fa-check"></i><b>4.2.2</b> Individual Differences in Word Recognition</a></li>
<li class="chapter" data-level="4.2.3" data-path="significance.html"><a href="significance.html#computational-modeling"><i class="fa fa-check"></i><b>4.2.3</b> Computational Modeling</a></li>
<li class="chapter" data-level="4.2.4" data-path="significance.html"><a href="significance.html#summary-1"><i class="fa fa-check"></i><b>4.2.4</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="research-hypotheses.html"><a href="research-hypotheses.html"><i class="fa fa-check"></i><b>5</b> Research Hypotheses</a><ul>
<li class="chapter" data-level="5.1" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-1-familiar-word-recognition-and-lexical-competition-1"><i class="fa fa-check"></i><b>5.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="5.2" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-2-referent-selection-and-mispronunciations-1"><i class="fa fa-check"></i><b>5.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="5.3" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-3-computational-modeling-1"><i class="fa fa-check"></i><b>5.3</b> Specific Aim 3 (Computational Modeling)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>6</b> Methods</a><ul>
<li class="chapter" data-level="6.1" data-path="methods.html"><a href="methods.html#general-research-design-participants"><i class="fa fa-check"></i><b>6.1</b> General Research Design: Participants</a></li>
<li class="chapter" data-level="6.2" data-path="methods.html"><a href="methods.html#general-eyetracking-procedure"><i class="fa fa-check"></i><b>6.2</b> General Eyetracking Procedure</a><ul>
<li class="chapter" data-level="6.2.1" data-path="methods.html"><a href="methods.html#experiment-administration"><i class="fa fa-check"></i><b>6.2.1</b> Experiment Administration</a></li>
<li class="chapter" data-level="6.2.2" data-path="methods.html"><a href="methods.html#stimuli"><i class="fa fa-check"></i><b>6.2.2</b> Stimuli</a></li>
<li class="chapter" data-level="6.2.3" data-path="methods.html"><a href="methods.html#data-preparation"><i class="fa fa-check"></i><b>6.2.3</b> Data Preparation</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="methods.html"><a href="methods.html#specific-procedure-aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>6.3</b> Specific Procedure: Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="6.4" data-path="methods.html"><a href="methods.html#specific-procedure-aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>6.4</b> Specific Procedure: Aim 2 (Referent Selection and Mispronunciations)</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="outcome-measures.html"><a href="outcome-measures.html"><i class="fa fa-check"></i><b>7</b> Outcome Measures</a><ul>
<li class="chapter" data-level="7.1" data-path="outcome-measures.html"><a href="outcome-measures.html#sample-data"><i class="fa fa-check"></i><b>7.1</b> Sample Data</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="analysis.html"><a href="analysis.html"><i class="fa fa-check"></i><b>8</b> Analysis</a><ul>
<li class="chapter" data-level="8.1" data-path="analysis.html"><a href="analysis.html#growth-curve-analysis"><i class="fa fa-check"></i><b>8.1</b> Growth Curve Analysis</a></li>
<li class="chapter" data-level="8.2" data-path="analysis.html"><a href="analysis.html#aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>8.2</b> Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="8.3" data-path="analysis.html"><a href="analysis.html#aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>8.3</b> Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="8.4" data-path="analysis.html"><a href="analysis.html#aim-3-computational-modeling"><i class="fa fa-check"></i><b>8.4</b> Aim 3 (Computational Modeling)</a><ul>
<li class="chapter" data-level="8.4.1" data-path="analysis.html"><a href="analysis.html#trace-model-architecture"><i class="fa fa-check"></i><b>8.4.1</b> TRACE Model Architecture</a></li>
<li class="chapter" data-level="8.4.2" data-path="analysis.html"><a href="analysis.html#modeling-looking-data"><i class="fa fa-check"></i><b>8.4.2</b> Modeling Looking Data</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="mp-experiment-items.html"><a href="mp-experiment-items.html"><i class="fa fa-check"></i><b>A</b> Items used in the mispronunciation experiment</a></li>
<li class="chapter" data-level="B" data-path="vw-experiment-items.html"><a href="vw-experiment-items.html"><i class="fa fa-check"></i><b>B</b> Items used in the visual world experiment</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Created with bookdown</a></li>
<li><a href="https://tjmahr.github.io/" target="blank">Tristan Mahr</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">My dissertation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="methods" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Methods</h1>
<div id="general-research-design-participants" class="section level2">
<h2><span class="header-section-number">6.1</span> General Research Design: Participants</h2>
<p>Word recognition data and vocabulary data, among other measures, were collected over a three-year longitudinal study (R01DC002932; the Learning to Talk project). Children were 28–39 months-old at Time 1, 39–52 at Time 2, and 51–65 at Time 3. Approximately, 180 children participated at Time 1, 170 at Time 2, and 160 at Time 3. Of these children, approximately 20 were identified by their parents as late talkers. Prospective families were interviewed over telephone before participating in the study, and “children with an individualized education program or any parent-reported visual problems, language problems, or developmental delays were not scheduled for testing” <span class="citation">(Law et al., <a href="#ref-RWLPaper">2016</a>)</span>.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> Recruitment and data collection occurred at two Learning to Talk lab sites—one at the University of Wisconsin–Madison and the other at the University of Minnesota.</p>
<p>Table <a href="methods.html#tab:participant-info">6.1</a> summarizes the cohort of children in each year of testing. The numbers and summary statistics here are approximate, describing children who participated at each year, but whose data may still be excluded from the analyses. Some potential reasons for exclusion include: excessive missing data during eyetracking, experiment or technology error, developmental concerns not identified until later in study, or a failed hearing screening. Final sample sizes will depend on the measures needed for an analysis and the results from data screening checks. For each project aim, I will disclose all measurements and data exclusions following guidelines by the Center for Open Science <span class="citation">(Nosek et al., <a href="#ref-OSF_Statement">2014</a>)</span>.</p>
<table>
<caption><span id="tab:participant-info">Table 6.1: </span> Participant characteristics. Education levels: <em>Low</em>: less than high school, or high school; <em>Middle</em>: trade school, technical or associates degree, some college, or college degree; and <em>High</em>: graduate degree.</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">Year 1</th>
<th align="left">Year 2</th>
<th align="left">Year 3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>N</td>
<td align="left">184</td>
<td align="left">175</td>
<td align="left">160</td>
</tr>
<tr class="even">
<td>Boys, Girls</td>
<td align="left">94, 90</td>
<td align="left">89, 86</td>
<td align="left">82, 78</td>
</tr>
<tr class="odd">
<td>Maternal education: Low, Middle, High</td>
<td align="left">15, 98, 71</td>
<td align="left">12, 92, 71</td>
<td align="left">6, 90, 64</td>
</tr>
<tr class="even">
<td>Dialect: MAE, AAE</td>
<td align="left">171, 13</td>
<td align="left">163, 12</td>
<td align="left">153, 7</td>
</tr>
<tr class="odd">
<td>Parent-identified late talkers</td>
<td align="left">20</td>
<td align="left">19</td>
<td align="left">16</td>
</tr>
<tr class="even">
<td>Age (months): Mean (SD) [Range]</td>
<td align="left">33 (3) [28–39]</td>
<td align="left">45 (4) [39–52]</td>
<td align="left">57 (4) [51–66]</td>
</tr>
<tr class="odd">
<td>EVT-2 standard score: Mean (SD)</td>
<td align="left">115 (18)</td>
<td align="left">118 (16)</td>
<td align="left">118 (14)</td>
</tr>
<tr class="even">
<td>PPVT-4 standard score: Mean (SD)</td>
<td align="left">113 (17)</td>
<td align="left">120 (16)</td>
<td align="left">—</td>
</tr>
<tr class="odd">
<td>GFTA-2 standard score: Mean (SD)</td>
<td align="left">92 (13)</td>
<td align="left">—</td>
<td align="left">91 (13)</td>
</tr>
</tbody>
</table>
</div>
<div id="general-eyetracking-procedure" class="section level2">
<h2><span class="header-section-number">6.2</span> General Eyetracking Procedure</h2>
<p>Two eyetracking experiments were performed each year of the longitudinal study. These experiments followed the same essential procedure: During each trial, photographs of images appeared on a computer screen for a few seconds followed by a prompt to view one of the images (e.g., <em>find the dog</em>). This procedure measures a child’s real-time comprehension of words by capturing how the child’s gaze location changes over time in response to speech.</p>
<div id="experiment-administration" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Experiment Administration</h3>
<p>Children participating in the study were tested over two lab visits (i.e., on different dates). The first portion of each visit involved “watching movies”—that is, performing two blocks of the eyetracking experiments. A play break or hearing screening occurred between the two eyetracking blocks, depending on the visit.</p>
<p>Each eyetracking experiment was administered as a block of trials (24 for the four-image task and 38 for the two-image task). Children received two different blocks of each experiment. The blocks for an experiment differed in trial ordering and other features (see Specific Procedures). Experiment order and block selection were counterbalanced over children and visits. For example, a child might have received Exp. 1 Block A and Exp. 2 Block B on Visit 1 and next received Exp. 2 Block A and Exp. 1 Block B on Visit 2. The purpose of this presentation was to control possible ordering effects where a particular experiment or block benefited from consistently occurring first or second.</p>
<p>Experiments were administered using E-Prime 2.0 and a Tobii T60XL eyetracker which recorded gaze location at a rate of 60 Hz. The experiments were conducted by two examiners, one “behind the scenes” who controlled the computer running the experiment and another “onstage” who guided the child through the experiment. At the beginning of each block, the child was positioned so the child’s eyes were approximately 60 cm from the screen. The examiners calibrated the eyetracker to the child’s eyes using a five-point calibration procedure (center of screen and centers of four screen quadrants). The examiners would repeated this calibration procedure if one of the five calibration points for one of the eyes did not calibrate successfully. During the experiment, the behind-the-scenes examiner monitored the child’s distance from the screen and whether the eyetracker was capturing the child’s gaze. The onstage examiner coached the child to stay fixated on the screen and repositioned the child as needed to ensure the child’s eyes were being tracked. Every six or seven trials in a block of an experiment, the experiment briefly paused with a reinforcing animation or activity. During these breaks, the onstage examiner could reposition the child if necessary before resuming the experiment.</p>
<p>We used a gaze-contingent stimulus presentation. “After 2 s of familiarization time with the images in silence, the experiment paused to verify that the child’s gaze was being tracked. After 300 ms of continuous gaze tracking, the trial advanced. Otherwise, if the gaze could not be verified after 10 s, the trial advanced. This step ensured that for nearly every trial, the gaze was being tracked before playing the carrier phrase, or in other words, that the child was ready to hear the carrier stimuli” (Mahr &amp; Edwards, in revision). During Year 1 and Year 2, an attention-getter (e.g., <em>check it out</em>!) played 1 s following the end of the target noun. These reinforcers were dropped in Year 3 to streamline the experiment for older listeners.</p>
</div>
<div id="stimuli" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Stimuli</h3>
<p>For both experiments, “stimuli were presented in children’s home dialect, either Mainstream American English (MAE) or African American English (AAE). We made an initial guess about what the home dialect was likely to be based on a number of factors, including the recruitment source and the child’s address. For most children, the home dialect was MAE. If we thought the home dialect might be AAE, a native AAE speaker who was a fluent dialect-shifter between AAE and MAE was scheduled for the lab visit, and she confirmed the home dialect by listening to the caregiver interact with the child during the consent procedure at the beginning of the visit” (Mahr &amp; Edwards, in revision). Prompts to view the target image of a trial (e.g., <em>find the girl</em>) used the carrier phrases “find the” and “see the”. These carriers were recording in the frame “find/see the egg” and cross-spliced with the target nouns to minimize coarticulatory cues on the determiner “the”.</p>
<p>The images used in each experiment consisted of color photographs on gray backgrounds. These images were piloted in a preschool classroom to ensure that children consistently used the same label for familiar objects and did not consistently use the same label for novel/unfamiliar objects.</p>
</div>
<div id="data-preparation" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Data Preparation</h3>
<p>Data from both experiments were prepared using the same procedure. “We mapped the gaze <em>x</em>-<em>y</em> coordinates onto the images onscreen. We performed <em>deblinking</em> by interpolating short windows of missing data (up to 150 ms) if the child fixated on the same image before and after a missing data window. In other words, if the gaze did not shift to another image, and if the missing data window was short enough, that window was classified as a blink and interpolated, using the fixated image as the imputed value” (Mahr &amp; Edwards, in revision). Next, we performed trial-level cleaning. “We examined eyetracking data in the 2-s window following the onset of the target word. A trial was considered unreliable if at least 50% of the eyetracking data during the 2-s window was missing. These trials were not reliable because the child did not look at the display for the majority of the analysis window” (Mahr &amp; Edwards, in revision). If more than half of a child’s trials, combined across blocks, were unreliable, that child was excluded from analysis. “Finally, we downsampled our data into 50-ms bins, reducing the eyetracking sampling rate from 60 Hz to 20 Hz. This procedure smoothed out high-frequency noise in the data by pooling together data from adjacent frames” (Mahr &amp; Edwards, in revision).</p>
</div>
</div>
<div id="specific-procedure-aim-1-familiar-word-recognition-and-lexical-competition" class="section level2">
<h2><span class="header-section-number">6.3</span> Specific Procedure: Aim 1 (Familiar Word Recognition and Lexical Competition)</h2>
<p><em>Visual World Paradigm Task.</em> In eyetracking studies with toddlers, two familiar images are usually presented: a target and a distractor. This experiment is a four-image eyetracking task that was designed to provide a more demanding word recognition task for preschoolers. In this procedure, four familiar images are presented onscreen followed by a prompt to view one of the images (e.g., <em>find the bell!</em>). The four images include the target word (e.g., <em>bell</em>), a semantically related word (<em>drum</em>), a phonologically similar word (<em>bee</em>), and an unrelated word (<em>swing</em>).</p>

<div class="figure"><span id="fig:sample-vw-screen"></span>
<img src="misc/rwl-screens/TimePoint1/actual/Block2_17_swing2_bell2_bee2_drum2_UpperRightImage_bell.png" alt="Example display for the target bell with the semantic foil drum, the phonological foil bee, and the unrelated swing." width="100%" />
<p class="caption">
Figure 6.1: Example display for the target <em>bell</em> with the semantic foil <em>drum</em>, the phonological foil <em>bee</em>, and the unrelated <em>swing</em>.
</p>
</div>
</div>
<div id="specific-procedure-aim-2-referent-selection-and-mispronunciations" class="section level2">
<h2><span class="header-section-number">6.4</span> Specific Procedure: Aim 2 (Referent Selection and Mispronunciations)</h2>
<p><em>Mispronunciation Task.</em> This experiment is an adaptation of the mispronunciation detection task by <span class="citation">White and Morgan (<a href="#ref-WhiteMorgan2008">2008</a>)</span> and <span class="citation">Law and Edwards (<a href="#ref-MPPaper">2015</a>)</span>. In this experiment, two images are presented onscreen—a familiar object and an unfamiliar object—and the child hears a prompt to view one of the images. In the <em>correct pronunciation</em> (or <em>real word</em>) and <em>mispronunciation</em> conditions, the child hears either the familiar word (e.g., <em>soup</em>) or a one-feature mispronunciation of the first consonant of the target word ([<em>sh</em>]<em>oup</em>). Importantly, within a block of trials, the child never hears both the correct and mispronounced forms of the word. These conditions are designed to test whether children map mispronunciations to novel words. To encourage fast referent selection, there were also trials in a <em>nonword</em> condition where the label was an unambiguous novel word (e.g., <em>cheem</em> presented with images of a bed and a novel-looking pastry mixer). Each nonword was constructed to match the phonotactic probability of one of the mispronunciations.</p>

<div class="figure"><span id="fig:sample-mp-screen"></span>
<img src="misc/mp-screens/TimePoint1/actual/Block1_03_MP_bull2_duck2_ImageR_guk.png" alt="Example display for a trial in which duck is mispronounced as “guck”." width="100%" />
<p class="caption">
Figure 6.2: Example display for a trial in which <em>duck</em> is mispronounced as “guck”.
</p>
</div>
<p>In a block of trials, there were 12 trials each from the nonword condition, correct production condition, and mispronunciation conditions, and children received two blocks of the experiment. A complete list of the items used in the experiment over the three years of the study is included in <a href="mp-experiment-items.html#mp-experiment-items">Appendix <a href="mp-experiment-items.html#mp-experiment-items">A</a></a>.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-RWLPaper">
<p>Law, F., II, Mahr, T., Schneeberg, A., &amp; Edwards, J. R. (2016). Vocabulary size and auditory word recognition in preschool children. <em>Applied Psycholinguistics</em>. doi:<a href="https://doi.org/10.1017/S0142716416000126">10.1017/S0142716416000126</a></p>
</div>
<div id="ref-OSF_Statement">
<p>Nosek, B. A., Simonsohn, U., Moore, D. A., Nelson, L. D., Simmons, J. P., Sallans, A., &amp; LeBel, E. P. (2014, February). Standard reviewer statement for disclosure of sample, conditions, measures, and exclusions. Open Science Framework. Retrieved from <a href="https://osf.io/hadz3" class="uri">https://osf.io/hadz3</a></p>
</div>
<div id="ref-WhiteMorgan2008">
<p>White, K. S., &amp; Morgan, J. L. (2008). Sub-segmental detail in early lexical representations. <em>Journal of Memory and Language</em>, <em>59</em>(1), 114–132. doi:<a href="https://doi.org/10.1016/j.jml.2008.03.001">10.1016/j.jml.2008.03.001</a></p>
</div>
<div id="ref-MPPaper">
<p>Law, F., II, &amp; Edwards, J. R. (2015). Effects of vocabulary size on online lexical processing by preschoolers. <em>Language Learning and Development</em>, <em>11</em>(4), 331–355. doi:<a href="https://doi.org/10.1080/15475441.2014.961066">10.1080/15475441.2014.961066</a></p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Appendix C (Related Work) describes how this dissertation relates to other work from our lab.<a href="methods.html#fnref1">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="research-hypotheses.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="outcome-measures.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["dissertation.pdf", "dissertation.epub", "dissertation.docx"],
"toc": {
"collapse": "subsection"
},
"split_bib": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
