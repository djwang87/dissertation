<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Development of word recognition in preschoolers</title>
  <meta name="description" content="Development of word recognition in preschoolers">
  <meta name="generator" content="bookdown 0.7.12 and GitBook 2.6.7">

  <meta property="og:title" content="Development of word recognition in preschoolers" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="assets/cover.png" />
  
  <meta name="github-repo" content="tjmahr/dissertation" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Development of word recognition in preschoolers" />
  
  
  <meta name="twitter:image" content="assets/cover.png" />

<meta name="author" content="Tristan Mahr">


<meta name="date" content="2018-08-06">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="real-nonword-selection.html">
<link rel="next" href="aim2-discussion.html">
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="assets\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="dedication.html"><a href="dedication.html"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i># Acknowledgements</a></li>
<li class="chapter" data-level="1" data-path="specific-aims.html"><a href="specific-aims.html"><i class="fa fa-check"></i><b>1</b> Specific aims</a><ul>
<li class="chapter" data-level="1.1" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>1.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="1.2" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>1.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="1.3" data-path="specific-aims.html"><a href="specific-aims.html#summary"><i class="fa fa-check"></i><b>1.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="research-hypotheses.html"><a href="research-hypotheses.html"><i class="fa fa-check"></i><b>2</b> Research hypotheses</a><ul>
<li class="chapter" data-level="2.1" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-1-familiar-word-recognition-and-lexical-competition-1"><i class="fa fa-check"></i><b>2.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="2.2" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-2-referent-selection-and-mispronunciations-1"><i class="fa fa-check"></i><b>2.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
</ul></li>
<li class="part"><span><b>Aim 1: Familiar Word Recognition and Lexical Competition</b></span></li>
<li class="chapter" data-level="3" data-path="aim1-introduction.html"><a href="aim1-introduction.html"><i class="fa fa-check"></i><b>3</b> Familiar word recognition</a><ul>
<li class="chapter" data-level="3.1" data-path="aim1-introduction.html"><a href="aim1-introduction.html#lexical-processing-dynamics"><i class="fa fa-check"></i><b>3.1</b> Lexical processing dynamics</a></li>
<li class="chapter" data-level="3.2" data-path="aim1-introduction.html"><a href="aim1-introduction.html#individual-differences-in-word-recognition"><i class="fa fa-check"></i><b>3.2</b> Individual differences in word recognition</a></li>
<li class="chapter" data-level="3.3" data-path="aim1-introduction.html"><a href="aim1-introduction.html#the-current-study"><i class="fa fa-check"></i><b>3.3</b> The current study</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="aim1-method.html"><a href="aim1-method.html"><i class="fa fa-check"></i><b>4</b> Method</a><ul>
<li class="chapter" data-level="4.1" data-path="aim1-method.html"><a href="aim1-method.html#aim1-participants"><i class="fa fa-check"></i><b>4.1</b> Participants</a></li>
<li class="chapter" data-level="4.2" data-path="aim1-method.html"><a href="aim1-method.html#aim1-procedure"><i class="fa fa-check"></i><b>4.2</b> Visual World Paradigm</a></li>
<li class="chapter" data-level="4.3" data-path="aim1-method.html"><a href="aim1-method.html#experiment-administration"><i class="fa fa-check"></i><b>4.3</b> Experiment administration</a></li>
<li class="chapter" data-level="4.4" data-path="aim1-method.html"><a href="aim1-method.html#stimuli"><i class="fa fa-check"></i><b>4.4</b> Stimuli</a></li>
<li class="chapter" data-level="4.5" data-path="aim1-method.html"><a href="aim1-method.html#data-screening"><i class="fa fa-check"></i><b>4.5</b> Data screening</a></li>
<li class="chapter" data-level="4.6" data-path="aim1-method.html"><a href="aim1-method.html#model-preparation"><i class="fa fa-check"></i><b>4.6</b> Model preparation</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="fam-rec.html"><a href="fam-rec.html"><i class="fa fa-check"></i><b>5</b> Analysis of familiar word recognition</a><ul>
<li class="chapter" data-level="5.1" data-path="fam-rec.html"><a href="fam-rec.html#growth-curve-analysis"><i class="fa fa-check"></i><b>5.1</b> Growth curve analysis</a><ul>
<li class="chapter" data-level="5.1.1" data-path="fam-rec.html"><a href="fam-rec.html#growth-curve-features-as-measures-of-word-recognition-performance"><i class="fa fa-check"></i><b>5.1.1</b> Growth curve features as measures of word recognition performance</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="fam-rec.html"><a href="fam-rec.html#year-over-year-changes-in-word-recognition-performance"><i class="fa fa-check"></i><b>5.2</b> Year over year changes in word recognition performance</a></li>
<li class="chapter" data-level="5.3" data-path="fam-rec.html"><a href="fam-rec.html#exploring-plausible-ranges-of-performance-over-time"><i class="fa fa-check"></i><b>5.3</b> Exploring plausible ranges of performance over time</a></li>
<li class="chapter" data-level="5.4" data-path="fam-rec.html"><a href="fam-rec.html#are-individual-differences-stable-over-time"><i class="fa fa-check"></i><b>5.4</b> Are individual differences stable over time?</a></li>
<li class="chapter" data-level="5.5" data-path="fam-rec.html"><a href="fam-rec.html#predicting-future-vocabulary-size"><i class="fa fa-check"></i><b>5.5</b> Predicting future vocabulary size</a></li>
<li class="chapter" data-level="5.6" data-path="fam-rec.html"><a href="fam-rec.html#discussion"><i class="fa fa-check"></i><b>5.6</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lex-competitors.html"><a href="lex-competitors.html"><i class="fa fa-check"></i><b>6</b> Effects of phonological and semantic competitors</a><ul>
<li class="chapter" data-level="6.1" data-path="lex-competitors.html"><a href="lex-competitors.html#looks-to-the-phonological-competitor"><i class="fa fa-check"></i><b>6.1</b> Looks to the phonological competitor</a></li>
<li class="chapter" data-level="6.2" data-path="lex-competitors.html"><a href="lex-competitors.html#looks-to-the-semantic-competitor"><i class="fa fa-check"></i><b>6.2</b> Looks to the semantic competitor</a></li>
<li class="chapter" data-level="6.3" data-path="lex-competitors.html"><a href="lex-competitors.html#child-level-differences-in-competitor-sensitivity-at-age-3"><i class="fa fa-check"></i><b>6.3</b> Child-level differences in competitor sensitivity at age 3</a></li>
<li class="chapter" data-level="6.4" data-path="lex-competitors.html"><a href="lex-competitors.html#discussion-1"><i class="fa fa-check"></i><b>6.4</b> Discussion</a><ul>
<li class="chapter" data-level="6.4.1" data-path="lex-competitors.html"><a href="lex-competitors.html#immediate-activation-of-phonological-neighbors"><i class="fa fa-check"></i><b>6.4.1</b> Immediate activation of phonological neighbors</a></li>
<li class="chapter" data-level="6.4.2" data-path="lex-competitors.html"><a href="lex-competitors.html#late-activation-of-semantic-neighbors"><i class="fa fa-check"></i><b>6.4.2</b> Late activation of semantic neighbors</a></li>
<li class="chapter" data-level="6.4.3" data-path="lex-competitors.html"><a href="lex-competitors.html#lexical-competitors-and-child-level-predictors"><i class="fa fa-check"></i><b>6.4.3</b> Lexical competitors and child-level predictors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="aim1-discussion.html"><a href="aim1-discussion.html"><i class="fa fa-check"></i><b>7</b> General discussion</a><ul>
<li class="chapter" data-level="7.1" data-path="aim1-discussion.html"><a href="aim1-discussion.html#how-to-improve-word-recognition"><i class="fa fa-check"></i><b>7.1</b> How to improve word recognition</a></li>
<li class="chapter" data-level="7.2" data-path="aim1-discussion.html"><a href="aim1-discussion.html#learn-words-and-learn-connections-between-words"><i class="fa fa-check"></i><b>7.2</b> Learn words and learn connections between words</a></li>
<li class="chapter" data-level="7.3" data-path="aim1-discussion.html"><a href="aim1-discussion.html#individual-differences-are-most-important-at-younger-ages"><i class="fa fa-check"></i><b>7.3</b> Individual differences are most important at younger ages</a></li>
<li class="chapter" data-level="7.4" data-path="aim1-discussion.html"><a href="aim1-discussion.html#limitations-and-implications"><i class="fa fa-check"></i><b>7.4</b> Limitations and implications</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="aim1-h-check.html"><a href="aim1-h-check.html"><i class="fa fa-check"></i><b>8</b> Hypothesis check</a></li>
<li class="part"><span><b>Aim 2: Referent Selection and Mispronunciations</b></span></li>
<li class="chapter" data-level="9" data-path="aim2-introduction.html"><a href="aim2-introduction.html"><i class="fa fa-check"></i><b>9</b> Mispronunciations and referent selection</a><ul>
<li class="chapter" data-level="9.1" data-path="aim2-introduction.html"><a href="aim2-introduction.html#how-phonetically-detailed-are-childrens-words"><i class="fa fa-check"></i><b>9.1</b> How phonetically detailed are children’s words?</a></li>
<li class="chapter" data-level="9.2" data-path="aim2-introduction.html"><a href="aim2-introduction.html#how-to-handle-nonwords"><i class="fa fa-check"></i><b>9.2</b> How to handle nonwords</a></li>
<li class="chapter" data-level="9.3" data-path="aim2-introduction.html"><a href="aim2-introduction.html#the-current-study-1"><i class="fa fa-check"></i><b>9.3</b> The current study</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="aim2-method.html"><a href="aim2-method.html"><i class="fa fa-check"></i><b>10</b> Method</a><ul>
<li class="chapter" data-level="10.1" data-path="aim2-method.html"><a href="aim2-method.html#mispronunciation-task"><i class="fa fa-check"></i><b>10.1</b> Mispronunciation task</a></li>
<li class="chapter" data-level="10.2" data-path="aim2-method.html"><a href="aim2-method.html#visual-stimuli"><i class="fa fa-check"></i><b>10.2</b> Visual stimuli</a></li>
<li class="chapter" data-level="10.3" data-path="aim2-method.html"><a href="aim2-method.html#novel-word-retention-tests"><i class="fa fa-check"></i><b>10.3</b> Novel word retention tests</a></li>
<li class="chapter" data-level="10.4" data-path="aim2-method.html"><a href="aim2-method.html#aim2-screening"><i class="fa fa-check"></i><b>10.4</b> Data screening</a><ul>
<li class="chapter" data-level="10.4.1" data-path="aim2-method.html"><a href="aim2-method.html#classifying-trials-based-on-initial-fixation-location"><i class="fa fa-check"></i><b>10.4.1</b> Classifying trials based on initial fixation location</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="aim2-method.html"><a href="aim2-method.html#model-preparation-1"><i class="fa fa-check"></i><b>10.5</b> Model preparation</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="real-nonword-selection.html"><a href="real-nonword-selection.html"><i class="fa fa-check"></i><b>11</b> Development of referent selection</a><ul>
<li class="chapter" data-level="11.1" data-path="real-nonword-selection.html"><a href="real-nonword-selection.html#nonwords-versus-familiar-words"><i class="fa fa-check"></i><b>11.1</b> Nonwords versus familiar words</a></li>
<li class="chapter" data-level="11.2" data-path="real-nonword-selection.html"><a href="real-nonword-selection.html#does-age-3-referent-selection-better-predict-age-5-vocabulary"><i class="fa fa-check"></i><b>11.2</b> Does age 3 referent selection better predict age 5 vocabulary?</a></li>
<li class="chapter" data-level="11.3" data-path="real-nonword-selection.html"><a href="real-nonword-selection.html#discussion-2"><i class="fa fa-check"></i><b>11.3</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html"><i class="fa fa-check"></i><b>12</b> Sensitivity to mispronunciations</a><ul>
<li class="chapter" data-level="12.1" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#unfamiliar-initial-trials-move-along-now"><i class="fa fa-check"></i><b>12.1</b> Unfamiliar-initial trials: Move along now</a><ul>
<li class="chapter" data-level="12.1.1" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#child-level-predictors"><i class="fa fa-check"></i><b>12.1.1</b> Child-level predictors</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#familiar-initial-trials-should-i-stay-or-should-i-go"><i class="fa fa-check"></i><b>12.2</b> Familiar-initial trials: Should I stay or should I go?</a><ul>
<li class="chapter" data-level="12.2.1" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#child-level-predictors-and-different-listening-behaviors"><i class="fa fa-check"></i><b>12.2.1</b> Child-level predictors and different listening behaviors</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#looking-behaviors-and-word-learning"><i class="fa fa-check"></i><b>12.3</b> Looking behaviors and word learning</a></li>
<li class="chapter" data-level="12.4" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#discussion-3"><i class="fa fa-check"></i><b>12.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="aim2-discussion.html"><a href="aim2-discussion.html"><i class="fa fa-check"></i><b>13</b> General discussion</a><ul>
<li class="chapter" data-level="13.1" data-path="aim2-discussion.html"><a href="aim2-discussion.html#a-lexical-processing-account-of-the-results"><i class="fa fa-check"></i><b>13.1</b> A lexical processing account of the results</a></li>
<li class="chapter" data-level="13.2" data-path="aim2-discussion.html"><a href="aim2-discussion.html#a-nonword-is-just-a-word-you-havent-learned-yet"><i class="fa fa-check"></i><b>13.2</b> A nonword is just a word you haven’t learned yet</a></li>
<li class="chapter" data-level="13.3" data-path="aim2-discussion.html"><a href="aim2-discussion.html#limitations-and-implications-1"><i class="fa fa-check"></i><b>13.3</b> Limitations and implications</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="aim2-h-check.html"><a href="aim2-h-check.html"><i class="fa fa-check"></i><b>14</b> Hypothesis check</a></li>
<li class="part"><span><b>Afterword</b></span></li>
<li class="chapter" data-level="15" data-path="general-discussion-of-both-studies.html"><a href="general-discussion-of-both-studies.html"><i class="fa fa-check"></i><b>15</b> General discussion of both studies</a><ul>
<li class="chapter" data-level="15.1" data-path="general-discussion-of-both-studies.html"><a href="general-discussion-of-both-studies.html#mechanisms-of-word-recognition"><i class="fa fa-check"></i><b>15.1</b> Mechanisms of word recognition</a><ul>
<li class="chapter" data-level="15.1.1" data-path="general-discussion-of-both-studies.html"><a href="general-discussion-of-both-studies.html#open-questions-about-word-recognition-mechanisms"><i class="fa fa-check"></i><b>15.1.1</b> Open questions about word recognition mechanisms</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="general-discussion-of-both-studies.html"><a href="general-discussion-of-both-studies.html#clinical-implications"><i class="fa fa-check"></i><b>15.2</b> Clinical implications</a></li>
<li class="chapter" data-level="15.3" data-path="general-discussion-of-both-studies.html"><a href="general-discussion-of-both-studies.html#contributions"><i class="fa fa-check"></i><b>15.3</b> Contributions</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="vw-experiment-items.html"><a href="vw-experiment-items.html"><i class="fa fa-check"></i><b>A</b> Items used in the visual world experiment</a></li>
<li class="chapter" data-level="B" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html"><i class="fa fa-check"></i><b>B</b> Computational details for Specific Aim 1</a><ul>
<li class="chapter" data-level="B.1" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#growth-curve-analyses"><i class="fa fa-check"></i><b>B.1</b> Growth curve analyses</a></li>
<li class="chapter" data-level="B.2" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#generalized-additive-models"><i class="fa fa-check"></i><b>B.2</b> Generalized additive models</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="mp-experiment-items.html"><a href="mp-experiment-items.html"><i class="fa fa-check"></i><b>C</b> Items used in the mispronunciation experiment</a></li>
<li class="chapter" data-level="D" data-path="aim2-gca-models.html"><a href="aim2-gca-models.html"><i class="fa fa-check"></i><b>D</b> Computational details for Specific Aim 2</a><ul>
<li class="chapter" data-level="D.1" data-path="aim2-gca-models.html"><a href="aim2-gca-models.html#real-words-versus-nonwords-growth-curves"><i class="fa fa-check"></i><b>D.1</b> Real words versus nonwords growth curves</a></li>
<li class="chapter" data-level="D.2" data-path="aim2-gca-models.html"><a href="aim2-gca-models.html#mispronunciation-growth-curves"><i class="fa fa-check"></i><b>D.2</b> Mispronunciation growth curves</a></li>
<li class="chapter" data-level="D.3" data-path="aim2-gca-models.html"><a href="aim2-gca-models.html#item-response-analysis-for-novel-word-retention"><i class="fa fa-check"></i><b>D.3</b> Item-response analysis for novel word retention</a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="aim2-mp-items.html"><a href="aim2-mp-items.html"><i class="fa fa-check"></i><b>E</b> Effects of specific mispronunciations</a></li>
<li class="chapter" data-level="F" data-path="related-work.html"><a href="related-work.html"><i class="fa fa-check"></i><b>F</b> Related work</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Created with bookdown</a></li>
<li><a href="https://tjmahr.github.io/" target="blank">Tristan Mahr</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Development of word recognition in preschoolers</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sensitivity-to-mispronunciations" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> Sensitivity to mispronunciations</h1>
<p>For the mispronunciation trials, there is no correct “target”, as there is for the other conditions. The design of the task allows the child to associate a mispronunciation with an unfamiliar object or with the familiar object with a name that sounds like the mispronunciation. As a result, I analyzed the mispronunciation trials separately for both initial-fixation locations. One analysis handled trials where a child’s gaze started on the familiar object and another analysis handled trials starting on the unfamiliar object. For these models, I fit a Bayesian logistic regression growth curve model that included indicators for Age and Time × Age interactions, as in the model from <a href="fam-rec.html#fam-rec">Chapter <a href="fam-rec.html#fam-rec">5</a></a>. The linear model was therefore:</p>
<p><span class="math display">\[
\small
\begin{align*}
   \text{log-odds}(\mathit{looking}) =\
    &amp;\beta_0 + 
      \beta_1\text{Time}^1 + 
      \beta_2\text{Time}^2 + 
      \beta_3\text{Time}^3\ + 
      &amp;\text{[age 3 curve]} \\
    (&amp;\gamma_{0} + 
      \gamma_{1}\text{Time}^1 + 
      \gamma_{2}\text{Time}^2 +
      \gamma_{3}\text{Time}^3)*\text{Age}\,\text{4}\ + \
      &amp;\text{[age 4 adjustments]} \\
    (&amp;\delta_{0}\!\ + 
      \delta_{1}\text{Time}^1\!\ + 
      \delta_{2}\text{Time}^2\!\ +
      \delta_{3}\text{Time}^3)*\text{Age}\,\text{5} \
      &amp;\text{[age 5 adjustments]} \\
\end{align*}
\normalsize
\]</span></p>
<p>The mixed effects model included by-child and by-child-by-age random effects so that it would capture how a child’s growth curve features may be similar over developmental time (by-child effects) and may differ at each age (by-child-by-age effects). <a href="aim2-gca-models.html#aim2-gca-models">Appendix <a href="aim2-gca-models.html#aim2-gca-models">D</a></a> contains the R code used to fit these models along with a description of the model’s specification/syntax.</p>
<p>For these analyses, I modeled the data from 300 to 1500 ms after target onset. As in the real word vs. nonword analyses, I removed any Age × Child levels if the child’s data had fewer than 4 fixations in a single time bin. As a result, children had to have at least 4 looks to one of the two images in every 50-ms time bin. For the unfamiliar-initial trials, this screening removed 6 children at age 3, 6 at age 4, and 2 at age 5, and for the familiar-initial trials, this screening removed 1, 4, and 0 children at ages 3, 4, and 5, respectively.</p>
<div id="unfamiliar-initial-trials-move-along-now" class="section level2">
<h2><span class="header-section-number">12.1</span> Unfamiliar-initial trials: Move along now</h2>
<p>When preschoolers started on the image of a novel object and heard a mispronunciation, they looked to the familiar image. Figure <a href="sensitivity-to-mispronunciations.html#fig:unfam-initial-mp-trials">12.1</a> shows the average of children’s growth curves along with the 100 model-estimated group averages. The growth curves all cross the .5 threshold, so the children on average looked more to the familiar than the unfamiliar image. Granted, the degree of referent selection is not as strong as that observed for the real words or nonwords. For those conditions, the average growth curve reached a peak of around .77 at age 3, but for the mispronunciations the age-3 peak is around .62. Children also were comparatively slower to process mispronunciations. For the real-word condition, the average age-3 growth curve crosses .5 looking probability around 775 ms after target onset, whereas in the mispronunciation condition, this threshold is crossed at 1000 ms. Children associate the mispronunciation with the familiar object, although they are slower and show greater uncertainty compared to real word trials.</p>

<div class="figure" style="text-align: center"><span id="fig:unfam-initial-mp-trials"></span>
<img src="23-mispronunciations-notebook_files/figure-html/unfam-initial-mp-trials-1.png" alt="Averages of participants’ growth curves in each age. The lines represent 100 posterior predictions of the group average." width="66%" />
<p class="caption">
Figure 12.1: Averages of participants’ growth curves in each age. The lines represent 100 posterior predictions of the group average.
</p>
</div>
<p>Of the growth curve features, developmental changes were only observed for the average probability (intercept) and peak probability features. At age 3, the average proportion of looks to the familiar image was .37 [90% UI: .34, .40]. At age 4, the looking proportion increased by .04 [−.01, .08] to .40 [.37, .44]. This year-over-year change was probably positive, but the the uncertainty interval still includes a change of 0 as a plausible result. Visually, this uncertainty appears in the growth curve plot by how close together the age-3 and age-4 growth curves appear. At age 4, the average proportion of looks increased by .07 [.03, .12] to .48 [.45, .51]. Here, there is more certainty that the year-over-year change was positive, and this result is consistent with the visual separation of the age-5 growth curve from the others. In short, performance was similar for age 3 and age 4 but there was a marked improvement at age 5.</p>
<p>Figure <a href="sensitivity-to-mispronunciations.html#fig:unfam-peaks-by-age">12.2</a> shows participant’s growth curve peaks for each year of the study. The peaks were computed as in other chapters by taking the median of the five highest values on the curve. The average of the participants’ peak looking probabilities followed the same pattern as the average looking probabilities: similar levels at age 3 and age 4 (.63 versus .64) but a clear gain in looking peak probability at age 5 (.69).</p>

<div class="figure" style="text-align: center"><span id="fig:unfam-peaks-by-age"></span>
<img src="23-mispronunciations-notebook_files/figure-html/unfam-peaks-by-age-1.png" alt="Growth curve peaks by age for mispronunciation trials starting on the unfamiliar image." width="50%" />
<p class="caption">
Figure 12.2: Growth curve peaks by age for mispronunciation trials starting on the unfamiliar image.
</p>
</div>
<p>Figure <a href="sensitivity-to-mispronunciations.html#fig:unfam-peaks-by-age">12.2</a> also indicates how most of the children at each age favored the familiar object over the unfamiliar object. The bottom hinge of the boxplots mark the location of the 25th percentile. Therefore, approximately 75% of children at age 3 were on or above the .5 threshold. Unlike the other conditions, very few listeners achieve a peak of looking probability of .99: At age 5, only 3 [1, 5] children reached ceiling performance, compared to approximately 40 for nonwords and 13 for real words.</p>
<p>None of the other growth curve features showed developmental changes. That is, there were no credible year-over-year changes for the linear, quadratic or cubic time components of the growth curve. Although Figure <a href="sensitivity-to-mispronunciations.html#fig:unfam-initial-mp-trials">12.1</a> shows children’s probability of looking to the familiar image increasing more quickly at age 5, this effect cannot be clearly tied to any of the model’s polynomial time features. After 600 ms, the age-5 curve is almost parallel to other curves. This visual feature is consistent with the intercept effect: The curve is higher than the others on average, but it does not show any differences in shape.</p>
<div id="child-level-predictors" class="section level3">
<h3><span class="header-section-number">12.1.1</span> Child-level predictors</h3>
<p>I tested whether child-level measures predicted looking behavior under these conditions. First, I asked if performance on a minimal pair discrimination task at age 3 predicted looking behavior at age 3. The rationale here is the hypothesis that children with better minimal pair discrimination may be especially sensitive to mispronunciations. Proportion of items correct on the task did not correlate with growth curve peaks, <em>r</em> = −.03 [90% UI: −.05, −.01], <em>n</em> = 138, nor with any other growth curve measures.</p>
<p>I also tested whether expressive vocabulary (EVT-2 standard score) predicted performance in this condition. In this case, there were significant effects at age 3 where a higher expressive vocabulary predicted higher peak probabilities and higher average probabilities. These effects, however, were very small. As shown in Figure <a href="sensitivity-to-mispronunciations.html#fig:plot-evt-mp-unfam-peaks">12.3</a>, for example, a 15-point increase in expressive vocabulary predicted an increase of growth curve peak of .03, <em>R</em><sup>2</sup> = .03. Expressive vocabulary did not predict any of the growth curve features at age 4 or at age 5.</p>

<div class="figure" style="text-align: center"><span id="fig:plot-evt-mp-unfam-peaks"></span>
<img src="23-mispronunciations-notebook_files/figure-html/plot-evt-mp-unfam-peaks-1.png" alt="Relationship between expressive vocabulary and growth curve peaks for mispronunciation trials starting on the unfamiliar image. I took 100 draws from the posterior distribution and computed participant’s growth curve peaks for each draw. Points represent the mean and standard error of 100 peaks. Lines represent regressions fit on each draw." width="50%" />
<p class="caption">
Figure 12.3: Relationship between expressive vocabulary and growth curve peaks for mispronunciation trials starting on the unfamiliar image. I took 100 draws from the posterior distribution and computed participant’s growth curve peaks for each draw. Points represent the mean and standard error of 100 peaks. Lines represent regressions fit on each draw.
</p>
</div>
<p><strong>Summary</strong>. When children are looking at the unfamiliar object and hear a mispronunciation, they shift their looks on average to the familiar image that sounds like the mispronunciation. Children are much more uncertain in this condition, compared to the real-word and nonword conditions where the appropriate referent is more obvious. The only developmental changes observed were the increases in average looking probability and peak looking probability at age 5. Finally, there was a small effect of expressive vocabulary on looking probability at age 3, but no other effects of vocabulary were observed. Minimal pair discrimination at age 3 also did not predict looking behavior.</p>
</div>
</div>
<div id="familiar-initial-trials-should-i-stay-or-should-i-go" class="section level2">
<h2><span class="header-section-number">12.2</span> Familiar-initial trials: Should I stay or should I go?</h2>
<p>The preceding results showed that preschoolers associate one-feature onset-mispronunciations with the familiar word that matches the rime of the word. But that was only for trials where children start on the unfamiliar object. I now consider the other situation, where children are fixating on a familiar object and hear a word that immediately mismatches with the name of that familiar object. On the basis of the first segment, children have information that supports switching to another image. But as the rest of the word unfolds, they hear a syllable rime that supports staying.</p>
<p>Figure <a href="sensitivity-to-mispronunciations.html#fig:fam-initial-mp-trials">12.4</a> shows the growth curve averages for trials starting on the familiar image. The looking patterns show a sharp fall towards .5 which is chance-level performance. Behaviorally, children on average move quickly to look at both images equally. They rush into maximum uncertainty, especially at age 4. Patterns are somewhat more restrained at age 5. Here, the average of the growth curves never dips below .5, and in fact, it shows a late rise to .6 looking probability. At this age, children are overall more likely to stay on the familiar object. Finally, at age-3, the curve begins to fall later than the other curves, reflecting a slower change from the starting probability.</p>
<!-- One possible interpretation of this pattern is that the children making  -->
<!-- brief confirmatory looks to the novel image; they checking out -->
<!-- the novel image. But this cannot be right because the growth curve never -->
<!-- dips much below .5 (certainly not below .4). So there is more likely a -->
<!-- mix of behaviors, with children staying put on some trials and -->
<!-- considering the novel object on some trials. -->

<div class="figure" style="text-align: center"><span id="fig:fam-initial-mp-trials"></span>
<img src="23-mispronunciations-notebook_files/figure-html/fam-initial-mp-trials-1.png" alt="Averages of participants’ growth curves in each age. The lines represent 100 posterior predictions of the group average." width="66%" />
<p class="caption">
Figure 12.4: Averages of participants’ growth curves in each age. The lines represent 100 posterior predictions of the group average.
</p>
</div>
<p>In other analyses, growth curves rise and plateau, and age-related effects appear in how quickly the curves rise or the height at which they plateau. In those cases, it is straightforward to interpret how the intercept and linear time effects contribute to the curve’s shape over development. For this model, the curves <em>fall</em> and plateau, and there is not an obvious developmental, year-over-year change among the curves. Thus, more effort is required to interpret the model parameters and how they combine to form the growth curve shape.</p>
<p>Figure <a href="sensitivity-to-mispronunciations.html#fig:mp-fam-gca-features">12.5</a> visualizes how the growth curve features are weighted at each year and how they contribute to the overall growth curve shape. At age 3, the intercept feature, or average proportion of looks to the familiar image, was .68 [90% UI: .65, .71]. The feature is less meaningful in this situation because the curves all start at a high probability which inflates the average value. That said, comparisons remain useful. At age 4, the average probability decreased by .05 [.02, .09] to .63 [.60, .66], and at age 5 the average probability returns to age-3 levels, .68 [.65, .71]. This intercept effect contributes to how the age-4 curve dips below the others and indeed briefly crosses the .5 probability threshold.</p>

<div class="figure" style="text-align: center"><span id="fig:mp-fam-gca-features"></span>
<img src="23-mispronunciations-notebook_files/figure-html/mp-fam-gca-features-1.png" alt="Weighted growth curve features. For the first four panels, the y axes are scaled to the same range. This scaling highlights how the cubic time component contributes less to the overall shape than the other features." width="100%" />
<p class="caption">
Figure 12.5: Weighted growth curve features. For the first four panels, the <em>y</em> axes are scaled to the same range. This scaling highlights how the cubic time component contributes less to the overall shape than the other features.
</p>
</div>
<p>For the linear time feature, the slope becomes flatter year over year, decreasing by 19% [7%, 29%] from age 3 to age 4 and decreasing by 30% [17%, 42%] from age 4 to age 5. For these curves, however, the starting location is the highest value on the curve, so the linear time feature in this case mostly works to set the starting location of the curves. When the features are combined in Figure <a href="sensitivity-to-mispronunciations.html#fig:mp-fam-gca-features">12.5</a>, the age-3 curve, which has the steepest linear time feature, starts at a higher value than the others.</p>
<p>There was a credible change in the quadratic time feature at age 5. One way to think of a positive quadratic trend is like a weight hanging on a string: It pulls and bends the whole curve downwards. At age 5, the quadratic feature is 12% [1%, 22%] smaller than at age 4, meaning that the age-5 curve has slightly less bend downwards. Finally, there were no credible differences in the cubic time feature. Compared to the other features, the cubic trend only a small amount to the overall shape of the curves.</p>
<p>The combination of these effects shows in the final panel of Figure <a href="sensitivity-to-mispronunciations.html#fig:mp-fam-gca-features">12.5</a>. The age-4 curve dips down furthest beneath 0 log-odds (.5 probability)—this is driven by in the intercept feature. The age-5 curve stays above 0 log-odds and eventually starts to rise away from its minimum value, owning to the dampened linear and quadratic features.</p>
<p><strong>Summary</strong>. The shape of the average growth curves changed with each year of the study. Given the interplay of the curve features, I will avoid assigning a developmental interpretation to individual features. There are two main noticeable developmental trends at play however. First, the age-3 curve starts to fall from its baseline probability a little later than the other curves. Second, the age-5 curve stays above .5 probability and starts to rise at the end of the trial. At age 5, children were more likely stay looking at the familiar object than look at both images equally.</p>
<div id="child-level-predictors-and-different-listening-behaviors" class="section level3">
<h3><span class="header-section-number">12.2.1</span> Child-level predictors and different listening behaviors</h3>
<p>In other word recognition analyses, I derived a growth curve “peak” value as a measure of maximum looking probability or minimum word recognition uncertainty. For these trials, I asked whether analogous growth curve “valleys” provided a meaningful feature for looking behavior when children start a trial fixated on the familiar image. This value was defined as the median of the five smallest values of a growth curve. Intuitively, it reflects the maximum degree to which the novel image is considered as a referent for the mispronunciation.</p>
<p>Figure <a href="sensitivity-to-mispronunciations.html#fig:fam-peaks-by-age">12.6</a> shows the posterior means of participants’ growth curve valleys. Note that there is considerable variability at each age, with the 0–1 interval nearly covered at age 4. The median value is closer to .5 at age 5, and this difference is consistent with the growth curve trajectories where the average age 5 curve had did not dip as low as the other curves.</p>

<div class="figure" style="text-align: center"><span id="fig:fam-peaks-by-age"></span>
<img src="23-mispronunciations-notebook_files/figure-html/fam-peaks-by-age-1.png" alt="Growth curve peaks by age for mispronunciation trials starting on the familiar image." width="50%" />
<p class="caption">
Figure 12.6: Growth curve peaks by age for mispronunciation trials starting on the familiar image.
</p>
</div>
<p>The wide range of values for the growth curve valleys suggests that there are a few different listening behaviors that are being averaged over in the above analyses. The valleys above .6, for example, indicate that some children on average stay with the familiar image, and the valleys below .4 indicate children who favor the unfamiliar image.</p>
<p>To explore individual listening behaviors, I visualized children’s individual growth curves based on their growth curve valleys. Within each year, I grouped children into sextiles based on the posterior mean of their valleys and plotted their individual growth curves. Figure <a href="sensitivity-to-mispronunciations.html#fig:age3-valley-curves">12.7</a> shows the results from age 3. The final two bins show children who stayed with the familiar image throughout the mispronunciation trials. The first two bins mostly contain children who switched to the unfamiliar image and stayed there. These are also children whose curves show a pronounced u-shaped trajectory. Specifically, the curves with the highest ending points in the first three bins highlight children with u-shaped trajectories. In these curves, the probability of fixating on the familiar image briefly decreases, as the child considers the other image.</p>

<div class="figure" style="text-align: center"><span id="fig:age3-valley-curves"></span>
<img src="23-mispronunciations-notebook_files/figure-html/age3-valley-curves-1.png" alt="Growth curves for mispronunciations trials starting on the unfamiliar object at age 3. Children were grouped into sextiles based on the posterior mean of their growth curve valleys—that is, the lowest point on the growth curve. Ten lines are drawn per child to visualize uncertainty. Children were assigned colors arbitrarily. On the right side of each panel are “rugs” which mark the valleys in that panel." width="80%" />
<p class="caption">
Figure 12.7: Growth curves for mispronunciations trials starting on the unfamiliar object at age 3. Children were grouped into sextiles based on the posterior mean of their growth curve valleys—that is, the lowest point on the growth curve. Ten lines are drawn per child to visualize uncertainty. Children were assigned colors arbitrarily. On the right side of each panel are “rugs” which mark the valleys in that panel.
</p>
</div>
<p>I asked whether any child-level factors predicted children’s looking behaviors. I first regressed growth curve valleys on EVT-2 standard score. There was a small effect at age 3, <em>R</em><sup>2</sup> = .09, <em>n</em> = 145. A 15-point increase in expressive vocabulary predicted decrease in growth curve valley of .05. At the other ages, the effects are negligibly small, as shown in Figure <a href="sensitivity-to-mispronunciations.html#fig:mp-fam-valley-evt">12.8</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:mp-fam-valley-evt"></span>
<img src="23-mispronunciations-notebook_files/figure-html/mp-fam-valley-evt-1.png" alt="Relationship between expressive vocabulary and growth curve valleys for mispronunciation trials starting on the familiar image. Valleys were computed on 100 draws of the posterior distribution. Points represent the mean and standard error of the valleys. Lines represent the fit of the regression in each draw. Although the slopes of age-4 and age-5 lines are noticeably different from the age-3 one, they cover a tiny amount of the y axis so they represent a negligible effect." width="50%" />
<p class="caption">
Figure 12.8: Relationship between expressive vocabulary and growth curve valleys for mispronunciation trials starting on the familiar image. Valleys were computed on 100 draws of the posterior distribution. Points represent the mean and standard error of the valleys. Lines represent the fit of the regression in each draw. Although the slopes of age-4 and age-5 lines are noticeably different from the age-3 one, they cover a tiny amount of the <em>y</em> axis so they represent a negligible effect.
</p>
</div>
<p>I regressed age-3 valleys onto expressive vocabulary, minimal-pair discrimination accuracy, and their interaction. The two main effects and their interaction were all statistically significant, <em>R</em><sup>2</sup> = .17, <em>n</em> = 139. The effects of vocabulary and minimal-pair discrimination were both negative, so that higher scores on these measures predicted lower growth curve valleys—that is, a greater maximum probability of fixating on the unfamiliar image. For an average participant, a 15-point increase in expressive vocabulary predicted decrease of .03, and an increase of minimal pair accuracy of .1 predicted a decrease in valley of .03. The interaction term, however, was positive, meaning that increasing one of the predictors simultaneously weakens the effect of the other. As one of the predictors increases, it can push the effect of the other closer to zero so that its simple effect is “no longer” statistically significant. In this case, the simple effect of expressive vocabulary was not significant when minimal pair accuracy was .71 or greater (that is, at the 60-percentile or greater). Conversely, the simple effect of minimal pair discrimination accuracy was not significant when expressive vocabulary standard score was 119 or greater (at the 60-percentile or greater). In summary, at age 3, both expressive vocabulary and minimal pair discrimination each predicted greater consideration of the unfamiliar image. But these effects was also redundant so that large changes in one predictor would weaken the effect of the other.</p>
<p>The growth curve valley feature measures the maximum extent to which the novel object is considered as the referent on these trials. But the u-shaped growth curves in Figure <a href="sensitivity-to-mispronunciations.html#fig:age3-valley-curves">12.7</a> suggest another listening response on this task: Confirmatory looks to the unfamiliar object. In these u-shaped curves, a child’s probability of fixating on the familiar object temporarily decreases as the novel object is considered, and the probability rises as that interpretation is rejected. To quantify this tendency, I computed each child’s growth curve on the probability scale and re-estimated the quadratic trends in these curves. Exploratory visualization showed that children with higher values on this quadratic trend were more likely to have a u-shape curve. This feature, however, also favored sigmoid or z-shaped curves that rapidly fell and plateaued. To avoid these kinds of curves, I weighted the quadratic trend using the median of the final five points of the curve. The weighted quadratic feature penalized curves that have a strong quadratic trend but end on a low probability. Figure <a href="sensitivity-to-mispronunciations.html#fig:mp-fam-prop-ot2-bins">12.9</a> shows growth curves of age 5 children binned using this feature. The bottom row of panels illustrates how the u-shaped feature becomes stronger in each bin. The weighted quadratic feature was weakly correlated with the growth curve valleys, <em>r</em> = −.12, and the lack of correlation appears in the figure by how the curves in each panel reach different valleys.</p>

<div class="figure" style="text-align: center"><span id="fig:mp-fam-prop-ot2-bins"></span>
<img src="23-mispronunciations-notebook_files/figure-html/mp-fam-prop-ot2-bins-1.png" alt="Growth curves for mispronunciations trials starting on the unfamiliar object at age 5. Children were grouped into sextiles based on the posterior mean of their curves quadratic trend weighted by the height of the curve in the final time bins. Ten lines are drawn per child to visualize uncertainty. Children were assigned colors arbitrarily." width="80%" />
<p class="caption">
Figure 12.9: Growth curves for mispronunciations trials starting on the unfamiliar object at age 5. Children were grouped into sextiles based on the posterior mean of their curves quadratic trend weighted by the height of the curve in the final time bins. Ten lines are drawn per child to visualize uncertainty. Children were assigned colors arbitrarily.
</p>
</div>
<p>I regressed the u-shaped curve feature onto expressive vocabulary standard score at each age and onto minimal pair discrimination for age 3. There was a tiny yet significant of vocabulary at age 5, <em>R</em><sup>2</sup> = .03, where children with lower vocabularies had a slightly stronger u-shaped trend in their growth curve. This effect, however, is so small as to be negligible. None of the effects were significant.</p>
<p><strong>Summary</strong>. At age 3, children with larger expressive vocabularies or better minimal pair discrimination had lower growth curve valleys—that is, they looked more to the unfamiliar object when they heard a mispronunciation while fixated on an image of the mispronounced word. These two child-level measures significantly interacted so that increasing both measures simultaneously had diminishing returns. I devised a measure of the how u-shaped the growth curves were, but there were not any meaningful effects of vocabulary or expressive vocabulary on this measure.</p>
</div>
</div>
<div id="looking-behaviors-and-word-learning" class="section level2">
<h2><span class="header-section-number">12.3</span> Looking behaviors and word learning</h2>
<p>At age 5, we tested children’s retention of the novel objects paired with the mispronunciations and nonwords. Children saw the two novel objects and heard either the mispronunciation or the nonword, and they had to point to the objects that went with the image. All six nonwords and mispronunciations were tested.</p>
<p>Table <a href="sensitivity-to-mispronunciations.html#tab:mp-norming-table">12.1</a> shows the results for each item. Overall, children performed better on the nonwords than the real words. Children performed decidedly better on the nonwords than the mispronunciations on four of pairs, and performed about equally well on the remaining two (<em>gake</em>-<em>pumm</em>, <em>wice</em>-<em>bape</em>).</p>
<table>
<caption><span id="tab:mp-norming-table">Table 12.1: </span>Results for the item recognition tests.</caption>
<thead>
<tr class="header">
<th align="left">Word Group</th>
<th align="left">Type</th>
<th align="left">Item</th>
<th align="right">Trials Correct</th>
<th align="right">Percent Correct</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">cake</td>
<td align="left">mispronunciation</td>
<td align="left">gake</td>
<td align="right">61 / 107</td>
<td align="right">57% ± 4.8</td>
</tr>
<tr class="even">
<td align="left"> </td>
<td align="left">nonword</td>
<td align="left">pumm</td>
<td align="right">56 / 107</td>
<td align="right">52% ± 4.8</td>
</tr>
<tr class="odd">
<td align="left">duck</td>
<td align="left">mispronunciation</td>
<td align="left">guck</td>
<td align="right">71 / 107</td>
<td align="right">66% ± 4.6</td>
</tr>
<tr class="even">
<td align="left"> </td>
<td align="left">nonword</td>
<td align="left">shan</td>
<td align="right">97 / 107</td>
<td align="right">91% ± 2.8</td>
</tr>
<tr class="odd">
<td align="left">girl</td>
<td align="left">mispronunciation</td>
<td align="left">dirl</td>
<td align="right">71 / 107</td>
<td align="right">66% ± 4.6</td>
</tr>
<tr class="even">
<td align="left"> </td>
<td align="left">nonword</td>
<td align="left">naydge</td>
<td align="right">98 / 107</td>
<td align="right">92% ± 2.7</td>
</tr>
<tr class="odd">
<td align="left">rice</td>
<td align="left">mispronunciation</td>
<td align="left">wice</td>
<td align="right">79 / 107</td>
<td align="right">74% ± 4.2</td>
</tr>
<tr class="even">
<td align="left"> </td>
<td align="left">nonword</td>
<td align="left">bape</td>
<td align="right">80 / 107</td>
<td align="right">75% ± 4.2</td>
</tr>
<tr class="odd">
<td align="left">shoes</td>
<td align="left">mispronunciation</td>
<td align="left">sues</td>
<td align="right">60 / 107</td>
<td align="right">56% ± 4.8</td>
</tr>
<tr class="even">
<td align="left"> </td>
<td align="left">nonword</td>
<td align="left">geeve</td>
<td align="right">90 / 107</td>
<td align="right">84% ± 3.5</td>
</tr>
<tr class="odd">
<td align="left">soup</td>
<td align="left">mispronunciation</td>
<td align="left">shoup</td>
<td align="right">63 / 107</td>
<td align="right">59% ± 4.8</td>
</tr>
<tr class="even">
<td align="left"> </td>
<td align="left">nonword</td>
<td align="left">cheem</td>
<td align="right">93 / 107</td>
<td align="right">87% ± 3.3</td>
</tr>
<tr class="odd">
<td align="left">(all)</td>
<td align="left">mispronunciation</td>
<td align="left"> </td>
<td align="right">405 / 642</td>
<td align="right">63% ± 1.9</td>
</tr>
<tr class="even">
<td align="left"> </td>
<td align="left">nonword</td>
<td align="left"> </td>
<td align="right">514 / 642</td>
<td align="right">80% ± 1.6</td>
</tr>
</tbody>
</table>
<p>I performed an item-response analysis using a mixed-effects logistic regression model. <a href="aim2-gca-models.html#aim2-gca-models">Appendix <a href="aim2-gca-models.html#aim2-gca-models">D</a></a> reports the code used to specify the model. The model included varying intercepts for child, child × item type, item, and word-group. The first two effects capture information about a child’s general ability and their ability on each type of item. The second two effects capture information about an item’s difficulty and difficulty of object-pairs. I also asked whether growth curve peaks predicted novel word recognition accuracy, so I included growth curve peaks from each condition in the model. For the nonwords, I used the age-5 peak proportion of looks to the novel image for trials that started on the familiar object. For the mispronunciations, I used the peak looks to the familiar object on trials that started on the unfamiliar object. I chose those peaks based on the conclusion that children were reliably treating the mispronunciations as imperfect productions of the familiar word. The model included data from 101 children.</p>
<p>The model confirmed that children were much more successful on the nonword trials. For a child with an average mispronunciation peak (.72), the predicted proportion correct on the mispronunciation retention trials was .64 [.49, .76]. A 1-SD (.19) increase in the mispronunciation peak predicted a change in proportion correct of −.05 [−.10, −.01]. Children who looked more to the familiar object on these mispronunciation trials were less successful during the retention trials. For a child with an average peak on the nonword trials (.90), the predicted proportion correct on the nonword retention trials was .82 [90% UI: .70, .89]. A 1-SD increase (.10 to 1.00) in nonword peaks predicted a change in proportion correct of −.01 [−.05, .02]. The uncertainty interval here includes positive and negative values. It is uncertain whether the effect is positive or negative, so I conclude that there was not a reliable effect in the nonword case.</p>
<p>Figure <a href="sensitivity-to-mispronunciations.html#fig:mp-norm-trials-by-peak">12.10</a> visualizes the model results. The difference in height between the two curves reflects the general advantage in the nonword condition. The negative slope for the mispronunciation line captures the effect of growth curve peaks. A change in mispronunciation growth curve peak from .5 to 1 roughly predicts a change from 4/6 to 3/6 mispronunciation items correct. The nonword line hovers around 5/6 items correct: There is not enough information in the peaks or in the number of retention trials for a reliable effect to emerge.</p>

<div class="figure" style="text-align: center"><span id="fig:mp-norm-trials-by-peak"></span>
<img src="23-mispronunciations-notebook_files/figure-html/mp-norm-trials-by-peak-1.png" alt="Effect of growth curve peaks on children’s accuracy on retention trials. For the mispronunciations, I used the peak looks to the familiar image on trials where the child started on the unfamiliar image, so it represents, say, how much a child looked at shoes given “suze”. Thus, more permissive listeners looked performed more poorly on the retention trials. For the nonwords, I used the peak look to the unfamiliar image on trials where the child started on the familiar image. Points were jittered by 1% to avoid overplotting. There were six trials per condition which is why the points fall into 6 bands." width="66%" />
<p class="caption">
Figure 12.10: Effect of growth curve peaks on children’s accuracy on retention trials. For the mispronunciations, I used the peak looks to the familiar image on trials where the child started on the unfamiliar image, so it represents, say, how much a child looked at <em>shoes</em> given “suze”. Thus, more permissive listeners looked performed more poorly on the retention trials. For the nonwords, I used the peak look to the unfamiliar image on trials where the child started on the familiar image. Points were jittered by 1% to avoid overplotting. There were six trials per condition which is why the points fall into 6 bands.
</p>
</div>
<p><strong>Summary</strong>. When 5-years-olds were tested on their retention of the unfamiliar images used on the mispronunciations and nonword trials, children were much more accurate for the nonwords than the mispronunciations. Children’s accuracy on the mispronunciations was related to their looking behaviors: Children looked more to the familiar image during mispronunciation trials had a lower accuracy on the mispronunciation retention trials.</p>
</div>
<div id="discussion-3" class="section level2">
<h2><span class="header-section-number">12.4</span> Discussion</h2>
<p>In the lab, when preschoolers are looking at a novel object and hear the name of a different familiar object, albeit mispronounced, they look to the familiar object. Children do this reliably at age 3 and even more reliably at age 5. Thus, children recognized these mispronunciations as productions of familiar words, but this recognition was not without a penalty. They looked much less to the familiar object under these conditions, compared to trials where they hear a correct production of the familiar object—see Figure <a href="sensitivity-to-mispronunciations.html#fig:mp-vs-real-peaks">12.11</a>–or when they hear a nonword in a context that supports fast-referent selection. Therefore, preschoolers are unquestionably sensitive to mispronunciations of familiar words, as they show more uncertainty when hearing a mispronunciation.</p>

<div class="figure" style="text-align: center"><span id="fig:mp-vs-real-peaks"></span>
<img src="23-mispronunciations-notebook_files/figure-html/mp-vs-real-peaks-1.png" alt="Comparison of growth curve peaks for the real words and mispronunciations." width="50%" />
<p class="caption">
Figure 12.11: Comparison of growth curve peaks for the real words and mispronunciations.
</p>
</div>
<p>Child-level measures generally did not predict how well children tolerated mispronunciations. There was a very small effect of expressive vocabulary at age 3 such that children with larger vocabularies looked more the familiar image on these trials. Although children differed in their tendency to look to a familiar image when given a mispronunciation, these differences could not be pinned to any child-level measures.</p>
<p>I also analyzed trials where children started on the familiar word and heard a mispronunciation. In this situation, there is no one clear strategy for referent selection, and children exhibit a few different patterns. Some listeners stay with the familiar image. Some reliably switch to the novel image. Some look at both equally. On average, the growth curve averages rush to .5—equal looking to both images and maximum uncertainty. At age 5, the curve does not reach quite as far down as the other curves, so they never fall into attain this degree of uncertainty. These sets of analyses mainly demonstrate that when children start on a familiar image and hear a mispronunciation, they have a few options for how to proceed.</p>
<p>Child-level predictors only were predictive at age 3 for curve valley. In this case, children with larger vocabularies or better minimal pair discrimination showed more consideration of the nonword object. I speculate that in this situation, the effect reflects that children with better abilities in these areas were more sensitive to the mispronunciation. These children were better at recognizing the mismatch from partial information and thus allocated more credibility to the alternative image.</p>
<p>One strategy to resolve the uncertainty in this situation would be to verify and reject the other image. Therefore, I also defined a weighted quadratic growth curve feature that measured how u-shaped the curves were. Such curves would reflect a child temporarily decreasing looks to the familiar image as a confirmatory looking behavior. The u-shaped curve features were not reliably related to any child-level factors, outside of negligibly small effect of expressive vocabulary at age 5.</p>
<p>Children demonstrated different looking behaviors based on their initial fixation location. For unfamiliar-initial trials, the growth curves show a reliable shift to the familiar image and we infer that the children treat the mispronunciation as passable production of the familiar word. For the familiar-initial trials, the children show much more uncertainty and a reliable advantage for the familiar word only begins to appear by age 5.</p>
<p>What are children doing in this situation? I initially thought that some children might “be finished” with the trial when they hear the word. That is, the child fixates on the familiar word, hears the mispronunciation prompt, and notice that they have found the image, and then look other parts of the screen. The problem with this possibility is that it does not happen in other conditions. For the nonword and real word conditions, when children start on the named image, they stick with the target. The average empirical growth curves in Figure <a href="aim2-method.html#fig:aim2-real-word-spaghetti">10.2</a> and Figure <a href="aim2-method.html#fig:aim2-nonword-spaghetti">10.3</a> tend to stay around 70–80% looking to the target image. Rather than reflecting disengagement from the task, the looking patterns indicate increased uncertainty in these trials.</p>
<p>Another possibility is that children show increased uncertainty because the mispronunciation effect is greater when the child is fixating on the familiar word. That is, children fixated on the familiar image might internally name the object and have built up the word’s resting activation. The mispronunciation directly conflicts with the child’s pre-naming expectations for the word’s name, thus inducing more uncertainty after the word is named. For the unfamiliar-initial trials, on the other hand, a child’s attention is on the novel object and they have a less potent expectation about the words they might hear.</p>
<p>Visual attention did seem to influence how children retained information from the mispronunciation trials. At age 5, we tested children’s retention of the mispronunciations and nonwords. Children were much more likely to recall which unfamiliar object appeared on the nonword trials than the mispronunciation trials. This difference is not unexpected. In the nonword trials, children looked to an unfamiliar object when given an unambiguous novel word for a label. Thus, each trial worked to build an association between a new word and an unfamiliar object. But children generally treated the mispronunciations as productions of the familiar words. For the unfamiliar-initial trials, they looked more to the familiar object, a result that held at all three ages. Rather than developing a new object-label mapping, children are working on resolving an ambiguous and uncertain production on these trials. This idea is consistent with the effect of growth curve peaks on retention accuracy: Child who looked less to the unfamiliar object on mispronunciation trials were less likely to recall that unfamiliar object during retention testing.</p>

</div>
</div>
<script type="text/javascript">
  $("div.page-wrapper > h3").appendTo(".page-inner > section");
  $("div.page-wrapper > #refs").appendTo(".page-inner > section");
  $("div.page-wrapper > .footnotes").appendTo(".page-inner > section");
  $("div.body-inner > h3").appendTo(".page-inner > section");
  $("div.body-inner > #refs").appendTo(".page-inner > section");
  $("div.body-inner > .footnotes").appendTo(".page-inner > section");
</script>
            </section>

          </div>
        </div>
      </div>
<a href="real-nonword-selection.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="aim2-discussion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"split_bib": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
