<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Development of word recognition in preschoolers</title>
  <meta name="description" content="Development of word recognition in preschoolers">
  <meta name="generator" content="bookdown 0.7.12 and GitBook 2.6.7">

  <meta property="og:title" content="Development of word recognition in preschoolers" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="assets/cover.png" />
  
  <meta name="github-repo" content="tjmahr/dissertation" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Development of word recognition in preschoolers" />
  
  
  <meta name="twitter:image" content="assets/cover.png" />

<meta name="author" content="Tristan Mahr">


<meta name="date" content="2018-07-15">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="development-of-referent-selection.html">
<link rel="next" href="vw-experiment-items.html">
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="assets\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="part"><span><b>Prospectus</b></span></li>
<li class="chapter" data-level="1" data-path="dissertation-information.html"><a href="dissertation-information.html"><i class="fa fa-check"></i><b>1</b> Dissertation information</a><ul>
<li class="chapter" data-level="" data-path="dissertation-information.html"><a href="dissertation-information.html#committee-members"><i class="fa fa-check"></i>Committee Members</a></li>
<li class="chapter" data-level="" data-path="dissertation-information.html"><a href="dissertation-information.html#planned-dissertation-format"><i class="fa fa-check"></i>Planned Dissertation Format</a></li>
<li class="chapter" data-level="" data-path="dissertation-information.html"><a href="dissertation-information.html#miscellany"><i class="fa fa-check"></i>Miscellany</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="specific-aims.html"><a href="specific-aims.html"><i class="fa fa-check"></i><b>2</b> Specific aims</a><ul>
<li class="chapter" data-level="2.1" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>2.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="2.2" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>2.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="2.3" data-path="specific-aims.html"><a href="specific-aims.html#summary"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="research-hypotheses.html"><a href="research-hypotheses.html"><i class="fa fa-check"></i><b>3</b> Research hypotheses</a><ul>
<li class="chapter" data-level="3.1" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-1-familiar-word-recognition-and-lexical-competition-1"><i class="fa fa-check"></i><b>3.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="3.2" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-2-referent-selection-and-mispronunciations-1"><i class="fa fa-check"></i><b>3.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
</ul></li>
<li class="part"><span><b>Aim 1: Familiar Word Recognition and Lexical Competition</b></span></li>
<li class="chapter" data-level="4" data-path="aim1-introduction.html"><a href="aim1-introduction.html"><i class="fa fa-check"></i><b>4</b> Familiar word recognition</a><ul>
<li class="chapter" data-level="4.1" data-path="aim1-introduction.html"><a href="aim1-introduction.html#lexical-processing-dynamics"><i class="fa fa-check"></i><b>4.1</b> Lexical processing dynamics</a></li>
<li class="chapter" data-level="4.2" data-path="aim1-introduction.html"><a href="aim1-introduction.html#individual-differences-in-word-recognition"><i class="fa fa-check"></i><b>4.2</b> Individual differences in word recognition</a></li>
<li class="chapter" data-level="4.3" data-path="aim1-introduction.html"><a href="aim1-introduction.html#the-current-study"><i class="fa fa-check"></i><b>4.3</b> The current study</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="aim1-method.html"><a href="aim1-method.html"><i class="fa fa-check"></i><b>5</b> Method</a><ul>
<li class="chapter" data-level="5.1" data-path="aim1-method.html"><a href="aim1-method.html#aim1-participants"><i class="fa fa-check"></i><b>5.1</b> Participants</a></li>
<li class="chapter" data-level="5.2" data-path="aim1-method.html"><a href="aim1-method.html#aim1-procedure"><i class="fa fa-check"></i><b>5.2</b> Visual World Paradigm</a></li>
<li class="chapter" data-level="5.3" data-path="aim1-method.html"><a href="aim1-method.html#experiment-administration"><i class="fa fa-check"></i><b>5.3</b> Experiment administration</a></li>
<li class="chapter" data-level="5.4" data-path="aim1-method.html"><a href="aim1-method.html#stimuli"><i class="fa fa-check"></i><b>5.4</b> Stimuli</a></li>
<li class="chapter" data-level="5.5" data-path="aim1-method.html"><a href="aim1-method.html#data-screening"><i class="fa fa-check"></i><b>5.5</b> Data screening</a></li>
<li class="chapter" data-level="5.6" data-path="aim1-method.html"><a href="aim1-method.html#model-preparation"><i class="fa fa-check"></i><b>5.6</b> Model preparation</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="fam-rec.html"><a href="fam-rec.html"><i class="fa fa-check"></i><b>6</b> Analysis of familiar word recognition</a><ul>
<li class="chapter" data-level="6.1" data-path="fam-rec.html"><a href="fam-rec.html#growth-curve-analysis"><i class="fa fa-check"></i><b>6.1</b> Growth curve analysis</a><ul>
<li class="chapter" data-level="6.1.1" data-path="fam-rec.html"><a href="fam-rec.html#growth-curve-features-as-measures-of-word-recognition-performance"><i class="fa fa-check"></i><b>6.1.1</b> Growth curve features as measures of word recognition performance</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="fam-rec.html"><a href="fam-rec.html#year-over-year-changes-in-word-recognition-performance"><i class="fa fa-check"></i><b>6.2</b> Year over year changes in word recognition performance</a></li>
<li class="chapter" data-level="6.3" data-path="fam-rec.html"><a href="fam-rec.html#exploring-plausible-ranges-of-performance-over-time"><i class="fa fa-check"></i><b>6.3</b> Exploring plausible ranges of performance over time</a></li>
<li class="chapter" data-level="6.4" data-path="fam-rec.html"><a href="fam-rec.html#are-individual-differences-stable-over-time"><i class="fa fa-check"></i><b>6.4</b> Are individual differences stable over time?</a></li>
<li class="chapter" data-level="6.5" data-path="fam-rec.html"><a href="fam-rec.html#predicting-future-vocabulary-size"><i class="fa fa-check"></i><b>6.5</b> Predicting future vocabulary size</a></li>
<li class="chapter" data-level="6.6" data-path="fam-rec.html"><a href="fam-rec.html#discussion"><i class="fa fa-check"></i><b>6.6</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lex-competitors.html"><a href="lex-competitors.html"><i class="fa fa-check"></i><b>7</b> Effects of phonological and semantic competitors</a><ul>
<li class="chapter" data-level="7.1" data-path="lex-competitors.html"><a href="lex-competitors.html#looks-to-the-phonological-competitor"><i class="fa fa-check"></i><b>7.1</b> Looks to the phonological competitor</a></li>
<li class="chapter" data-level="7.2" data-path="lex-competitors.html"><a href="lex-competitors.html#looks-to-the-semantic-competitor"><i class="fa fa-check"></i><b>7.2</b> Looks to the semantic competitor</a></li>
<li class="chapter" data-level="7.3" data-path="lex-competitors.html"><a href="lex-competitors.html#child-level-differences-in-competitor-sensitivity-at-age-3"><i class="fa fa-check"></i><b>7.3</b> Child-level differences in competitor sensitivity at age 3</a></li>
<li class="chapter" data-level="7.4" data-path="lex-competitors.html"><a href="lex-competitors.html#discussion-1"><i class="fa fa-check"></i><b>7.4</b> Discussion</a><ul>
<li class="chapter" data-level="7.4.1" data-path="lex-competitors.html"><a href="lex-competitors.html#immediate-activation-of-phonological-neighbors"><i class="fa fa-check"></i><b>7.4.1</b> Immediate activation of phonological neighbors</a></li>
<li class="chapter" data-level="7.4.2" data-path="lex-competitors.html"><a href="lex-competitors.html#late-activation-of-semantic-neighbors"><i class="fa fa-check"></i><b>7.4.2</b> Late activation of semantic neighbors</a></li>
<li class="chapter" data-level="7.4.3" data-path="lex-competitors.html"><a href="lex-competitors.html#lexical-competitors-and-child-level-predictors"><i class="fa fa-check"></i><b>7.4.3</b> Lexical competitors and child-level predictors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="aim1-discussion.html"><a href="aim1-discussion.html"><i class="fa fa-check"></i><b>8</b> General discussion</a><ul>
<li class="chapter" data-level="8.1" data-path="aim1-discussion.html"><a href="aim1-discussion.html#how-to-improve-word-recognition"><i class="fa fa-check"></i><b>8.1</b> How to improve word recognition</a></li>
<li class="chapter" data-level="8.2" data-path="aim1-discussion.html"><a href="aim1-discussion.html#learn-words-and-learn-connections-between-words"><i class="fa fa-check"></i><b>8.2</b> Learn words and learn connections between words</a></li>
<li class="chapter" data-level="8.3" data-path="aim1-discussion.html"><a href="aim1-discussion.html#individual-differences-are-most-important-at-younger-ages"><i class="fa fa-check"></i><b>8.3</b> Individual differences are most important at younger ages</a></li>
<li class="chapter" data-level="8.4" data-path="aim1-discussion.html"><a href="aim1-discussion.html#limitations-and-implications"><i class="fa fa-check"></i><b>8.4</b> Limitations and implications</a></li>
</ul></li>
<li class="part"><span><b>Aim 2: Referent Selection and Mispronunciations</b></span></li>
<li class="chapter" data-level="9" data-path="aim2-method.html"><a href="aim2-method.html"><i class="fa fa-check"></i><b>9</b> Method</a><ul>
<li class="chapter" data-level="9.1" data-path="aim2-method.html"><a href="aim2-method.html#mispronunciation-task"><i class="fa fa-check"></i><b>9.1</b> Mispronunciation task</a></li>
<li class="chapter" data-level="9.2" data-path="aim2-method.html"><a href="aim2-method.html#visual-stimuli"><i class="fa fa-check"></i><b>9.2</b> Visual stimuli</a></li>
<li class="chapter" data-level="9.3" data-path="aim2-method.html"><a href="aim2-method.html#aim2-screening"><i class="fa fa-check"></i><b>9.3</b> Data screening</a><ul>
<li class="chapter" data-level="9.3.1" data-path="aim2-method.html"><a href="aim2-method.html#classifying-trials-based-on-initial-fixation-location"><i class="fa fa-check"></i><b>9.3.1</b> Classifying trials based on initial fixation location</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="aim2-method.html"><a href="aim2-method.html#model-preparation-1"><i class="fa fa-check"></i><b>9.4</b> Model preparation</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="development-of-referent-selection.html"><a href="development-of-referent-selection.html"><i class="fa fa-check"></i><b>10</b> Development of referent selection</a><ul>
<li class="chapter" data-level="10.1" data-path="development-of-referent-selection.html"><a href="development-of-referent-selection.html#nonwords-versus-familiar-words"><i class="fa fa-check"></i><b>10.1</b> Nonwords versus familiar words</a></li>
<li class="chapter" data-level="10.2" data-path="development-of-referent-selection.html"><a href="development-of-referent-selection.html#does-age-3-referent-selection-better-predicts-age-5-vocabulary"><i class="fa fa-check"></i><b>10.2</b> Does age 3 referent selection better predicts age 5 vocabulary?</a><ul>
<li class="chapter" data-level="10.2.1" data-path="development-of-referent-selection.html"><a href="development-of-referent-selection.html#points-for-discussion"><i class="fa fa-check"></i><b>10.2.1</b> Points for discussion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html"><i class="fa fa-check"></i><b>11</b> Sensitivity to mispronunciations</a><ul>
<li class="chapter" data-level="11.1" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#unfamiliar-initial-trials"><i class="fa fa-check"></i><b>11.1</b> Unfamiliar-initial trials</a></li>
<li class="chapter" data-level="11.2" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#familiar-initial-trials-should-i-stay-or-should-i-go"><i class="fa fa-check"></i><b>11.2</b> Familiar-initial trials: Should I stay or should I go?</a><ul>
<li class="chapter" data-level="11.2.1" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#quantifying-looking-behaviors"><i class="fa fa-check"></i><b>11.2.1</b> Quantifying looking behaviors</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#discussion-2"><i class="fa fa-check"></i><b>11.3</b> Discussion</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="vw-experiment-items.html"><a href="vw-experiment-items.html"><i class="fa fa-check"></i><b>A</b> Items used in the visual world experiment</a></li>
<li class="chapter" data-level="B" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html"><i class="fa fa-check"></i><b>B</b> Computational details for Specific Aim 1</a><ul>
<li class="chapter" data-level="B.1" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#growth-curve-analyses"><i class="fa fa-check"></i><b>B.1</b> Growth curve analyses</a></li>
<li class="chapter" data-level="B.2" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#generalized-additive-models"><i class="fa fa-check"></i><b>B.2</b> Generalized additive models</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="mp-experiment-items.html"><a href="mp-experiment-items.html"><i class="fa fa-check"></i><b>C</b> Items used in the mispronunciation experiment</a></li>
<li class="chapter" data-level="D" data-path="aim2-gca-models.html"><a href="aim2-gca-models.html"><i class="fa fa-check"></i><b>D</b> Computational details for Specific Aim 2</a><ul>
<li class="chapter" data-level="D.1" data-path="aim2-gca-models.html"><a href="aim2-gca-models.html#growth-curve-analyses-1"><i class="fa fa-check"></i><b>D.1</b> Growth curve analyses</a><ul>
<li class="chapter" data-level="D.1.1" data-path="aim2-gca-models.html"><a href="aim2-gca-models.html#model-summaries"><i class="fa fa-check"></i><b>D.1.1</b> Model summaries</a></li>
<li class="chapter" data-level="D.1.2" data-path="aim2-gca-models.html"><a href="aim2-gca-models.html#real-words-versus-nonwords-at-age-3"><i class="fa fa-check"></i><b>D.1.2</b> Real words versus nonwords at age 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="E" data-path="related-work.html"><a href="related-work.html"><i class="fa fa-check"></i><b>E</b> Related work</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Created with bookdown</a></li>
<li><a href="https://tjmahr.github.io/" target="blank">Tristan Mahr</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Development of word recognition in preschoolers</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sensitivity-to-mispronunciations" class="section level1">
<h1><span class="header-section-number">Chapter 11</span> Sensitivity to mispronunciations</h1>
<ul>
<li>[x] update p1 code to work on new peak dataframes</li>
<li>[x] make a p1 code chunk that verifies no relationship between gca features and minp/evt</li>
<li>[x] update p2 code to work on new peak dataframes</li>
<li>[x] report evt x minp interaction for valleys</li>
<li>[x] describe and plot quadratic effect</li>
<li>[x] report evt and minp effects for quadratic effects</li>
</ul>
<p>For the mispronunciation trials, there is no correct “target”, as there is for real word or nonword trials. The design of the task allows the child to associate the mispronunciation with a unfamiliar object or with a familiar object with phonologically similar name. As a result, there are not any “distractor-initial” trials, so I analyzed the mispronunciation trials separately for both initial-fixation locations. One model handled trials where a child’s gaze started on the familiar object and another model handled trials starting on the unfamiliar object. For these models, I fit a growth curve model that included indicators for Age and Time × Age interactions, as in the model from <a href="fam-rec.html#fam-rec">Chapter <a href="fam-rec.html#fam-rec">6</a></a>. The basic model was therefore:</p>
<p><span class="math display">\[
\small
\begin{align*}
   \text{log-odds}(\mathit{looking\,}) =\
    &amp;\beta_0 + 
      \beta_1\text{Time}^1 + 
      \beta_2\text{Time}^2 + 
      \beta_3\text{Time}^3\ + 
      &amp;\text{[age 3 growth curve]} \\
    (&amp;\gamma_{0} + 
      \gamma_{1}\text{Time}^1 + 
      \gamma_{2}\text{Time}^2 +
      \gamma_{3}\text{Time}^3)*\text{Age}\,\text{4} + \
      &amp;\text{[adjustments for age 4]} \\
    (&amp;\delta_{0}\!\ + 
      \delta_{1}\text{Time}^1\!\ + 
      \delta_{2}\text{Time}^2\!\ +
      \delta_{3}\text{Time}^3)*\text{Age}\,\text{5} \
      &amp;\text{[adjustments for age 5]} \\
\end{align*}
\]</span></p>
<p><a href="aim2-gca-models.html#aim2-gca-models">Appendix <a href="aim2-gca-models.html#aim2-gca-models">D</a></a> contains the R code used to fit these models along with a description of the specifications represented by the model syntax. The mixed effects model included by-child and by-child-by-age random effects so that it could capture how a child’s growth curve features may be similar over developmental time (by-child effects) and may differ at each age (by-child-by-age effects).</p>
<p>For these analyses, I modeled the data from 300 to 1500 ms after target onset. As in the real word vs. nonword analyses, I removed any Age × Child levels if the child’s data had fewer than 4 fixations in a single time bin. As a result, children had to have at least 4 looks to one of the two images in every 50 ms time bin. For the familiar-initial trials, this screening removed 1 child at age 3, 4 at age 4, and 0 at age 5, and for the unfamiliar-initial trials, this screening removed 6, 6, and 2 children at ages 3, 4, and 5, respectively.</p>
<div id="unfamiliar-initial-trials" class="section level2">
<h2><span class="header-section-number">11.1</span> Unfamiliar-initial trials</h2>
<p>When children start on the image of a novel object and hear a mispronunciation, they look to the familiar image. Figure <a href="sensitivity-to-mispronunciations.html#fig:unfam-initial-mp-trials">11.1</a> shows the average of children’s growth curves along with the 100 model-estimated group averages. The growth curves all cross the .5 threshold, so that the children on average looked more to the familiar than the unfamiliar image. Granted, the degree of referent selection is not as great as that observed for the real words or nonwords. For those conditions, the average growth curves reached a peak of around .77 at age 3 whereas for the mispronunciations the age-3 peak is around .62. Children were slower to process mispronunciations. For the real-word condition, the average age 3 growth curve crosses .5 looking probability around 775 ms after target onset whereas in the mispronunciation condition, this threshold is crossed at 1000 ms. Children associate the mispronunciation with the familiar object, although they are slower and show greater uncertainty compared to real word trials.</p>

<div class="figure" style="text-align: center"><span id="fig:unfam-initial-mp-trials"></span>
<img src="23-mispronunciations-notebook_files/figure-html/unfam-initial-mp-trials-1.png" alt="Averages of participants’ growth curves in each age. The lines represent 100 posterior predictions of the group average." width="66%" />
<p class="caption">
Figure 11.1: Averages of participants’ growth curves in each age. The lines represent 100 posterior predictions of the group average.
</p>
</div>
<p>Of the growth curve features, developmental changes were only observed for the average probability (intercept) and peak probability features. At age 3, the average proportion of looks to the familiar image was .37 [90% UI: .34, .40]. The looking proportion increased by .04 [−.01, .08] to .40 [.37, .44] at age 4. This year-over-year change is probably positive, but a change of 0 is still a plausible result. Visually, this uncertainty appears in the growth curve plot by how close together the age-3 and age-4 growth curves appear. The average proportion of looks increased by .07 [.03, .12] to .48 [.45, .51] at age 5. Here, there is more certainty that the year-over-year change was positive. In short, performance was similar for age 3 and age 4 but there was a marked improvement at age 5.</p>
<p>Figure <a href="sensitivity-to-mispronunciations.html#fig:unfam-peaks-by-age">11.2</a> shows participant’s growth curve peaks for each year of the study. There were computed as in other chapters by taking the median of the five highest values on a growth curve. The average of the participants’ growth curve peaks followed the same pattern as the intercept: similar levels at age 3 and age 4 (.63 versus .64) but a clear gain in looking peak probability at age 5 (.69). The bottom hinge of the boxplots in Figure <a href="sensitivity-to-mispronunciations.html#fig:unfam-peaks-by-age">11.2</a> mark the location of the 25th percentile. Thus, at age 3, approximately 75% of children were at or above the .5 threshold. Unlike the nonword conditions, very few listeners achieve a peak of looking probability of .99: At age 5, only 3 [1, 5] children reached ceiling performance.</p>

<div class="figure" style="text-align: center"><span id="fig:unfam-peaks-by-age"></span>
<img src="23-mispronunciations-notebook_files/figure-html/unfam-peaks-by-age-1.png" alt="Growth curve peaks by age for mispronunciation trials starting on the unfamiliar image." width="50%" />
<p class="caption">
Figure 11.2: Growth curve peaks by age for mispronunciation trials starting on the unfamiliar image.
</p>
</div>
<p>None of the other growth curve features showed developmental changes. That is, there were no credible year-over-year changes for the linear, quadratic or cubic time components of the growth curve. Although Figure <a href="sensitivity-to-mispronunciations.html#fig:unfam-initial-mp-trials">11.1</a> shows children’s probability of looking to the familiar image increasing more quickly at age 5, this effect cannot be clear tied to any of the model’s polynomial time features. After about 600 ms, the age 5 curve is almost parallel to other curves. This visual feature is consistent with the intercept effect: The curve is higher than the others on average, but it does not show any differences in shape.</p>
<p>I additionally asked whether any child-level factors predicted looking behavior under these conditions. First, I asked whether performance on a minimal pair discrimination task at age 3 predicted looking behavior at age 3. The rationale here is the hypothesis that children with better minimal pair discrimination may be especially sensitive to mispronunciations. Proportion of items correct on the task did not correlate with growth curve peaks, <em>r</em> = −.03 [90% UI: −.05, −.01] with <em>n</em> = 138, or with any other growth curve measures.</p>

<div class="figure" style="text-align: center"><span id="fig:plot-evt-mp-unfam-peaks"></span>
<img src="23-mispronunciations-notebook_files/figure-html/plot-evt-mp-unfam-peaks-1.png" alt="Relationship between expressive vocabulary and growth curve peaks for mispronunciation trials starting on the unfamiliar image. I drew 100 samples from the posterior distribution and computed participant’s growth curve peaks for each draw. Points represent the mean and standard error of the 100 peaks. For each draw, I regressed the peak values onto EVT-2 standard score. Lines represent the fits of the regressions." width="50%" />
<p class="caption">
Figure 11.3: Relationship between expressive vocabulary and growth curve peaks for mispronunciation trials starting on the unfamiliar image. I drew 100 samples from the posterior distribution and computed participant’s growth curve peaks for each draw. Points represent the mean and standard error of the 100 peaks. For each draw, I regressed the peak values onto EVT-2 standard score. Lines represent the fits of the regressions.
</p>
</div>
<p>I also tested whether expressive vocabulary (EVT-2 standard score) predicted performance in this condition. In this case, there were significant effects at age 3 where a higher expressive vocabulary predicted a higher growth curve peak and a higher average probability. These effects, however, were very small. For example, a 15-point increase in expressive vocabulary predicted an increase of growth curve peak of .03, <em>R</em><sup>2</sup> = .03—see Figure <a href="sensitivity-to-mispronunciations.html#fig:plot-evt-mp-unfam-peaks">11.3</a> . Expressive vocabulary did not predict any of the growth curve features at age 4 or at age 5.</p>
<p><strong>Summary</strong>. When children look at the unfamiliar object and hear a mispronunciation, they on average look to the familiar image that sounds like the mispronunciation. Children are much more uncertain in this condition, compared to the conditions whether appropriate referent is more obvious. The only development changes observed were the increases in average looking probability and peak looking probability at age 5. There was a small effect of expressive vocabulary on looking probability at age 3, but no other effects of vocabulary were observed.</p>
</div>
<div id="familiar-initial-trials-should-i-stay-or-should-i-go" class="section level2">
<h2><span class="header-section-number">11.2</span> Familiar-initial trials: Should I stay or should I go?</h2>
<p>The above analyses showed that preschoolers associate one-feature onset-mispronunciations with the familiar word that matches the rime of the word. But that was only for trials that started on the unfamilar object. I now consider the other situation, where children are fixating on a familiar object and hear a word that immediately mismatches with the name of that familiar object. On the basis of the first segment, children have information that supports switching to another image. But as the rest of the word unfolds, they hear a syllable rime that supports staying.</p>
<p>Figure <a href="sensitivity-to-mispronunciations.html#fig:fam-initial-mp-trials">11.4</a> shows the growth curve averages for trials starting on the familiar image. The looking patterns show a sharp fall towards .5 which is chance-level performance. Behaviorally, children on average move quickly to look at both images equally; they rush into maximum uncertainty. At age 5, the average of the growth curves never dips below .5, and in fact, it shows a late rise to .6 looking probability. At this age, children are overall more likely to stay on the familiar object.</p>
<!-- One possible interpretation of this pattern is that the children making  -->
<!-- brief confirmatory looks to the novel image; they checking out -->
<!-- the novel image. But this cannot be right because the growth curve never -->
<!-- dips much below .5 (certainly not below .4). So there is more likely a -->
<!-- mix of behaviors, with children staying put on some trials and -->
<!-- considering the novel object on some trials. -->

<div class="figure" style="text-align: center"><span id="fig:fam-initial-mp-trials"></span>
<img src="23-mispronunciations-notebook_files/figure-html/fam-initial-mp-trials-1.png" alt="Averages of participants’ growth curves in each age. The lines represent 100 posterior predictions of the group average." width="66%" />
<p class="caption">
Figure 11.4: Averages of participants’ growth curves in each age. The lines represent 100 posterior predictions of the group average.
</p>
</div>
<p>In the other analyses, the growth curves become steeper and attain higher average values and higher peak values. As a result, it is straightforward to interpret how the intercept and linear time effects contribute to the growth curve’s shape. For this model, some more effort is required to interpret the model parameters and how they combine to form the growth curve shape.</p>
<p>Figure <a href="sensitivity-to-mispronunciations.html#fig:mp-fam-gca-features">11.5</a> shows how the growth curve features are weighted at each year and contribute to the overall growth curve shape. At age 3, the intercept term, or average proportion of looks to the familiar image, was .68 [90% UI: .65, .71]. In this situation, the term is less useful because the curves all start at a high probability which inflates the average value. That said, comparisons remain useful. At age 4, the average probability decreased by .05 [.02, .09] to .63 [.60, .66], and at age 5 the average probability returns to age-3 levels .68 [.65, .71]. These effects contribute to how the age 4 curves dips below the others and indeed below the .5 level. For the linear time term, the slope becomes flatter year over year, decreasing by 19% [7%, 29%] from age 3 to age 4 and decreasing by 30% [17%, 42%] from age 4 to age 5.</p>

<div class="figure" style="text-align: center"><span id="fig:mp-fam-gca-features"></span>
<img src="23-mispronunciations-notebook_files/figure-html/mp-fam-gca-features-1.png" alt="Weighted growth curve features. For the first four panels, the y axes are scaled to the same range. This scaling highlights how the cubic time component contributes less to the overall shape than the other features." width="100%" />
<p class="caption">
Figure 11.5: Weighted growth curve features. For the first four panels, the <em>y</em> axes are scaled to the same range. This scaling highlights how the cubic time component contributes less to the overall shape than the other features.
</p>
</div>
<p>There was a credible change in the quadratic time parameter at age 5. One way to think of positive quadratic trend is like a weight hanging on a string: It pulls and bends the whole curve downwards. At age 5, the quadratic is 12% [1%, 22%] smaller than at age 4, meaning that the age-5 curve has slightly less bend downwards. Finally, there were no credible differences in the cubic time component. Compared to the other features, the cubic time feature only a small amount to the overall shape of the growth curves.</p>
<p>The combination of these effects shows in the final panel of the plot. The Age 4 curve dips down furthest beneath 0 log-odds (.5 probability)—this is driven by in the intercept feature. The Age 5 curve stays above 0 log-odds and starts to rise away from its minimum value, owning to the dampened linear and quadratic features.</p>
<p>The developmental story, if any, is that children stick with the familiar object slightly more at age 5. The growth curves hit maximum uncertainty, but not at age 5.</p>
<div id="quantifying-looking-behaviors" class="section level3">
<h3><span class="header-section-number">11.2.1</span> Quantifying looking behaviors</h3>
<p>In the earlier analyses, I derived a growth curve peak value. Here, I asked whether analogous growth curve “valleys” provided a meaningful feature for looking behavior in this context. This value was defined as the median of the five smallest proportions of a growth curve. Intuitively, it reflects the maximum degree to which the novel image is considered as a referent for the mispronunciation.</p>
<p>Figure <a href="sensitivity-to-mispronunciations.html#fig:fam-peaks-by-age">11.6</a> shows the posterior means of participants’ growth curve valleys. Note that there is considerable variability at each age, with the 0–1 interval nearly covered at age 4. The median value is closer to .5 at age 5, and this difference is consistent with the growth curve trajectories where the average age 5 curve had did not dip as low as the other curves.</p>

<div class="figure" style="text-align: center"><span id="fig:fam-peaks-by-age"></span>
<img src="23-mispronunciations-notebook_files/figure-html/fam-peaks-by-age-1.png" alt="Growth curve peaks by age for mispronunciation trials starting on the familiar image." width="50%" />
<p class="caption">
Figure 11.6: Growth curve peaks by age for mispronunciation trials starting on the familiar image.
</p>
</div>
<p>The wide range of values for the growth curve valleys suggests that there are a few different listening behaviors that are being averaged over in the above analyses. For example, the valleys above .6 indicate that some children stay with the familiar image on average, and the valleys below .4 indicate children who favor the unfamiliar image.</p>
<p>To explore individual listening behaviors, I visualized children’s individual growth curves based on their growth curve valleys. Within each year, I grouped children into sextiles based on the posterior mean of the their growth curve valley and plotted their individual growth curves. Figure <a href="sensitivity-to-mispronunciations.html#fig:age3-valley-curves">11.7</a> shows the results from age 3. The final two bins show children who on average stayed with the familiar image throughout the mispronuciation trials. The first two bins mostly contain children switched to the unfamilar image and stayed there. These are also some children whose curves show a pronounced u-shaped trajectory; the curves with the highest ending points in the first three bins show children with u-shaped trajectories.</p>

<div class="figure" style="text-align: center"><span id="fig:age3-valley-curves"></span>
<img src="23-mispronunciations-notebook_files/figure-html/age3-valley-curves-1.png" alt="Growth curves for mispronunciations trials starting on the unfamilar object at age 3. Children were grouped into sextiles based on the posterior mean of the growth curve valley (minimum). Ten lines are drawn per child to visualize uncertainty. Children were assigned colors arbitrarily. On the right side of each panel are “rugs” which mark the valleys in that panel." width="80%" />
<p class="caption">
Figure 11.7: Growth curves for mispronunciations trials starting on the unfamilar object at age 3. Children were grouped into sextiles based on the posterior mean of the growth curve valley (minimum). Ten lines are drawn per child to visualize uncertainty. Children were assigned colors arbitrarily. On the right side of each panel are “rugs” which mark the valleys in that panel.
</p>
</div>
<p>I asked whether any child-level factors predicted children’s looking behaviors. I first regressed growth curve valleys on EVT-2 standard score. There was a small effect at age 3, <em>R</em><sup>2</sup> = .09, <em>n</em> = 145. A 15-point increase in expressive vocabulary predicted decrease in growth curve valley of .05. At the other ages, the effects are neglibly small, as shown in Figure <a href="sensitivity-to-mispronunciations.html#fig:mp-fam-valley-evt">11.8</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:mp-fam-valley-evt"></span>
<img src="23-mispronunciations-notebook_files/figure-html/mp-fam-valley-evt-1.png" alt="Relationship between expressive vocabulary and growth curve valleys for mispronunciation trials starting on the familiar image. Valleys were computed on 100 draws of the posterior distribution. Points represent the mean and standard error of the valleys. Lines represent the fit of the regression in each draw. Although the slope of age 4 and age 5 lines are noticeably different from the age 3 one, they cover a tiny amount of the y axis so they represent a neglible effect." width="50%" />
<p class="caption">
Figure 11.8: Relationship between expressive vocabulary and growth curve valleys for mispronunciation trials starting on the familiar image. Valleys were computed on 100 draws of the posterior distribution. Points represent the mean and standard error of the valleys. Lines represent the fit of the regression in each draw. Although the slope of age 4 and age 5 lines are noticeably different from the age 3 one, they cover a tiny amount of the <em>y</em> axis so they represent a neglible effect.
</p>
</div>
<p>At age 3, a child’s proportion of trials correct on minimal pairs discrimination also had a small effect on growth curve valleys, <em>R</em><sup>2</sup> = .08, <em>n</em> = 140. An increase in minimal pair discrimination accuracy of .1 probability units predicts a decrease of growth curve peak by .04.</p>
<p>I regressed age-3 valleys onto both EVT-2 standard score, minimal-pair discrimination accuracy and their interaction. Both main effects and the interaction were statistically significant, <em>R</em><sup>2</sup> = .17, <em>n</em> = 139. The effects of vocabulary and minimal-pair discrimination were both negative, so that higher scores on these measures predicted lower growth curve valleys. For an average participant, a 15-point increase in expressive vocabulary predicted decrease of .03, and an increase of minimal pair accuracy of .1 predicted a decrease in valley of .03. The interaction term, however, was positive, meaning that increasing one of the predictors simulataneously weakens the effect of the other. The simple effect of expressive vocabulary is no longer nominally significant when minimal pair accuracy is .71 or greater (at the 60-percentile or greater). Conversely, the simple effect of minimal pair accuracy is no longer significant when expressive vocabulary standard score is 119 or greater (at the 60-percentile or greater). <strong>interpret this effect</strong></p>
<p>The valley feature considers the maximum extent to which the novel object is considered as the referent on these trials. But the u-shaped growth curves in Figure <a href="sensitivity-to-mispronunciations.html#fig:age3-valley-curves">11.7</a> reveal another listening response on this task: Confirmatory looks to the unfamiliar object. In these u-shaped curves, children’s probability of fixating on the familiar object temporarily decreases as the novel object is considered, and the probability rises as that interpretation is rejected. To quantify this tendency, I computed each child’s growth curve on the probability scale and re-estimated the quadratic trends in these curves. Exploratory visualization showed that children with higher values on this quadratic trend were more likely to have a u-shape curve. This feature, however, also favored sigmoid or z-shaped curves that rapidly fell and plateaued. To avoid these kinds of curves, I weighted the quadratic trend using the median of the final five points of the curve. The weighted quadratic feature penalized curves that have a strong quadratic trend but end on a low probability. Figure <a href="sensitivity-to-mispronunciations.html#fig:mp-fam-prop-ot2-bins">11.9</a> shows growth curves of age 3 children binned using this feature. The bottom of panels illustrated how the u-shaped features becomes stronger in each bin. The quadratic feature was weakly correlated with the growth curve valleys, <em>r</em> = −.12, and the lack of correlation appears in the figure by how the curves in each panel reach different minimum valleys.</p>

<div class="figure" style="text-align: center"><span id="fig:mp-fam-prop-ot2-bins"></span>
<img src="23-mispronunciations-notebook_files/figure-html/mp-fam-prop-ot2-bins-1.png" alt="Text reference for caption" width="80%" />
<p class="caption">
Figure 11.9: Text reference for caption
</p>
</div>
<p>I regressed the u-shaped curve feature onto expressive vocabulary standard score at each age and onto minimal pair discrimination for age 3. There was a tiny but yet nominally significant of vocabulary at age 5, <em>R</em><sup>2</sup> = .03, where children with lower vocabularies were had a slightly stronger u-shaped trend in their growth curve. This effect, however, is so small as to be negligible. None of the effects were significant.</p>
</div>
</div>
<div id="discussion-2" class="section level2">
<h2><span class="header-section-number">11.3</span> Discussion</h2>
<ul>
<li>For the first set of analyses, they reliably and more reliably with age look to the familiar image.</li>
<li>There is a definite penalty to the mispronunciation when we compare against real word or nonword peaks.</li>
<li>Unlike those conditions which started to show ceiling effects at age 4, children are much more uncertain here.</li>
<li>In terms of lexical processing, the syllable onset leads them down a garden path. They have to hear more of the word in order to associate the mispronunciation with the target. This is a bit like processing a rime word.</li>
<li>The development story is that they can use the rest of the word more effectively to associate the MP with the familiar image. This would predict that children become more sensitive to rime-based lexical competitors during the preschool years.</li>
<li>But there is no effect of expressive vocabulary here, especially at older ages.</li>
<li><p>So they are sensitive but they become more accommodating of the mispronounced version.</p></li>
<li>For second set of analyses, there is no one clear strategy for referent selection. We see a few different patterns among children. Some stay put. Some always switch. Some do both.</li>
<li>The growth curve averages rush to .5, which is equal looks to both images, which is maximum uncertainty.</li>
<li>The age 5 curve doesn’t dip as far, so they are slightly more likely to stay put.</li>
<li>These sets of analyses mainly demonstrate that when children start on a familiar image and hear a mispronunciation, they have a few options for how to proceed.</li>
<li><p>This also shows a possible decoupling between lexical processing and referent selection. It is unlikely that children heard the mispronunciations differently in these trials, but rather the responded differently.</p></li>
</ul>

</div>
</div>



</div>
<script type="text/javascript">
  $("div.page-wrapper > h3").appendTo(".page-inner > section");
  $("div.page-wrapper > #refs").appendTo(".page-inner > section");
  $("div.page-wrapper > .footnotes").appendTo(".page-inner > section");
  $("div.body-inner > h3").appendTo(".page-inner > section");
  $("div.body-inner > #refs").appendTo(".page-inner > section");
  $("div.body-inner > .footnotes").appendTo(".page-inner > section");
</script>
            </section>

          </div>
        </div>
      </div>
<a href="development-of-referent-selection.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="vw-experiment-items.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"split_bib": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
