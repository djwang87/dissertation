<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>My dissertation</title>
  <meta name="description" content="My dissertation">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="My dissertation" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="tjmahr/dissertation" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="My dissertation" />
  
  
  

<meta name="author" content="Tristan Mahr">


<meta name="date" content="2017-12-14">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="prepare-and-explore-the-data.html">
<link rel="next" href="visualize-looks-to-each-image-type.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="assets\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">My dissertation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Development of word recognition in preschoolers</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#updates"><i class="fa fa-check"></i>Updates</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="scratch-paper.html"><a href="scratch-paper.html"><i class="fa fa-check"></i><b>1</b> Scratch paper</a><ul>
<li class="chapter" data-level="1.1" data-path="scratch-paper.html"><a href="scratch-paper.html#bookdown-cheatsheet"><i class="fa fa-check"></i><b>1.1</b> Bookdown cheatsheet</a><ul>
<li class="chapter" data-level="1.1.1" data-path="scratch-paper.html"><a href="scratch-paper.html#manual-section-label-demo"><i class="fa fa-check"></i><b>1.1.1</b> Cross-references to sections</a></li>
<li class="chapter" data-level="1.1.2" data-path="scratch-paper.html"><a href="scratch-paper.html#cross-references-to-appendices"><i class="fa fa-check"></i><b>1.1.2</b> Cross-references to appendices</a></li>
<li class="chapter" data-level="1.1.3" data-path="scratch-paper.html"><a href="scratch-paper.html#cross-references-to-tables"><i class="fa fa-check"></i><b>1.1.3</b> Cross-references to tables</a></li>
<li class="chapter" data-level="1.1.4" data-path="scratch-paper.html"><a href="scratch-paper.html#figure-references-and-using-text-references-as-captions"><i class="fa fa-check"></i><b>1.1.4</b> Figure references and using text references as captions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="scratch-paper.html"><a href="scratch-paper.html#debug-info"><i class="fa fa-check"></i><b>1.2</b> Debug info</a></li>
</ul></li>
<li class="part"><span><b>Prospectus</b></span></li>
<li class="chapter" data-level="2" data-path="front-matter.html"><a href="front-matter.html"><i class="fa fa-check"></i><b>2</b> Front Matter</a><ul>
<li class="chapter" data-level="" data-path="front-matter.html"><a href="front-matter.html#about-this-document"><i class="fa fa-check"></i>About This Document</a></li>
<li class="chapter" data-level="" data-path="front-matter.html"><a href="front-matter.html#dissertation-committee-members"><i class="fa fa-check"></i>Dissertation Committee Members</a></li>
<li class="chapter" data-level="" data-path="front-matter.html"><a href="front-matter.html#planned-dissertation-format"><i class="fa fa-check"></i>Planned Dissertation Format</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="specific-aims.html"><a href="specific-aims.html"><i class="fa fa-check"></i><b>3</b> Specific Aims</a><ul>
<li class="chapter" data-level="3.1" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>3.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="3.2" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>3.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="3.3" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-3-computational-modeling"><i class="fa fa-check"></i><b>3.3</b> Specific Aim 3 (Computational Modeling)</a></li>
<li class="chapter" data-level="3.4" data-path="specific-aims.html"><a href="specific-aims.html#summary"><i class="fa fa-check"></i><b>3.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="significance.html"><a href="significance.html"><i class="fa fa-check"></i><b>4</b> Significance</a><ul>
<li class="chapter" data-level="4.1" data-path="significance.html"><a href="significance.html#public-health-significance"><i class="fa fa-check"></i><b>4.1</b> Public Health Significance</a></li>
<li class="chapter" data-level="4.2" data-path="significance.html"><a href="significance.html#scientific-significance"><i class="fa fa-check"></i><b>4.2</b> Scientific Significance</a><ul>
<li class="chapter" data-level="4.2.1" data-path="significance.html"><a href="significance.html#lexical-processing-dynamics"><i class="fa fa-check"></i><b>4.2.1</b> Lexical Processing Dynamics</a></li>
<li class="chapter" data-level="4.2.2" data-path="significance.html"><a href="significance.html#individual-differences-in-word-recognition"><i class="fa fa-check"></i><b>4.2.2</b> Individual Differences in Word Recognition</a></li>
<li class="chapter" data-level="4.2.3" data-path="significance.html"><a href="significance.html#computational-modeling"><i class="fa fa-check"></i><b>4.2.3</b> Computational Modeling</a></li>
<li class="chapter" data-level="4.2.4" data-path="significance.html"><a href="significance.html#summary-1"><i class="fa fa-check"></i><b>4.2.4</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="research-hypotheses.html"><a href="research-hypotheses.html"><i class="fa fa-check"></i><b>5</b> Research Hypotheses</a><ul>
<li class="chapter" data-level="5.1" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-1-familiar-word-recognition-and-lexical-competition-1"><i class="fa fa-check"></i><b>5.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="5.2" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-2-referent-selection-and-mispronunciations-1"><i class="fa fa-check"></i><b>5.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="5.3" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-3-computational-modeling-1"><i class="fa fa-check"></i><b>5.3</b> Specific Aim 3 (Computational Modeling)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>6</b> Methods</a><ul>
<li class="chapter" data-level="6.1" data-path="methods.html"><a href="methods.html#general-research-design-participants"><i class="fa fa-check"></i><b>6.1</b> General Research Design: Participants</a></li>
<li class="chapter" data-level="6.2" data-path="methods.html"><a href="methods.html#general-eyetracking-procedure"><i class="fa fa-check"></i><b>6.2</b> General Eyetracking Procedure</a><ul>
<li class="chapter" data-level="6.2.1" data-path="methods.html"><a href="methods.html#experiment-administration"><i class="fa fa-check"></i><b>6.2.1</b> Experiment Administration</a></li>
<li class="chapter" data-level="6.2.2" data-path="methods.html"><a href="methods.html#stimuli"><i class="fa fa-check"></i><b>6.2.2</b> Stimuli</a></li>
<li class="chapter" data-level="6.2.3" data-path="methods.html"><a href="methods.html#data-preparation"><i class="fa fa-check"></i><b>6.2.3</b> Data Preparation</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="methods.html"><a href="methods.html#specific-procedure-aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>6.3</b> Specific Procedure: Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="6.4" data-path="methods.html"><a href="methods.html#specific-procedure-aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>6.4</b> Specific Procedure: Aim 2 (Referent Selection and Mispronunciations)</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="outcome-measures.html"><a href="outcome-measures.html"><i class="fa fa-check"></i><b>7</b> Outcome Measures</a><ul>
<li class="chapter" data-level="7.1" data-path="outcome-measures.html"><a href="outcome-measures.html#sample-data"><i class="fa fa-check"></i><b>7.1</b> Sample Data</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="analysis.html"><a href="analysis.html"><i class="fa fa-check"></i><b>8</b> Analysis</a><ul>
<li class="chapter" data-level="8.1" data-path="analysis.html"><a href="analysis.html#growth-curve-analysis"><i class="fa fa-check"></i><b>8.1</b> Growth Curve Analysis</a></li>
<li class="chapter" data-level="8.2" data-path="analysis.html"><a href="analysis.html#aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>8.2</b> Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="8.3" data-path="analysis.html"><a href="analysis.html#aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>8.3</b> Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="8.4" data-path="analysis.html"><a href="analysis.html#aim-3-computational-modeling"><i class="fa fa-check"></i><b>8.4</b> Aim 3 (Computational Modeling)</a><ul>
<li class="chapter" data-level="8.4.1" data-path="analysis.html"><a href="analysis.html#trace-model-architecture"><i class="fa fa-check"></i><b>8.4.1</b> TRACE Model Architecture</a></li>
<li class="chapter" data-level="8.4.2" data-path="analysis.html"><a href="analysis.html#modeling-looking-data"><i class="fa fa-check"></i><b>8.4.2</b> Modeling Looking Data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Aim 1: Familiar Word Recognition and Lexical Competition</b></span></li>
<li class="chapter" data-level="9" data-path="prepare-and-explore-the-data.html"><a href="prepare-and-explore-the-data.html"><i class="fa fa-check"></i><b>9</b> Prepare and explore the data</a><ul>
<li class="chapter" data-level="9.1" data-path="prepare-and-explore-the-data.html"><a href="prepare-and-explore-the-data.html#raw-data-visualization"><i class="fa fa-check"></i><b>9.1</b> Raw data visualization</a></li>
<li class="chapter" data-level="9.2" data-path="prepare-and-explore-the-data.html"><a href="prepare-and-explore-the-data.html#data-screening"><i class="fa fa-check"></i><b>9.2</b> Data screening</a><ul>
<li class="chapter" data-level="9.2.1" data-path="prepare-and-explore-the-data.html"><a href="prepare-and-explore-the-data.html#add-a-note-about-the-bad-version-of-the-experiment"><i class="fa fa-check"></i><b>9.2.1</b> Add a note about the bad version of the experiment</a></li>
<li class="chapter" data-level="9.2.2" data-path="prepare-and-explore-the-data.html"><a href="prepare-and-explore-the-data.html#special-case-data-screening"><i class="fa fa-check"></i><b>9.2.2</b> Special case data screening</a></li>
<li class="chapter" data-level="9.2.3" data-path="prepare-and-explore-the-data.html"><a href="prepare-and-explore-the-data.html#interim-summary"><i class="fa fa-check"></i><b>9.2.3</b> Interim summary</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="prepare-and-explore-the-data.html"><a href="prepare-and-explore-the-data.html#prepare-the-dataset-for-modeling"><i class="fa fa-check"></i><b>9.3</b> Prepare the dataset for modeling</a></li>
<li class="chapter" data-level="9.4" data-path="prepare-and-explore-the-data.html"><a href="prepare-and-explore-the-data.html#data-preparation-1"><i class="fa fa-check"></i><b>9.4</b> Data preparation</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html"><i class="fa fa-check"></i><b>10</b> Analyze familiar word recognition</a><ul>
<li class="chapter" data-level="10.1" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#maximum-likelihood-results"><i class="fa fa-check"></i><b>10.1</b> Maximum likelihood results</a><ul>
<li class="chapter" data-level="10.1.1" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#whats-being-captured-by-the-random-effects"><i class="fa fa-check"></i><b>10.1.1</b> What’s being captured by the random effects?</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#bayesian-model-results"><i class="fa fa-check"></i><b>10.2</b> Bayesian model results</a><ul>
<li class="chapter" data-level="10.2.1" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#fixed-effects-plots"><i class="fa fa-check"></i><b>10.2.1</b> Fixed effects plots</a></li>
<li class="chapter" data-level="10.2.2" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#plot-the-intervals-for-the-random-effect-parameters"><i class="fa fa-check"></i><b>10.2.2</b> Plot the intervals for the random effect parameters</a></li>
<li class="chapter" data-level="10.2.3" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#check-for-stable-individual-differences"><i class="fa fa-check"></i><b>10.2.3</b> Check for stable individual differences</a></li>
<li class="chapter" data-level="10.2.4" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#summary-of-this-section"><i class="fa fa-check"></i><b>10.2.4</b> Summary of this section</a></li>
<li class="chapter" data-level="10.2.5" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>10.2.5</b> Posterior predictive checks</a></li>
<li class="chapter" data-level="10.2.6" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#simulating-data-from-new-participants"><i class="fa fa-check"></i><b>10.2.6</b> Simulating data from new participants</a></li>
<li class="chapter" data-level="10.2.7" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#predicting-the-future"><i class="fa fa-check"></i><b>10.2.7</b> Predicting the future</a></li>
<li class="chapter" data-level="10.2.8" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#relationship-with-child-level-variables"><i class="fa fa-check"></i><b>10.2.8</b> Relationship with child-level variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="visualize-looks-to-each-image-type.html"><a href="visualize-looks-to-each-image-type.html"><i class="fa fa-check"></i><b>11</b> Visualize looks to each image type</a><ul>
<li class="chapter" data-level="11.1" data-path="visualize-looks-to-each-image-type.html"><a href="visualize-looks-to-each-image-type.html#comparing-strong-versus-weak-foils"><i class="fa fa-check"></i><b>11.1</b> Comparing strong versus weak foils</a></li>
<li class="chapter" data-level="11.2" data-path="visualize-looks-to-each-image-type.html"><a href="visualize-looks-to-each-image-type.html#preparing-data-for-the-model"><i class="fa fa-check"></i><b>11.2</b> Preparing data for the model</a></li>
<li class="chapter" data-level="11.3" data-path="visualize-looks-to-each-image-type.html"><a href="visualize-looks-to-each-image-type.html#look-for-individual-differences-in-competitor-sensitivity"><i class="fa fa-check"></i><b>11.3</b> Look for individual differences in competitor sensitivity</a></li>
<li class="chapter" data-level="11.4" data-path="visualize-looks-to-each-image-type.html"><a href="visualize-looks-to-each-image-type.html#interim-summary-1"><i class="fa fa-check"></i><b>11.4</b> Interim summary</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="mp-experiment-items.html"><a href="mp-experiment-items.html"><i class="fa fa-check"></i><b>A</b> Items used in the mispronunciation experiment</a></li>
<li class="chapter" data-level="B" data-path="vw-experiment-items.html"><a href="vw-experiment-items.html"><i class="fa fa-check"></i><b>B</b> Items used in the visual world experiment</a></li>
<li class="chapter" data-level="C" data-path="related-work.html"><a href="related-work.html"><i class="fa fa-check"></i><b>C</b> Related Work</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Created with bookdown</a></li>
<li><a href="https://tjmahr.github.io/" target="blank">Tristan Mahr</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">My dissertation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="analyze-familiar-word-recognition" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> Analyze familiar word recognition</h1>
<p>Current steps:</p>
<ul>
<li>Model year over year changes.</li>
<li>Download test scores and individual differences.</li>
<li>Analyze individual differences</li>
</ul>
<div id="maximum-likelihood-results" class="section level2">
<h2><span class="header-section-number">10.1</span> Maximum likelihood results</h2>
<p>Fit a maximum likelihood model as a first pass for the analysis. We won’t fit the model automatically (whenever this page is updated). It’s too time consuming. Instead, we do it manually here, and save the results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lme4)
m &lt;-<span class="st"> </span><span class="kw">glmer</span>(
    <span class="kw">cbind</span>(Primary, Others) <span class="op">~</span>
<span class="st">      </span>(ot1 <span class="op">+</span><span class="st"> </span>ot2 <span class="op">+</span><span class="st"> </span>ot3) <span class="op">*</span><span class="st"> </span>Study <span class="op">+</span>
<span class="st">      </span>(ot1 <span class="op">+</span><span class="st"> </span>ot2 <span class="op">+</span><span class="st"> </span>ot3 <span class="op">|</span><span class="st"> </span>ResearchID<span class="op">/</span>Study),
    <span class="dt">family =</span> binomial,
    <span class="dt">data =</span> d_m)
readr<span class="op">::</span><span class="kw">write_rds</span>(m, <span class="st">&quot;./data/aim1_cubic_model.rds.gz&quot;</span>)</code></pre></div>
<p>And reload the saved model here.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lme4)
<span class="co">#&gt; Loading required package: Matrix</span>
m &lt;-<span class="st"> </span>readr<span class="op">::</span><span class="kw">read_rds</span>(<span class="st">&quot;./data/aim1_cubic_model.rds.gz&quot;</span>)
arm<span class="op">::</span><span class="kw">display</span>(m)
<span class="co">#&gt; glmer(formula = cbind(Primary, Others) ~ (ot1 + ot2 + ot3) * </span>
<span class="co">#&gt;     Study + (ot1 + ot2 + ot3 | ResearchID/Study), data = d_m, </span>
<span class="co">#&gt;     family = binomial)</span>
<span class="co">#&gt;                     coef.est coef.se</span>
<span class="co">#&gt; (Intercept)         -0.47     0.03  </span>
<span class="co">#&gt; ot1                  1.58     0.06  </span>
<span class="co">#&gt; ot2                  0.05     0.04  </span>
<span class="co">#&gt; ot3                 -0.17     0.03  </span>
<span class="co">#&gt; StudyTimePoint2      0.41     0.03  </span>
<span class="co">#&gt; StudyTimePoint3      0.70     0.04  </span>
<span class="co">#&gt; ot1:StudyTimePoint2  0.56     0.08  </span>
<span class="co">#&gt; ot1:StudyTimePoint3  1.10     0.08  </span>
<span class="co">#&gt; ot2:StudyTimePoint2 -0.16     0.05  </span>
<span class="co">#&gt; ot2:StudyTimePoint3 -0.35     0.05  </span>
<span class="co">#&gt; ot3:StudyTimePoint2 -0.12     0.04  </span>
<span class="co">#&gt; ot3:StudyTimePoint3 -0.21     0.04  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Error terms:</span>
<span class="co">#&gt;  Groups           Name        Std.Dev. Corr              </span>
<span class="co">#&gt;  Study:ResearchID (Intercept) 0.30                       </span>
<span class="co">#&gt;                   ot1         0.68      0.18             </span>
<span class="co">#&gt;                   ot2         0.44     -0.12  0.03       </span>
<span class="co">#&gt;                   ot3         0.29     -0.09 -0.44 -0.05 </span>
<span class="co">#&gt;  ResearchID       (Intercept) 0.27                       </span>
<span class="co">#&gt;                   ot1         0.46      0.86             </span>
<span class="co">#&gt;                   ot2         0.09     -0.99 -0.85       </span>
<span class="co">#&gt;                   ot3         0.03     -0.92 -0.98  0.92 </span>
<span class="co">#&gt;  Residual                     1.00                       </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; number of obs: 12584, groups: Study:ResearchID, 484; ResearchID, 195</span>
<span class="co">#&gt; AIC = 74467.3, DIC = -61745.9</span>
<span class="co">#&gt; deviance = 6328.7</span>

d_m<span class="op">$</span>cubic_fit &lt;-<span class="st"> </span><span class="kw">fitted</span>(m)

<span class="kw">ggplot</span>(d_m) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> Time, <span class="dt">y =</span> cubic_fit) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), <span class="dt">alpha =</span> .<span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_grid</span>(. <span class="op">~</span><span class="st"> </span>Study) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">labs</span>(
      <span class="dt">x =</span> <span class="st">&quot;Time after target onset (smoothed to 50 ms bins)&quot;</span>,
      <span class="dt">y =</span> <span class="st">&quot;Proportion looks to target (fitted)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_grey</span>(<span class="dt">base_size =</span> <span class="dv">9</span>) </code></pre></div>
<p><img src="12-aim1-notebook_files/figure-html/cubic-model-fits-1.png" width="100%" /></p>
<div id="whats-being-captured-by-the-random-effects" class="section level3">
<h3><span class="header-section-number">10.1.1</span> What’s being captured by the random effects?</h3>
<p>First, let’s plot just the fixed effect predictions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predict_y &lt;-<span class="st"> </span><span class="cf">function</span>(...) <span class="kw">predict</span>(..., <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
d_m<span class="op">$</span>fixef_fit &lt;-<span class="st"> </span><span class="kw">predict_y</span>(m, <span class="dt">re.form =</span> <span class="op">~</span><span class="st"> </span><span class="dv">0</span>)
d_m<span class="op">$</span>subj_fit  &lt;-<span class="st"> </span><span class="kw">predict_y</span>(m, <span class="dt">re.form =</span> <span class="op">~</span><span class="st"> </span>(ot1 <span class="op">+</span><span class="st"> </span>ot2 <span class="op">+</span><span class="st"> </span>ot3 <span class="op">|</span><span class="st"> </span>ResearchID))
d_m<span class="op">$</span>study_fit &lt;-<span class="st"> </span><span class="kw">predict_y</span>(m, <span class="dt">re.form =</span> <span class="op">~</span><span class="st"> </span>(ot1 <span class="op">+</span><span class="st"> </span>ot2 <span class="op">+</span><span class="st"> </span>ot3 <span class="op">|</span><span class="st"> </span>Study<span class="op">:</span>ResearchID))
d_m<span class="op">$</span>full_fit  &lt;-<span class="st"> </span><span class="kw">predict_y</span>(m, <span class="dt">re.form =</span> <span class="op">~</span><span class="st"> </span>(ot1 <span class="op">+</span><span class="st"> </span>ot2 <span class="op">+</span><span class="st"> </span>ot3 <span class="op">|</span><span class="st"> </span>Study<span class="op">:</span>ResearchID) <span class="op">+</span><span class="st"> </span>
<span class="st">                            </span>(ot1 <span class="op">+</span><span class="st"> </span>ot2 <span class="op">+</span><span class="st"> </span>ot3 <span class="op">|</span><span class="st"> </span>ResearchID))

<span class="kw">ggplot</span>(d_m) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> Time, <span class="dt">y =</span> fixef_fit) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), <span class="dt">alpha =</span> .<span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_grid</span>(. <span class="op">~</span><span class="st"> </span>Study) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_grey</span>(<span class="dt">base_size =</span> <span class="dv">9</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&quot;Time after target onset (smoothed to 50 ms bins)&quot;</span>,
    <span class="dt">y =</span> <span class="st">&quot;Proportion looks to target (fitted)&quot;</span>,
    <span class="dt">caption =</span> <span class="st">&quot;Conditioned on no random effects&quot;</span>) </code></pre></div>
<p><img src="12-aim1-notebook_files/figure-html/cubic-model-fits-fixes-1.png" width="100%" /></p>
<p>Now, we condition on child level effects.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(d_m) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> Time, <span class="dt">y =</span> subj_fit) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), <span class="dt">alpha =</span> .<span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_grid</span>(. <span class="op">~</span><span class="st"> </span>Study) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_grey</span>(<span class="dt">base_size =</span> <span class="dv">9</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&quot;Time after target onset (smoothed to 50 ms bins)&quot;</span>,
    <span class="dt">y =</span> <span class="st">&quot;Proportion looks to target (fitted)&quot;</span>,
    <span class="dt">caption =</span> <span class="st">&quot;Conditioned on Child effects&quot;</span>) </code></pre></div>
<p><img src="12-aim1-notebook_files/figure-html/cubic-model-fits-child-efs-1.png" width="100%" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
<span class="kw">ggplot</span>(d_m) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> Time, <span class="dt">y =</span> subj_fit <span class="op">-</span><span class="st"> </span>fixef_fit) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), <span class="dt">alpha =</span> .<span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_grid</span>(. <span class="op">~</span><span class="st"> </span>Study) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_grey</span>(<span class="dt">base_size =</span> <span class="dv">9</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&quot;Time after target onset (smoothed to 50 ms bins)&quot;</span>,
    <span class="dt">y =</span> <span class="st">&quot;Child-conditioned minus study means&quot;</span>) </code></pre></div>
<p><img src="12-aim1-notebook_files/figure-html/cubic-model-fits-child-efs-2.png" width="100%" /></p>
<p>It looks like the range of y values is smaller in TimePoint2 and TimePoint3, but could that just be the different numbers of participants who contribute to each study?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d_m <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">distinct</span>(ResearchID, Study) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">count</span>(Study) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="st">`</span><span class="dt">Num children in model</span><span class="st">`</span> =<span class="st"> </span>n) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Study</th>
<th align="right">Num children in model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">TimePoint1</td>
<td align="right">163</td>
</tr>
<tr class="even">
<td align="left">TimePoint2</td>
<td align="right">165</td>
</tr>
<tr class="odd">
<td align="left">TimePoint3</td>
<td align="right">156</td>
</tr>
</tbody>
</table>
<p>Now we condition on Study x Child effects. These would be capturing the subject-x-study variability.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(d_m) <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> Time, <span class="dt">y =</span> study_fit) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), <span class="dt">alpha =</span> .<span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_grid</span>(. <span class="op">~</span><span class="st"> </span>Study) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_grey</span>(<span class="dt">base_size =</span> <span class="dv">9</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&quot;Time after target onset (smoothed to 50 ms bins)&quot;</span>,
    <span class="dt">y =</span> <span class="st">&quot;Proportion looks to target (fitted)&quot;</span>,
    <span class="dt">caption =</span> <span class="st">&quot;Conditioned on Study x Child effects&quot;</span>)</code></pre></div>
<p><img src="12-aim1-notebook_files/figure-html/cubic-model-fits-ranefs-1.png" width="100%" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
<span class="kw">ggplot</span>(d_m) <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> Time, <span class="dt">y =</span> study_fit <span class="op">-</span><span class="st"> </span>fixef_fit) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), <span class="dt">alpha =</span> .<span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_grid</span>(. <span class="op">~</span><span class="st"> </span>Study) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_grey</span>(<span class="dt">base_size =</span> <span class="dv">9</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&quot;Time after target onset (smoothed to 50 ms bins)&quot;</span>,
    <span class="dt">y =</span> <span class="st">&quot;Child-x-Study-conditioned minus study means&quot;</span>)</code></pre></div>
<p><img src="12-aim1-notebook_files/figure-html/cubic-model-fits-ranefs-2.png" width="100%" /></p>
<p>Look for weak spots in the time series.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d_corr &lt;-<span class="st"> </span>d_m <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Time, Study) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">r =</span> <span class="kw">cor</span>(Prop, cubic_fit)) 

<span class="kw">ggplot</span>(d_corr) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> Time, <span class="dt">y =</span> r, <span class="dt">color =</span> Study) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">3</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ylim</span>(<span class="kw">c</span>(.<span class="dv">8</span>, <span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&quot;Time after target onset (smoothed to 50 ms bins)&quot;</span>,
    <span class="dt">y =</span> <span class="st">&quot;Correlation of fitted and observed&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_grey</span>(<span class="dt">base_size =</span> <span class="dv">9</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(
    <span class="dt">legend.position =</span> <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.05</span>), 
    <span class="dt">legend.justification =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) </code></pre></div>
<p><img src="12-aim1-notebook_files/figure-html/cubic-model-raw-fit-corr-1.png" width="50%" /></p>
<p>Rank the participants by their growth curve parameters—that is, the growth curve features when conditioned on child ID.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">xstudy_effects &lt;-<span class="st"> </span>m <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ranef</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">getElement</span>(<span class="st">&quot;ResearchID&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>tibble<span class="op">::</span><span class="kw">rownames_to_column</span>(<span class="st">&quot;ResearchID&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(ResearchID, <span class="dt">intercept =</span> <span class="st">`</span><span class="dt">(Intercept)</span><span class="st">`</span>, <span class="dt">slope =</span> ot1)

top_<span class="dv">20</span> &lt;-<span class="st"> </span><span class="kw">top_n</span>(xstudy_effects, <span class="dv">20</span>, slope)
bot_<span class="dv">20</span> &lt;-<span class="st"> </span><span class="kw">top_n</span>(xstudy_effects, <span class="dv">20</span>, <span class="op">-</span>slope)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(d_m <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Study <span class="op">==</span><span class="st"> &quot;TimePoint2&quot;</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> Time, <span class="dt">y =</span> subj_fit) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), <span class="dt">alpha =</span> .<span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), 
            <span class="dt">data =</span> <span class="kw">semi_join</span>(d_m, top_<span class="dv">20</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Study <span class="op">==</span><span class="st"> &quot;TimePoint2&quot;</span>), 
            <span class="dt">size =</span> .<span class="dv">7</span>, <span class="dt">color =</span> <span class="st">&quot;#0074D9&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), 
            <span class="dt">data =</span> <span class="kw">semi_join</span>(d_m, bot_<span class="dv">20</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Study <span class="op">==</span><span class="st"> &quot;TimePoint2&quot;</span>), 
            <span class="dt">size =</span> .<span class="dv">7</span>, <span class="dt">color =</span> <span class="st">&quot;#FF4136&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_grey</span>(<span class="dt">base_size =</span> <span class="dv">9</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;TP2 fits conditioned on Child effects&quot;</span>, 
       <span class="dt">x =</span> <span class="st">&quot;Time after target onset (smoothed to 50 ms bins)&quot;</span>,
       <span class="dt">caption =</span> <span class="st">&quot;Colors: Top 20 and bottom 20 children by linear time effect&quot;</span>)
<span class="co">#&gt; Joining, by = &quot;ResearchID&quot;</span>
<span class="co">#&gt; Joining, by = &quot;ResearchID&quot;</span></code></pre></div>
<p><img src="12-aim1-notebook_files/figure-html/cubic-model-fits-child-efs-ranks-1.png" width="50%" /></p>
<p>Visualize the model fits for the top and bottom 20 children. This plot illustrates that the children with strongest and weakest linear time components overall stay clustered away from each other when looking study level predictions. That is, the top 20 in general perform bunch together in all three studies.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(d_m) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> Time, <span class="dt">y =</span> cubic_fit) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), <span class="dt">alpha =</span> .<span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), <span class="dt">data =</span> <span class="kw">semi_join</span>(d_m, top_<span class="dv">20</span>), 
            <span class="dt">size =</span> .<span class="dv">7</span>, <span class="dt">color =</span> <span class="st">&quot;#0074D9&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), <span class="dt">data =</span> <span class="kw">semi_join</span>(d_m, bot_<span class="dv">20</span>), 
            <span class="dt">size =</span> .<span class="dv">7</span>, <span class="dt">color =</span> <span class="st">&quot;#FF4136&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_grid</span>(. <span class="op">~</span><span class="st"> </span>Study) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_grey</span>(<span class="dt">base_size =</span> <span class="dv">9</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Proportion looks to target [model fits]&quot;</span>, 
       <span class="dt">x =</span> <span class="st">&quot;Time after target onset (smoothed to 50 ms bins)&quot;</span>,
       <span class="dt">caption =</span> <span class="st">&quot;Colors: Top 20 and bottom 20 children by linear time effect&quot;</span>)
<span class="co">#&gt; Joining, by = &quot;ResearchID&quot;</span>
<span class="co">#&gt; Joining, by = &quot;ResearchID&quot;</span></code></pre></div>
<p><img src="12-aim1-notebook_files/figure-html/ranks-1.png" width="100%" /></p>
<p>To confirm that this differences are not just an artifact of modeling, visualize the ranks on the observed data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(d_m) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> Time, <span class="dt">y =</span> Prop) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), <span class="dt">alpha =</span> .<span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), <span class="dt">data =</span> <span class="kw">semi_join</span>(d_m, top_<span class="dv">20</span>), 
            <span class="dt">size =</span> .<span class="dv">7</span>, <span class="dt">color =</span> <span class="st">&quot;#0074D9&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> ResearchID), <span class="dt">data =</span> <span class="kw">semi_join</span>(d_m, bot_<span class="dv">20</span>), 
            <span class="dt">size =</span> .<span class="dv">7</span>, <span class="dt">color =</span> <span class="st">&quot;#FF4136&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_grid</span>(. <span class="op">~</span><span class="st"> </span>Study) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Proportion looks to target&quot;</span>, 
       <span class="dt">x =</span> <span class="st">&quot;Time after target onset (smoothed to 50 ms bins)&quot;</span>,
       <span class="dt">caption =</span> <span class="st">&quot;Colors: Top 20 and bottom 20 children by linear time effect&quot;</span>)
<span class="co">#&gt; Joining, by = &quot;ResearchID&quot;</span>
<span class="co">#&gt; Joining, by = &quot;ResearchID&quot;</span></code></pre></div>
<p><img src="12-aim1-notebook_files/figure-html/ranks-on-raw-1.png" width="100%" /></p>
<p>Open questions:</p>
<ul>
<li>How to test for stability of individual differences over time?</li>
<li>Intuitively, I would say that the differences are unstable if the red and blue lines got shuffled in each study. What stats formalize this intuition?</li>
</ul>
</div>
</div>
<div id="bayesian-model-results" class="section level2">
<h2><span class="header-section-number">10.2</span> Bayesian model results</h2>
<p>Here is the code used to fit the model with Stan. It took about 24 hours to run the model. The regression terms have the prior Normal(0, 1)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rstanarm)
<span class="kw">options</span>(<span class="dt">mc.cores =</span> parallel<span class="op">::</span><span class="kw">detectCores</span>())

m &lt;-<span class="st"> </span><span class="kw">stan_glmer</span>(
  <span class="kw">cbind</span>(Primary, Others) <span class="op">~</span>
<span class="st">    </span>(ot1 <span class="op">+</span><span class="st"> </span>ot2 <span class="op">+</span><span class="st"> </span>ot3) <span class="op">*</span><span class="st"> </span>Study <span class="op">+</span>
<span class="st">    </span>(ot1 <span class="op">+</span><span class="st"> </span>ot2 <span class="op">+</span><span class="st"> </span>ot3 <span class="op">|</span><span class="st"> </span>ResearchID<span class="op">/</span>Study),
  <span class="dt">family =</span> binomial,
  <span class="dt">prior =</span> <span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">autoscale =</span> <span class="ot">FALSE</span>),
  <span class="dt">prior_intercept =</span> <span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">2</span>),
  <span class="dt">prior_covariance =</span> <span class="kw">decov</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>),
  <span class="dt">data =</span> d_m)
readr<span class="op">::</span><span class="kw">write_rds</span>(m, <span class="st">&quot;./data/stan_aim1_cubic_model.rds.gz&quot;</span>)</code></pre></div>
<p>The output below contains the model quick view, a summary of the fixed effect terms, and a summary of the priors used.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b
<span class="co">#&gt; stan_glmer</span>
<span class="co">#&gt;  family:  binomial [logit]</span>
<span class="co">#&gt;  formula: cbind(Primary, Others) ~ (ot1 + ot2 + ot3) * Study + (ot1 + ot2 + </span>
<span class="co">#&gt;     ot3 | ResearchID/Study)</span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Estimates:</span>
<span class="co">#&gt;                     Median MAD_SD</span>
<span class="co">#&gt; (Intercept)         -0.5    0.0  </span>
<span class="co">#&gt; ot1                  1.6    0.1  </span>
<span class="co">#&gt; ot2                  0.0    0.0  </span>
<span class="co">#&gt; ot3                 -0.2    0.0  </span>
<span class="co">#&gt; StudyTimePoint2      0.4    0.0  </span>
<span class="co">#&gt; StudyTimePoint3      0.7    0.0  </span>
<span class="co">#&gt; ot1:StudyTimePoint2  0.6    0.1  </span>
<span class="co">#&gt; ot1:StudyTimePoint3  1.1    0.1  </span>
<span class="co">#&gt; ot2:StudyTimePoint2 -0.2    0.0  </span>
<span class="co">#&gt; ot2:StudyTimePoint3 -0.4    0.1  </span>
<span class="co">#&gt; ot3:StudyTimePoint2 -0.1    0.0  </span>
<span class="co">#&gt; ot3:StudyTimePoint3 -0.2    0.0  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Error terms:</span>
<span class="co">#&gt;  Groups           Name        Std.Dev. Corr             </span>
<span class="co">#&gt;  Study:ResearchID (Intercept) 0.305                     </span>
<span class="co">#&gt;                   ot1         0.691     0.20            </span>
<span class="co">#&gt;                   ot2         0.437    -0.11  0.02      </span>
<span class="co">#&gt;                   ot3         0.294    -0.11 -0.44 -0.06</span>
<span class="co">#&gt;  ResearchID       (Intercept) 0.264                     </span>
<span class="co">#&gt;                   ot1         0.423     0.78            </span>
<span class="co">#&gt;                   ot2         0.125    -0.75 -0.56      </span>
<span class="co">#&gt;                   ot3         0.058    -0.23 -0.31  0.19</span>
<span class="co">#&gt; Num. levels: Study:ResearchID 484, ResearchID 195 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Sample avg. posterior predictive </span>
<span class="co">#&gt; distribution of y (X = xbar):</span>
<span class="co">#&gt;          Median MAD_SD</span>
<span class="co">#&gt; mean_PPD 49.9    0.1  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt; For info on the priors used see help(&#39;prior_summary.stanreg&#39;).</span>

<span class="kw">summary</span>(b, <span class="dt">pars =</span> <span class="kw">names</span>(<span class="kw">fixef</span>(b)))
<span class="co">#&gt; </span>
<span class="co">#&gt; Model Info:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  function:  stan_glmer</span>
<span class="co">#&gt;  family:    binomial [logit]</span>
<span class="co">#&gt;  formula:   cbind(Primary, Others) ~ (ot1 + ot2 + ot3) * Study + (ot1 + ot2 + </span>
<span class="co">#&gt;     ot3 | ResearchID/Study)</span>
<span class="co">#&gt;  algorithm: sampling</span>
<span class="co">#&gt;  priors:    see help(&#39;prior_summary&#39;)</span>
<span class="co">#&gt;  sample:    4000 (posterior sample size)</span>
<span class="co">#&gt;  num obs:   12584</span>
<span class="co">#&gt;  groups:    Study:ResearchID (484), ResearchID (195)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Estimates:</span>
<span class="co">#&gt;                       mean   sd   2.5%   25%   50%   75%   97.5%</span>
<span class="co">#&gt; (Intercept)         -0.5    0.0 -0.5   -0.5  -0.5  -0.4  -0.4   </span>
<span class="co">#&gt; ot1                  1.6    0.1  1.4    1.5   1.6   1.6   1.7   </span>
<span class="co">#&gt; ot2                  0.0    0.0  0.0    0.0   0.0   0.1   0.1   </span>
<span class="co">#&gt; ot3                 -0.2    0.0 -0.2   -0.2  -0.2  -0.2  -0.1   </span>
<span class="co">#&gt; StudyTimePoint2      0.4    0.0  0.3    0.4   0.4   0.4   0.5   </span>
<span class="co">#&gt; StudyTimePoint3      0.7    0.0  0.6    0.7   0.7   0.7   0.8   </span>
<span class="co">#&gt; ot1:StudyTimePoint2  0.6    0.1  0.4    0.5   0.6   0.6   0.7   </span>
<span class="co">#&gt; ot1:StudyTimePoint3  1.1    0.1  0.9    1.0   1.1   1.2   1.3   </span>
<span class="co">#&gt; ot2:StudyTimePoint2 -0.2    0.1 -0.3   -0.2  -0.2  -0.1  -0.1   </span>
<span class="co">#&gt; ot2:StudyTimePoint3 -0.4    0.1 -0.5   -0.4  -0.4  -0.3  -0.3   </span>
<span class="co">#&gt; ot3:StudyTimePoint2 -0.1    0.0 -0.2   -0.1  -0.1  -0.1   0.0   </span>
<span class="co">#&gt; ot3:StudyTimePoint3 -0.2    0.0 -0.3   -0.2  -0.2  -0.2  -0.1   </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Diagnostics:</span>
<span class="co">#&gt;                     mcse Rhat n_eff</span>
<span class="co">#&gt; (Intercept)         0.0  1.0  1086 </span>
<span class="co">#&gt; ot1                 0.0  1.0   857 </span>
<span class="co">#&gt; ot2                 0.0  1.0   842 </span>
<span class="co">#&gt; ot3                 0.0  1.0  1156 </span>
<span class="co">#&gt; StudyTimePoint2     0.0  1.0  1034 </span>
<span class="co">#&gt; StudyTimePoint3     0.0  1.0   959 </span>
<span class="co">#&gt; ot1:StudyTimePoint2 0.0  1.0   674 </span>
<span class="co">#&gt; ot1:StudyTimePoint3 0.0  1.0   934 </span>
<span class="co">#&gt; ot2:StudyTimePoint2 0.0  1.0   836 </span>
<span class="co">#&gt; ot2:StudyTimePoint3 0.0  1.0   762 </span>
<span class="co">#&gt; ot3:StudyTimePoint2 0.0  1.0  1183 </span>
<span class="co">#&gt; ot3:StudyTimePoint3 0.0  1.0  1390 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).</span>

<span class="kw">prior_summary</span>(b)
<span class="co">#&gt; Priors for model &#39;b&#39; </span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt; Intercept (after predictors centered)</span>
<span class="co">#&gt;  ~ normal(location = 0, scale = 5)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients</span>
<span class="co">#&gt;  ~ normal(location = [0,0,0,...], scale = [1,1,1,...])</span>
<span class="co">#&gt;      **adjusted scale = [3.33,3.33,3.33,...]</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Covariance</span>
<span class="co">#&gt;  ~ decov(reg. = 2, conc. = 1, shape = 1, scale = 1)</span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt; See help(&#39;prior_summary.stanreg&#39;) for more details</span></code></pre></div>
<p>We used moderately informative priors for the effects of time and</p>
<ul>
<li>b ~ Normal(mean = 0, sd = 1)</li>
</ul>
<p>When we computed the orthogonal polynomial features for Time, they were rescaled so that the linear feature ranged from −.5 to .5. Under this scaling a unit change in Time<sup>1</sup> was equal to change from the start to the end of the analysis window. The polynomial features for the Time had the following ranges:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d_m <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">distinct</span>(ot1, ot2, ot3) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>tidyr<span class="op">::</span><span class="kw">gather</span>(<span class="st">&quot;Feature&quot;</span>, <span class="st">&quot;Value&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Feature) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">Min =</span> <span class="kw">min</span>(Value), <span class="dt">Max =</span> <span class="kw">max</span>(Value), <span class="dt">Range =</span> Max <span class="op">-</span><span class="st"> </span>Min) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate_if</span>(is.numeric, round, <span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Feature =</span> stringr<span class="op">::</span><span class="kw">str_replace</span>(Feature, <span class="st">&quot;ot(</span><span class="ch">\\</span><span class="st">d)&quot;</span>, <span class="st">&quot;Time^</span><span class="ch">\\</span><span class="st">1^&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Feature</th>
<th align="right">Min</th>
<th align="right">Max</th>
<th align="right">Range</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Time<sup>1</sup></td>
<td align="right">-0.50</td>
<td align="right">0.50</td>
<td align="right">1.00</td>
</tr>
<tr class="even">
<td align="left">Time<sup>2</sup></td>
<td align="right">-0.33</td>
<td align="right">0.60</td>
<td align="right">0.93</td>
</tr>
<tr class="odd">
<td align="left">Time<sup>3</sup></td>
<td align="right">-0.63</td>
<td align="right">0.63</td>
<td align="right">1.26</td>
</tr>
</tbody>
</table>
<p>Under the Normal(0, 1) prior, before seeing any data, we expect 95% of plausible effects to fall in the range ±1.96, which is an adequate range for these growth curve models. For example, consider just the effect of Time<sup>1</sup>. If a listener starts at chance performance, 25% or -1.1 logits, and increases to, say, 65% or 0.62, the effect of a unit change in Time<sup>1</sup> would be a change of 1.72 logits. This magnitude of effect is accommodated by our Normal(0, 1) prior.</p>
<p>For the hierarchical part of the model, I used RstanARM’s <code>decov()</code> prior which simultaneously sets a prior of the variances and correlations of the model’s random effect terms. For these terms, I used the default prior for the variance terms and used a weakly informative LKJ(2) prior on the random effect correlations. Under LKJ(1) supports all correlations in the range ±1, but under LKJ(2) extreme correlations are less plausible. In the figure below, we see that the LKJ(2) prior nudges some of the probability mass away from ±1 towards the center. The motivation for this kind of prior was <em>regularization</em>: We give the model a small amount of information to nudge it away from extreme, degenerate values.</p>
<p><img src="12-aim1-notebook_files/figure-html/unnamed-chunk-11-1.png" width="80" /></p>
<p>Let’s try to understand our model by making some plots.</p>
<div id="fixed-effects-plots" class="section level3">
<h3><span class="header-section-number">10.2.1</span> Fixed effects plots</h3>
<p>First, let’s prepare to plot the intervals for the fixed effects.</p>
<p>Figure <a href="analyze-familiar-word-recognition.html#fig:effects2">10.1</a> depicts uncertainty intervals with the model’s average effects of each time-point on the growth curve features. The intercept and time effects increase each year, confirming that children get more reliable and faster at recognizing words as they grow older. For each effect, the change from year 1 to year 2 is approximately the same as the change from year 2 to year 3, as visible in figure <a href="analyze-familiar-word-recognition.html#fig:pairwise-effects">10.2</a>.</p>

<div class="figure"><span id="fig:effects2"></span>
<img src="12-aim1-notebook_files/figure-html/effects2-1.png" alt="Uncertainty intervals for the effects of study timepoints on growth curve features." width="80%" />
<p class="caption">
Figure 10.1: Uncertainty intervals for the effects of study timepoints on growth curve features.
</p>
</div>

<div class="figure"><span id="fig:pairwise-effects"></span>
<img src="12-aim1-notebook_files/figure-html/pairwise-effects-1.png" alt="Uncertainty intervals for the differences between study timepoints." width="80%" />
<p class="caption">
Figure 10.2: Uncertainty intervals for the differences between study timepoints.
</p>
</div>
<p>Bayesplot supports transformations so we could invert the log-odds measure to see the intercepts (area under curve/average accuracy) in proportion units.</p>
<table>
<thead>
<tr class="header">
<th align="left">parameter</th>
<th align="right">outer</th>
<th align="right">inner</th>
<th align="right">ll</th>
<th align="right">l</th>
<th align="right">m</th>
<th align="right">h</th>
<th align="right">hh</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">plogis(Intercept~~(TP1))</td>
<td align="right">0.9</td>
<td align="right">0.5</td>
<td align="right">0.372</td>
<td align="right">0.380</td>
<td align="right">0.385</td>
<td align="right">0.390</td>
<td align="right">0.397</td>
</tr>
<tr class="even">
<td align="left">plogis(Intercept~~(TP2))</td>
<td align="right">0.9</td>
<td align="right">0.5</td>
<td align="right">0.473</td>
<td align="right">0.480</td>
<td align="right">0.485</td>
<td align="right">0.490</td>
<td align="right">0.498</td>
</tr>
<tr class="odd">
<td align="left">plogis(Intercept~~(TP3))</td>
<td align="right">0.9</td>
<td align="right">0.5</td>
<td align="right">0.544</td>
<td align="right">0.551</td>
<td align="right">0.557</td>
<td align="right">0.562</td>
<td align="right">0.569</td>
</tr>
</tbody>
</table>
<p><img src="12-aim1-notebook_files/figure-html/intercepts-1.png" width="60%" /></p>
<p>We can compute differences in average accuracy as well.</p>
<p><img src="12-aim1-notebook_files/figure-html/intercept-differences-1.png" width="60%" /></p>
<p>The average accuracy was 0.385 [90% UI: 0.372–0.397] for timepoint 1, 0.485 [0.473–0.498] for timepoint 2, and 0.557 [0.544–0.569] for timepoint 3. The average accuracy increased by 0.1 [0.087–0.114] from timepoint 1 to timepoint 2 and by 0.072 [0.058–0.085] from timepoint 2 to timepoint 3. These results numerically confirm the hypothesis that children would improve in their accuracy each year over year and in their processing efficiency year over year.</p>
</div>
<div id="plot-the-intervals-for-the-random-effect-parameters" class="section level3">
<h3><span class="header-section-number">10.2.2</span> Plot the intervals for the random effect parameters</h3>
<p>These are the parameters governing the random effect distributions. First, we plot the standard deviations. Recall that in our hierarchical model we suppose that each growth curve is drawn from a population of related curves. The model’s fixed effects estimate the means of the distribution. These terms estimate the variability around that mean. We did not have any a priori hypotheses about the values of these scales, so do not discuss them any further.</p>
<p><img src="12-aim1-notebook_files/figure-html/posterior-sds-1.png" width="80%" /></p>
<p>Then the correlations.</p>
<p><img src="12-aim1-notebook_files/figure-html/posterior-cors-1.png" width="80%" /></p>
</div>
<div id="check-for-stable-individual-differences" class="section level3">
<h3><span class="header-section-number">10.2.3</span> Check for stable individual differences</h3>
<p>We predicted that children would show stable individual differences such that children who are faster and more accurate at recognizing words at age 3 remain relatively faster and more accurate at age 5. To evaluate this hypothesis, we used Kendall’s <em>W</em> (the coefficient of correspondence or concordance). This nonparametric statistic measures the degree of agreement among <em>J</em> judges who are rating <em>I</em> items. For our purposes, the items are the 123 children who provided reliable eyetracking for all three years of the study. (That is, we excluded children who only had reliable eyetracking data for one or two years.) The judges are the sets of growth curve parameters from each year of study. For example, the intercept term provides three sets of ratings: The participants’ intercept terms from year 1 are one set of ratings and the terms from years 2 and 3 provide two more sets of ratings. These three ratings are the “judges” used to compute the intercept’s <em>W</em>. Thus, we compute four sets of <em>W</em> coefficients, one for each set of growth curve features: Intercept, Time<sup>1</sup>, Time<sup>2</sup>, and Time<sup>3</sup>.</p>
<p>(<em>Maybe: Table X illustrates some sample ratings of these participants.</em>)</p>
<table>
<thead>
<tr class="header">
<th align="left">Participant ID</th>
<th align="left">Growth curve feature</th>
<th align="right">Year 1</th>
<th align="right">Year 2</th>
<th align="right">Year 3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">640L</td>
<td align="left">intercept</td>
<td align="right">0.09 (006)</td>
<td align="right">1.78 (001)</td>
<td align="right">1.53 (001)</td>
</tr>
<tr class="even">
<td align="left">040L</td>
<td align="left">intercept</td>
<td align="right">0.02 (009)</td>
<td align="right">0.31 (017)</td>
<td align="right">1.18 (002)</td>
</tr>
<tr class="odd">
<td align="left">080L</td>
<td align="left">intercept</td>
<td align="right">−0.02 (013)</td>
<td align="right">0.77 (005)</td>
<td align="right">1.09 (003)</td>
</tr>
<tr class="even">
<td align="left">037L</td>
<td align="left">intercept</td>
<td align="right">−0.33 (052)</td>
<td align="right">−0.03 (060)</td>
<td align="right">0.95 (004)</td>
</tr>
<tr class="odd">
<td align="left">043L</td>
<td align="left">intercept</td>
<td align="right">0.22 (002)</td>
<td align="right">0.87 (003)</td>
<td align="right">0.94 (005)</td>
</tr>
<tr class="even">
<td align="left">050L</td>
<td align="left">intercept</td>
<td align="right">−0.39 (063)</td>
<td align="right">0.45 (008)</td>
<td align="right">0.92 (006)</td>
</tr>
<tr class="odd">
<td align="left">014L</td>
<td align="left">intercept</td>
<td align="right">−0.06 (015)</td>
<td align="right">0.05 (047)</td>
<td align="right">0.92 (007)</td>
</tr>
<tr class="even">
<td align="left">090L</td>
<td align="left">intercept</td>
<td align="right">−0.10 (019)</td>
<td align="right">−0.20 (088)</td>
<td align="right">0.90 (008)</td>
</tr>
<tr class="odd">
<td align="left">106L</td>
<td align="left">intercept</td>
<td align="right">−0.06 (016)</td>
<td align="right">0.88 (002)</td>
<td align="right">0.86 (009)</td>
</tr>
<tr class="even">
<td align="left">674L</td>
<td align="left">intercept</td>
<td align="right">−0.03 (014)</td>
<td align="right">0.21 (024)</td>
<td align="right">0.79 (010)</td>
</tr>
</tbody>
</table>
<p>Because we used a Bayesian model, we have a distribution of ratings and thus a distribution of concordance statistics. Each sample of the posterior distribution fits a growth curve for each child in each study, so each sample provides a set of ratings for concordance coefficients. The distribution of <em>W</em>’s lets us quantify our uncertainty because we can compute <em>W</em>’s for each of the 4000 samples from the posterior distribution.</p>
<p>One final matter is how do we assess whether a concordance statistic is meaningful. To tackle this question, we also included a “null rater”, a fake parameter that assigned each child in each year a random number. We can use the distribution of <em>W</em>’s generated by randomly rating children as a benchmark for assessing whether the other concordance statistics differ meaningfully from chance.</p>
<p>We used the <code>kendall()</code> function in the <code>irr</code> package (vers. 0.84, CITATION) to compute concordance statistics.</p>

<div class="figure"><span id="fig:kendall-stats"></span>
<img src="12-aim1-notebook_files/figure-html/kendall-stats-1.png" alt="Uncertainty intervals for the Kendall’s coefficient of concordance. Random ratings provide a baseline of null W statistics. The intercept and linear time features are decisively non-null, indicating a significant degree of correspondence in children’s relative word recognition reliability and efficiency over three years of study." width="80%" />
<p class="caption">
Figure 10.3: Uncertainty intervals for the Kendall’s coefficient of concordance. Random ratings provide a baseline of null <em>W</em> statistics. The intercept and linear time features are decisively non-null, indicating a significant degree of correspondence in children’s relative word recognition reliability and efficiency over three years of study.
</p>
</div>
<p>Figure <a href="analyze-familiar-word-recognition.html#fig:kendall-stats">10.3</a> depicts uncertainty intervals for the Kendall <em>W</em>’s for these growth curve features. The 90% uncertainty interval of <em>W</em> statistics from random ratings [0.279–0.392] subsumes the intervals for the Time<sup>2</sup> effect [0.295–0.351] and the Time<sup>3</sup> effect [0.276–0.348], indicating that these values do not differentiate children in a longitudinally stable way. That is, the Time<sup>2</sup> and Time<sup>3</sup> features differentiate children across studies as well as random numbers. Earlier, we stated that only the intercept and linear terms have psychologically meaningful interpretations and that the higher-order terms of these models serve to capture the shape of the growth curve data. These statistics support that assertion.</p>
<p>Concordance is strongest for the intercept term, <em>W</em> = 0.585 [0.573–0.596], followed by the linear time term, <em>W</em> = 0.501 [0.483–0.518]. Because these values are from the statistics for random ratings, we conclude that there is a credible degree of correspondence across studies when we rank children using their average accuracy (the intercept) or their growth curve slope (linear time).</p>
</div>
<div id="summary-of-this-section" class="section level3">
<h3><span class="header-section-number">10.2.4</span> Summary of this section</h3>
<p>Growth curve features reflect individual differences in word recognition efficiency and accuracy. By using Kendall’s <em>W</em> to measure the degree of concordance among growth curve features over time, we can measure whether individual differences in lexical processing are stable over time. We found that the intercept and linear time terms were stable over time.</p>
</div>
<div id="posterior-predictive-checks" class="section level3">
<h3><span class="header-section-number">10.2.5</span> Posterior predictive checks</h3>
<p>Bayesian models are generative; they describe how the data could have been generated. One way to evaluate the model is to have it simulate new observations. If the simulated data closely resembles the observed data, then we have some confidence that our model has learned an approximation of how the data could have been generated. Figure <a href="analyze-familiar-word-recognition.html#fig:post-pred">10.4</a> depicts the density of the observed data from each year of the study versus 200 posterior simulations. Because the simulations closely track the density of the observed data, we can infer that the model has learned how to generate data from each year of the study.</p>

<div class="figure"><span id="fig:post-pred"></span>
<img src="12-aim1-notebook_files/figure-html/post-pred-1.png" alt="Posterior predictive density for the observed data from each year of the study. The x-axis represents the outcome measure—the proportion of looks to the target image—and the y-axis is the density of those values at year. At age 3, there is a large density of looks around chance performance (.25) with a rightward skew (above-chance looks are common). At age 4 and age 5, a bimodal distribution emerges, reflecting how looks start at chance and reliably increase to above-chance performance. Each light line is a simulation of the observed data from the model, and the thick lines are the observed data. Because the thick line is surrounded by light lines, we visually infer that the the model faithfully approximates the observed data." width="80%" />
<p class="caption">
Figure 10.4: Posterior predictive density for the observed data from each year of the study. The <em>x</em>-axis represents the outcome measure—the proportion of looks to the target image—and the <em>y</em>-axis is the density of those values at year. At age 3, there is a large density of looks around chance performance (.25) with a rightward skew (above-chance looks are common). At age 4 and age 5, a bimodal distribution emerges, reflecting how looks start at chance and reliably increase to above-chance performance. Each light line is a simulation of the observed data from the model, and the thick lines are the observed data. Because the thick line is surrounded by light lines, we visually infer that the the model faithfully approximates the observed data.
</p>
</div>
<p>We can ask the model make even more specific posterior predictions. Below we plot the posterior predictions for random participants. This is the model simulating new data for these participants.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">09272017</span>)

ppred &lt;-<span class="st"> </span>d_m <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">sample_n_of</span>(<span class="dv">8</span>, ResearchID) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>tristan<span class="op">::</span><span class="kw">augment_posterior_predict</span>(b, <span class="dt">newdata =</span> ., <span class="dt">nsamples =</span> <span class="dv">100</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">trials =</span> Primary <span class="op">+</span><span class="st"> </span>Others)

<span class="kw">ggplot</span>(ppred) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> Time, <span class="dt">y =</span> Prop, <span class="dt">color =</span> Study, <span class="dt">group =</span> Study) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> .posterior_value <span class="op">/</span><span class="st"> </span>trials, 
                <span class="dt">group =</span> <span class="kw">interaction</span>(.draw, Study)), 
            <span class="dt">alpha =</span> .<span class="dv">20</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">color =</span> <span class="st">&quot;grey50&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="st">&quot;ResearchID&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme</span>(
    <span class="dt">legend.position =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="dv">0</span>), 
    <span class="dt">legend.justification =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>),
    <span class="dt">legend.margin =</span> <span class="kw">margin</span>(<span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">guides</span>(<span class="dt">color =</span> <span class="kw">guide_legend</span>(<span class="dt">title =</span> <span class="ot">NULL</span>, <span class="dt">override.aes =</span> <span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">1</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">title =</span> <span class="st">&quot;Observed means and 100 simulations of new data&quot;</span>,
    <span class="dt">x =</span> <span class="st">&quot;Time after target onset&quot;</span>,
    <span class="dt">y =</span> <span class="st">&quot;Proportion looks to target&quot;</span>) </code></pre></div>
<p><img src="12-aim1-notebook_files/figure-html/posterior-lines-1.png" width="100%" /></p>
<p>Or we can plot the linear predictions. These are posterior predictions of the log-odds of looking to target before adding binomial noise.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lpred &lt;-<span class="st"> </span>d_m <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">sample_n_of</span>(<span class="dv">8</span>, ResearchID) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>tristan<span class="op">::</span><span class="kw">augment_posterior_linpred</span>(b, <span class="dt">newdata =</span> ., <span class="dt">nsamples =</span> <span class="dv">100</span>)

<span class="kw">ggplot</span>(lpred) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> Time, <span class="dt">y =</span> .posterior_value, <span class="dt">color =</span> Study) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> <span class="kw">interaction</span>(Study, ResearchID, .draw)), 
            <span class="dt">alpha =</span> .<span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="st">&quot;ResearchID&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="kw">qlogis</span>(Prop)), <span class="dt">shape =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme</span>(
    <span class="dt">legend.position =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="dv">0</span>), 
    <span class="dt">legend.justification =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>),
    <span class="dt">legend.margin =</span> <span class="kw">margin</span>(<span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">guides</span>(<span class="dt">color =</span> <span class="kw">guide_legend</span>(<span class="dt">title =</span> <span class="ot">NULL</span>, <span class="dt">override.aes =</span> <span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">1</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">title =</span> <span class="st">&quot;Observed data and 100 posterior predictions&quot;</span>,
    <span class="dt">x =</span> <span class="st">&quot;Time after target onset&quot;</span>,
    <span class="dt">y =</span> <span class="st">&quot;Posterior log-odds&quot;</span>)</code></pre></div>
<p><img src="12-aim1-notebook_files/figure-html/posterior-mean-lines-1.png" width="100%" /></p>
</div>
<div id="simulating-data-from-new-participants" class="section level3">
<h3><span class="header-section-number">10.2.6</span> Simulating data from new participants</h3>
<p>This mixed effects model assumes that the each child’s growth curve is drawn from a distribution of related growth curves, and it tries to infer the parameters of that distribution of growth curves (like the scale of individual differences in the intercept term or the correlation among growth curve features). A natural next step is to ask the model to simulate new samples from that distribution of growth curves: That is, predict new data for a hypothetical, unobserved child drawn from the same distribution as the <code>N CHILDREN</code> observed children.This procedure lets us explore the range of variability in performance at each age.</p>
<p>Figure <a href="analyze-familiar-word-recognition.html#fig:new-participants">10.5</a> shows the posterior predictions for 1,000 simulated participants, which demonstrates how the model expects new participants to improve longitudinally but also exhibit stable individual differences over time. Figure <a href="analyze-familiar-word-recognition.html#fig:new-participants-intervals">10.6</a> shows uncertainty intervals for these simulations. The model has learned to predict less accurate and more variable performance at age 3 with improving accuracy and narrowing variability at age 4 and age 5.</p>

<div class="figure"><span id="fig:new-participants"></span>
<img src="12-aim1-notebook_files/figure-html/new-participants-1.png" alt="Posterior predictions for new unobserved participants. Each line represents the predicted performance for a new participant. The three dark lines highlight predictions from one single simulated participant. The simulated participant shows both longitudinal improvement in word recognition and similar relative performance compared to other simulations each year, indicating that the model would predict new children to improve year over year and show stable individual differences over time." width="80%" />
<p class="caption">
Figure 10.5: Posterior predictions for new <em>unobserved</em> participants. Each line represents the predicted performance for a new participant. The three dark lines highlight predictions from one single simulated participant. The simulated participant shows both longitudinal improvement in word recognition and similar relative performance compared to other simulations each year, indicating that the model would predict new children to improve year over year and show stable individual differences over time.
</p>
</div>

<div class="figure"><span id="fig:new-participants-intervals"></span>
<img src="12-aim1-notebook_files/figure-html/new-participants-intervals-1.png" alt="Uncertainty intervals for the simulated participants. Variability is widest at age 3 and narrowest at age 5, consistent with the prediction that children become less variable as they grow older." width="80%" />
<p class="caption">
Figure 10.6: Uncertainty intervals for the simulated participants. Variability is widest at age 3 and narrowest at age 5, consistent with the prediction that children become less variable as they grow older.
</p>
</div>
<p>One of the predictions was that children would become less variable as they grew older and converge on a mature level of performance. We can tackle this question by inspecting the ranges of predictions for the simulated participants. The claim that children become less variable would imply that the range of predictions should be narrower age 5 than for age 4 than age 3. Figure <a href="analyze-familiar-word-recognition.html#fig:new-ranges">10.7</a> depicts the range of the predictions, both in terms of the 90 percentile range (i.e., the range of the middle 90% of the data) and in terms of the 50 percentile (interquartile) range. The ranges of performance decrease from age 3 to age 4 to age 5, consistent with the hypothesized reduction in variability.</p>

<div class="figure"><span id="fig:new-ranges"></span>
<img src="12-aim1-notebook_files/figure-html/new-ranges-1.png" alt="Ranges of predictions for simulated participants over the course of a trial. The ranges are most similar during the first half of the trial when participants are at chance performance, and the ranges are most different at the end of the trial as children reliably fixate on the target image. The ranges of performance decreases with each year of the study as children show less variability." width="80%" />
<p class="caption">
Figure 10.7: Ranges of predictions for simulated participants over the course of a trial. The ranges are most similar during the first half of the trial when participants are at chance performance, and the ranges are most different at the end of the trial as children reliably fixate on the target image. The ranges of performance decreases with each year of the study as children show less variability.
</p>
</div>
</div>
<div id="predicting-the-future" class="section level3">
<h3><span class="header-section-number">10.2.7</span> Predicting the future</h3>
<p>We predicted that individual differences in word recognition at age 3 will be more discriminating and predictive future language outcomes than differences at age 4 or age 5. To test this hypothesis, we calculated the correlations of growth curve features with year 3 expressive vocabulary size and year 2 receptive vocabulary. (The receptive test was not administered during year 3 for logistical reasons). As with the concordance statistics, we computed each of the statistics for each sample of the posterior distribution so we obtained a distribution of correlations.</p>
<p>Figure <a href="analyze-familiar-word-recognition.html#fig:evt2-gca-cors">10.8</a> shows the correlations of the intercept and linear time features with expressive vocabulary size at year 3, and Figure <a href="analyze-familiar-word-recognition.html#fig:ppvt4-gca-cors">10.9</a> shows analagous correlations for the receptive vocabulary at year 2. For both cases, the strongest correlations were found between the growth curve features at year 1. Lexical processing efficiency at year 1 correlated with year 3 vocabulary with <em>r</em> = .413, 90% UI [0.389–0.438], whereas the concurrent lexical processing feature at year 3 only showed a correlation of <em>r</em> = .283, [0.259–0.306], a difference between year 1 and year 3 of <em>r</em><sub>TP1−TP3</sub> = .13, [0.097–0.164]. For the intercept feature, the correlation for year 1, <em>r</em> = .391, [0.389–0.438], was probably only slightly greater than the correlation for year 2, <em>r</em><sub>TP1−TP2</sub> = .018, [-0.005–0.042] but much considerably greater than the concurrent correlation at year 3, <em>r</em><sub>TP1−TP3</sub> = .077, [0.054–0.099]. For year 2 receptive vocabulary, the correlation of year 1 intercept, <em>r</em>  = .454, [0.437–0.47], was greater than the year 2 correlation, <em>r</em><sub>TP1−TP2</sub> = .084, [.084], and the correlation for year 1 linear time, <em>r</em> = .514, [0.492–0.538], was likewise greater than the year 2 correlation, <em>r</em><sub>TP1−TP2</sub> = .225, [0.192–0.257].</p>

<div class="figure"><span id="fig:evt2-gca-cors"></span>
<img src="12-aim1-notebook_files/figure-html/evt2-gca-cors-1.png" alt="Uncertainty intervals for the correlations of growth curve features at each time point with expressive vocabulary (EVT2 standard scores) at year 3. The bottom rows provide intervals for the pairwise differences in correlations between time points." width="80%" />
<p class="caption">
Figure 10.8: Uncertainty intervals for the correlations of growth curve features at each time point with expressive vocabulary (EVT2 standard scores) at year 3. The bottom rows provide intervals for the pairwise differences in correlations between time points.
</p>
</div>

<div class="figure"><span id="fig:ppvt4-gca-cors"></span>
<img src="12-aim1-notebook_files/figure-html/ppvt4-gca-cors-1.png" alt="Uncertainty intervals for the correlations of growth curve features at each time point with expressive vocabulary (PPVT4 standard scores) at year 2. The bottom row shows pairwise differences between the correlations at year 1 and year 2." width="80%" />
<p class="caption">
Figure 10.9: Uncertainty intervals for the correlations of growth curve features at each time point with expressive vocabulary (PPVT4 standard scores) at year 2. The bottom row shows pairwise differences between the correlations at year 1 and year 2.
</p>
</div>
</div>
<div id="relationship-with-child-level-variables" class="section level3">
<h3><span class="header-section-number">10.2.8</span> Relationship with child-level variables</h3>
<blockquote>
<p>Vocabulary size and lexical processing will be tightly correlated such that large year-over-year gains in one measure will predict large year-over-years gains in the other measure.</p>
</blockquote>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="prepare-and-explore-the-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="visualize-looks-to-each-image-type.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["dissertation.pdf", "dissertation.epub", "dissertation.docx"],
"toc": {
"collapse": "subsection"
},
"split_bib": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
