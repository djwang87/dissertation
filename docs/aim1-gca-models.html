<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Development of word recognition in preschoolers</title>
  <meta name="description" content="Development of word recognition in preschoolers">
  <meta name="generator" content="bookdown 0.7.12 and GitBook 2.6.7">

  <meta property="og:title" content="Development of word recognition in preschoolers" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="assets/cover.png" />
  
  <meta name="github-repo" content="tjmahr/dissertation" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Development of word recognition in preschoolers" />
  
  
  <meta name="twitter:image" content="assets/cover.png" />

<meta name="author" content="Tristan Mahr">


<meta name="date" content="2018-07-24">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="vw-experiment-items.html">
<link rel="next" href="mp-experiment-items.html">
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="assets\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="dedication.html"><a href="dedication.html"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="1" data-path="specific-aims.html"><a href="specific-aims.html"><i class="fa fa-check"></i><b>1</b> Specific aims</a><ul>
<li class="chapter" data-level="1.1" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>1.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="1.2" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>1.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="1.3" data-path="specific-aims.html"><a href="specific-aims.html#summary"><i class="fa fa-check"></i><b>1.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="research-hypotheses.html"><a href="research-hypotheses.html"><i class="fa fa-check"></i><b>2</b> Research hypotheses</a><ul>
<li class="chapter" data-level="2.1" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-1-familiar-word-recognition-and-lexical-competition-1"><i class="fa fa-check"></i><b>2.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="2.2" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-2-referent-selection-and-mispronunciations-1"><i class="fa fa-check"></i><b>2.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
</ul></li>
<li class="part"><span><b>Aim 1: Familiar Word Recognition and Lexical Competition</b></span></li>
<li class="chapter" data-level="3" data-path="aim1-introduction.html"><a href="aim1-introduction.html"><i class="fa fa-check"></i><b>3</b> Familiar word recognition</a><ul>
<li class="chapter" data-level="3.1" data-path="aim1-introduction.html"><a href="aim1-introduction.html#lexical-processing-dynamics"><i class="fa fa-check"></i><b>3.1</b> Lexical processing dynamics</a></li>
<li class="chapter" data-level="3.2" data-path="aim1-introduction.html"><a href="aim1-introduction.html#individual-differences-in-word-recognition"><i class="fa fa-check"></i><b>3.2</b> Individual differences in word recognition</a></li>
<li class="chapter" data-level="3.3" data-path="aim1-introduction.html"><a href="aim1-introduction.html#the-current-study"><i class="fa fa-check"></i><b>3.3</b> The current study</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="aim1-method.html"><a href="aim1-method.html"><i class="fa fa-check"></i><b>4</b> Method</a><ul>
<li class="chapter" data-level="4.1" data-path="aim1-method.html"><a href="aim1-method.html#aim1-participants"><i class="fa fa-check"></i><b>4.1</b> Participants</a></li>
<li class="chapter" data-level="4.2" data-path="aim1-method.html"><a href="aim1-method.html#aim1-procedure"><i class="fa fa-check"></i><b>4.2</b> Visual World Paradigm</a></li>
<li class="chapter" data-level="4.3" data-path="aim1-method.html"><a href="aim1-method.html#experiment-administration"><i class="fa fa-check"></i><b>4.3</b> Experiment administration</a></li>
<li class="chapter" data-level="4.4" data-path="aim1-method.html"><a href="aim1-method.html#stimuli"><i class="fa fa-check"></i><b>4.4</b> Stimuli</a></li>
<li class="chapter" data-level="4.5" data-path="aim1-method.html"><a href="aim1-method.html#data-screening"><i class="fa fa-check"></i><b>4.5</b> Data screening</a></li>
<li class="chapter" data-level="4.6" data-path="aim1-method.html"><a href="aim1-method.html#model-preparation"><i class="fa fa-check"></i><b>4.6</b> Model preparation</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="fam-rec.html"><a href="fam-rec.html"><i class="fa fa-check"></i><b>5</b> Analysis of familiar word recognition</a><ul>
<li class="chapter" data-level="5.1" data-path="fam-rec.html"><a href="fam-rec.html#growth-curve-analysis"><i class="fa fa-check"></i><b>5.1</b> Growth curve analysis</a><ul>
<li class="chapter" data-level="5.1.1" data-path="fam-rec.html"><a href="fam-rec.html#growth-curve-features-as-measures-of-word-recognition-performance"><i class="fa fa-check"></i><b>5.1.1</b> Growth curve features as measures of word recognition performance</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="fam-rec.html"><a href="fam-rec.html#year-over-year-changes-in-word-recognition-performance"><i class="fa fa-check"></i><b>5.2</b> Year over year changes in word recognition performance</a></li>
<li class="chapter" data-level="5.3" data-path="fam-rec.html"><a href="fam-rec.html#exploring-plausible-ranges-of-performance-over-time"><i class="fa fa-check"></i><b>5.3</b> Exploring plausible ranges of performance over time</a></li>
<li class="chapter" data-level="5.4" data-path="fam-rec.html"><a href="fam-rec.html#are-individual-differences-stable-over-time"><i class="fa fa-check"></i><b>5.4</b> Are individual differences stable over time?</a></li>
<li class="chapter" data-level="5.5" data-path="fam-rec.html"><a href="fam-rec.html#predicting-future-vocabulary-size"><i class="fa fa-check"></i><b>5.5</b> Predicting future vocabulary size</a></li>
<li class="chapter" data-level="5.6" data-path="fam-rec.html"><a href="fam-rec.html#discussion"><i class="fa fa-check"></i><b>5.6</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lex-competitors.html"><a href="lex-competitors.html"><i class="fa fa-check"></i><b>6</b> Effects of phonological and semantic competitors</a><ul>
<li class="chapter" data-level="6.1" data-path="lex-competitors.html"><a href="lex-competitors.html#looks-to-the-phonological-competitor"><i class="fa fa-check"></i><b>6.1</b> Looks to the phonological competitor</a></li>
<li class="chapter" data-level="6.2" data-path="lex-competitors.html"><a href="lex-competitors.html#looks-to-the-semantic-competitor"><i class="fa fa-check"></i><b>6.2</b> Looks to the semantic competitor</a></li>
<li class="chapter" data-level="6.3" data-path="lex-competitors.html"><a href="lex-competitors.html#child-level-differences-in-competitor-sensitivity-at-age-3"><i class="fa fa-check"></i><b>6.3</b> Child-level differences in competitor sensitivity at age 3</a></li>
<li class="chapter" data-level="6.4" data-path="lex-competitors.html"><a href="lex-competitors.html#discussion-1"><i class="fa fa-check"></i><b>6.4</b> Discussion</a><ul>
<li class="chapter" data-level="6.4.1" data-path="lex-competitors.html"><a href="lex-competitors.html#immediate-activation-of-phonological-neighbors"><i class="fa fa-check"></i><b>6.4.1</b> Immediate activation of phonological neighbors</a></li>
<li class="chapter" data-level="6.4.2" data-path="lex-competitors.html"><a href="lex-competitors.html#late-activation-of-semantic-neighbors"><i class="fa fa-check"></i><b>6.4.2</b> Late activation of semantic neighbors</a></li>
<li class="chapter" data-level="6.4.3" data-path="lex-competitors.html"><a href="lex-competitors.html#lexical-competitors-and-child-level-predictors"><i class="fa fa-check"></i><b>6.4.3</b> Lexical competitors and child-level predictors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="aim1-discussion.html"><a href="aim1-discussion.html"><i class="fa fa-check"></i><b>7</b> General discussion</a><ul>
<li class="chapter" data-level="7.1" data-path="aim1-discussion.html"><a href="aim1-discussion.html#how-to-improve-word-recognition"><i class="fa fa-check"></i><b>7.1</b> How to improve word recognition</a></li>
<li class="chapter" data-level="7.2" data-path="aim1-discussion.html"><a href="aim1-discussion.html#learn-words-and-learn-connections-between-words"><i class="fa fa-check"></i><b>7.2</b> Learn words and learn connections between words</a></li>
<li class="chapter" data-level="7.3" data-path="aim1-discussion.html"><a href="aim1-discussion.html#individual-differences-are-most-important-at-younger-ages"><i class="fa fa-check"></i><b>7.3</b> Individual differences are most important at younger ages</a></li>
<li class="chapter" data-level="7.4" data-path="aim1-discussion.html"><a href="aim1-discussion.html#limitations-and-implications"><i class="fa fa-check"></i><b>7.4</b> Limitations and implications</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="aim1-h-check.html"><a href="aim1-h-check.html"><i class="fa fa-check"></i><b>8</b> Hypothesis check (Specific Aim 1)</a></li>
<li class="part"><span><b>Aim 2: Referent Selection and Mispronunciations</b></span></li>
<li class="chapter" data-level="9" data-path="aim2-method.html"><a href="aim2-method.html"><i class="fa fa-check"></i><b>9</b> Method</a><ul>
<li class="chapter" data-level="9.1" data-path="aim2-method.html"><a href="aim2-method.html#mispronunciation-task"><i class="fa fa-check"></i><b>9.1</b> Mispronunciation task</a></li>
<li class="chapter" data-level="9.2" data-path="aim2-method.html"><a href="aim2-method.html#visual-stimuli"><i class="fa fa-check"></i><b>9.2</b> Visual stimuli</a></li>
<li class="chapter" data-level="9.3" data-path="aim2-method.html"><a href="aim2-method.html#novel-word-retention-tests"><i class="fa fa-check"></i><b>9.3</b> Novel word retention tests</a></li>
<li class="chapter" data-level="9.4" data-path="aim2-method.html"><a href="aim2-method.html#aim2-screening"><i class="fa fa-check"></i><b>9.4</b> Data screening</a><ul>
<li class="chapter" data-level="9.4.1" data-path="aim2-method.html"><a href="aim2-method.html#classifying-trials-based-on-initial-fixation-location"><i class="fa fa-check"></i><b>9.4.1</b> Classifying trials based on initial fixation location</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="aim2-method.html"><a href="aim2-method.html#model-preparation-1"><i class="fa fa-check"></i><b>9.5</b> Model preparation</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="real-nonword-selection.html"><a href="real-nonword-selection.html"><i class="fa fa-check"></i><b>10</b> Development of referent selection</a><ul>
<li class="chapter" data-level="10.1" data-path="real-nonword-selection.html"><a href="real-nonword-selection.html#nonwords-versus-familiar-words"><i class="fa fa-check"></i><b>10.1</b> Nonwords versus familiar words</a></li>
<li class="chapter" data-level="10.2" data-path="real-nonword-selection.html"><a href="real-nonword-selection.html#does-age-3-referent-selection-better-predict-age-5-vocabulary"><i class="fa fa-check"></i><b>10.2</b> Does age 3 referent selection better predict age 5 vocabulary?</a></li>
<li class="chapter" data-level="10.3" data-path="real-nonword-selection.html"><a href="real-nonword-selection.html#discussion-2"><i class="fa fa-check"></i><b>10.3</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html"><i class="fa fa-check"></i><b>11</b> Sensitivity to mispronunciations</a><ul>
<li class="chapter" data-level="11.1" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#unfamiliar-initial-trials-move-along-now"><i class="fa fa-check"></i><b>11.1</b> Unfamiliar-initial trials: Move along now</a><ul>
<li class="chapter" data-level="11.1.1" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#child-level-predictors"><i class="fa fa-check"></i><b>11.1.1</b> Child-level predictors</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#familiar-initial-trials-should-i-stay-or-should-i-go"><i class="fa fa-check"></i><b>11.2</b> Familiar-initial trials: Should I stay or should I go?</a><ul>
<li class="chapter" data-level="11.2.1" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#child-level-predictors-and-different-listening-behaviors"><i class="fa fa-check"></i><b>11.2.1</b> Child-level predictors and different listening behaviors</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#looking-behaviors-and-word-learning"><i class="fa fa-check"></i><b>11.3</b> Looking behaviors and word learning</a></li>
<li class="chapter" data-level="11.4" data-path="sensitivity-to-mispronunciations.html"><a href="sensitivity-to-mispronunciations.html#discussion-3"><i class="fa fa-check"></i><b>11.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="aim2-discussion.html"><a href="aim2-discussion.html"><i class="fa fa-check"></i><b>12</b> General discussion</a><ul>
<li class="chapter" data-level="12.1" data-path="aim2-discussion.html"><a href="aim2-discussion.html#a-lexical-processing-account-of-the-findings"><i class="fa fa-check"></i><b>12.1</b> A lexical processing account of the findings</a></li>
<li class="chapter" data-level="12.2" data-path="aim2-discussion.html"><a href="aim2-discussion.html#limitations-and-implications-1"><i class="fa fa-check"></i><b>12.2</b> Limitations and implications</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="aim2-h-check.html"><a href="aim2-h-check.html"><i class="fa fa-check"></i><b>13</b> Hypothesis check (Specific Aim 2)</a></li>
<li class="chapter" data-level="14" data-path="part-afterword.html"><a href="part-afterword.html"><i class="fa fa-check"></i><b>14</b> (PART*) Afterword</a></li>
<li class="chapter" data-level="15" data-path="a-needle-in-a-self-organizing-haystack.html"><a href="a-needle-in-a-self-organizing-haystack.html"><i class="fa fa-check"></i><b>15</b> A needle in a self-organizing haystack</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="vw-experiment-items.html"><a href="vw-experiment-items.html"><i class="fa fa-check"></i><b>A</b> Items used in the visual world experiment</a></li>
<li class="chapter" data-level="B" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html"><i class="fa fa-check"></i><b>B</b> Computational details for Specific Aim 1</a><ul>
<li class="chapter" data-level="B.1" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#growth-curve-analyses"><i class="fa fa-check"></i><b>B.1</b> Growth curve analyses</a></li>
<li class="chapter" data-level="B.2" data-path="aim1-gca-models.html"><a href="aim1-gca-models.html#generalized-additive-models"><i class="fa fa-check"></i><b>B.2</b> Generalized additive models</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="mp-experiment-items.html"><a href="mp-experiment-items.html"><i class="fa fa-check"></i><b>C</b> Items used in the mispronunciation experiment</a></li>
<li class="chapter" data-level="D" data-path="aim2-gca-models.html"><a href="aim2-gca-models.html"><i class="fa fa-check"></i><b>D</b> Computational details for Specific Aim 2</a><ul>
<li class="chapter" data-level="D.1" data-path="aim2-gca-models.html"><a href="aim2-gca-models.html#real-words-versus-nonwords-growth-curves"><i class="fa fa-check"></i><b>D.1</b> Real words versus nonwords growth curves</a></li>
<li class="chapter" data-level="D.2" data-path="aim2-gca-models.html"><a href="aim2-gca-models.html#mispronunication-growth-curves"><i class="fa fa-check"></i><b>D.2</b> Mispronunication growth curves</a></li>
<li class="chapter" data-level="D.3" data-path="aim2-gca-models.html"><a href="aim2-gca-models.html#item-response-analysis-for-novel-word-retention"><i class="fa fa-check"></i><b>D.3</b> Item-response analysis for novel word retention</a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="aim2-mp-items.html"><a href="aim2-mp-items.html"><i class="fa fa-check"></i><b>E</b> Effects of specific mispronunciations</a></li>
<li class="chapter" data-level="F" data-path="related-work.html"><a href="related-work.html"><i class="fa fa-check"></i><b>F</b> Related work</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Created with bookdown</a></li>
<li><a href="https://tjmahr.github.io/" target="blank">Tristan Mahr</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Development of word recognition in preschoolers</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="aim1-gca-models" class="section level1">
<h1><span class="header-section-number">B</span> Computational details for Specific Aim 1</h1>
<div id="growth-curve-analyses" class="section level2">
<h2><span class="header-section-number">B.1</span> Growth curve analyses</h2>
<p>These models were fit in R <span class="citation">(vers. 3.4.3; R Core Team, <a href="#ref-R-base">2018</a>)</span> with the RStanARM package <span class="citation">(vers. 2.16.3; Gabry &amp; Goodrich, <a href="#ref-R-rstanarm">2018</a>)</span>.</p>
<p>When I computed the orthogonal polynomial features for Time, they were scaled so that the linear feature ranged from −.5 to .5. Under this scaling a unit change in Time<sup>1</sup> was equal to change from the start to the end of the analysis window. Table <a href="#tab:poly-feature-range"><strong>??</strong></a> shows the ranges of the time features.</p>
<table>
<caption><span id="tab:poly-feature-ranges">Table B.1: </span>Ranges of the polynomial time features.</caption>
<thead>
<tr class="header">
<th align="left">Feature</th>
<th align="right">Min</th>
<th align="right">Max</th>
<th align="right">Range</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Time<sup>1</sup></td>
<td align="right">−0.50</td>
<td align="right">0.50</td>
<td align="right">1.00</td>
</tr>
<tr class="even">
<td align="left">Time<sup>2</sup></td>
<td align="right">−0.33</td>
<td align="right">0.60</td>
<td align="right">0.93</td>
</tr>
<tr class="odd">
<td align="left">Time<sup>3</sup></td>
<td align="right">−0.63</td>
<td align="right">0.63</td>
<td align="right">1.26</td>
</tr>
<tr class="even">
<td align="left">Trial window (ms)</td>
<td align="right">250.00</td>
<td align="right">1500.00</td>
<td align="right">1250.00</td>
</tr>
</tbody>
</table>
<p>It took approximately 24 hours to run the model on four Monte Carlo sampling chains with 1000 warm-up iterations and 1000 sampling iterations. Warm-up iterations are discarded, so the model comprises 4000 samples from the posterior distribution.</p>
<p>The code used to fit the model with RStanARM is printed below. The variables <code>ot1</code>, <code>ot2</code>, and <code>ot3</code> are the polynomial time features, <code>ResearchID</code> identifies children, and <code>Study</code> identifies the age/year of the study. <code>Primary</code> counts the number of looks to the target image at each time bin; <code>Others</code> counts looks to the other three images. <code>cbind(Primary, Others)</code> is used to package both counts together for a logistic regression.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rstanarm)

<span class="co"># Run chains on different cores</span>
<span class="kw">options</span>(<span class="dt">mc.cores =</span> parallel<span class="op">::</span><span class="kw">detectCores</span>())

m &lt;-<span class="st"> </span><span class="kw">stan_glmer</span>(
  <span class="kw">cbind</span>(Primary, Others) <span class="op">~</span>
<span class="st">    </span>(ot1 <span class="op">+</span><span class="st"> </span>ot2 <span class="op">+</span><span class="st"> </span>ot3) <span class="op">*</span><span class="st"> </span>Study <span class="op">+</span>
<span class="st">    </span>(ot1 <span class="op">+</span><span class="st"> </span>ot2 <span class="op">+</span><span class="st"> </span>ot3 <span class="op">|</span><span class="st"> </span>ResearchID<span class="op">/</span>Study),
  <span class="dt">family =</span> binomial,
  <span class="dt">prior =</span> <span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>),
  <span class="dt">prior_intercept =</span> <span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>),
  <span class="dt">prior_covariance =</span> <span class="kw">decov</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>),
  <span class="dt">data =</span> d_m)

<span class="co"># Save the output</span>
readr<span class="op">::</span><span class="kw">write_rds</span>(m, <span class="st">&quot;./data/stan_aim1_cubic_model.rds.gz&quot;</span>)</code></pre></div>
<p>The code <code>cbind(Primary, Others) ~ (ot1 + ot2 + ot3) * Study</code> fits a cubic growth curve for each year of the study. It uses R’s formula syntax to regress the looking counts onto an intercept term (implicitly included by default), <code>ot1</code>, <code>ot2</code>, <code>ot3</code> along with the interactions of the <code>Study</code> variable with the intercept, <code>ot1</code>, <code>ot2</code>, and <code>ot3</code>.</p>
<p>The line <code>(ot1 + ot2 + ot3 | ResearchID/Study)</code> describes the random-effect structure of the model with the <code>/</code> indicating that data from each <code>Study</code> is nested within each <code>ResearchID</code>. Thus, for each child, we have a general intercept and general effects for Time<sup>1</sup>, Time<sup>2</sup>, and Time<sup>3</sup>. These child-level effects are further adjusted using <code>Study:ResearchID</code> effects. The effects in each level are allowed to correlate. For example, I would expect that participants with low average looking probabilities (low intercepts) to have flatter growth curves (low Time<sup>1</sup> effects), and this relationship would be captured by one of the random-effect correlation terms.</p>
<p>Printing the model object reports the point estimates of the model fixed effects and point-estimate correlation matrices for the random effects.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(m, <span class="dt">digits =</span> <span class="dv">2</span>)
<span class="co">#&gt; stan_glmer</span>
<span class="co">#&gt;  family:       binomial [logit]</span>
<span class="co">#&gt;  formula:      cbind(Primary, Others) ~ (ot1 + ot2 + ot3) * Study + (ot1 + ot2 + </span>
<span class="co">#&gt;     ot3 | ResearchID/Study)</span>
<span class="co">#&gt;  observations: 12584</span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt;                     Median MAD_SD</span>
<span class="co">#&gt; (Intercept)         -0.47   0.03 </span>
<span class="co">#&gt; ot1                  1.57   0.06 </span>
<span class="co">#&gt; ot2                  0.05   0.04 </span>
<span class="co">#&gt; ot3                 -0.18   0.03 </span>
<span class="co">#&gt; StudyTimePoint2      0.41   0.03 </span>
<span class="co">#&gt; StudyTimePoint3      0.70   0.04 </span>
<span class="co">#&gt; ot1:StudyTimePoint2  0.56   0.08 </span>
<span class="co">#&gt; ot1:StudyTimePoint3  1.10   0.08 </span>
<span class="co">#&gt; ot2:StudyTimePoint2 -0.16   0.05 </span>
<span class="co">#&gt; ot2:StudyTimePoint3 -0.35   0.05 </span>
<span class="co">#&gt; ot3:StudyTimePoint2 -0.12   0.04 </span>
<span class="co">#&gt; ot3:StudyTimePoint3 -0.21   0.04 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Error terms:</span>
<span class="co">#&gt;  Groups           Name        Std.Dev. Corr             </span>
<span class="co">#&gt;  Study:ResearchID (Intercept) 0.3054                    </span>
<span class="co">#&gt;                   ot1         0.6914    0.20            </span>
<span class="co">#&gt;                   ot2         0.4367   -0.11  0.02      </span>
<span class="co">#&gt;                   ot3         0.2938   -0.11 -0.44 -0.06</span>
<span class="co">#&gt;  ResearchID       (Intercept) 0.2635                    </span>
<span class="co">#&gt;                   ot1         0.4228    0.78            </span>
<span class="co">#&gt;                   ot2         0.1251   -0.75 -0.56      </span>
<span class="co">#&gt;                   ot3         0.0576   -0.23 -0.31  0.19</span>
<span class="co">#&gt; Num. levels: Study:ResearchID 484, ResearchID 195 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Sample avg. posterior predictive distribution of y:</span>
<span class="co">#&gt;          Median MAD_SD</span>
<span class="co">#&gt; mean_PPD 49.86   0.06 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt; For info on the priors used see help(&#39;prior_summary.stanreg&#39;).</span></code></pre></div>
<p>The model used the following priors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prior_summary</span>(m)
<span class="co">#&gt; Priors for model &#39;m&#39; </span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt; Intercept (after predictors centered)</span>
<span class="co">#&gt;  ~ normal(location = 0, scale = 5)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients</span>
<span class="co">#&gt;  ~ normal(location = [0,0,0,...], scale = [1,1,1,...])</span>
<span class="co">#&gt;      **adjusted scale = [3.33,3.33,3.33,...]</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Covariance</span>
<span class="co">#&gt;  ~ decov(reg. = 2, conc. = 1, shape = 1, scale = 1)</span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt; See help(&#39;prior_summary.stanreg&#39;) for more details</span></code></pre></div>
<p>The priors for the intercept and regression coefficients are wide, very weakly informative normal distributions. These distributions are centered at 0, so negative and positive effects are equally likely. The intercept distribution as a standard deviation of 5, and the coefficients have a standard deviation of around 3. On the log-odds scale, 95% looking to target would be 2.94, so effects of this magnitude are easily accommodated by distributions like Normal(0 [mean], 3 [SD]) and Normal(0, 5).</p>
<p>For the random-effect part of the model, I used RStanARM’s <code>decov()</code> prior which simultaneously sets a prior on the variances and correlations of the model’s random effect terms. I used the default prior for the variance terms and applied a weakly informative LKJ(2) prior on the random-effect correlations. Figure <a href="aim1-gca-models.html#fig:lkj-prior">B.1</a> shows samples from the prior distribution of two dummy models fit with the default LKJ(1) prior and the weakly informative LKJ(2) prior used here. Under LKJ(2), extreme correlations are less plausible; the prior shifts the probability mass away from the ±1 boundaries towards the center. The motivation for this kind of prior was <em>regularization</em>: I give the model a small amount of information to nudge it away from extreme, degenerate values.</p>

<div class="figure" style="text-align: center"><span id="fig:lkj-prior"></span>
<img src="92-app-aim1-models_files/figure-html/lkj-prior-1.png" alt="Samples of correlation effects drawn from LKJ(1) and LKJ(2) priors." width="50%" />
<p class="caption">
Figure B.1: Samples of correlation effects drawn from <em>LKJ</em>(1) and <em>LKJ</em>(2) priors.
</p>
</div>
<p>Summary of the familiar word recognition model with diagnostics and 90% uncertainty intervals:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># the last 20 column names are the random effects</span>
ranef_names &lt;-<span class="st"> </span><span class="kw">tail</span>(<span class="kw">colnames</span>(<span class="kw">as_tibble</span>(m)), <span class="dv">20</span>)

<span class="kw">summary</span>(
  <span class="dt">object =</span> m, 
  <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, ranef_names),
  <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">05</span>, .<span class="dv">95</span>),
  <span class="dt">digits =</span> <span class="dv">3</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Model Info:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  function:     stan_glmer</span>
<span class="co">#&gt;  family:       binomial [logit]</span>
<span class="co">#&gt;  formula:      cbind(Primary, Others) ~ (ot1 + ot2 + ot3) * Study + (ot1 + ot2 + </span>
<span class="co">#&gt;     ot3 | ResearchID/Study)</span>
<span class="co">#&gt;  algorithm:    sampling</span>
<span class="co">#&gt;  priors:       see help(&#39;prior_summary&#39;)</span>
<span class="co">#&gt;  sample:       4000 (posterior sample size)</span>
<span class="co">#&gt;  observations: 12584</span>
<span class="co">#&gt;  groups:       Study:ResearchID (484), ResearchID (195)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Estimates:</span>
<span class="co">#&gt;                                                   mean   sd     5%     95% </span>
<span class="co">#&gt; (Intercept)                                     -0.469  0.032 -0.523 -0.419</span>
<span class="co">#&gt; ot1                                              1.575  0.066  1.465  1.682</span>
<span class="co">#&gt; ot2                                              0.048  0.038 -0.014  0.110</span>
<span class="co">#&gt; ot3                                             -0.175  0.026 -0.218 -0.130</span>
<span class="co">#&gt; StudyTimePoint2                                  0.410  0.035  0.355  0.468</span>
<span class="co">#&gt; StudyTimePoint3                                  0.697  0.035  0.641  0.757</span>
<span class="co">#&gt; ot1:StudyTimePoint2                              0.565  0.079  0.437  0.695</span>
<span class="co">#&gt; ot1:StudyTimePoint3                              1.099  0.080  0.968  1.233</span>
<span class="co">#&gt; ot2:StudyTimePoint2                             -0.157  0.052 -0.242 -0.073</span>
<span class="co">#&gt; ot2:StudyTimePoint3                             -0.354  0.053 -0.443 -0.267</span>
<span class="co">#&gt; ot3:StudyTimePoint2                             -0.121  0.036 -0.181 -0.061</span>
<span class="co">#&gt; ot3:StudyTimePoint3                             -0.213  0.036 -0.275 -0.155</span>
<span class="co">#&gt; Sigma[Study:ResearchID:(Intercept),(Intercept)]  0.093  0.008  0.081  0.107</span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot1,(Intercept)]          0.042  0.013  0.022  0.064</span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot2,(Intercept)]         -0.015  0.008 -0.029 -0.001</span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot3,(Intercept)]         -0.010  0.005 -0.019 -0.001</span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot1,ot1]                  0.478  0.043  0.411  0.551</span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot2,ot1]                  0.006  0.019 -0.026  0.036</span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot3,ot1]                 -0.089  0.013 -0.111 -0.069</span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot2,ot2]                  0.191  0.015  0.166  0.217</span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot3,ot2]                 -0.007  0.008 -0.019  0.005</span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot3,ot3]                  0.086  0.008  0.074  0.099</span>
<span class="co">#&gt; Sigma[ResearchID:(Intercept),(Intercept)]        0.069  0.012  0.051  0.090</span>
<span class="co">#&gt; Sigma[ResearchID:ot1,(Intercept)]                0.087  0.018  0.060  0.117</span>
<span class="co">#&gt; Sigma[ResearchID:ot2,(Intercept)]               -0.025  0.009 -0.040 -0.011</span>
<span class="co">#&gt; Sigma[ResearchID:ot3,(Intercept)]               -0.004  0.004 -0.011  0.003</span>
<span class="co">#&gt; Sigma[ResearchID:ot1,ot1]                        0.179  0.043  0.113  0.252</span>
<span class="co">#&gt; Sigma[ResearchID:ot2,ot1]                       -0.030  0.015 -0.056 -0.006</span>
<span class="co">#&gt; Sigma[ResearchID:ot3,ot1]                       -0.008  0.008 -0.022  0.004</span>
<span class="co">#&gt; Sigma[ResearchID:ot2,ot2]                        0.016  0.008  0.005  0.030</span>
<span class="co">#&gt; Sigma[ResearchID:ot3,ot2]                        0.001  0.002 -0.002  0.006</span>
<span class="co">#&gt; Sigma[ResearchID:ot3,ot3]                        0.003  0.002  0.001  0.008</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Diagnostics:</span>
<span class="co">#&gt;                                                 mcse  Rhat  n_eff</span>
<span class="co">#&gt; (Intercept)                                     0.001 1.005 1086 </span>
<span class="co">#&gt; ot1                                             0.002 1.004  857 </span>
<span class="co">#&gt; ot2                                             0.001 1.006  842 </span>
<span class="co">#&gt; ot3                                             0.001 1.002 1156 </span>
<span class="co">#&gt; StudyTimePoint2                                 0.001 1.007 1034 </span>
<span class="co">#&gt; StudyTimePoint3                                 0.001 1.006  959 </span>
<span class="co">#&gt; ot1:StudyTimePoint2                             0.003 1.014  674 </span>
<span class="co">#&gt; ot1:StudyTimePoint3                             0.003 1.005  934 </span>
<span class="co">#&gt; ot2:StudyTimePoint2                             0.002 1.003  836 </span>
<span class="co">#&gt; ot2:StudyTimePoint3                             0.002 1.006  762 </span>
<span class="co">#&gt; ot3:StudyTimePoint2                             0.001 1.003 1183 </span>
<span class="co">#&gt; ot3:StudyTimePoint3                             0.001 1.001 1390 </span>
<span class="co">#&gt; Sigma[Study:ResearchID:(Intercept),(Intercept)] 0.000 1.002 1093 </span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot1,(Intercept)]         0.001 1.009  475 </span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot2,(Intercept)]         0.000 1.023  323 </span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot3,(Intercept)]         0.000 1.003  792 </span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot1,ot1]                 0.002 1.003  547 </span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot2,ot1]                 0.001 1.013  277 </span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot3,ot1]                 0.000 1.005  806 </span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot2,ot2]                 0.001 1.010  665 </span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot3,ot2]                 0.000 1.001 1131 </span>
<span class="co">#&gt; Sigma[Study:ResearchID:ot3,ot3]                 0.000 1.004 1220 </span>
<span class="co">#&gt; Sigma[ResearchID:(Intercept),(Intercept)]       0.000 1.004  913 </span>
<span class="co">#&gt; Sigma[ResearchID:ot1,(Intercept)]               0.001 1.008  636 </span>
<span class="co">#&gt; Sigma[ResearchID:ot2,(Intercept)]               0.001 1.026  307 </span>
<span class="co">#&gt; Sigma[ResearchID:ot3,(Intercept)]               0.000 1.006  711 </span>
<span class="co">#&gt; Sigma[ResearchID:ot1,ot1]                       0.003 1.010  261 </span>
<span class="co">#&gt; Sigma[ResearchID:ot2,ot1]                       0.001 1.021  242 </span>
<span class="co">#&gt; Sigma[ResearchID:ot3,ot1]                       0.000 1.006  331 </span>
<span class="co">#&gt; Sigma[ResearchID:ot2,ot2]                       0.000 1.037  257 </span>
<span class="co">#&gt; Sigma[ResearchID:ot3,ot2]                       0.000 1.009  439 </span>
<span class="co">#&gt; Sigma[ResearchID:ot3,ot3]                       0.000 1.007  340 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).</span></code></pre></div>
</div>
<div id="generalized-additive-models" class="section level2">
<h2><span class="header-section-number">B.2</span> Generalized additive models</h2>
<p>To model the looks to the competitor images, I used generalized additive (mixed) models. The models were fit in R (vers. 3.4.3) using the mgcv R package <span class="citation">(vers. 1.8.23; Wood, <a href="#ref-Wood2017">2017</a>)</span> with support from tools in the itsadug R package <span class="citation">(vers. 2.3; van Rij et al., <a href="#ref-itsadug">2017</a>)</span>.</p>
<p>I will briefly walk through the code used to fit one of these models in order to articulate the modeling decisions at play. I first convert the categorical variables into the right types, so that the model can fit difference smooths.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create a Study dummy variabe with Age 4 as the reference level</span>
phon_d<span class="op">$</span>S &lt;-<span class="st"> </span><span class="kw">factor</span>(phon_d<span class="op">$</span>Study, <span class="kw">c</span>(<span class="st">&quot;TimePoint2&quot;</span>, <span class="st">&quot;TimePoint1&quot;</span>, <span class="st">&quot;TimePoint3&quot;</span>))

<span class="co"># Convert the ResearchID into a factor</span>
phon_d<span class="op">$</span>R &lt;-<span class="st"> </span><span class="kw">as.factor</span>(phon_d<span class="op">$</span>ResearchID)

<span class="co"># Convert the Study factor (phon_d$S) into an ordered factor.</span>
<span class="co"># This step is needed for the ti model estimate difference smooths.</span>
phon_d<span class="op">$</span>S2 &lt;-<span class="st"> </span><span class="kw">as.ordered</span>(phon_d<span class="op">$</span>S)
<span class="kw">contrasts</span>(phon_d<span class="op">$</span>S2) &lt;-<span class="st"> &quot;contr.treatment&quot;</span>
<span class="kw">contrasts</span>(phon_d<span class="op">$</span>S2)</code></pre></div>
<p>I fit the generalized additive model with the code below. The outcome <code>elog</code> is the empirical log-odds of looking to the phonological competitor relative to the unrelated word.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mgcv)

phon_gam &lt;-<span class="st"> </span><span class="kw">bam</span>(
  elog <span class="op">~</span><span class="st"> </span>S2 <span class="op">+</span>
<span class="st">    </span><span class="kw">s</span>(Time) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(Time, <span class="dt">by =</span> S2) <span class="op">+</span>
<span class="st">    </span><span class="kw">s</span>(Time, R, <span class="dt">bs =</span> <span class="st">&quot;fs&quot;</span>, <span class="dt">m =</span> <span class="dv">1</span>, <span class="dt">k =</span> <span class="dv">5</span>),
  <span class="dt">data =</span> phon_d)

<span class="co"># Save the output</span>
readr<span class="op">::</span><span class="kw">write_rds</span>(phon_gam, <span class="st">&quot;./data/aim1-phon-random-smooths.rds.gz&quot;</span>)</code></pre></div>
<p>There is just one parametric term: <code>S2</code>. The term computes the average effect of each study with Age 4 serving as the reference condition (and as the model intercept).</p>
<p>Next come the smooth terms. <code>s(Time)</code> fits the shape of Time for the reference condition (Age 4). <code>s(Time, by = S2)</code> fits the difference smooths for Age 3 versus Age 4 and Age 5 versus Age 4. <code>s(Time, R, bs = &quot;fs&quot;, m = 1, k = 5)</code> fits a smooth for each participant (<code>R</code>). <code>bs = &quot;fs&quot;</code> means that the model should use a factor smooth (<code>fs</code>) basis (<code>bs</code>)—that is, a “random effect” smooth for each participant. <code>m = 1</code> changes the smoothness penalty so that the random effects are pulled towards the group average; <span class="citation">Winter and Wieling (<a href="#ref-Winter2016">2016</a>)</span> and <span class="citation">Baayen, Rij, Cat, and Wood (<a href="#ref-Baayen2016">2016</a>)</span> suggest using this option. <code>k = 5</code> means to use 5 knots (<code>k</code>) for the basis function. The other smooths use the default number of knots (10). I used fewer knots for the by-child smooths because of limited data. As a result, these smooths capture by-child variation by making coarse adjustments to study-level growth curves.</p>
<p>Summary of the phonological model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_p &lt;-<span class="st"> </span>readr<span class="op">::</span><span class="kw">read_rds</span>(<span class="st">&quot;./data/aim1-phon-random-smooths.rds.gz&quot;</span>)
<span class="kw">summary</span>(m_p)
<span class="co">#&gt; </span>
<span class="co">#&gt; Family: gaussian </span>
<span class="co">#&gt; Link function: identity </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Formula:</span>
<span class="co">#&gt; elog ~ S2 + s(Time) + s(Time, by = S2) + s(Time, R, bs = &quot;fs&quot;, </span>
<span class="co">#&gt;     m = 1, k = 5)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Parametric coefficients:</span>
<span class="co">#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)   0.159200   0.048807   3.262  0.00111 ** </span>
<span class="co">#&gt; S2TimePoint1 -0.002641   0.013840  -0.191  0.84864    </span>
<span class="co">#&gt; S2TimePoint3  0.151073   0.013601  11.107  &lt; 2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Approximate significance of smooth terms:</span>
<span class="co">#&gt;                          edf  Ref.df     F  p-value    </span>
<span class="co">#&gt; s(Time)                7.277   8.165 10.61 3.51e-15 ***</span>
<span class="co">#&gt; s(Time):S2TimePoint1   5.478   6.590 17.10  &lt; 2e-16 ***</span>
<span class="co">#&gt; s(Time):S2TimePoint3   1.001   1.002 17.86 2.37e-05 ***</span>
<span class="co">#&gt; s(Time,R)            852.928 974.000 12.97  &lt; 2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; R-sq.(adj) =  0.311   Deviance explained = 33.1%</span>
<span class="co">#&gt; fREML =  41726  Scale est. = 0.8629    n = 30008</span></code></pre></div>
<p>Summary of the semantic model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_s &lt;-<span class="st"> </span>readr<span class="op">::</span><span class="kw">read_rds</span>(<span class="st">&quot;./data/aim1-semy-random-smooths.rds.gz&quot;</span>)
<span class="kw">summary</span>(m_s)
<span class="co">#&gt; </span>
<span class="co">#&gt; Family: gaussian </span>
<span class="co">#&gt; Link function: identity </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Formula:</span>
<span class="co">#&gt; elog ~ S2 + s(Time) + s(Time, by = S2) + s(Time, R, bs = &quot;fs&quot;, </span>
<span class="co">#&gt;     m = 1, k = 5)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Parametric coefficients:</span>
<span class="co">#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)   0.43878    0.04907   8.943  &lt; 2e-16 ***</span>
<span class="co">#&gt; S2TimePoint1 -0.13985    0.01352 -10.345  &lt; 2e-16 ***</span>
<span class="co">#&gt; S2TimePoint3  0.06486    0.01329   4.881 1.06e-06 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Approximate significance of smooth terms:</span>
<span class="co">#&gt;                          edf  Ref.df      F  p-value    </span>
<span class="co">#&gt; s(Time)                7.038   7.988 11.018 1.16e-15 ***</span>
<span class="co">#&gt; s(Time):S2TimePoint1   1.001   1.001  0.387 0.534636    </span>
<span class="co">#&gt; s(Time):S2TimePoint3   3.739   4.623  4.909 0.000323 ***</span>
<span class="co">#&gt; s(Time,R)            867.572 974.000 15.750  &lt; 2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; R-sq.(adj) =  0.379   Deviance explained = 39.7%</span>
<span class="co">#&gt; fREML =  42860  Scale est. = 0.85001   n = 30976</span></code></pre></div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-base">
<p>R Core Team. (2018). <em>R: A language and environment for statistical computing</em>. Vienna, Austria: R Foundation for Statistical Computing. Retrieved from <a href="https://www.R-project.org/" class="uri">https://www.R-project.org/</a></p>
</div>
<div id="ref-R-rstanarm">
<p>Gabry, J., &amp; Goodrich, B. (2018). <em>Rstanarm: Bayesian applied regression modeling via stan</em>. Retrieved from <a href="https://CRAN.R-project.org/package=rstanarm" class="uri">https://CRAN.R-project.org/package=rstanarm</a></p>
</div>
<div id="ref-Wood2017">
<p>Wood, S. N. (2017). <em>Generalized additive models: An introduction with R</em> (2nd ed.). CRC Press.</p>
</div>
<div id="ref-itsadug">
<p>van Rij, J., Wieling, M., Baayen, R. H., &amp; van Rijn, H. (2017). itsadug: Interpreting time series and autocorrelated data using GAMMs.</p>
</div>
<div id="ref-Winter2016">
<p>Winter, B., &amp; Wieling, M. (2016). How to analyze linguistic change using mixed models, growth curve analysis and generalized additive modeling. <em>Journal of Language Evolution</em>, <em>1</em>(1), 7–18. doi:<a href="https://doi.org/10.1093/jole/lzv003">10.1093/jole/lzv003</a></p>
</div>
<div id="ref-Baayen2016">
<p>Baayen, R. H., Rij, J. van, Cat, C. de, &amp; Wood, S. N. (2016). Autocorrelated errors in experimental data in the language sciences: Some solutions offered by generalized additive mixed models. Retrieved from <a href="http://arxiv.org/abs/1601.02043" class="uri">http://arxiv.org/abs/1601.02043</a></p>
</div>
</div>
<script type="text/javascript">
  $("div.page-wrapper > h3").appendTo(".page-inner > section");
  $("div.page-wrapper > #refs").appendTo(".page-inner > section");
  $("div.page-wrapper > .footnotes").appendTo(".page-inner > section");
  $("div.body-inner > h3").appendTo(".page-inner > section");
  $("div.body-inner > #refs").appendTo(".page-inner > section");
  $("div.body-inner > .footnotes").appendTo(".page-inner > section");
</script>
            </section>

          </div>
        </div>
      </div>
<a href="vw-experiment-items.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mp-experiment-items.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"split_bib": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
