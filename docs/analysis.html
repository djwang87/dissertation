<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>My dissertation</title>
  <meta name="description" content="My dissertation">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="My dissertation" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="tjmahr/dissertation" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="My dissertation" />
  
  
  

<meta name="author" content="Tristan Mahr">


<meta name="date" content="2017-10-12">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="outcome-measures.html">
<link rel="next" href="prepare-and-explore-the-data.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="assets\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">My dissertation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Development of word recognition in preschoolers</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#updates"><i class="fa fa-check"></i>Updates</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="scratch-paper.html"><a href="scratch-paper.html"><i class="fa fa-check"></i><b>1</b> Scratch paper</a><ul>
<li class="chapter" data-level="1.1" data-path="scratch-paper.html"><a href="scratch-paper.html#bookdown-cheatsheet"><i class="fa fa-check"></i><b>1.1</b> Bookdown cheatsheet</a><ul>
<li class="chapter" data-level="1.1.1" data-path="scratch-paper.html"><a href="scratch-paper.html#manual-section-label-demo"><i class="fa fa-check"></i><b>1.1.1</b> Cross-references to sections</a></li>
<li class="chapter" data-level="1.1.2" data-path="scratch-paper.html"><a href="scratch-paper.html#cross-references-to-appendices"><i class="fa fa-check"></i><b>1.1.2</b> Cross-references to appendices</a></li>
<li class="chapter" data-level="1.1.3" data-path="scratch-paper.html"><a href="scratch-paper.html#cross-references-to-tables"><i class="fa fa-check"></i><b>1.1.3</b> Cross-references to tables</a></li>
<li class="chapter" data-level="1.1.4" data-path="scratch-paper.html"><a href="scratch-paper.html#figure-references-and-using-text-references-as-captions"><i class="fa fa-check"></i><b>1.1.4</b> Figure references and using text references as captions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="scratch-paper.html"><a href="scratch-paper.html#debug-info"><i class="fa fa-check"></i><b>1.2</b> Debug info</a></li>
</ul></li>
<li class="part"><span><b>Prospectus</b></span></li>
<li class="chapter" data-level="2" data-path="front-matter.html"><a href="front-matter.html"><i class="fa fa-check"></i><b>2</b> Front Matter</a><ul>
<li class="chapter" data-level="" data-path="front-matter.html"><a href="front-matter.html#about-this-document"><i class="fa fa-check"></i>About This Document</a></li>
<li class="chapter" data-level="" data-path="front-matter.html"><a href="front-matter.html#dissertation-committee-members"><i class="fa fa-check"></i>Dissertation Committee Members</a></li>
<li class="chapter" data-level="" data-path="front-matter.html"><a href="front-matter.html#planned-dissertation-format"><i class="fa fa-check"></i>Planned Dissertation Format</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="specific-aims.html"><a href="specific-aims.html"><i class="fa fa-check"></i><b>3</b> Specific Aims</a><ul>
<li class="chapter" data-level="3.1" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>3.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="3.2" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>3.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="3.3" data-path="specific-aims.html"><a href="specific-aims.html#specific-aim-3-computational-modeling"><i class="fa fa-check"></i><b>3.3</b> Specific Aim 3 (Computational Modeling)</a></li>
<li class="chapter" data-level="3.4" data-path="specific-aims.html"><a href="specific-aims.html#summary"><i class="fa fa-check"></i><b>3.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="significance.html"><a href="significance.html"><i class="fa fa-check"></i><b>4</b> Significance</a><ul>
<li class="chapter" data-level="4.1" data-path="significance.html"><a href="significance.html#public-health-significance"><i class="fa fa-check"></i><b>4.1</b> Public Health Significance</a></li>
<li class="chapter" data-level="4.2" data-path="significance.html"><a href="significance.html#scientific-significance"><i class="fa fa-check"></i><b>4.2</b> Scientific Significance</a><ul>
<li class="chapter" data-level="4.2.1" data-path="significance.html"><a href="significance.html#lexical-processing-dynamics"><i class="fa fa-check"></i><b>4.2.1</b> Lexical Processing Dynamics</a></li>
<li class="chapter" data-level="4.2.2" data-path="significance.html"><a href="significance.html#individual-differences-in-word-recognition"><i class="fa fa-check"></i><b>4.2.2</b> Individual Differences in Word Recognition</a></li>
<li class="chapter" data-level="4.2.3" data-path="significance.html"><a href="significance.html#computational-modeling"><i class="fa fa-check"></i><b>4.2.3</b> Computational Modeling</a></li>
<li class="chapter" data-level="4.2.4" data-path="significance.html"><a href="significance.html#summary-1"><i class="fa fa-check"></i><b>4.2.4</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="research-hypotheses.html"><a href="research-hypotheses.html"><i class="fa fa-check"></i><b>5</b> Research Hypotheses</a><ul>
<li class="chapter" data-level="5.1" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-1-familiar-word-recognition-and-lexical-competition-1"><i class="fa fa-check"></i><b>5.1</b> Specific Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="5.2" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-2-referent-selection-and-mispronunciations-1"><i class="fa fa-check"></i><b>5.2</b> Specific Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="5.3" data-path="research-hypotheses.html"><a href="research-hypotheses.html#specific-aim-3-computational-modeling-1"><i class="fa fa-check"></i><b>5.3</b> Specific Aim 3 (Computational Modeling)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>6</b> Methods</a><ul>
<li class="chapter" data-level="6.1" data-path="methods.html"><a href="methods.html#general-research-design-participants"><i class="fa fa-check"></i><b>6.1</b> General Research Design: Participants</a></li>
<li class="chapter" data-level="6.2" data-path="methods.html"><a href="methods.html#general-eyetracking-procedure"><i class="fa fa-check"></i><b>6.2</b> General Eyetracking Procedure</a><ul>
<li class="chapter" data-level="6.2.1" data-path="methods.html"><a href="methods.html#experiment-administration"><i class="fa fa-check"></i><b>6.2.1</b> Experiment Administration</a></li>
<li class="chapter" data-level="6.2.2" data-path="methods.html"><a href="methods.html#stimuli"><i class="fa fa-check"></i><b>6.2.2</b> Stimuli</a></li>
<li class="chapter" data-level="6.2.3" data-path="methods.html"><a href="methods.html#data-preparation"><i class="fa fa-check"></i><b>6.2.3</b> Data Preparation</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="methods.html"><a href="methods.html#specific-procedure-aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>6.3</b> Specific Procedure: Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="6.4" data-path="methods.html"><a href="methods.html#specific-procedure-aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>6.4</b> Specific Procedure: Aim 2 (Referent Selection and Mispronunciations)</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="outcome-measures.html"><a href="outcome-measures.html"><i class="fa fa-check"></i><b>7</b> Outcome Measures</a><ul>
<li class="chapter" data-level="7.1" data-path="outcome-measures.html"><a href="outcome-measures.html#sample-data"><i class="fa fa-check"></i><b>7.1</b> Sample Data</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="analysis.html"><a href="analysis.html"><i class="fa fa-check"></i><b>8</b> Analysis</a><ul>
<li class="chapter" data-level="8.1" data-path="analysis.html"><a href="analysis.html#growth-curve-analysis"><i class="fa fa-check"></i><b>8.1</b> Growth Curve Analysis</a></li>
<li class="chapter" data-level="8.2" data-path="analysis.html"><a href="analysis.html#aim-1-familiar-word-recognition-and-lexical-competition"><i class="fa fa-check"></i><b>8.2</b> Aim 1 (Familiar Word Recognition and Lexical Competition)</a></li>
<li class="chapter" data-level="8.3" data-path="analysis.html"><a href="analysis.html#aim-2-referent-selection-and-mispronunciations"><i class="fa fa-check"></i><b>8.3</b> Aim 2 (Referent Selection and Mispronunciations)</a></li>
<li class="chapter" data-level="8.4" data-path="analysis.html"><a href="analysis.html#aim-3-computational-modeling"><i class="fa fa-check"></i><b>8.4</b> Aim 3 (Computational Modeling)</a><ul>
<li class="chapter" data-level="8.4.1" data-path="analysis.html"><a href="analysis.html#trace-model-architecture"><i class="fa fa-check"></i><b>8.4.1</b> TRACE Model Architecture</a></li>
<li class="chapter" data-level="8.4.2" data-path="analysis.html"><a href="analysis.html#modeling-looking-data"><i class="fa fa-check"></i><b>8.4.2</b> Modeling Looking Data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Aim 1: Familiar Word Recognition and Lexical Competition</b></span></li>
<li class="chapter" data-level="9" data-path="prepare-and-explore-the-data.html"><a href="prepare-and-explore-the-data.html"><i class="fa fa-check"></i><b>9</b> Prepare and explore the data</a><ul>
<li class="chapter" data-level="9.1" data-path="prepare-and-explore-the-data.html"><a href="prepare-and-explore-the-data.html#data-cleaning"><i class="fa fa-check"></i><b>9.1</b> Data cleaning</a><ul>
<li class="chapter" data-level="9.1.1" data-path="prepare-and-explore-the-data.html"><a href="prepare-and-explore-the-data.html#add-a-note-about-the-bad-version-of-the-experiment"><i class="fa fa-check"></i><b>9.1.1</b> Add a note about the bad version of the experiment</a></li>
<li class="chapter" data-level="9.1.2" data-path="prepare-and-explore-the-data.html"><a href="prepare-and-explore-the-data.html#special-case-data-screening"><i class="fa fa-check"></i><b>9.1.2</b> Special case data screening</a></li>
<li class="chapter" data-level="9.1.3" data-path="prepare-and-explore-the-data.html"><a href="prepare-and-explore-the-data.html#interim-summary"><i class="fa fa-check"></i><b>9.1.3</b> Interim summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html"><i class="fa fa-check"></i><b>10</b> Analyze familiar word recognition</a><ul>
<li class="chapter" data-level="10.1" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#data-preparation-1"><i class="fa fa-check"></i><b>10.1</b> Data preparation</a></li>
<li class="chapter" data-level="10.2" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#maximum-likelihood-results"><i class="fa fa-check"></i><b>10.2</b> Maximum likelihood results</a></li>
<li class="chapter" data-level="10.3" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#bayesian-model-results"><i class="fa fa-check"></i><b>10.3</b> Bayesian model results</a><ul>
<li class="chapter" data-level="10.3.1" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#fixed-effects-plots"><i class="fa fa-check"></i><b>10.3.1</b> Fixed effects plots</a></li>
<li class="chapter" data-level="10.3.2" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#plot-the-intervals-for-the-random-effect-parameters"><i class="fa fa-check"></i><b>10.3.2</b> Plot the intervals for the random effect parameters</a></li>
<li class="chapter" data-level="10.3.3" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>10.3.3</b> Posterior predictive checks</a></li>
<li class="chapter" data-level="10.3.4" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#look-at-some-predictions"><i class="fa fa-check"></i><b>10.3.4</b> Look at some predictions</a></li>
<li class="chapter" data-level="10.3.5" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#predicting-the-future"><i class="fa fa-check"></i><b>10.3.5</b> Predicting the future</a></li>
<li class="chapter" data-level="10.3.6" data-path="analyze-familiar-word-recognition.html"><a href="analyze-familiar-word-recognition.html#relationship-with-child-level-variables"><i class="fa fa-check"></i><b>10.3.6</b> Relationship with child-level variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="visualize-looks-to-each-image-type.html"><a href="visualize-looks-to-each-image-type.html"><i class="fa fa-check"></i><b>11</b> Visualize looks to each image type</a><ul>
<li class="chapter" data-level="11.1" data-path="visualize-looks-to-each-image-type.html"><a href="visualize-looks-to-each-image-type.html#comparing-strong-versus-weak-foils"><i class="fa fa-check"></i><b>11.1</b> Comparing strong versus weak foils</a></li>
<li class="chapter" data-level="11.2" data-path="visualize-looks-to-each-image-type.html"><a href="visualize-looks-to-each-image-type.html#look-for-individual-differences-in-competitor-sensitivity"><i class="fa fa-check"></i><b>11.2</b> Look for individual differences in competitor sensitivity</a></li>
<li class="chapter" data-level="11.3" data-path="visualize-looks-to-each-image-type.html"><a href="visualize-looks-to-each-image-type.html#interim-summary-1"><i class="fa fa-check"></i><b>11.3</b> Interim summary</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="mp-experiment-items.html"><a href="mp-experiment-items.html"><i class="fa fa-check"></i><b>A</b> Items used in the mispronunciation experiment</a></li>
<li class="chapter" data-level="B" data-path="vw-experiment-items.html"><a href="vw-experiment-items.html"><i class="fa fa-check"></i><b>B</b> Items used in the visual world experiment</a></li>
<li class="chapter" data-level="C" data-path="related-work.html"><a href="related-work.html"><i class="fa fa-check"></i><b>C</b> Related Work</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Created with bookdown</a></li>
<li><a href="https://tjmahr.github.io/" target="blank">Tristan Mahr</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">My dissertation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="analysis" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Analysis</h1>
<div id="growth-curve-analysis" class="section level2">
<h2><span class="header-section-number">8.1</span> Growth Curve Analysis</h2>
<p>Eyetracking growth curves will be analyzed using <strong>Bayesian mixed effects logistic regression</strong>. I will use <em>logistic</em> regression because the outcome measurement is a probability (the log-odds of looking to the target image versus a distractor). I will use <em>mixed-effects</em> models because I want to estimate a separate growth curve for each child (to measure individual differences in word recognition) but also treat each child’s individual growth curve as a draw from a distribution of related curves.</p>
<p>I plan to use <em>Bayesian</em> techniques to study a generative model of the data. Instead of reporting and describing a single, best-fitting model of some data, Bayesian techniques consider an entire distribution of plausible models that are consistent with the data and any prior information we have about the models. By using this approach, I can explicitly quantify uncertainty about statistical effects and draw inferences using estimates of uncertainty (instead of using statistical significance—which is not a straightforward matter for mixed-effects models).<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<p>The eyetracking growth curves will be fit using an orthogonal cubic polynomial function of time <span class="citation">(a now-conventional approach; see Mirman, <a href="#ref-Mirman2014">2014</a>)</span>. Put differently, I will model the probability of looking to the target during an eyetracking task as:</p>
<p><span class="math display">\[
\text{log-odds}(\mathit{looking}) = \beta_0 + \beta_1 * \textit{Time}^1 +  \beta_2 * \textit{Time}^2 +   \beta_3 * \textit{Time}^3
\]</span></p>
<p>That the time terms are <em>orthogonal</em> means that <span class="math inline">\(\textit{Time}^1\)</span>, <span class="math inline">\(\textit{Time}^2\)</span> and <span class="math inline">\(\textit{Time}^3\)</span> are transformed so that they are uncorrelated. Under this formulation, the parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> have a clear interpretation in terms of lexical processing performance. The intercept, <span class="math inline">\(\beta_0\)</span>, measures the area under the growth curve—or the probability of fixating on the target word averaged over the whole window. We can think of <span class="math inline">\(\beta_0\)</span> as a measure of average accuracy or of <em>word recognition reliability</em>. The linear time parameter, <span class="math inline">\(\beta_1\)</span>, estimates the steepness of the growth curve—or how the probability of fixating changes from frame to frame. We can think of <span class="math inline">\(\beta_1\)</span> as a measure of <em>processing efficiency</em>, because growth curves with stronger linear features exhibit steeper frame-by-frame increases in looking probability.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<p>For each experimental task, I will study how word recognition changes over time by modeling how growth curves change over developmental time. This amounts to study how the growth curve parameters changes year over year in the study. I can model the data for an eyetracking task by including dummy-coded indicators for Year 1, Year 2, and Year 3 and having these indicators interact with the growth curve parameters. In such a model, Year 2 would be the reference year, so the Year 1 parameters would estimate how the word-recognition-curves change from Year 2 to Year 1, and Year 3 parameters would be interpreted similarly.</p>
<p><span class="math display">\[
\begin{align*}
   \text{Year 2 Growth Curve:}\\ 
   \text{log-odds}(\mathit{looking}) &amp;= \beta_0 + \beta_1 * \textit{Time}^1 +  \beta_2 * \textit{Time}^2 +   \beta_3 * \textit{Time}^3 \\
   \text{Adjustments to Year 2:} \\
  \beta_i &amp;= \gamma_{i:2} + \gamma_{i:1} * \text{Year1}  + \gamma_{i:3} * \text{Year3}  \\
\end{align*}
\]</span></p>
<p>Thus, the interaction effects for the intercept term (<span class="math inline">\(\gamma_{0:1}\)</span>, <span class="math inline">\(\gamma_{0:3}\)</span>) describe how overall accuracy changed between years, and interaction effects for the linear-time terms (<span class="math inline">\(\gamma_{1:1}\)</span>, <span class="math inline">\(\gamma_{1:3}\)</span>) describe changes in overall processing efficiency between years.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<p>Lastly, a brief comment about priors. Bayesian models require prior information (“priors”). For these models, I will use weakly to moderately informative priors. For example, suppose <em>x</em> and <em>y</em> are scaled to mean 0 and standard deviation 1. A weakly informative prior for the effect of <em>x</em> on <em>y</em> might be Normal(0, 5)—a normal distribution with mean 0 and standard deviation 5. If we fit a regression model and observed an effect size of 12 SD units, our first assumption would be that something went wrong with our software. The weakly informative prior captures this level of prior information. A moderately informative prior would be Normal(0, 1). This prior information captures our disciplinary experience that effect sizes greater than ±1 relatively uncommon in child language research. A strongly informative prior for this effect might be something like Normal(.4, .1) which says that our model should be very skeptical of negative effects and of effects larger than .8. For this project, I will default to the first two levels of prior information.</p>
</div>
<div id="aim-1-familiar-word-recognition-and-lexical-competition" class="section level2">
<h2><span class="header-section-number">8.2</span> Aim 1 (Familiar Word Recognition and Lexical Competition)</h2>
<p>In the four-image task, I will model the development of familiar word recognition by studying how looks to the target image change year over year, as described in <a href="analysis.html#growth-curve-analysis">Growth Curve Analysis</a>.</p>
<p>I predict that children will be more sensitive to the phonological foil and semantic foils in this task as they age and learn more words. This hypothesis is based on the idea that children discover similarities among words as they learn word and integrate them into their lexicon. To test this hypothesis, I will study how the probability of fixating on the foils changes over trial-time and how these growth curves change from year to year. In the conventional model of eyetracking data, the outcome is a binomial choice—Target versus Distractor—and we can estimate the log-odds of fixating on the target image relative to the distractors. To study the specific effect of the Phonological foil in this task, <span class="citation">Law et al. (<a href="#ref-RWLPaper">2016</a>)</span> treated the Unrelated foil as a reference distractor and compared two separate binomial growth curves (see Figure <a href="analysis.html#fig:rwl-comp-to-unre">8.1</a>): Target versus Phonological, and Target versus Unrelated. The same technique was used on the Semantic foil as well. With this approach, shown below, we observed an early negative effect of the phonological foil and a late negative effect of the semantic foil.</p>

<div class="figure"><span id="fig:rwl-comp-to-unre"></span>
<img src="misc/rwl-screenshot.png" alt="Reprint of Figure 4 from Law et al. (2016) to illustrate the strategy of examining lexical competition effects where the semantic foil and phonological foil are compared to the unrelated image." width="100%" />
<p class="caption">
Figure 8.1: Reprint of Figure 4 from <span class="citation">Law et al. (<a href="#ref-RWLPaper">2016</a>)</span> to illustrate the strategy of examining lexical competition effects where the semantic foil and phonological foil are compared to the unrelated image.
</p>
</div>
<p>I plan to employ this technique for studying lexical competition effects and their development from Year 1 to Year 2 to Year 3.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> Increased lexical completion would be reflected in greater interference from the foils compared to the unrelated image.</p>
<p>A more comprehensive statistical model for this experiment would capture the fact that the data are multinomial: Target versus Phonological versus Semantic versus Unrelated. However, multinomial mixed effects growth curves have not been used for eyetracking data. They are not estimable with the standard classical modeling software (lme4). I plan to examine whether such a model is feasible with Bayesian techniques, but it may prove to be too unstable. In that case, I will fall back to the above described strategy.</p>
<p>I will also examine whether individual differences in lexical processing are stable over time. For an initial analytic step, I will identify how frequently children change quartiles or deciles. The idea here is that stable individual differences in processing should preserve some relative rankings—fast-processing children should remain relatively fast compared to their peers. If children make large swings in their rankings, e.g., changing from the bottom 55<sup>th</sup> to the 30<sup>th</sup> percentile, then we have evidence that these rankings are unstable. I am also interested in how the magnitude of individual differences change over time. The differences among children could diminish over time so that the rankings are unstable and reflect small variations among children.</p>
<p>Another question concerns the relationship between the development of lexical processing and the development of vocabulary size. Specifically, I will ask how age-adjusted lexical processing measures (accuracy and efficiency) correlate with age-adjusted vocabulary size each year. Moreover, I will also examine whether children who make large gains in vocabulary size also show large concurrent changes in their lexical processing measures.</p>
</div>
<div id="aim-2-referent-selection-and-mispronunciations" class="section level2">
<h2><span class="header-section-number">8.3</span> Aim 2 (Referent Selection and Mispronunciations)</h2>
<p>For this task, I will model how the looks to the familiar image differ in each condition (real words, mispronunciations, nonwords) and how the growth curves for each condition change year over year. This model will use growth curve model described in <a href="analysis.html#growth-curve-analysis">Growth Curve Analysis</a> but augmented with Condition effects.</p>
<p>I will examine whether and when any dissociation is observed for word recognition in the real word and nonword conditions. <span class="citation">McMurray et al. (<a href="#ref-McMurray2012">2012</a>)</span> argue that familiar word recognition and fast association for novel words reflect the same cognitive process: referent selection. Data from this task would support with this hypothesis when the growth curves for looks to the familiar image are symmetrical for the real word and nonword conditions. Figure <a href="analysis.html#fig:le-means">8.2</a>, showing data from <span class="citation">Law and Edwards (<a href="#ref-MPPaper">2015</a>, <em>n</em> = 34 children, 30-46 months old)</span>, shows some symmetry for the real word and nonword conditions.</p>

<div class="figure"><span id="fig:le-means"></span>
<img src="misc/le_means.png" alt="Condition averages for data described by Law and Edwards (2015). Compare to Figure 2 in the original manuscript." width="100%" />
<p class="caption">
Figure 8.2: Condition averages for data described by <span class="citation">Law and Edwards (<a href="#ref-MPPaper">2015</a>)</span>. Compare to Figure 2 in the original manuscript.
</p>
</div>
<p>I will test whether the two measures ever dissociate by computing the posterior predicted difference between the growth curves. This approach is similar to the bootstrap-based divergence analyses used in some word recognition experiments <span class="citation">(Dink &amp; Ferguson, <a href="#ref-eyetrackingR">2016</a>; e.g., Oleson, Cavanaugh, McMurray, &amp; Brown, <a href="#ref-Oleson2015">2015</a>)</span>. The essential question is when—at which specific time points—do two growth curves differ significantly from one another. The bootstrap approach uses resampling to get an estimate, whereas I will use posterior predicted samples to estimate these differences. (I have not seen my approach used yet in the literature, so it is a small innovation.)</p>
<p>Specifically, I will compute the posterior-predicted looks to the familiar object in the real word condition, P(Familiar | Real Word, Time <em>t</em>, Child <em>i</em>) and the analogous looks to the unfamiliar object in the nonword condition, P(Unfamiliar | Nonword, Time <em>t</em>, Child <em>i</em>). The difference between these two probabilities estimates how the time course of word recognition differs between these two conditions, and I can use 50% and 90% uncertainty intervals to determine during which time points the curves credibly differ from each other. Figure <a href="analysis.html#fig:le-post-diff">8.3</a> shows this calculation performed on data from <span class="citation">Law and Edwards (<a href="#ref-MPPaper">2015</a>)</span>. If feasible, I will also examine whether these measures dissociate <em>within</em> children and examine which child-level factors are associated with these kinds of listeners.</p>

<div class="figure"><span id="fig:le-post-diff"></span>
<img src="misc/mp_post_diff.png" alt="Demonstration of posterior difference technique on data from Law and Edwards (2015)." width="100%" />
<p class="caption">
Figure 8.3: Demonstration of posterior difference technique on data from <span class="citation">Law and Edwards (<a href="#ref-MPPaper">2015</a>)</span>.
</p>
</div>
<p>Even though performance on the real word and nonword conditions might be highly correlated, one might intuitively hypothesize that that performance on the nonword condition to be a better predictor of concurrent or future vocabulary size. The rationale would be that referent selection for novel words is a more transparent test of the word learner’s basic task of associating new labels with objects. Therefore, I will examine how each of these measures relates to vocabulary growth.</p>
<p>I will describe how looking behavior in the mispronunciation condition changes over time and changes for specific mispronunciation patterns. Overall, I predict that children will be more tolerant of mispronunciations as they age, because older children know more words and have more implicit knowledge about the similarities among words. As for specific mispronunciation items, let us (safely) suppose that speech perception improves with age, especially for later mastered sounds. Then we should expect that looking patterns for the <em>rice</em>-<em>wice</em> trials change significantly between Year 2 and Year 3, at least compared to looking patterns on trials with mispronunciations of earlier acquired sounds (e.g., <em>girl</em>-<em>dirl</em> or <em>duck</em>-<em>guck</em>). Therefore, I will examine individual mispronunciation effects and how they are associated with child-level measures, including speech perception.</p>
</div>
<div id="aim-3-computational-modeling" class="section level2">
<h2><span class="header-section-number">8.4</span> Aim 3 (Computational Modeling)</h2>
<div id="trace-model-architecture" class="section level3">
<h3><span class="header-section-number">8.4.1</span> TRACE Model Architecture</h3>
<p>TRACE <span class="citation">(McClelland &amp; Elman, <a href="#ref-TRACE">1986</a>)</span> is an interactive activation model, and it interprets an input pattern by spreading energy (activation) through a network of processing units. The pattern of activation over the network is its interpretation of the input signal, so that more active units represent more likely interpretations. Over many processing cycles, the network propagates energy among its connections until it settles into a stable pattern of activation.</p>
<p>The input for TRACE is a mock-speech signal that activates perceptual feature-detectors. These units respond to phonetic features like voicing or vocalic resonance. The perceptual units activate phoneme units, and the phoneme units activate lexical word units, as shown in Figure <a href="analysis.html#fig:trace-schematic">8.4</a>.</p>

<div class="figure"><span id="fig:trace-schematic"></span>
<img src="misc/trace-schematic.jpeg" alt="TRACE model architecture. Thick arrows indicate excitatory connections between layers, including a top-down connections from words onto phoneme units. Lines with points at the end reflect inhibitory connections among competing units within a layer. This image is a lightly modified public-domain version of Figure 1 in Strauss et al. (2007): https://en.wikipedia.org/wiki/File:TRACE_architecture.jpg" width="100%" />
<p class="caption">
Figure 8.4: TRACE model architecture. Thick arrows indicate excitatory connections between layers, including a top-down connections from words onto phoneme units. Lines with points at the end reflect inhibitory connections among competing units within a layer. This image is a lightly modified public-domain version of Figure 1 in <span class="citation">Strauss et al. (<a href="#ref-jTRACE">2007</a>)</span>: <a href="https://en.wikipedia.org/wiki/File:TRACE_architecture.jpg" class="uri">https://en.wikipedia.org/wiki/File:TRACE_architecture.jpg</a>
</p>
</div>
<p>Units within a level (phonetic, phonemic, lexical) compete through lateral inhibition, so that more active units can suppress less active units. This inhibition allows the network to rule out possible units and narrow its interpretations over time. There are also top-down connections so that word units in the lexical layer can reinforce the sound units that make up those words. One consequence of this feature is that the network can resolve ambiguous phonemes, as in <em>Xift</em> where <em>X</em> is a sound between /k/ and /g/ and top-down influence supports <em>gift</em> rather than <em>kift</em>. Lastly, activation in units gradually decays over time, and the network will eventually “forget” it input pattern to return to a resting state.</p>
<p>The model parameters that govern how activation propagates through the network map onto psychological processing constructs. For instance, the phoneme inhibition strength parameter controls how decisively (or categorically) the network interprets speech sounds. Phoneme-to-word activation strength reflects how quickly speech sounds begin to activate words. Decay parameters control the model’s temporary memory for different kinds of representations.</p>
</div>
<div id="modeling-looking-data" class="section level3">
<h3><span class="header-section-number">8.4.2</span> Modeling Looking Data</h3>
<p>To simulate behavioral data, we need a <em>linking hypothesis</em> for translating between human behavior and network behavior <span class="citation">(Magnuson, Mirman, &amp; Harris, <a href="#ref-Magnuson2012_Models">2012</a>)</span>. During each network cycle, some words are activated, some more activated than others, so that the unit with the highest activation is the preferred interpretation of the input. We can convert these activations into probabilities using the <em>softmax</em> function:</p>
<p><span class="math display">\[P(\textit{word}_w) = 
  \mathrm{softmax}(\textit{activation}_w) = 
  \frac{\exp(k * \textit{activation}_w)}
       {\sum{\exp(k * \textit{activation}_{[\text{words to choose from}]})}}\]</span></p>
<p>In other words, scale the activation using some parameter <em>k</em>, exponentiate the scaled activation values of all relevant choices, and the proportion of the total exponentiated activation belonging to word w is the probability of fixating on word <em>w</em>.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> The scaling value <em>k</em> is manipulated to help the model-simulated probabilities match the observed looking probabilities.</p>
<p>The next step, and this process will be rather open-ended and iterative, is to simulate the behavioral data with the model. As a first step, I will need to create a developmentally appropriate lexicon. I will use developmental norms and databases to determine an appropriate set of items. I will first try to simulate the mispronunciation experiment. <span class="citation">Mayor and Plunkett (<a href="#ref-TRACE_Mispro">2014</a>)</span> successfully simulated some mispronunciation data from experiments with data, so I will borrow some of their strategies for modeling these kinds of experiments. After I get the model to simulate Year 1 data, I will explore which parameters need to change to account for Year 2 and then Year 3 data. There are many degrees of freedom (model parameters) for how to replicate these development changes, so I will plan to systematically report the model fitting and the development consequences of the model fit.</p>
<p>The four-image experiment is slightly trickier, because it incorporates semantically related information, and TRACE has no built-in semantic representations. Two options for modeling the experiment are 1) to ignore looks to the semantic foil, following the Luce choice rule <span class="citation">(<a href="#ref-Luce1959">1959</a>, <a href="#ref-Luce2008">2008</a>)</span> and 2) to try to incorporate semantic information into the model by modifying connections between semantically related words—although it is unclear whether either is tractable. At any rate, part of this project will be to explore how to reconcile these data with this apparent limitation with the TRACE model.</p>
<p>Finally, I would like to account for individual differences among children and incorporate child-level information into the simulations. Specifically, I would like to test how vocabulary differences are associated with large lexicons for model simulations. Moreover, I would like to whether children’s speech perception abilities systematically relate to the model’s phonological activation parameters. Such a correspondence would further validate the models. These simulations would further validate these child-level measures by describing how they specifically affect word recognition.</p>
<p>For these research questions, I will following the modeling heuristics described by <span class="citation">Magnuson et al. (<a href="#ref-Magnuson2012_Models">2012</a>)</span>. For example, for any modeling failures, I will assess the failure in terms of the computational consequences: Is the failure a problem with the theory, implementation, parameters or link between human data and model activity? Similarly, can the model fit specific item effects or just condition effects? The authors provide other heuristics, and these guidelines heuristics will help formalize the assessment and comparison of computational models.</p>

</div>
</div>
</div>



</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Mirman2014">
<p>Mirman, D. (2014). <em>Growth curve analysis and visualization using R</em>. Boca Raton, FL: Chapman &amp; Hall/CRC.</p>
</div>
<div id="ref-RWLPaper">
<p>Law, F., II, Mahr, T., Schneeberg, A., &amp; Edwards, J. R. (2016). Vocabulary size and auditory word recognition in preschool children. <em>Applied Psycholinguistics</em>. doi:<a href="https://doi.org/10.1017/S0142716416000126">10.1017/S0142716416000126</a></p>
</div>
<div id="ref-McMurray2012">
<p>McMurray, B., Horst, J. S., &amp; Samuelson, L. K. (2012). Word learning emerges from the interaction of online referent selection and slow associative learning. <em>Psychological Review</em>, <em>119</em>(4), 831–877. doi:<a href="https://doi.org/10.1037/a0029872">10.1037/a0029872</a></p>
</div>
<div id="ref-MPPaper">
<p>Law, F., II, &amp; Edwards, J. R. (2015). Effects of vocabulary size on online lexical processing by preschoolers. <em>Language Learning and Development</em>, <em>11</em>(4), 331–355. doi:<a href="https://doi.org/10.1080/15475441.2014.961066">10.1080/15475441.2014.961066</a></p>
</div>
<div id="ref-eyetrackingR">
<p>Dink, J., &amp; Ferguson, B. (2016). <em>eyetrackingR</em>. Retrieved from <a href="http://www.eyetracking-R.com" class="uri">http://www.eyetracking-R.com</a></p>
</div>
<div id="ref-Oleson2015">
<p>Oleson, J. J., Cavanaugh, J. .., McMurray, B., &amp; Brown, G. (2015). Detecting time-specific differences between temporal nonlinear curves: Analyzing data from the visual world paradigm. <em>Statistical Methods in Medical Research</em>. doi:<a href="https://doi.org/10.1177/0962280215607411">10.1177/0962280215607411</a></p>
</div>
<div id="ref-TRACE">
<p>McClelland, J. L., &amp; Elman, J. L. (1986). The TRACE model of speech perception. <em>Cognitive Psychology</em>, <em>18</em>(1), 1–86. doi:<a href="https://doi.org/10.1016/0010-0285(86)90015-0">10.1016/0010-0285(86)90015-0</a></p>
</div>
<div id="ref-jTRACE">
<p>Strauss, T. J., Harris, H. D., &amp; Magnuson, J. S. (2007). jTRACE: A reimplementation and extension of the TRACE model of speech perception and spoken word recognition. <em>Behavior Research Methods</em>, <em>39</em>(1), 19–30. doi:<a href="https://doi.org/10.3758/BF03192840">10.3758/BF03192840</a></p>
</div>
<div id="ref-Magnuson2012_Models">
<p>Magnuson, J. S., Mirman, D., &amp; Harris, H. D. (2012). Computational models of spoken word recognition. In M. J. Spivey, K. McRae, &amp; M. F. Joanisse (Eds.), <em>The cambridge handbook of psycholinguistics</em> (pp. 76–103). Cambridge: Cambridge University Press.</p>
</div>
<div id="ref-TRACE_Mispro">
<p>Mayor, J., &amp; Plunkett, K. (2014). Infant word recognition: Insights from TRACE simulations. <em>Journal of Memory and Language</em>, <em>71</em>(1), 89–123. doi:<a href="https://doi.org/10.1016/j.jml.2013.09.009">10.1016/j.jml.2013.09.009</a></p>
</div>
<div id="ref-Luce1959">
<p>Luce, R. D. (1959). <em>Individual choice behavior</em>. New York: Wiley.</p>
</div>
<div id="ref-Luce2008">
<p>Luce, R. D. (2008). Luce’s choice axiom. <em>Scholarpedia</em>, <em>3</em>(12), 8077. doi:<a href="https://doi.org/10.4249/scholarpedia.8077">10.4249/scholarpedia.8077</a></p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>It is tempting to further justify this approach by comparing Bayesian versus classical/frequentist statistics, but my goals in using this method are simple: To estimate statistical effects and quantify uncertainty about those effects. This pragmatic brand of Bayesian statistics is illustrated in texts by <span class="citation">Gelman and Hill (<a href="#ref-GelmanHill">2007</a>)</span> and <span class="citation">McElreath (<a href="#ref-RethinkingBook">2016</a>)</span>.<a href="analysis.html#fnref2">↩</a></p></li>
<li id="fn3"><p>The polynomial other terms are less important—or rather, they have do not map as neatly onto behavioral descriptions as the accuracy and efficiency parameters. The primary purpose of quadratic and cubic terms is to ensure that the estimated growth curve adequately fits the data. In this kind of data, there is a steady baseline at chance probability before the child hears the word, followed a window of increasing probability of fixating on the target as the child recognizes the word, followed by a period of plateauing and then diminishing looks to target. The cubic polynomial allows the growth curve to be fit with two inflection points: the point when the looks to target start to increase from baseline and the point when the looks to target stops increasing.<a href="analysis.html#fnref3">↩</a></p></li>
<li id="fn4"><p>In the case that these omnibus multi-year interaction models do not converge or are otherwise computationally ill-behaved, I will model each year separately, extract each participant’s growth curve parameters, and compare those measures in a second stage of modeling.<a href="analysis.html#fnref4">↩</a></p></li>
<li id="fn5"><p>Most of the phonological foils for this task are cohorts or words that shared onset consonants (<em>bear-bell</em>, <em>flag-fly</em>). Only trials with this type of phonological foil will be used to measure phonological interference effects. The other phonological foils included some rhymes (like <em>ring</em>-<em>swing</em>) and some words with onsets that differed by a phonetic feature (<em>kite-gift</em>). Effects from those foils will be considered separately.<a href="analysis.html#fnref5">↩</a></p></li>
<li id="fn6"><p>Some terminology trivia: This linking function is usually ascribed to Luce <span class="citation">(<a href="#ref-Luce1959">1959</a>, <a href="#ref-Luce2008">2008</a>)</span>: “The Luce choice rule is the standard method of linking model activations to behavioral responses (e.g., McClelland &amp; Elman, 1986), including fixation behavior measured in human participants” <span class="citation">(Mirman et al., <a href="#ref-Mirman2011">2011</a>, p. 62)</span>. From my reading, it seems that the mathematical function is the softmax, but the Luce rule is a trick that let us ignore irrelevant choices: “An important property of the softmax function […] is known as independence from irrelevant attributes (Luce, 1959, 2008). The model implies that the ratio of probabilities of two outcomes is the same regardless of what other possible outcomes are included in the set” <span class="citation">(Kruschke, <a href="#ref-kruschke2015doing">2015</a>, p. 654)</span>. In other words, to model a 4-alternative force choice task, we only need to consider the activation of the four relevant alternatives.<a href="analysis.html#fnref6">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="outcome-measures.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="prepare-and-explore-the-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["dissertation.pdf", "dissertation.epub", "dissertation.docx"],
"toc": {
"collapse": "subsection"
},
"split_bib": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
