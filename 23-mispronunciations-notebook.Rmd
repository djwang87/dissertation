Sensitivity to mispronunciations
=======================================================================

```{r setup, include = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r helpers, message = FALSE, warning = FALSE}
```

```{r plotting-helpers, include = FALSE}
# knitr::opts_chunk$set(cache = TRUE)
constants$cap_emp_and_draw <- 
  "Intervals: Empirical mean ± SE. Lines: 100 posterior means."

library(bayesplot)
theme_set(theme_teej())
```

```{r load, include = FALSE}
d_raw <- readr::read_csv("./data/aim2-model-ready.csv.gz")

d <- d_raw %>% 
  select(-starts_with("ot")) %>% 
  filter(Condition == "MP", !is.na(Bias_Fam), 300 <= Time) %>% 
  mutate(Trials = Target + Distractor) %>% 
  polypoly::poly_add_columns(
    Time, degree = 3, scale_width = 1, prefix = "ot")

study_child_with_empty_cells <- d %>% 
  filter(Trials < 4) %>% 
  distinct(Study, ResearchID, Bias_Fam)

study_counts <- study_child_with_empty_cells %>%
  count(Study, Bias_Fam) %>% 
  tidyr::complete(Bias_Fam, Study, fill = list(n = 0))

study_counts_f <- study_counts %>%
  filter(Bias_Fam == "Familiar") %>% 
  split(.$Study) %>%
  lapply(pull, n) %>%
  set_names(stringr::str_replace, "TimePoint", "T")

noun_f_t1 <- ngettext(study_counts_f$T1, "child", "children")

study_counts_u <- study_counts %>%
  filter(Bias_Fam == "Unfamiliar") %>% 
  split(.$Study) %>%
  lapply(pull, n) %>%
  set_names(stringr::str_replace, "TimePoint", "T")

d <- d %>% 
  anti_join(study_child_with_empty_cells)

d_u <- d %>% filter(Bias_Fam == "Unfamiliar")
d_f <- d %>% filter(Bias_Fam == "Familiar")

# readr::write_csv(d_u, "./data/aim2-mp-unfam-modeled-data.csv.gz")
# readr::write_csv(d_f, "./data/aim2-mp-fam-modeled-data.csv.gz")

library(brms)
mp_unfam <- readr::read_rds("./data/aim2-mp-unfam.rds.gz")
mp_unfam

mp_fam <- readr::read_rds("data/aim2-mp-fam.rds.gz")
mp_fam

unfam_peaks <- readr::read_csv(
  file = "./data/aim2-mp-unfam-peaks.csv.gz", 
  col_types = readr::cols(
    .default = readr::col_double(),
    .draw = readr::col_integer(),
    Study = readr::col_character(),
    ResearchID = readr::col_character()))  %>% 
  mutate(Study = convert_study_to_age(Study)) %>% 
  rename(Peak = Peak_Prop)

fam_peaks <- readr::read_csv(
  file = "./data/aim2-mp-fam-peaks.csv.gz", 
  col_types = readr::cols(
    .default = readr::col_double(),
    .draw = readr::col_integer(),
    Study = readr::col_character(),
    ResearchID = readr::col_character())) %>% 
  mutate(Study = convert_study_to_age(Study))
```

For the mispronunciation trials, there is no correct "target", as there
is for the other conditions. The design of the task allows the child to
associate a mispronunciation with an unfamiliar object or with the
familiar object with a name that sounds like the mispronunciation. As a
result, I analyzed the mispronunciation trials separately for both
initial-fixation locations. One analysis handled trials where a child's
gaze started on the familiar object and another analysis handled trials
starting on the unfamiliar object. For these models, I fit a Bayesian
logistic regression growth curve model that included indicators for Age
and Time × Age interactions, as in the model from
[Chapter \@ref(fam-rec)](#fam-rec). The linear model was therefore:

`r insert_html_math()`
\small
\begin{align*}
   \text{log-odds}(\mathit{looking}) =\
    &\beta_0 + 
      \beta_1\text{Time}^1 + 
      \beta_2\text{Time}^2 + 
      \beta_3\text{Time}^3\ + 
      &\text{[age 3 growth curve]} \\
    (&\gamma_{0} + 
      \gamma_{1}\text{Time}^1 + 
      \gamma_{2}\text{Time}^2 +
      \gamma_{3}\text{Time}^3)*\text{Age}\,\text{4} + \
      &\text{[adjustments for age 4]} \\
    (&\delta_{0}\!\ + 
      \delta_{1}\text{Time}^1\!\ + 
      \delta_{2}\text{Time}^2\!\ +
      \delta_{3}\text{Time}^3)*\text{Age}\,\text{5} \
      &\text{[adjustments for age 5]} \\
\end{align*}
`r insert_html_math()`

The mixed effects model included by-child and by-child-by-age random
effects so that it would capture how a child's growth curve features may
be similar over developmental time (by-child effects) and may differ at
each age (by-child-by-age effects).
[Appendix \@ref(aim2-gca-models)](#aim2-gca-models) contains the R code
used to fit these models along with a description of the model's
specification/syntax.

For these analyses, I modeled the data from `r min(d$Time)`
to `r max(d$Time)` ms after target onset. As in the real word vs.
nonword analyses, I removed any Age × Child levels if the child's data
had fewer than 4 fixations in a single time bin. As a result, children
had to have at least 4 looks to one of the two images in every 50-ms
time bin. For the unfamiliar-initial trials, this screening removed
`r study_counts_u$T1` children at age 3, `r study_counts_u$T2` at age 4,
and `r study_counts_u$T3` at age 5, and for the familiar-initial trials,
this screening removed `r study_counts_f$T1`, `r study_counts_f$T2`, and
`r study_counts_f$T3` children at ages 3, 4, and 5, respectively.


## Unfamiliar-initial trials: Move along now

```{r unfam-model-intervals}
test <- posterior_samples(mp_unfam, pars = "^b_") %>% 
  mutate(
    b_Intercept_Age3 = b_Intercept,
    b_Intercept_Age4 = b_Intercept + b_StudyTimePoint2,
    b_Intercept_Age5 = b_Intercept + b_StudyTimePoint3,
    b_ot1_Age3 = b_ot1,
    b_ot1_Age4 = b_ot1 + `b_ot1:StudyTimePoint2`,
    b_ot1_Age5 = b_ot1 + `b_ot1:StudyTimePoint3`,
    b_ot2_Age3 = b_ot2,
    b_ot2_Age4 = b_ot2 + `b_ot2:StudyTimePoint2`,
    b_ot2_Age5 = b_ot2 + `b_ot2:StudyTimePoint3`,
    b_ot3_Age3 = b_ot3,
    b_ot3_Age4 = b_ot3 + `b_ot3:StudyTimePoint2`,
    b_ot3_Age5 = b_ot3 + `b_ot3:StudyTimePoint3`,
    b_Intercept_Prop_Age3 = plogis(b_Intercept_Age3),
    b_Intercept_Prop_Age4 = plogis(b_Intercept_Age4),
    b_Intercept_Prop_Age5 = plogis(b_Intercept_Age5),
    d_Intercept_Age4 = b_Intercept_Age4 - b_Intercept_Age3,
    d_Intercept_Age5 = b_Intercept_Age5 - b_Intercept_Age4,
    d_Intercept_Prop_Age4 = b_Intercept_Prop_Age4 - b_Intercept_Prop_Age3,
    d_Intercept_Prop_Age5 = b_Intercept_Prop_Age5 - b_Intercept_Prop_Age4,
    d_Intercept_Prop_Age5_3 = b_Intercept_Prop_Age5 - b_Intercept_Prop_Age3,
    d_ot1_Age4 = b_ot1_Age4 - b_ot1_Age3,
    d_ot1_Age5 = b_ot1_Age5 - b_ot1_Age4,
    d_ot2_Age4 = b_ot2_Age4 - b_ot2_Age3,
    d_ot2_Age5 = b_ot2_Age5 - b_ot2_Age4,
    d_ot3_Age4 = b_ot3_Age4 - b_ot3_Age3,
    d_ot3_Age5 = b_ot3_Age5 - b_ot3_Age4)

group_average_peaks <- unfam_peaks %>%
  select(Study, ResearchID, .draw, Peak) %>% 
  group_by(Study, .draw) %>%
  summarise_at(vars(Peak), mean, na.rm = TRUE) %>% 
  ungroup() %>% 
  tidyr::spread(Study, Peak) %>% 
  select(-.draw) %>% 
  mutate(d_43 = `Age 4` - `Age 3`, d_54 = `Age 5` - `Age 4`) %>% 
  mcmc_intervals_data()

group_peaks <- group_average_peaks %>% 
  split(.$parameter) %>% 
  lapply(pull, m) %>% 
  lapply(printy::fmt_fix_digits, 2) %>% 
  lapply(printy::fmt_leading_zero)

unfam_ceilings <- unfam_peaks %>%
  select(Study, ResearchID, .draw, Peak) %>% 
  group_by(Study, .draw) %>% 
  summarise(Ceiling = sum(Peak >= .99)) %>% 
  ungroup() %>% 
  select(Study, Ceiling) %>%
  tidyr::nest(-Study) %>% 
  mutate(intervals = data %>% purrr::map(mcmc_intervals_data)) %>% 
  select(-data) %>% 
  tidyr::unnest(intervals) %>% 
  mutate(
    Study = stringr::str_replace(Study, "TimePoint", "TP"),
    parameter = stringr::str_replace(parameter, "nonsense", "nons"))

ceilings <- unfam_ceilings  %>% 
  split(.$Study) %>% 
  fmt_inline_median_interval(0) %>% 
  add_ui_slug_to_first(slug = "90%&nbsp;UI: ")

i_ints <- mcmc_intervals_data(test, regex_pars = "Prop_Age") %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  add_ui_slug_to_first("90% UI: ") %>% 
  lapply(stringr::str_replace_all, "0[.]", ".")
```

When preschoolers started on the image of a novel object and heard a
mispronunciation, they looked to the familiar image.
Figure \@ref(fig:unfam-initial-mp-trials) shows the average of
children's growth curves along with the 100 model-estimated group
averages. The growth curves all cross the .5 threshold, so the
children on average looked more to the familiar than the unfamiliar
image. Granted, the degree of referent selection is not as strong as
that observed for the real words or nonwords. For those conditions, the
average growth curve reached a peak of around .77 at age 3, but for the
mispronunciations the age-3 peak is around .62. Children also were
comparatively slower to process mispronunciations. For the real-word
condition, the average age-3 growth curve crosses .5 looking probability
around 775 ms after target onset, whereas in the mispronunciation
condition, this threshold is crossed at 1000 ms. Children associate the
mispronunciation with the familiar object, although they are slower and
show greater uncertainty compared to real word trials.

(ref:unfam-initial-mp-trials) Averages of participants' growth curves in each age. The lines represent 100 posterior predictions of the group average. 

```{r unfam-initial-mp-trials, fig.cap = "(ref:unfam-initial-mp-trials)", fig.width = 4.5, fig.height = 3.5, out.width = "66%"}
newdata <- d_u %>% 
  distinct(Study, ResearchID, Time, ot1, ot2, ot3) %>% 
  mutate(Target = 0, Trials = 30)

m_u_new_fits_each <- augment_linpred(
  mp_unfam, newdata, nsamples = 100, allow_new_levels = TRUE) %>% 
  mutate(Study = convert_study_to_age(Study)) 

m_u_new_fits <- m_u_new_fits_each %>% 
  group_by(Study, .draw, Time) %>% 
  summarise(Prop = mean(plogis(.posterior_value))) %>% 
  group_by(Study, .draw)

df_u_label <- tibble::tribble(
  ~Study, ~Time, ~Prop,
  "Age 3", 1050, .42,
  # "Age 4", 1000, .42,
  "Age 5", 1300, .72)

d_u_plotting <- d_u %>% 
  mutate(Study = convert_study_to_age(Study)) 

ggplot(d_u_plotting) + 
  aes(x = Time, y = Prop, color = Study) + 
  geom_hline(yintercept = .5, size = 2, color = "white") +
  stat_summary(fun.data = mean_se, geom = "pointrange") + 
  geom_line(aes(group = .group), data = m_u_new_fits, alpha = .05) +
  geom_text(
    aes(label = Study),
    data = df_u_label,
    size = 5, 
    family = "Lato Semibold") +
  geom_text(
    aes(label = label),
    data = data_frame(
      Time = 425, 
      Prop = .11, 
      label = constants$note_mp_unfam),
    size = 3, 
    hjust = 0,
    color = constants$col_off_black,
    family = "Lato") +
  scale_color_study() + 
  expand_limits(y = .76) +
  guides(color = FALSE) +
  labs(
    x = constants$x_time,
    y = constants$y_prop_fam,
    caption = constants$cap_emp_and_draw)
```

Of the growth curve features, developmental changes were only observed
for the average probability (intercept) and peak probability features.
At age 3, the average proportion of looks to the familiar image was
`r i_ints$b_Intercept_Prop_Age3`. At age 4, the looking proportion
increased by `r i_ints$d_Intercept_Prop_Age4` to
`r i_ints$b_Intercept_Prop_Age4`. This year-over-year change was probably
positive, but the the uncertainty interval still includes a change of 0
as a plausible result. Visually, this uncertainty appears in the growth
curve plot by how close together the age-3 and age-4 growth curves
appear. At age 4, the average proportion of looks
increased by `r i_ints$d_Intercept_Prop_Age5` to
`r i_ints$b_Intercept_Prop_Age5`. Here, there is more certainty that the
year-over-year change was positive, and this result is consistent with
the visual separation of the age-5 growth curve from the others. In
short, performance was similar for age 3 and age 4 but there was a
marked improvement at age 5.

Figure \@ref(fig:unfam-peaks-by-age) shows participant's growth curve
peaks for each year of the study. The peaks were computed as in other
chapters by taking the median of the five highest values on the curve.
The average of the participants' peak looking probabilities followed the same
pattern as the average looking probabilities: similar levels at age 3 and age 4
(`r group_peaks[["Age 3"]]` versus `r group_peaks[["Age 4"]]`) but a
clear gain in looking peak probability at age 5
(`r group_peaks[["Age 5"]]`). 


(ref:unfam-peaks-by-age) Growth curve peaks by age for mispronunciation trials starting on the unfamiliar image.

```{r unfam-peaks-by-age, fig.cap = "(ref:unfam-peaks-by-age)", fig.width=4, fig.height=3, out.width="50%"}
set.seed(20180715)

study_peak_counts <- unfam_peaks %>%
  distinct(Study, ResearchID) %>%
  mutate(StudyCounts = Study %>% fct_add_counts()) %>%
  distinct(Study, StudyCounts)

x_levels <- setNames(
  as.character(study_peak_counts$StudyCounts), 
  as.character(study_peak_counts$Study))

unfam_peaks_avgs <- unfam_peaks %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(Peak), mean, na.rm = TRUE) %>% 
  ungroup() 

ggplot(unfam_peaks_avgs) + 
  aes(x = Study, y = Peak) + 
  geom_hline(yintercept = .5, size = 2, color = "white") + 
  geom_boxplot(width = .4, fill = NA, outlier.alpha = 0) +
  geom_point(
    position = position_jitter(width = .2), 
    alpha = .4, 
    shape = 1) + 
  labs(
    title = "Growth curve peaks",
    subtitle = constants$note_mp_unfam,
    x = NULL,
    y = NULL,
    caption = "Points: Participant posterior means.") + 
  scale_x_discrete(labels = x_levels) +
  theme(plot.subtitle = element_text(size = rel(.9))) 

# + 
#     scale_y_continuous(
#       minor_breaks = c(.1, .3, .5, .7, .9),
#       breaks = c(0, .2, .4, .6, .8, 1),
#       labels = c("0", ".2", ".4", ".6", ".8", "1.0")) 
```
Figure \@ref(fig:unfam-peaks-by-age) also indicates how most of the
children at each age favored the familiar object over the unfamilar
object. The bottom hinge of the boxplots mark the location of the 25th
percentile. Therefore, approximately 75% of children at age 3 were on or
above the .5 threshold. Unlike the other conditions, very few
listeners achieve a peak of looking probability of .99: At age 5, only
`r ceilings[["Age 5"]]` children reached ceiling performance, compared
to approximately 40 for nonwords and 13 for real words.

None of the other growth curve features showed developmental changes.
That is, there were no credible year-over-year changes for the linear,
quadratic or cubic time components of the growth curve. Although
Figure \@ref(fig:unfam-initial-mp-trials) shows children's probability
of looking to the familiar image increasing more quickly at age 5, this
effect cannot be clearly tied to any of the model's polynomial time
features. After 600 ms, the age-5 curve is almost parallel to
other curves. This visual feature is consistent with the intercept
effect: The curve is higher than the others on average, but it does not
show any differences in shape.


```{r, include = FALSE}
scores <- readr::read_csv("./data-raw/test_scores.csv") %>% 
  mutate(
    MinPair_ProportionCorrect = ifelse(
      MinPair_ProportionCorrect < .2, NA, MinPair_ProportionCorrect),
    Study = convert_study_to_age(Study))

tp1 <- scores %>% filter(Study == "Age 3")
tp2 <- scores %>% filter(Study == "Age 4")
tp3 <- scores %>% filter(Study == "Age 5")

# minp <- readr::read_csv(file = "./data-raw/age3-minpair-fits.csv") %>%
#   filter(Model == "base + age + ppvt") %>%
#   mutate(Study = "Age 3")

minp_cors <- unfam_peaks %>% 
  filter(Study == "Age 3") %>% 
  left_join(tp1, by = c("Study", "ResearchID")) %>% 
  group_by(.draw) %>%  
  tidy_correlation(Peak, MinPair_ProportionCorrect) 

min_p_cor <- minp_cors %>% 
  filter(column1 == "Peak", column2 == "MinPair_ProportionCorrect") %>% 
  select(MinP = estimate) %>% 
  mcmc_intervals_data() %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  add_ui_slug_to_first("90% UI: ") %>% 
  lapply(stringr::str_replace_all, "0[.]", ".")

min_p_n <- minp_cors %>% 
  filter(column1 == "Peak", column2 == "MinPair_ProportionCorrect") %>% 
  pull(n) %>% 
  unique()

# Report Peak ~ EVT at age 3
m_evt_age3 <- unfam_peaks_avgs %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 3") %>% 
  lm(Peak ~ scale(EVT_Standard, scale = FALSE), .)
summary(m_evt_age3)

# Small effect
delta_by_15 <- (coef(m_evt_age3)[2] * 15) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

peak_evt_r_squared <- m_evt_age3 %>% 
  broom::glance() %>% 
  pull(r.squared) %>%
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

# Get 100 samples of peaks to model
to_model <- unfam_peaks %>% 
  sample_n_of(100, .draw) %>% 
  left_join(scores) 

# Given a df with a EVT_Standard column, make a grid for ploting based on that
# df.
make_grid <- function(df) {
  modelr::data_grid(df, EVT_Standard = modelr::seq_range(EVT_Standard, 80))
}

# Fit 100 regressions
lines <- to_model %>% 
  tidyr::nest(-Study, -.draw) %>% 
  mutate(
    model = data %>% 
      purrr::map(~ lm(Peak ~ EVT_Standard, .x)),
    grid = data %>% purrr::map(make_grid),
    grid = purrr::map2(grid, model, modelr::add_predictions)) %>% 
  select(Study, .draw, grid) %>% 
  tidyr::unnest()

p_evt_peaks <- to_model %>% 
  filter(!is.na(EVT_Standard)) %>% 
  ggplot() + 
    aes(x = EVT_Standard, y = Peak, color = Study) + 
    geom_hline(size = 2, color = "white", yintercept = .5) +
    stat_summary(fun.y = mean, geom = "point") + 
    stat_summary(fun.data = mean_se, geom = "linerange") + 
    geom_line(
      aes(y = pred, group = interaction(.draw, Study)), 
      data = lines, 
      alpha = .1)  +
    geom_text(
      aes(label = Study),
      data = data_frame(
        EVT_Standard = c(55, 156),
        Study = c("Age 3", "Age 4"),
        Peak = c(.44, .59)),
        size = 5, 
       family = "Lato Semibold") +
    scale_color_study() +
    guides(color = FALSE) +
    labs(
      x = "EVT-2 standard score",
      y = "Growth curve peak",
      title = "Vocabulary weakly predicts peaks at age 3",
      caption = "Lines: Regressions on 100 posterior samples of peaks")
```


```{r optionally-verify-unfam-regressions, eval = FALSE}
# This code checks over whether any regression effects held between MinPair/EVT
# and GCA.
regressions <- unfam_peaks %>% 
  sample_n_of(100, .draw) %>% 
  select(.draw, Study, ResearchID, Peak, Prop_Intercept:Prop_ot3) %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>%
  tidyr::gather("Feature", "Value", Prop_Intercept:Prop_ot3, Peak) %>% 
  tidyr::gather(
    "Predictor", "Score", 
    EVT_Standard, MinPair_ProportionCorrect) %>% 
  anti_join(
    data_frame(
      Study = c("Age 4", "Age 5"), 
      Predictor = c("MinPair_ProportionCorrect", "MinPair_ProportionCorrect")),
    by = c("Study", "Predictor")) %>% 
  tidyr::nest(-.draw, -Study, -Feature, -Predictor) %>% 
  mutate(
    results = data %>% 
      purrr::map(~ lm(Value ~ Score, .x)) %>% 
      purrr::map(broom::tidy)) %>% 
  select(-data) %>% 
  tidyr::unnest(results) %>% 
  filter(term != "(Intercept)")

# Just quickly eyeball/confirm that EVT Standard predicted age 3
# reliability/accuracy feature. It's bad practice to look at p-values like this
# but I need a quick piece of code to run/re-run to verify my claim in the prose
# that the only effects held on age 3 x evt standard x intercept/peak.
ggplot(regressions %>% group_by(Study, Feature, Predictor)) +
  aes(x = Feature, y = p.value, color = Study) +
  stat_summary(
    aes(group = .group), 
    fun.data = median_hilow, 
    position = position_dodge(width = .4)) +
  geom_hline(yintercept = .05) + 
  facet_wrap("Predictor")
  
# gca_sextiles <- unfam_peaks %>% 
#   select(.draw, Study, ResearchID, Peak, Prop_Intercept:Prop_ot3) %>% 
#   tidyr::gather("Feature", "Value", Prop_Intercept:Prop_ot3, Peak) %>% 
#   group_by(Study, ResearchID, Feature) %>% 
#   summarise(Value = mean(Value)) %>% 
#   group_by(Study, Feature) %>% 
#    mutate(
#     ntile = factor(ntile(Value, 6)),
#     num = fct_add_counts(ntile) %>% as.character()) 
```

### Child-level predictors

I tested whether child-level measures predicted looking
behavior under these conditions. First, I asked if performance on a
minimal pair discrimination task at age 3 predicted looking behavior at
age 3. The rationale here is the hypothesis that children with better
minimal pair discrimination may be especially sensitive to
mispronunciations. Proportion of items correct on the task did not
correlate with growth curve peaks, *r* = `r min_p_cor`, *n* =
`r min_p_n`, nor with any other growth curve measures.

I also tested whether expressive vocabulary (EVT-2 standard score)
predicted performance in this condition. In this case, there were
significant effects at age 3 where a higher expressive vocabulary
predicted higher peak probabilities and higher average probabilities.
These effects, however, were very small. As shown in
Figure \@ref(fig:plot-evt-mp-unfam-peaks), for example, a 15-point
increase in expressive vocabulary predicted an increase of growth curve
peak of `r delta_by_15`, *R*^2^ = `r peak_evt_r_squared`. Expressive
vocabulary did not predict any of the growth curve features at age 4 or
at age 5.

(ref:plot-evt-mp-unfam-peaks) Relationship between expressive vocabulary and growth curve peaks for mispronunciation trials starting on the unfamiliar image. I took 100 draws from the posterior distribution and computed participant's growth curve peaks for each draw. Points represent the mean and standard error of 100 peaks. Lines represent regressions fit on each draw. 

```{r plot-evt-mp-unfam-peaks, fig.cap = "(ref:plot-evt-mp-unfam-peaks)", out.width = "50%", fig.width = 4.25, fig.height = 4}
p_evt_peaks
```

**Summary**. When children are looking at the unfamiliar object and hear
a mispronunciation, they shift their looks on average to the familiar
image that sounds like the mispronunciation. Children are much more
uncertain in this condition, compared to the real-word and nonword
conditions where the appropriate referent is more obvious. The only
developmental changes observed were the increases in average looking
probability and peak looking probability at age 5. Finally, there was a
small effect of expressive vocabulary on looking probability at age 3,
but no other effects of vocabulary were observed. Minimal pair
discrimination at age 3 also did not predict looking behavior.





Familiar-initial trials: Should I stay or should I go?
------------------------------------------------------------------------

```{r mp-fam-effects}
# Create in-line stats valeus

percent_diff <- function(new, old) {
  # A change from 100 to 80 is (80 - 100) / 100 = -20 / 100 = -20% change
  (new - old) / old
}

mp_fam_fixef <- posterior_samples(mp_fam, pars = "^b_") %>% 
  transmute(
    b_Intercept_Age3 = b_Intercept,
    b_Intercept_Age4 = b_Intercept + b_StudyTimePoint2,
    b_Intercept_Age5 = b_Intercept + b_StudyTimePoint3,
    b_ot1_Age3 = b_ot1,
    b_ot1_Age4 = b_ot1 + `b_ot1:StudyTimePoint2`,
    b_ot1_Age5 = b_ot1 + `b_ot1:StudyTimePoint3`,
    b_ot2_Age3 = b_ot2,
    b_ot2_Age4 = b_ot2 + `b_ot2:StudyTimePoint2`,
    b_ot2_Age5 = b_ot2 + `b_ot2:StudyTimePoint3`,
    b_ot3_Age3 = b_ot3,
    b_ot3_Age4 = b_ot3 + `b_ot3:StudyTimePoint2`,
    b_ot3_Age5 = b_ot3 + `b_ot3:StudyTimePoint3`,
    b_Intercept_Prop_Age3 = plogis(b_Intercept_Age3),
    b_Intercept_Prop_Age4 = plogis(b_Intercept_Age4),
    b_Intercept_Prop_Age5 = plogis(b_Intercept_Age5),
    d_Intercept_Age4 = b_Intercept_Age4 - b_Intercept_Age3,
    d_Intercept_Age5 = b_Intercept_Age5 - b_Intercept_Age4,
    d_Intercept_Prop_Age4 = b_Intercept_Prop_Age4 - b_Intercept_Prop_Age3,
    neg_d_Intercept_Prop_Age4 = d_Intercept_Prop_Age4 * -1,
    d_Intercept_Prop_Age5 = b_Intercept_Prop_Age5 - b_Intercept_Prop_Age4,
    d_Intercept_Prop_Age5_3 = b_Intercept_Prop_Age5 - b_Intercept_Prop_Age3,
    per_d_Intercept_Prop_Age4 = percent_diff(
      b_Intercept_Prop_Age4, 
      b_Intercept_Prop_Age3),
    per_d_Intercept_Prop_Age5 = percent_diff(
      b_Intercept_Prop_Age5, 
      b_Intercept_Prop_Age4),
    d_ot1_Age4 = b_ot1_Age4 - b_ot1_Age3,
    d_ot1_Age5 = b_ot1_Age5 - b_ot1_Age4,
    per_d_ot1_Age4 = percent_diff(b_ot1_Age4, b_ot1_Age3),
    per_d_ot1_Age5 = percent_diff(b_ot1_Age5, b_ot1_Age4),
    neg_per_d_ot1_Age4 = -percent_diff(b_ot1_Age4, b_ot1_Age3),
    neg_per_d_ot1_Age5 = -percent_diff(b_ot1_Age5, b_ot1_Age4),
    d_ot2_Age4 = b_ot2_Age4 - b_ot2_Age3,
    d_ot2_Age5 = b_ot2_Age5 - b_ot2_Age4,
    per_d_ot2_Age4 = percent_diff(b_ot2_Age4, b_ot2_Age3),
    per_d_ot2_Age5 = percent_diff(b_ot2_Age5, b_ot2_Age4),
    neg_per_d_ot2_Age4 = -percent_diff(b_ot2_Age4, b_ot2_Age3),
    neg_per_d_ot2_Age5 = -percent_diff(b_ot2_Age5, b_ot2_Age4),
    d_ot3_Age4 = b_ot3_Age4 - b_ot3_Age3,
    d_ot3_Age5 = b_ot3_Age5 - b_ot3_Age4,
    per_d_ot3_Age4 = percent_diff(b_ot3_Age4, b_ot3_Age3),
    per_d_ot3_Age5 = percent_diff(b_ot3_Age5, b_ot3_Age4),
    neg_per_d_ot3_Age4 = -percent_diff(b_ot3_Age4, b_ot3_Age3),
    neg_per_d_ot3_Age5 = -percent_diff(b_ot3_Age5, b_ot3_Age4)) %>% 
  as_tibble()

# mcmc_intervals(data.frame(x = mp_fam_fixef$per_d_ot1_Age4))
# mcmc_intervals(data.frame(x = mp_fam_fixef$b_Intercept_Prop_Age3))
# mcmc_intervals(mp_fam_fixef,  regex_pars = "Intercept_Prop")
# mcmc_intervals_data(mp_fam_fixef,  regex_pars = "Intercept_Prop")

props <- mp_fam_fixef %>% 
  mcmc_intervals_data(regex_pars = "Intercept_Prop") %>% 
  mutate(
    parameter = parameter %>% stringr::str_replace("Intercept_Prop_", "")) %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  add_ui_slug_to_first("90% UI: ") %>% 
  lapply(fmt_remove_leading_zeros_in_text)

time1 <- mp_fam_fixef %>% 
  mcmc_intervals_data(regex_pars = "ot1") %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  purrr::map_at(
    .at = c("per_d_ot1_Age4", "per_d_ot1_Age5", 
            "neg_per_d_ot1_Age4", "neg_per_d_ot1_Age5"), 
    .f = fmt_convert_prop_to_percent)

time2 <- mp_fam_fixef %>% 
  mcmc_intervals_data(regex_pars = "ot2") %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  purrr::map_at(
    .at = c(
      "per_d_ot2_Age4", "per_d_ot2_Age5", 
      "neg_per_d_ot2_Age4", "neg_per_d_ot2_Age5"), 
    .f = fmt_convert_prop_to_percent)
```

The preceding results showed that preschoolers associate one-feature
onset-mispronunciations with the familiar word that matches the rime of
the word. But that was only for trials where children start on the unfamilar
object. I now consider the other situation, where children are fixating
on a familiar object and hear a word that immediately mismatches with
the name of that familiar object. On the basis of the first segment,
children have information that supports switching to another image. But
as the rest of the word unfolds, they hear a syllable rime that supports
staying.

Figure \@ref(fig:fam-initial-mp-trials) shows the growth curve averages
for trials starting on the familiar image. The looking patterns show a
sharp fall towards .5 which is chance-level performance. Behaviorally,
children on average move quickly to look at both images equally. They
rush into maximum uncertainty, especially at age 4. Patterns are
somewhat more restrained at age 5. Here, the average of the growth
curves never dips below .5, and in fact, it shows a late rise to .6
looking probability. At this age, children are overall more likely to
stay on the familiar object. Finally, at age-3, the curve begins to fall
later than the other curves, reflecting a slower change from the
starting probability.

<!-- One possible interpretation of this pattern is that the children making  -->
<!-- brief confirmatory looks to the novel image; they checking out -->
<!-- the novel image. But this cannot be right because the growth curve never -->
<!-- dips much below .5 (certainly not below .4). So there is more likely a -->
<!-- mix of behaviors, with children staying put on some trials and -->
<!-- considering the novel object on some trials. -->

(ref:fam-initial-mp-trials) Averages of participants' growth curves in each age. The lines represent 100 posterior predictions of the group average. 

```{r fam-initial-mp-trials, fig.cap = "(ref:fam-initial-mp-trials)", fig.width = 5, fig.height = 4, out.width = "66%"}
f_newdata <- d_f %>% 
  distinct(Study, ResearchID, Time, ot1, ot2, ot3) %>% 
  mutate(Target = 0, Trials = 30)

m_f_new_fits_each <- augment_linpred(
  mp_fam, f_newdata, nsamples = 100, allow_new_levels = TRUE) %>% 
  mutate(Study = convert_study_to_age(Study)) 
  
m_f_new_fits <- m_f_new_fits_each %>% 
  group_by(Study, .draw, Time) %>% 
  summarise(Prop = mean(plogis(.posterior_value))) %>% 
  group_by(Study, .draw)

df_f_label <- tibble::tribble(
  ~Study, ~Time, ~Prop,
  "Age 3", 650, .80,
  "Age 4", 1000, .41,
  "Age 5", 1400, .66)

df_f_plotting <- d_f %>% 
  mutate(Study = convert_study_to_age(Study)) 

ggplot(df_f_plotting) + 
  aes(x = Time, y = Prop, color = Study) + 
  geom_hline(yintercept = .5, size = 2, color = "white") +
  stat_summary(fun.data = mean_se, geom = "pointrange") + 
  geom_line(aes(group = .group), data = m_f_new_fits, alpha = .05) +
  geom_text(
    aes(label = label),
    data = data_frame(
      Time = 410, 
      Prop = .93, 
      label = constants$note_mp_fam),
    size = 3, 
    hjust = 0,
    color = constants$col_off_black,
    family = "Lato") +
  geom_text(
    aes(label = Study),
    data = df_f_label,
    size = 5, 
    family = "Lato Semibold") +
  scale_color_study() + 
  expand_limits(y = .38) +
  guides(color = FALSE) +
  labs(
    x = constants$x_time,
    y = constants$y_prop_fam,
    caption = constants$cap_emp_and_draw)
```

In other analyses, growth curves rise and plateau, and age-related
effects appear in how quickly the curves rise or the height at which
they plateau. In those cases, it is straightforward to interpret how the
intercept and linear time effects contribute to the curve's shape over
development. For this model, the curves *fall* and plateau, and there is
not an obvious developmental, year-over-year change among the curves.
Thus, more effort is required to interpret the model parameters and how
they combine to form the growth curve shape.

Figure \@ref(fig:mp-fam-gca-features) visualizes how the growth curve
features are weighted at each year and how they contribute to the
overall growth curve shape. At age 3, the intercept feature, or average
proportion of looks to the familiar image, was `r props$b_Age3`. The
feature is less meaningful in this situation because the curves all
start at a high probability which inflates the average value. That said,
comparisons remain useful. At age 4, the average probability decreased
by `r props$neg_d_Age4` to `r props$b_Age4`, and at age 5 the average
probability returns to age-3 levels, `r props$b_Age5`. This intercept
effect contributes to how the age-4 curve dips below the others and
indeed briefly crosses the .5 probability threshold.


(ref:mp-fam-gca-features) Weighted growth curve features. For the first four panels, the *y* axes are scaled to the same range. This scaling highlights how the cubic time component contributes less to the overall shape than the other features.

```{r mp-fam-gca-features, fig.cap = "(ref:mp-fam-gca-features)", eval = TRUE, fig.width = 7, fig.height = 3, out.width = "100%"}
draws <- mp_fam_fixef %>% 
  tibble::rowid_to_column(".draw") %>% 
  sample_n(200) 

by_study <- df_f_plotting %>% 
  mutate(Intercept = 1) %>% 
  distinct(Study, Time, Intercept, ot1, ot2, ot3) %>% 
  tidyr::crossing(.draw = unique(draws$.draw)) %>% 
  left_join(draws) %>% 
  split(.$Study)

by_study$`Age 3`  <- by_study$`Age 3` %>% 
  mutate(
    b_Intercept = Intercept * b_Intercept_Age3,
    b_ot1  = ot1 * b_ot1_Age3,
    b_ot2  = ot2 * b_ot2_Age3,
    b_ot3  = ot3 * b_ot3_Age3)

by_study$`Age 4`  <- by_study$`Age 4` %>% 
  mutate(
    b_Intercept = Intercept * b_Intercept_Age4,
    b_ot1  = ot1 * b_ot1_Age4,
    b_ot2  = ot2 * b_ot2_Age4,
    b_ot3  = ot3 * b_ot3_Age4)

by_study$`Age 5`  <- by_study$`Age 5` %>% 
  mutate(
    b_Intercept = Intercept * b_Intercept_Age5,
    b_ot1  = ot1 * b_ot1_Age5,
    b_ot2  = ot2 * b_ot2_Age5,
    b_ot3  = ot3 * b_ot3_Age5)

feature_draws <- bind_rows(by_study) %>% 
  mutate(b_sum = b_Intercept + b_ot1 + b_ot2 + b_ot3) %>% 
  distinct(.draw, Study, Time, b_Intercept, b_ot1, b_ot2, b_ot3, b_sum) %>% 
  tidyr::gather("Feature", "Value", b_Intercept:b_sum) 

p <- feature_draws %>% 
  mutate(
    Feature = factor(
      Feature, 
      levels = c("b_Intercept", "b_ot1", "b_ot2", "b_ot3", "b_sum"),
      labels = c("Intercept", "Time^1", "Time^2", "Time^3", "Total"))) %>% 
  group_by(Study, Feature, .draw) %>% 
  ggplot() + 
    aes(x = Time, y = Value, color = Study) + 
    geom_hline(color = "white", size = 1.5, yintercept = 0) + 
    geom_line(aes(group = .group), alpha = .05) + 
    facet_wrap(
      facets = "Feature", 
      nrow = 1, 
      labeller = label_parsed, 
      scales = "free_y") +
    scale_color_study() + 
    guides(color = FALSE) +
    geom_text(
      aes(label = Study, hjust = hjust),
      data = data_frame(
        Study = c("Age 3", "Age 4", "Age 5", "Age 5", "Age 5"),
        Time = c(650, 900, 300, 900, 1400),
        Value = c(1.1, .20, 0, 0, .9),
        hjust = c(0, .5, 0, .5, 1),
        Feature = c("Time^1", "Intercept", "Time^1", "Time^2", "Total")), 
      size = 4,
      family = "Lato Semibold") + 
    expand_limits(y = range(by_study$`Age 3`$b_ot1)) +
  labs(
    x = constants$x_time, 
    y = "Growth curve feature (log-odds)",
    caption = "200 posterior samples of population-average (fixed) effects")
p
```


For the linear time feature, the slope becomes flatter year over year,
decreasing by `r time1$neg_per_d_ot1_Age4` from age 3 to age 4 and
decreasing by `r time1$neg_per_d_ot1_Age5` from age 4 to age 5. For
these curves, however, the starting location is the highest value on the
curve, so the linear time feature in this case mostly works to set the
starting location of the curves. When the features are combined in
Figure \@ref(fig:mp-fam-gca-features), the age-3 curve, which has the
steepest linear time feature, starts at a higher value than the others.

There was a credible change in the quadratic time feature at
age 5. One way to think of a positive quadratic trend is like a weight
hanging on a string: It pulls and bends the whole curve downwards. At
age 5, the quadratic feature is `r time2$neg_per_d_ot2_Age5` smaller than at
age 4, meaning that the age-5 curve has slightly less bend downwards.
Finally, there were no credible differences in the cubic time feature.
Compared to the other features, the cubic trend only a small amount to
the overall shape of the curves.

The combination of these effects shows in the final panel of
Figure \@ref(fig:mp-fam-gca-features). The age-4 curve dips down
furthest beneath 0 log-odds (.5 probability)---this is driven by in the
intercept feature. The age-5 curve stays above 0 log-odds and eventually
starts to rise away from its minimum value, owning to the dampened
linear and quadratic features.

**Summary**. The shape of the average growth curves changed with each
year of the study. Given the interplay of the curve features, I will
avoid assigning a developmental intepretation to individual features.
There are two main noticeable developmental trends at play however.
First, the age-3 curve starts to fall from its baseline probability a
little later than the other curves. Second, the age-5 curve stays above
.5 probability and starts to rise at the end of the trial. At age 5,
children were more likely stay looking at the familiar object than look
at both images equally.


### Child-level predictors and different listening behaviors

In other word recognition analyses, I derived a growth curve "peak"
value as a measure of maximum looking probability or minimum word
recognition uncertainty. For these trials, I asked whether analogous
growth curve "valleys" provided a meaningful feature for looking
behavior when children start a trial fixated on the familiar image. This
value was defined as the median of the five smallest values of a growth
curve. Intuitively, it reflects the maximum degree to which the novel
image is considered as a referent for the mispronunciation.

Figure \@ref(fig:fam-peaks-by-age) shows the posterior means of
participants' growth curve valleys. Note that there is considerable
variability at each age, with the 0--1 interval nearly covered at age 4.
The median value is closer to .5 at age 5, and this difference is
consistent with the growth curve trajectories where the average age 5
curve had did not dip as low as the other curves.

(ref:fam-peaks-by-age) Growth curve peaks by age for mispronunciation trials starting on the familiar image.


```{r fam-peaks-by-age, fig.cap = "(ref:fam-peaks-by-age)", fig.width = 4, fig.height = 3, out.width = "50%"}
study_peak_counts <- fam_peaks %>%
  distinct(Study, ResearchID) %>%
  mutate(
    StudyCounts = Study %>% fct_add_counts()) %>%
  distinct(Study, StudyCounts)

x_levels <- setNames(
  as.character(study_peak_counts$StudyCounts), 
  as.character(study_peak_counts$Study))

fam_peaks %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(Valley_Prop), mean, na.rm = TRUE) %>% 
    ggplot() + 
      aes(x = Study, y = Valley_Prop) + 
      geom_hline(yintercept = .5, size = 2, color = "white") + 
      geom_boxplot(width = .4, fill = NA, outlier.alpha = 0) +
      geom_point(
        position = position_jitter(width = .2), alpha = .3, shape = 1) + 
      labs(
        title = "Growth curve valleys",
        subtitle = constants$note_mp_fam,
        x = NULL,
        y = NULL,
        caption = "Points: Participant posterior means.") + 
    scale_x_discrete(labels = x_levels) +
    theme(plot.subtitle = element_text(size = rel(.9)))
```

The wide range of values for the growth curve valleys suggests that
there are a few different listening behaviors that are being averaged
over in the above analyses. The valleys above .6, for example, indicate
that some children on average stay with the familiar image, and the
valleys below .4 indicate children who favor the unfamiliar image. 

To explore individual listening behaviors, I visualized children's
individual growth curves based on their growth curve valleys. Within
each year, I grouped children into sextiles based on the posterior mean
of the their valley and plotted their individual growth
curves. Figure \@ref(fig:age3-valley-curves) shows the results from
age 3. The final two bins show children who stayed with the
familiar image throughout the mispronuciation trials. The first two bins
mostly contain children who switched to the unfamilar image and stayed
there. These are also children whose curves show a pronounced u-shaped
trajectory. Specifically, the curves with the highest ending points in
the first three bins highligh children with u-shaped trajectories. In
these curves, the probability of fixating on the familiar image briefly
decreases, as the child considers the other image.

(ref:age3-valley-curves) Growth curves for mispronunciations trials starting on the unfamilar object at age 3. Children were grouped into sextiles based on the posterior mean of the growth curve valley---that is, the lowest point on the growth curve. Ten lines are drawn per child to visualize uncertainty. Children were assigned colors arbitrarily. On the right side of each panel are "rugs" which mark the valleys in that panel.

```{r age3-valley-curves, fig.cap = "(ref:age3-valley-curves)", width = 6, height = 6, out.width="80%"}
feature_means <- fam_peaks %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(
    vars(
      Valley_Prop, RiseAfterValley_Prop, PeakAfterValley_Prop, 
      Prop_Intercept:Logit_ot3), 
    mean, na.rm = TRUE) %>% 
  ungroup()

ends <- m_f_new_fits_each %>% 
  group_by(Study, ResearchID, .draw) %>% 
  top_n(5, Time) %>% 
  summarise(End = median(plogis(.posterior_value))) %>% 
  ungroup()

feature_means <- feature_means %>% 
  left_join(
    ends %>% group_by(Study, ResearchID) %>% summarise(End = mean(End))) %>% 
  mutate(WeightedProp_ot2 = Prop_ot2 * End)

valley_groups <- feature_means %>% 
  group_by(Study) %>% 
  mutate(
    ntile = factor(ntile(Valley_Prop, 6)),
    num = ntile %>% 
      fct_add_counts(first_fmt = "{levels} ({counts} children)") %>% 
      as.character()) %>% 
  distinct(Study, ResearchID, Valley_Prop, ntile, num)

set.seed(20180713)

to_plot <- m_f_new_fits_each %>% 
  sample_n_of(10, .draw) %>% 
  left_join(valley_groups, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 3") %>% 
  group_by(ResearchID, Study, .draw)

minima <- to_plot %>% 
  summarise(
    num = unique(num), 
    min = min(plogis(.posterior_value)), 
    Time = max(Time)) %>% 
  group_by(ResearchID, Study, .draw)

ggplot(to_plot) + 
  aes(x = Time, y = plogis(.posterior_value), color = ResearchID) + 
  geom_hline(size = 2, yintercept = .5, color = "white") + 
  geom_rug(
    aes(group = .group, y = min),
    sides = "r", 
    data = minima, 
    alpha = .1, 
    color = "grey20") +
  geom_line(aes(group = .group), alpha = .1) +
  facet_wrap("num") + 
  guides(color = FALSE) + 
  labs(
    x = constants$x_time,
    y = constants$y_prop_fam,
    title = "Age 3 children binned by valley",
    caption = "10 posterior samples per child. Right rugs: Valleys in panel.")

# # This looks at whether age 3 valley predicts later vocab
# valley_groups %>%
#   ungroup() %>%
#   filter(Study == "Age 3") %>%
#   select(-Study) %>%
#   inner_join(scores) %>%
#   ggplot() +
#   aes(x = Peak, y = EVT_Standard, color = Study) +
#   geom_point() +
#   stat_smooth(method = "lm")
```

```{r evt-vs-mp-valley, include = FALSE}
# Extract a model coefficient and optionally multiply it a value
pull_effect <- function(model, index, scale = 1) {
  coef(model)[index] * scale
}

valley_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  lm(Valley_Prop ~ scale(EVT_Standard) * Study, .) %>% 
  summary()

valley_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 3") %>% 
  lm(Valley_Prop ~ scale(EVT_Standard), .) %>% 
  summary()

valley_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 4") %>% 
  lm(Valley_Prop ~ scale(EVT_Standard), .) %>% 
  summary()

valley_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 5") %>% 
  lm(Valley_Prop ~ scale(EVT_Standard), .) %>% 
  summary()

m_fam_valley_evt_age3 <- valley_groups %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 3") %>% 
  lm(Valley_Prop ~ scale(EVT_Standard, scale = FALSE), .)
summary(m_fam_valley_evt_age3)

# Small effect
neg_valley_delta_by_evt15 <- m_fam_valley_evt_age3 %>% 
  pull_effect("scale(EVT_Standard, scale = FALSE)", -15) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

r2_valley_evt <- m_fam_valley_evt_age3 %>% 
  broom::glance() %>% 
  pull(r.squared) %>%
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()




```

```{r minp-vs-mp-valley, include = FALSE}
# minp <- readr::read_csv(file = "./data-raw/age3-minpair-fits.csv") %>%
#   filter(Model == "base + age + ppvt") %>%
#   mutate(Study = "Age 3") %>% 
#   select(ResearchID, Study, MinPair_Ability = coef)

m_fam_valley_prop_age3 <- valley_groups %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 3") %>% 
  lm(Valley_Prop ~ scale(MinPair_ProportionCorrect, scale = FALSE), .)
summary(m_fam_valley_prop_age3)

# Small effect
neg_valley_delta_by_minp1 <- m_fam_valley_prop_age3 %>% 
  pull_effect("scale(MinPair_ProportionCorrect, scale = FALSE)", -.1) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

r2_valley_minp <- m_fam_valley_prop_age3 %>% 
  broom::glance() %>% 
  pull(r.squared) %>%
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()
```

```{r evt-x-minp-vs-mp-valley, include = FALSE}
evt_minp_age3 <- valley_groups %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 3") %>% 
  filter(!is.na(MinPair_ProportionCorrect), !is.na(EVT_Standard))

m_fam_valley_evt_minp_age3 <- 
  lm(
    scale(Valley_Prop, scale = FALSE) ~ 
      scale(MinPair_ProportionCorrect, scale = FALSE) * 
      scale(EVT_Standard, scale = FALSE), 
    evt_minp_age3)
summary(m_fam_valley_evt_minp_age3)

m_fam_valley_evt_minp_age3_raw <- lm(
  Valley_Prop ~ MinPair_ProportionCorrect * EVT_Standard, 
  evt_minp_age3)
summary(m_fam_valley_evt_minp_age3_raw)

# jtools::sim_slopes(
#   m_fam_valley_evt_minp_age3_raw,
#   pred = MinPair_ProportionCorrect,
#   modx = EVT_Standard,
#   jnplot = TRUE)

# jtools::interact_plot(
#   m_fam_valley_evt_minp_age3_raw,
#   pred = MinPair_ProportionCorrect,
#   modx = EVT_Standard,
#   plot.points = TRUE)
# jtools::interact_plot(
#   m_fam_valley_evt_minp_age3_raw,
#   pred = EVT_Standard,
#   modx = MinPair_ProportionCorrect,
#   plot.points = TRUE)

minp_cutpoint <- m_fam_valley_evt_minp_age3_raw %>% 
  jtools::johnson_neyman(
    pred = EVT_Standard, 
    modx = MinPair_ProportionCorrect) %>% 
  getElement("bounds") %>% 
  getElement("Lower") %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()
  
evt_cutpoint <- m_fam_valley_evt_minp_age3_raw %>% 
  jtools::johnson_neyman(
    pred = MinPair_ProportionCorrect, 
    modx = EVT_Standard) %>% 
  getElement("bounds") %>% 
  getElement("Lower") %>% 
  round()

evt_cutpoint_tile <- 
  round(ecdf(evt_minp_age3$EVT_Standard)(evt_cutpoint), 2) * 100

minp_cutpoint_tile <- 
  round(ecdf(evt_minp_age3$MinPair_ProportionCorrect)(minp_cutpoint), 2) * 100

neg_evt_minp_valley_delta_by_minp1 <- m_fam_valley_evt_minp_age3 %>% 
  pull_effect("scale(MinPair_ProportionCorrect, scale = FALSE)", -.1) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

neg_evt_minp_valley_delta_by_evt15 <- m_fam_valley_evt_minp_age3 %>% 
  pull_effect("scale(EVT_Standard, scale = FALSE)", -15) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

r2_valley_evt_minp <- m_fam_valley_evt_minp_age3 %>% 
  broom::glance() %>% 
  pull(r.squared) %>%
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()
```

```{r, eval = FALSE}
# This code checks over whether any regression effects held between MinPair/EVT
# and GCA.
regressions <- fam_peaks %>% 
  mutate(WeightedProp_ot2_alt = Prop_ot2 * PeakAfterValley_Prop) %>% 
  sample_n_of(100, .draw) %>% 
  select(
    .draw, Study, ResearchID, Valley_Prop, RiseAfterValley_Prop, 
    PeakAfterValley_Prop, Peak_Prop, Prop_Intercept:Prop_ot3,
    WeightedProp_ot2_alt) %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>%
  tidyr::gather(
    "Feature", "Value", Valley_Prop, RiseAfterValley_Prop, 
    PeakAfterValley_Prop, Peak_Prop, Prop_Intercept:Prop_ot3,
    WeightedProp_ot2_alt) %>% 
  tidyr::gather(
    "Predictor", "Score", 
    EVT_Standard, MinPair_ProportionCorrect) %>% 
  anti_join(
    data_frame(
      Study = c("Age 4", "Age 5"), 
      Predictor = c("MinPair_ProportionCorrect", "MinPair_ProportionCorrect")),
    by = c("Study", "Predictor")) %>% 
  tidyr::nest(-.draw, -Study, -Feature, -Predictor) %>% 
  mutate(
    results = data %>% 
      purrr::map(~ lm(Value ~ Score, .x)) %>% 
      purrr::map(broom::tidy)) %>% 
  select(-data) %>% 
  tidyr::unnest(results) %>% 
  filter(term != "(Intercept)")

# Just quickly eyeball/confirm that EVT Standard predicted age 3
# reliability/accuracy feature. It's bad practice to look at p-values like this
# but I need a quick piece of code to run/re-run to verify my claim in the prose
# that the only effects held on age 3 x evt standard x intercept/peak.
ggplot(regressions %>% group_by(Study, Feature, Predictor)) +
  aes(x = Feature, y = p.value, color = Study) +
  stat_summary(
    aes(group = .group), 
    fun.data = median_hilow, 
    position = position_dodge(width = .4)) +
  geom_hline(yintercept = .05) + 
  facet_wrap("Predictor") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0))

# These things tend to be super correlated
feature_means %>% 
  group_by(Study) %>% 
  select(
    Study, ResearchID, Valley_Prop, RiseAfterValley_Prop, 
    PeakAfterValley_Prop, Prop_Intercept:Prop_ot3) %>% 
  tidy_correlation(
    Valley_Prop, RiseAfterValley_Prop, 
    PeakAfterValley_Prop, Prop_Intercept:Prop_ot3)
```


I asked whether any child-level factors predicted children's looking
behaviors. I first regressed growth curve valleys on EVT-2 standard
score. There was a small effect at age 3, *R*^2^ =
`r r2_valley_evt`, *n* = `r nobs(m_fam_valley_evt_age3)`. A 15-point
increase in expressive vocabulary predicted decrease in growth curve
valley of `r neg_valley_delta_by_evt15`. At the other ages, the effects are
neglibly small, as shown in Figure \@ref(fig:mp-fam-valley-evt).

(ref:mp-fam-valley-evt) Relationship between expressive vocabulary and growth curve valleys for mispronunciation trials starting on the familiar image. Valleys were computed on 100 draws of the posterior distribution. Points represent the mean and standard error of the valleys. Lines represent the fit of the regression in each draw. Although the slopes of age-4 and age-5 lines are noticeably different from the age-3 one, they cover a tiny amount of the *y* axis so they represent a neglible effect.

```{r mp-fam-valley-evt, fig.cap = "(ref:mp-fam-valley-evt)", out.width = "50%", fig.width = 4.25, fig.height = 4}
# Get 100 samples of peaks to model
to_model <- fam_peaks %>% 
  sample_n_of(100, .draw) %>% 
  left_join(scores) 

# Given a df with a EVT_Standard column, make a grid for ploting based on that
# df.
make_grid <- function(df) {
  modelr::data_grid(df, EVT_Standard = modelr::seq_range(EVT_Standard, 80))
}

# Fit 100 regressions
lines <- to_model %>% 
  tidyr::nest(-Study, -.draw) %>% 
  mutate(
    model = data %>% 
      purrr::map(~ lm(Valley_Prop ~ EVT_Standard, .x)),
    grid = data %>% purrr::map(make_grid),
    grid = purrr:::map2(grid, model, modelr::add_predictions)) %>% 
  select(Study, .draw, grid) %>% 
  tidyr::unnest()

to_model %>% 
  filter(!is.na(EVT_Standard)) %>% 
  ggplot() + 
    aes(x = EVT_Standard, y = Valley_Prop, color = Study) + 
    geom_hline(size = 2, color = "white", yintercept = .5) +
    stat_summary(fun.y = mean, geom = "point") + 
    stat_summary(fun.data = mean_se, geom = "linerange") + 
    geom_line(
      aes(y = pred, group = interaction(.draw, Study)), 
      data = lines, 
      alpha = .1)  +
    geom_text(
      aes(label = Study),
      data = data_frame(
        EVT_Standard = c(55, 72),
        Study = c("Age 3", "Age 5"),
        Valley_Prop = c(.70, .36)),
        size = 5, 
       family = "Lato Semibold") +
    scale_color_study() +
    guides(color = FALSE) +
    labs(
      x = "EVT-2 standard score",
      y = "Growth curve valley",
      title = "Vocabulary weakly predicts valleys at age 3",
      caption = "Lines: Regressions on 100 posterior samples of valleys")
```


I regressed age-3 valleys onto expressive vocabulary, minimal-pair
discrimination accuracy, and their interaction. The two main effects and
their interaction were all statistically significant, *R*^2^ =
`r r2_valley_evt_minp`, *n* = `r nobs(m_fam_valley_evt_minp_age3)`. The
effects of vocabulary and minimal-pair discrimination were both
negative, so that higher scores on these measures predicted lower growth
curve valleys---that is, a greater maximum probability of fixating on
the unfamilar image. For an average participant, a 15-point increase in
expressive vocabulary predicted decrease of
`r neg_evt_minp_valley_delta_by_evt15`, and an increase of minimal pair
accuracy of .1 predicted a decrease in valley of
`r neg_evt_minp_valley_delta_by_minp1`. The interaction term, however,
was positive, meaning that increasing one of the predictors
simulataneously weakens the effect of the other. As one of the
predictors increases, it can push the effect of the other closer to zero
so that its simple effect is "no longer" statistically significant. In
this case, the simple effect of expressive vocabulary was not
significant when minimal pair accuracy was `r minp_cutpoint` or greater
(that is, at the `r minp_cutpoint_tile`-percentile or greater).
Conversely, the simple effect of minimal pair discrimination accuracy
was not significant when expressive vocabulary standard score was
`r evt_cutpoint` or greater (at the `r minp_cutpoint_tile`-percentile or
greater). In summary, at age 3, both expressive vocabulary and minimal
pair discrimination each predicted greater consideration of the
unfamiliar image. But these effects was also redundant so that large
changes in one predictor would weaken the effect of the other. 

```{r compute-weighted-quadratic}
ends <- m_f_new_fits_each %>% 
  group_by(Study, ResearchID, .draw) %>% 
  top_n(5, Time) %>% 
  summarise(End = median(plogis(.posterior_value)))

end_means <- ends %>% 
  summarise(End = mean(End))

feature_means <- feature_means %>% 
  left_join(end_means) %>% 
  mutate(WeightedProp_ot2 = Prop_ot2 * End)

prop_ot2_groups <- feature_means %>% 
  group_by(Study) %>% 
  mutate(
    ntile = factor(ntile(WeightedProp_ot2, 6)),
    num = ntile %>% 
      fct_add_counts(first_fmt = "{levels} ({counts} children)") %>% 
      as.character()) %>% 
  distinct(Study, ResearchID, WeightedProp_ot2, ntile, num)

cor_prop_valley <- cor(feature_means$Prop_ot2, feature_means$Valley_Prop) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero() %>% 
  printy::fmt_minus_sign()

cor_wprop_valley <- feature_means$WeightedProp_ot2 %>% 
  cor(feature_means$Valley_Prop) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero() %>% 
  printy::fmt_minus_sign()

cor_wprop_prop <- feature_means$WeightedProp_ot2 %>% 
  cor(feature_means$Prop_ot2) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero() %>% 
  printy::fmt_minus_sign()
```

The growth curve valley feature measures the maximum extent to which the novel
object is considered as the referent on these trials. But the u-shaped
growth curves in Figure \@ref(fig:age3-valley-curves) suggest another
listening response on this task: Confirmatory looks to the unfamiliar
object. In these u-shaped curves, a child's probability of fixating on
the familiar object temporarily decreases as the novel object is
considered, and the probability rises as that interpretation is
rejected. To quantify this tendency, I computed each child's growth
curve on the probability scale and re-estimated the quadratic trends in
these curves. Exploratory visualization showed that children with higher
values on this quadratic trend were more likely to have a u-shape curve.
This feature, however, also favored sigmoid or z-shaped curves that
rapidly fell and plateaued. To avoid these kinds of curves, I weighted
the quadratic trend using the median of the final five points of the
curve. The weighted quadratic feature penalized curves that have a
strong quadratic trend but end on a low probability. Figure
\@ref(fig:mp-fam-prop-ot2-bins) shows growth curves of age 5 children
binned using this feature. The bottom row of panels illustrates how the
u-shaped feature becomes stronger in each bin. The weighted quadratic feature
was weakly correlated with the growth curve valleys, *r* =
`r cor_wprop_valley`, and the lack of correlation appears in the figure
by how the curves in each panel reach different valleys.

(ref:mp-fam-prop-ot2-bins) Growth curves for mispronunciations trials starting on the unfamilar object at age 5. Children were grouped into sextiles based on the posterior mean of their curves quadratic trend weighted by the height of the curve in the final time bins. Ten lines are drawn per child to visualize uncertainty. Children were assigned colors arbitrarily. 

```{r mp-fam-prop-ot2-bins, fig.cap = "(ref:mp-fam-prop-ot2-bins)", width = 6, height = 6, out.width="80%"}
set.seed(20180713)

prop_ot2_to_plot <- m_f_new_fits_each %>% 
  sample_n_of(10, .draw) %>% 
  left_join(prop_ot2_groups, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 5") %>% 
  group_by(ResearchID, Study, .draw)

ggplot(prop_ot2_to_plot) + 
  aes(x = Time, y = plogis(.posterior_value), color = ResearchID) + 
  geom_hline(size = 2, yintercept = .5, color = "white") + 
  geom_line(aes(group = .group), alpha = .1) +
  facet_wrap("num") + 
  guides(color = FALSE) + 
  labs(
    x = constants$x_time,
    y = constants$y_prop_fam,
    title = "Age 5 children binned by weighted quadratic trend",
    caption = "10 posterior samples per child.")

# bottom_fifth <- function(xs) {
#   xs <= quantile(xs, .2)
# }
# ggplot(prop_ot2_to_plot %>% inner_join(scores)) + 
#   aes(x = Time, y = plogis(.posterior_value), color = bottom_fifth(EVT_Standard)) + 
#   geom_hline(size = 2, yintercept = .5, color = "white") + 
#   geom_line(aes(group = .group), alpha = .1) +
#   facet_wrap("num") + 
#   guides(color = FALSE) + 
#   scale_color_manual(values = c("grey50", constants$col_blue_highlight)) +
#   labs(
#     x = constants$x_time,
#     y = constants$y_prop_fam,
#     title = "Age 5 children binned by weighted quadratic trend",
#     caption = "10 posterior samples per child.")
```


```{r, include = FALSE}
prop_ot2_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  lm(WeightedProp_ot2 ~ scale(EVT_Standard) * Study, .) %>% 
  summary()

prop_ot2_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 3") %>% 
  lm(WeightedProp_ot2 ~ scale(MinPair_ProportionCorrect), .) %>% 
  summary()

prop_ot2_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 3") %>% 
  lm(WeightedProp_ot2 ~ scale(EVT_Standard), .) %>% 
  summary()

prop_ot2_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 4") %>% 
  lm(WeightedProp_ot2 ~ scale(EVT_Standard), .) %>% 
  summary()

prop_ot2_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 5") %>% 
  tidy_correlation(EVT_Standard, WeightedProp_ot2)

m_fam_wot2_evt_age5 <- prop_ot2_groups %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 5") %>% 
  lm(WeightedProp_ot2 ~ scale(EVT_Standard, scale = FALSE), .)
summary(m_fam_wot2_evt_age5)

# Small effect
r2_wot2_evt <- m_fam_wot2_evt_age5 %>% 
  broom::glance() %>% 
  pull(r.squared) %>%
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

prop_ot2_groups %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>% 
  ggplot() + 
    aes(x = EVT_Standard, y = WeightedProp_ot2, color = Study) + 
    geom_point() + 
    stat_smooth(method = "lm")
```

I regressed the u-shaped curve feature onto expressive vocabulary
standard score at each age and onto minimal pair discrimination for
age 3. There was a tiny yet significant of vocabulary at
age 5, *R*^2^ = `r r2_wot2_evt`, where children with lower vocabularies
had a slightly stronger u-shaped trend in their growth curve. This
effect, however, is so small as to be negligible. None of the effects were 
significant.

**Summary**. At age 3, children with larger expressive vocabularies or
better minimal pair discrimination had lower growth curve valleys---that
is, they looked more to the unfamiliar object when they heard a
mispronunciation while fixated on an image of the mispronounced word.
These two child-level measures significantly interacted so that
increasing both measures simultaneously had diminishing returns. I
devised a measure of the how u-shaped the growth curves were, but there
were not any meaningful effects of vocabulary or expressive vocabulary
on this measure.


## Discussion

In the lab, when preschoolers are looking at a novel object and hear the name of
a different familiar object, albeit mispronounced, they look to the familiar
object. Children do this reliably at age 3 and even more reliably at age 5. They
look much less to the object compared to trials where they hear a correct
production of the familiar word---see Figure \@ref(fig:mp-vs-real-peaks)--or
when they hear a nonword in a context that supports fast-referent selection.
Therefore, they are unquestionably sensitive to mispronunciations of familiar
words so that they are more uncertain when they hear a mispronunciation.

  - Unlike those conditions which started to show ceiling effects at
    age 4, children are much more uncertain here.
  - In terms of lexical processing, the syllable onset leads them down a
    garden path. They have to hear more of the word in order to
    associate the mispronunciation with the target. This is a bit like
    processing a rime word.
  - The development story is that they can use the rest of the word more
    effectively to associate the MP with the familiar image. This would
    predict that children become more sensitive to rime-based lexical
    competitors during the preschool years.
  - But there is no effect of expressive vocabulary here, especially at older ages.
  - So they are sensitive but they become more accommodating of the
    mispronounced version.
  


(ref:mp-vs-real-peaks) Text reference for caption

```{r mp-vs-real-peaks, fig.cap = "(ref:mp-vs-real-peaks)", fig.width=4, fig.height=3, out.width="50%"}
set.seed(20180715)
peaks <- readr::read_rds("./data/aim2-real-vs-nw-all-peaks.rds.gz")
peaks <- peaks %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(nonsense, real), mean) %>% 
  ungroup() %>% 
  mutate(Study = convert_study_to_age(Study))

peaks_all <- unfam_peaks %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(Peak), mean, na.rm = TRUE) %>% 
  ungroup() %>% 
  rename(mp = Peak) %>% 
  right_join(peaks)


condition_means <- peaks_all %>% 
  select(-nonsense) %>% 
  filter(!is.na(mp), !is.na(real)) %>% 
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  ungroup()


study_peak_counts <- condition_means %>%
  distinct(Study, ResearchID) %>%
  mutate(StudyCounts = Study %>% fct_add_counts()) %>%
  distinct(Study, StudyCounts)

x_levels <- setNames(
  as.character(study_peak_counts$StudyCounts), 
  as.character(study_peak_counts$Study))

ggplot(condition_means) + 
  aes(x = Study, y = Peak, color = Condition) + 
    geom_hline(yintercept = .5, size = 2, color = "white") + 
  geom_text(
    aes(label = label),
    data = data_frame(
      Peak = 1.06, 
      label = c("mispronunciations", " "),
      Condition = c("mp", "real"),
      Study = c("Age 3", "Age 3")), 
    position = position_dodge(width = .75), 
    size = 3, 
    family = "Lato Medium") +
  geom_text(
    aes(label = label),
    data = data_frame(
      Peak = 1.06, 
      label = c(" ", "real words"),
      Condition = c("mp", "real"),
      Study = c("Age 4", "Age 4")), 
    position = position_dodge(width = 1.15), 
    size = 3, 
    family = "Lato Medium") +
  geom_point(
    position = position_jitterdodge(jitter.width = 0.25, dodge.width = 1.05), 
    alpha = .5, 
    shape = 1) +
  geom_boxplot(
    width = .2, 
    position = position_dodge(width = .3), 
    outlier.alpha = 0)  +
  guides(color = FALSE) +
  labs(
    title = "Mispronunciation penalty",
    x = NULL,
    y = NULL,
    subtitle = "Peaks for trials starting on unfamiliar image",
    caption = "Points: Participant posterior means.") + 
  scale_x_discrete(labels = x_levels) +
  scale_y_continuous(
    minor_breaks = c(.1, .3, .5, .7, .9),
    breaks = c(0, .2, .4, .6, .8, 1)) +
  scale_color_manual(values = c("cyan4", "#6b7a8f", "#f7882f"))  +
  theme(plot.subtitle = element_text(size = rel(.9))) 
```


  - For second set of analyses, there is no one clear strategy for
    referent selection. We see a few different patterns among children.
    Some stay put. Some always switch. Some do both.
  - The growth curve averages rush to .5, which is equal looks to both
    images, which is maximum uncertainty.
  - The age 5 curve doesn't dip as far, so they are slightly more likely
    to stay put.
  - These sets of analyses mainly demonstrate that when children start
    on a familiar image and hear a mispronunciation, they have a few
    options for how to proceed.
  - This also shows a possible decoupling between lexical processing and
  referent selection. It is unlikely that children heard the mispronunciations
  differently in these trials, but rather the responded differently.
  


