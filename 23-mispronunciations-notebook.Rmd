Sensitivity to mispronunciations {#sensitivity-to-mispronunciations}
=======================================================================

```{r setup, include = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r helpers, message = FALSE, warning = FALSE}
```

```{r plotting-helpers, include = FALSE}
# knitr::opts_chunk$set(cache = TRUE)
constants$cap_emp_and_draw <- 
  "Intervals: Empirical mean ± SE. Lines: 100 posterior means."

library(bayesplot)
theme_set(theme_teej())
```

```{r load, include = FALSE}
d_raw <- readr::read_csv("./data/aim2-model-ready.csv.gz")

d <- d_raw %>% 
  select(-starts_with("ot")) %>% 
  filter(Condition == "MP", !is.na(Bias_Fam), 300 <= Time) %>% 
  mutate(Trials = Target + Distractor) %>% 
  polypoly::poly_add_columns(
    Time, degree = 3, scale_width = 1, prefix = "ot")

study_child_with_empty_cells <- d %>% 
  filter(Trials < 4) %>% 
  distinct(Study, ResearchID, Bias_Fam)

study_counts <- study_child_with_empty_cells %>%
  count(Study, Bias_Fam) %>% 
  tidyr::complete(Bias_Fam, Study, fill = list(n = 0))

study_counts_f <- study_counts %>%
  filter(Bias_Fam == "Familiar") %>% 
  split(.$Study) %>%
  lapply(pull, n) %>%
  set_names(stringr::str_replace, "TimePoint", "T")

noun_f_t1 <- ngettext(study_counts_f$T1, "child", "children")

study_counts_u <- study_counts %>%
  filter(Bias_Fam == "Unfamiliar") %>% 
  split(.$Study) %>%
  lapply(pull, n) %>%
  set_names(stringr::str_replace, "TimePoint", "T")

d <- d %>% 
  anti_join(study_child_with_empty_cells)

d_u <- d %>% filter(Bias_Fam == "Unfamiliar")
d_f <- d %>% filter(Bias_Fam == "Familiar")

# readr::write_csv(d_u, "./data/aim2-mp-unfam-modeled-data.csv.gz")
# readr::write_csv(d_f, "./data/aim2-mp-fam-modeled-data.csv.gz")

library(brms)
mp_unfam <- readr::read_rds("./data/aim2-mp-unfam.rds.gz")
mp_unfam

mp_fam <- readr::read_rds("data/aim2-mp-fam.rds.gz")
mp_fam

unfam_peaks <- readr::read_csv(
  file = "./data/aim2-mp-unfam-peaks.csv.gz", 
  col_types = readr::cols(
    .default = readr::col_double(),
    .draw = readr::col_integer(),
    Study = readr::col_character(),
    ResearchID = readr::col_character()))  %>% 
  mutate(Study = convert_study_to_age(Study)) %>% 
  rename(Peak = Peak_Prop)

fam_peaks <- readr::read_csv(
  file = "./data/aim2-mp-fam-peaks.csv.gz", 
  col_types = readr::cols(
    .default = readr::col_double(),
    .draw = readr::col_integer(),
    Study = readr::col_character(),
    ResearchID = readr::col_character())) %>% 
  mutate(Study = convert_study_to_age(Study))
```

For the mispronunciation trials, there is no correct "target", as there
is for the other conditions. The design of the task allows the child to
associate a mispronunciation with an unfamiliar object or with the
familiar object with a name that sounds like the mispronunciation. As a
result, I analyzed the mispronunciation trials separately for both
initial-fixation locations. One analysis handled trials where a child's
gaze started on the familiar object and another analysis handled trials
starting on the unfamiliar object. For these models, I fit a Bayesian
logistic regression growth curve model that included indicators for Age
and Time × Age interactions, as in the model from
[Chapter \@ref(fam-rec)](#fam-rec). The linear model was therefore:

`r insert_html_math()`
\small
\begin{align*}
  \text{log odds}(\text{looking}) =\
    &\beta_0 + 
      \beta_1\text{Time}^1 + 
      \beta_2\text{Time}^2 + 
      \beta_3\text{Time}^3\ + 
      &\text{[age 3 growth curve]} \\
    (&\gamma_{0} + 
      \gamma_{1}\text{Time}^1 + 
      \gamma_{2}\text{Time}^2 +
      \gamma_{3}\text{Time}^3)*\text{Age}\,\text{4}\ + \
      &\text{[age 4 adjustments]} \\
    (&\delta_{0} + 
      \delta_{1}\text{Time}^1 + 
      \delta_{2}\text{Time}^2 +
      \delta_{3}\text{Time}^3)*\text{Age}\,\text{5} \
      &\text{[age 5 adjustments]} \\
\end{align*}
\normalsize
`r insert_html_math()`

The mixed effects model included by-child and by-child-by-age random
effects so that it would capture how a child's growth curve features may
be similar over developmental time (by-child effects) and may differ at
each age (by-child-by-age effects).
[Appendix \@ref(aim2-gca-models)](#aim2-gca-models) contains the R code
used to fit these models along with a description of the model's
specification/syntax.

For these analyses, I modeled the data from `r min(d$Time)`
to `r max(d$Time)` ms after target onset. As in the real word vs.
nonword analyses, I removed any Age × Child levels if the child's data
had fewer than 4 fixations in a single time bin. As a result, children
had to have at least 4 looks to one of the two images in every 50-ms
time bin. For the unfamiliar-initial trials, this screening removed
`r study_counts_u$T1` children at age 3, `r study_counts_u$T2` at age 4,
and `r study_counts_u$T3` at age 5, and for the familiar-initial trials,
this screening removed `r study_counts_f$T1`, `r study_counts_f$T2`, and
`r study_counts_f$T3` children at ages 3, 4, and 5, respectively.


## Unfamiliar-initial trials: Move along now

```{r unfam-model-intervals}
test <- posterior_samples(mp_unfam, pars = "^b_") %>% 
  mutate(
    b_Intercept_Age3 = b_Intercept,
    b_Intercept_Age4 = b_Intercept + b_StudyTimePoint2,
    b_Intercept_Age5 = b_Intercept + b_StudyTimePoint3,
    b_ot1_Age3 = b_ot1,
    b_ot1_Age4 = b_ot1 + `b_ot1:StudyTimePoint2`,
    b_ot1_Age5 = b_ot1 + `b_ot1:StudyTimePoint3`,
    b_ot2_Age3 = b_ot2,
    b_ot2_Age4 = b_ot2 + `b_ot2:StudyTimePoint2`,
    b_ot2_Age5 = b_ot2 + `b_ot2:StudyTimePoint3`,
    b_ot3_Age3 = b_ot3,
    b_ot3_Age4 = b_ot3 + `b_ot3:StudyTimePoint2`,
    b_ot3_Age5 = b_ot3 + `b_ot3:StudyTimePoint3`,
    b_Intercept_Prop_Age3 = plogis(b_Intercept_Age3),
    b_Intercept_Prop_Age4 = plogis(b_Intercept_Age4),
    b_Intercept_Prop_Age5 = plogis(b_Intercept_Age5),
    d_Intercept_Age4 = b_Intercept_Age4 - b_Intercept_Age3,
    d_Intercept_Age5 = b_Intercept_Age5 - b_Intercept_Age4,
    d_Intercept_Prop_Age4 = b_Intercept_Prop_Age4 - b_Intercept_Prop_Age3,
    d_Intercept_Prop_Age5 = b_Intercept_Prop_Age5 - b_Intercept_Prop_Age4,
    d_Intercept_Prop_Age5_3 = b_Intercept_Prop_Age5 - b_Intercept_Prop_Age3,
    d_ot1_Age4 = b_ot1_Age4 - b_ot1_Age3,
    d_ot1_Age5 = b_ot1_Age5 - b_ot1_Age4,
    d_ot2_Age4 = b_ot2_Age4 - b_ot2_Age3,
    d_ot2_Age5 = b_ot2_Age5 - b_ot2_Age4,
    d_ot3_Age4 = b_ot3_Age4 - b_ot3_Age3,
    d_ot3_Age5 = b_ot3_Age5 - b_ot3_Age4)

group_average_peaks <- unfam_peaks %>%
  select(Study, ResearchID, .draw, Peak) %>% 
  group_by(Study, .draw) %>%
  summarise_at(vars(Peak), mean, na.rm = TRUE) %>% 
  ungroup() %>% 
  tidyr::spread(Study, Peak) %>% 
  select(-.draw) %>% 
  mutate(d_43 = `Age 4` - `Age 3`, d_54 = `Age 5` - `Age 4`) %>% 
  mcmc_intervals_data()

group_peaks <- group_average_peaks %>% 
  split(.$parameter) %>% 
  lapply(pull, m) %>% 
  lapply(printy::fmt_fix_digits, 2) %>% 
  lapply(printy::fmt_leading_zero)

unfam_ceilings <- unfam_peaks %>%
  select(Study, ResearchID, .draw, Peak) %>% 
  group_by(Study, .draw) %>% 
  summarise(Ceiling = sum(Peak >= .99)) %>% 
  ungroup() %>% 
  select(Study, Ceiling) %>%
  tidyr::nest(-Study) %>% 
  mutate(intervals = data %>% purrr::map(mcmc_intervals_data)) %>% 
  select(-data) %>% 
  tidyr::unnest(intervals) %>% 
  mutate(
    Study = stringr::str_replace(Study, "TimePoint", "TP"),
    parameter = stringr::str_replace(parameter, "nonsense", "nons"))

ceilings <- unfam_ceilings  %>% 
  split(.$Study) %>% 
  fmt_inline_median_interval(0) %>% 
  add_ui_slug_to_first(slug = "90%&nbsp;UI: ")

i_ints <- mcmc_intervals_data(test, regex_pars = "Prop_Age") %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  add_ui_slug_to_first("90% UI: ") %>% 
  lapply(stringr::str_replace_all, "0[.]", ".")
```

When preschoolers started on the image of a novel object and heard a
mispronunciation, they looked to the familiar image.
Figure \@ref(fig:unfam-initial-mp-trials) shows the average of
children's growth curves along with the 100 model-estimated group
averages. The growth curves all cross the .5 threshold, so the
children on average looked more to the familiar than the unfamiliar
image. Granted, the degree of referent selection is not as strong as
that observed for the real words or nonwords. For those conditions, the
average growth curve reached a peak of around .77 at age 3, but for the
mispronunciations the age-3 peak is around .62. Children also were
comparatively slower to process mispronunciations. For the real-word
condition, the average age-3 growth curve crosses .5 looking probability
around 775 ms after target onset, whereas in the mispronunciation
condition, this threshold is crossed at 1000 ms. Children associate the
mispronunciation with the familiar object, although they are slower and
show greater uncertainty compared to real word trials.

(ref:unfam-initial-mp-trials) Average looks to familiar image for mispronunciation trials starting on the unfamiliar image at each age. Lines represent 100 posterior predictions of the group average (the average of participants' individual growth curves). 

(ref:unfam-initial-mp-trials-scap) Average looks to familiar image for mispronunciation trials starting on the unfamiliar image at each age.

```{r unfam-initial-mp-trials, fig.scap = "(ref:unfam-initial-mp-trials-scap)", fig.cap = "(ref:unfam-initial-mp-trials)", fig.width = 4.5, fig.height = 3.5, out.width = out_tex80_else66}
newdata <- d_u %>% 
  distinct(Study, ResearchID, Time, ot1, ot2, ot3) %>% 
  mutate(Target = 0, Trials = 30)

m_u_new_fits_each <- augment_linpred(
  mp_unfam, newdata, nsamples = 100, allow_new_levels = TRUE) %>% 
  mutate(Study = convert_study_to_age(Study)) 

m_u_new_fits <- m_u_new_fits_each %>% 
  group_by(Study, .draw, Time) %>% 
  summarise(Prop = mean(plogis(.posterior_value))) %>% 
  group_by(Study, .draw)

df_u_label <- tibble::tribble(
  ~Study, ~Time, ~Prop,
  "Age 3", 1050, .42,
  # "Age 4", 1000, .42,
  "Age 5", 1300, .72)

d_u_plotting <- d_u %>% 
  mutate(Study = convert_study_to_age(Study)) 

ggplot(d_u_plotting) + 
  aes(x = Time, y = Prop, color = Study) + 
  geom_hline(yintercept = .5, size = 2, color = "white") +
  stat_summary(fun.data = mean_se, geom = "pointrange") + 
  geom_line(aes(group = .group), data = m_u_new_fits, alpha = .05) +
  geom_text(
    aes(label = Study),
    data = df_u_label,
    size = 5, 
    family = "Lato Semibold") +
  geom_text(
    aes(label = label),
    data = data_frame(
      Time = 425, 
      Prop = .11, 
      label = constants$note_mp_unfam),
    size = 3.5, 
    hjust = 0,
    color = constants$col_off_black,
    family = "Lato") +
  scale_color_study() + 
  expand_limits(y = .76) +
  guides(color = FALSE) +
  labs(
    x = constants$x_time,
    y = constants$y_prop_fam,
    caption = constants$cap_emp_and_draw)
```

Of the growth curve features, developmental changes were only observed
for the average probability (intercept) and peak probability features.
At age 3, the average proportion of looks to the familiar image was
`r i_ints$b_Intercept_Prop_Age3`. At age 4, the looking proportion
increased by `r i_ints$d_Intercept_Prop_Age4` to
`r i_ints$b_Intercept_Prop_Age4`. This year-over-year change was probably
positive, but the uncertainty interval still includes a change of 0
as a plausible result. Visually, this uncertainty appears in the growth
curve plot by how close together the age-3 and age-4 growth curves
appear. At age 4, the average proportion of looks
increased by `r i_ints$d_Intercept_Prop_Age5` to
`r i_ints$b_Intercept_Prop_Age5`. Here, there is more certainty that the
year-over-year change was positive, and this result is consistent with
the visual separation of the age-5 growth curve from the others. In
short, performance was similar for age 3 and age 4 but there was a
marked improvement at age 5.

Figure \@ref(fig:unfam-peaks-by-age) shows participant's growth curve
peaks for each year of the study. The peaks were computed as in other
chapters by taking the median of the five highest values on the curve.
The average of the participants' peak looking probabilities followed the same
pattern as the average looking probabilities: similar levels at age 3 and age 4
(`r group_peaks[["Age 3"]]` versus `r group_peaks[["Age 4"]]`) but a
clear gain in looking peak probability at age 5
(`r group_peaks[["Age 5"]]`). 


(ref:unfam-peaks-by-age) Growth curve peaks by age for mispronunciation trials starting on the unfamiliar image.

(ref:unfam-peaks-by-age-scap) Growth curve peaks by age for mispronunciation trials starting on the unfamiliar image.

```{r unfam-peaks-by-age, fig.scap = "(ref:unfam-peaks-by-age-scap)", fig.cap = "(ref:unfam-peaks-by-age)", fig.width = 4, fig.height = 3, out.width = out_tex80_else50}
set.seed(20180715)

study_peak_counts <- unfam_peaks %>%
  distinct(Study, ResearchID) %>%
  mutate(StudyCounts = Study %>% fct_add_counts()) %>%
  distinct(Study, StudyCounts)

x_levels <- setNames(
  as.character(study_peak_counts$StudyCounts), 
  as.character(study_peak_counts$Study))

unfam_peaks_avgs <- unfam_peaks %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(Peak), mean, na.rm = TRUE) %>% 
  ungroup() 

ggplot(unfam_peaks_avgs) + 
  aes(x = Study, y = Peak) + 
  geom_hline(yintercept = .5, size = 2, color = "white") + 
  geom_boxplot(width = .4, fill = NA, outlier.alpha = 0) +
  geom_point(
    position = position_jitter(width = .2), 
    alpha = .4, 
    shape = 1) + 
  labs(
    title = "Growth curve peaks",
    subtitle = constants$note_mp_unfam,
    x = NULL,
    y = NULL,
    caption = "Points: Participant posterior means.") + 
  scale_x_discrete(labels = x_levels) +
  theme(plot.subtitle = element_text(size = rel(.9))) 

# + 
#     scale_y_continuous(
#       minor_breaks = c(.1, .3, .5, .7, .9),
#       breaks = c(0, .2, .4, .6, .8, 1),
#       labels = c("0", ".2", ".4", ".6", ".8", "1.0")) 
```

Figure \@ref(fig:unfam-peaks-by-age) also indicates how most of the
children at each age favored the familiar object over the unfamiliar
object. The bottom hinge of the boxplots mark the location of the 25th
percentile. Therefore, approximately 75% of children at age 3 were on or
above the .5 threshold. Unlike the other conditions, very few
listeners achieve a peak of looking probability of .99: At age 5, only
`r ceilings[["Age 5"]]` children reached ceiling performance, compared
to approximately 40 for nonwords and 13 for real words.

None of the other growth curve features showed developmental changes.
That is, there were no credible year-over-year changes for the linear,
quadratic or cubic time components of the growth curve. Although
Figure \@ref(fig:unfam-initial-mp-trials) shows children's probability
of looking to the familiar image increasing more quickly at age 5, this
effect cannot be clearly tied to any of the model's polynomial time
features. After 600 ms, the age-5 curve is almost parallel to
other curves. This visual feature is consistent with the intercept
effect: The curve is higher than the others on average, but it does not
show any differences in shape.


```{r, include = FALSE}
scores <- readr::read_csv("./data-raw/test_scores.csv") %>% 
  mutate(
    MinPair_ProportionCorrect = ifelse(
      MinPair_ProportionCorrect < .2, NA, MinPair_ProportionCorrect),
    Study = convert_study_to_age(Study))

tp1 <- scores %>% filter(Study == "Age 3")
tp2 <- scores %>% filter(Study == "Age 4")
tp3 <- scores %>% filter(Study == "Age 5")

# minp <- readr::read_csv(file = "./data-raw/age3-minpair-fits.csv") %>%
#   filter(Model == "base + age + ppvt") %>%
#   mutate(Study = "Age 3")

minp_cors <- unfam_peaks %>% 
  filter(Study == "Age 3") %>% 
  left_join(tp1, by = c("Study", "ResearchID")) %>% 
  group_by(.draw) %>%  
  tidy_correlation(Peak, MinPair_ProportionCorrect) 

min_p_cor <- minp_cors %>% 
  filter(column1 == "Peak", column2 == "MinPair_ProportionCorrect") %>% 
  select(MinP = estimate) %>% 
  mcmc_intervals_data() %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  add_ui_slug_to_first("90% UI: ") %>% 
  lapply(stringr::str_replace_all, "0[.]", ".")

min_p_n <- minp_cors %>% 
  filter(column1 == "Peak", column2 == "MinPair_ProportionCorrect") %>% 
  pull(n) %>% 
  unique()

# Report Peak ~ EVT at age 3
m_evt_age3 <- unfam_peaks_avgs %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 3") %>% 
  lm(Peak ~ scale(EVT_Standard, scale = FALSE), .)
summary(m_evt_age3)

# Small effect
delta_by_15 <- (coef(m_evt_age3)[2] * 15) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

peak_evt_r_squared <- m_evt_age3 %>% 
  broom::glance() %>% 
  pull(r.squared) %>%
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

# Get 100 samples of peaks to model
to_model <- unfam_peaks %>% 
  sample_n_of(100, .draw) %>% 
  left_join(scores) 

# Given a df with a EVT_Standard column, make a grid for ploting based on that
# df.
make_grid <- function(df) {
  modelr::data_grid(df, EVT_Standard = modelr::seq_range(EVT_Standard, 80))
}

# Fit 100 regressions
lines <- to_model %>% 
  tidyr::nest(-Study, -.draw) %>% 
  mutate(
    model = data %>% 
      purrr::map(~ lm(Peak ~ EVT_Standard, .x)),
    grid = data %>% purrr::map(make_grid),
    grid = purrr::map2(grid, model, modelr::add_predictions)) %>% 
  select(Study, .draw, grid) %>% 
  tidyr::unnest()

p_evt_peaks <- to_model %>% 
  filter(!is.na(EVT_Standard)) %>% 
  ggplot() + 
    aes(x = EVT_Standard, y = Peak, color = Study) + 
    geom_hline(size = 2, color = "white", yintercept = .5) +
    stat_summary(fun.y = mean, geom = "point") + 
    stat_summary(fun.data = mean_se, geom = "linerange") + 
    geom_line(
      aes(y = pred, group = interaction(.draw, Study)), 
      data = lines, 
      alpha = .1)  +
    geom_text(
      aes(label = Study),
      data = data_frame(
        EVT_Standard = c(55, 156),
        Study = c("Age 3", "Age 4"),
        Peak = c(.44, .59)),
        size = 5, 
       family = "Lato Semibold") +
    scale_color_study() +
    guides(color = FALSE) +
    labs(
      x = "EVT-2 standard score",
      y = "Growth curve peak",
      title = "Vocabulary weakly predicts peaks at age 3",
      caption = "Lines: Regressions on 100 posterior samples of peaks")
```


```{r optionally-verify-unfam-regressions, eval = FALSE}
# This code checks over whether any regression effects held between MinPair/EVT
# and GCA.
regressions <- unfam_peaks %>% 
  sample_n_of(100, .draw) %>% 
  select(.draw, Study, ResearchID, Peak, Prop_Intercept:Prop_ot3) %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>%
  tidyr::gather("Feature", "Value", Prop_Intercept:Prop_ot3, Peak) %>% 
  tidyr::gather(
    "Predictor", "Score", 
    EVT_Standard, MinPair_ProportionCorrect) %>% 
  anti_join(
    data_frame(
      Study = c("Age 4", "Age 5"), 
      Predictor = c("MinPair_ProportionCorrect", "MinPair_ProportionCorrect")),
    by = c("Study", "Predictor")) %>% 
  tidyr::nest(-.draw, -Study, -Feature, -Predictor) %>% 
  mutate(
    results = data %>% 
      purrr::map(~ lm(Value ~ Score, .x)) %>% 
      purrr::map(broom::tidy)) %>% 
  select(-data) %>% 
  tidyr::unnest(results) %>% 
  filter(term != "(Intercept)")

# Just quickly eyeball/confirm that EVT Standard predicted age 3
# reliability/accuracy feature. It's bad practice to look at p-values like this
# but I need a quick piece of code to run/re-run to verify my claim in the prose
# that the only effects held on age 3 x evt standard x intercept/peak.
ggplot(regressions %>% group_by(Study, Feature, Predictor)) +
  aes(x = Feature, y = p.value, color = Study) +
  stat_summary(
    aes(group = .group), 
    fun.data = median_hilow, 
    position = position_dodge(width = .4)) +
  geom_hline(yintercept = .05) + 
  facet_wrap("Predictor")
  
# gca_sextiles <- unfam_peaks %>% 
#   select(.draw, Study, ResearchID, Peak, Prop_Intercept:Prop_ot3) %>% 
#   tidyr::gather("Feature", "Value", Prop_Intercept:Prop_ot3, Peak) %>% 
#   group_by(Study, ResearchID, Feature) %>% 
#   summarise(Value = mean(Value)) %>% 
#   group_by(Study, Feature) %>% 
#    mutate(
#     ntile = factor(ntile(Value, 6)),
#     num = fct_add_counts(ntile) %>% as.character()) 
```

### Child-level predictors

I tested whether child-level measures predicted looking
behavior under these conditions. First, I asked if performance on a
minimal pair discrimination task at age 3 predicted looking behavior at
age 3. The rationale here is the hypothesis that children with better
minimal pair discrimination may be especially sensitive to
mispronunciations. Proportion of items correct on the task did not
correlate with growth curve peaks, *r* = `r min_p_cor`, *n* =
`r min_p_n`, nor with any other growth curve measures.

I also tested whether expressive vocabulary (EVT-2 standard score)
predicted performance in this condition. In this case, there were
significant effects at age 3 where a higher expressive vocabulary
predicted higher peak probabilities and higher average probabilities.
These effects, however, were very small. As shown in
Figure \@ref(fig:plot-evt-mp-unfam-peaks), for example, a 15-point
increase in expressive vocabulary predicted an increase of growth curve
peak of `r delta_by_15`, *R*^2^ = `r peak_evt_r_squared`. Expressive
vocabulary did not predict any of the growth curve features at age 4 or
at age 5.

(ref:plot-evt-mp-unfam-peaks) Relationship between expressive vocabulary and growth curve peaks for mispronunciation trials starting on the unfamiliar image. I took 100 draws from the posterior distribution and computed participant's growth curve peaks for each draw. Points represent the mean and standard error of 100 peaks. Lines represent regressions fit on each draw. 

```{r plot-evt-mp-unfam-peaks, fig.cap = "(ref:plot-evt-mp-unfam-peaks)", out.width = out_tex80_else50, fig.width = 4.25, fig.height = 4}
p_evt_peaks
```

**Summary**. When children are looking at the unfamiliar object and hear
a mispronunciation, they shift their looks on average to the familiar
image that sounds like the mispronunciation. Children are much more
uncertain in this condition, compared to the real-word and nonword
conditions where the appropriate referent is more obvious. The only
developmental changes observed were the increases in average looking
probability and peak looking probability at age 5. Finally, there was a
small effect of expressive vocabulary on looking probability at age 3,
but no other effects of vocabulary were observed. Minimal pair
discrimination at age 3 also did not predict looking behavior.





Familiar-initial trials: Should I stay or should I go?
------------------------------------------------------------------------

```{r mp-fam-effects}
# Create in-line stats valeus

percent_diff <- function(new, old) {
  # A change from 100 to 80 is (80 - 100) / 100 = -20 / 100 = -20% change
  (new - old) / old
}

mp_fam_fixef <- posterior_samples(mp_fam, pars = "^b_") %>% 
  transmute(
    b_Intercept_Age3 = b_Intercept,
    b_Intercept_Age4 = b_Intercept + b_StudyTimePoint2,
    b_Intercept_Age5 = b_Intercept + b_StudyTimePoint3,
    b_ot1_Age3 = b_ot1,
    b_ot1_Age4 = b_ot1 + `b_ot1:StudyTimePoint2`,
    b_ot1_Age5 = b_ot1 + `b_ot1:StudyTimePoint3`,
    b_ot2_Age3 = b_ot2,
    b_ot2_Age4 = b_ot2 + `b_ot2:StudyTimePoint2`,
    b_ot2_Age5 = b_ot2 + `b_ot2:StudyTimePoint3`,
    b_ot3_Age3 = b_ot3,
    b_ot3_Age4 = b_ot3 + `b_ot3:StudyTimePoint2`,
    b_ot3_Age5 = b_ot3 + `b_ot3:StudyTimePoint3`,
    b_Intercept_Prop_Age3 = plogis(b_Intercept_Age3),
    b_Intercept_Prop_Age4 = plogis(b_Intercept_Age4),
    b_Intercept_Prop_Age5 = plogis(b_Intercept_Age5),
    d_Intercept_Age4 = b_Intercept_Age4 - b_Intercept_Age3,
    d_Intercept_Age5 = b_Intercept_Age5 - b_Intercept_Age4,
    d_Intercept_Prop_Age4 = b_Intercept_Prop_Age4 - b_Intercept_Prop_Age3,
    neg_d_Intercept_Prop_Age4 = d_Intercept_Prop_Age4 * -1,
    d_Intercept_Prop_Age5 = b_Intercept_Prop_Age5 - b_Intercept_Prop_Age4,
    d_Intercept_Prop_Age5_3 = b_Intercept_Prop_Age5 - b_Intercept_Prop_Age3,
    per_d_Intercept_Prop_Age4 = percent_diff(
      b_Intercept_Prop_Age4, 
      b_Intercept_Prop_Age3),
    per_d_Intercept_Prop_Age5 = percent_diff(
      b_Intercept_Prop_Age5, 
      b_Intercept_Prop_Age4),
    d_ot1_Age4 = b_ot1_Age4 - b_ot1_Age3,
    d_ot1_Age5 = b_ot1_Age5 - b_ot1_Age4,
    per_d_ot1_Age4 = percent_diff(b_ot1_Age4, b_ot1_Age3),
    per_d_ot1_Age5 = percent_diff(b_ot1_Age5, b_ot1_Age4),
    neg_per_d_ot1_Age4 = -percent_diff(b_ot1_Age4, b_ot1_Age3),
    neg_per_d_ot1_Age5 = -percent_diff(b_ot1_Age5, b_ot1_Age4),
    d_ot2_Age4 = b_ot2_Age4 - b_ot2_Age3,
    d_ot2_Age5 = b_ot2_Age5 - b_ot2_Age4,
    per_d_ot2_Age4 = percent_diff(b_ot2_Age4, b_ot2_Age3),
    per_d_ot2_Age5 = percent_diff(b_ot2_Age5, b_ot2_Age4),
    neg_per_d_ot2_Age4 = -percent_diff(b_ot2_Age4, b_ot2_Age3),
    neg_per_d_ot2_Age5 = -percent_diff(b_ot2_Age5, b_ot2_Age4),
    d_ot3_Age4 = b_ot3_Age4 - b_ot3_Age3,
    d_ot3_Age5 = b_ot3_Age5 - b_ot3_Age4,
    per_d_ot3_Age4 = percent_diff(b_ot3_Age4, b_ot3_Age3),
    per_d_ot3_Age5 = percent_diff(b_ot3_Age5, b_ot3_Age4),
    neg_per_d_ot3_Age4 = -percent_diff(b_ot3_Age4, b_ot3_Age3),
    neg_per_d_ot3_Age5 = -percent_diff(b_ot3_Age5, b_ot3_Age4)) %>% 
  as_tibble()

# mcmc_intervals(data.frame(x = mp_fam_fixef$per_d_ot1_Age4))
# mcmc_intervals(data.frame(x = mp_fam_fixef$b_Intercept_Prop_Age3))
# mcmc_intervals(mp_fam_fixef,  regex_pars = "Intercept_Prop")
# mcmc_intervals_data(mp_fam_fixef,  regex_pars = "Intercept_Prop")

props <- mp_fam_fixef %>% 
  mcmc_intervals_data(regex_pars = "Intercept_Prop") %>% 
  mutate(
    parameter = parameter %>% stringr::str_replace("Intercept_Prop_", "")) %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  add_ui_slug_to_first("90% UI: ") %>% 
  lapply(fmt_remove_leading_zeros_in_text)

time1 <- mp_fam_fixef %>% 
  mcmc_intervals_data(regex_pars = "ot1") %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  purrr::map_at(
    .at = c("per_d_ot1_Age4", "per_d_ot1_Age5", 
            "neg_per_d_ot1_Age4", "neg_per_d_ot1_Age5"), 
    .f = fmt_convert_prop_to_percent)

time2 <- mp_fam_fixef %>% 
  mcmc_intervals_data(regex_pars = "ot2") %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  purrr::map_at(
    .at = c(
      "per_d_ot2_Age4", "per_d_ot2_Age5", 
      "neg_per_d_ot2_Age4", "neg_per_d_ot2_Age5"), 
    .f = fmt_convert_prop_to_percent)
```

The preceding results showed that preschoolers associate one-feature
onset-mispronunciations with the familiar word that matches the rime of
the word. But that was only for trials where children start on the unfamiliar
object. I now consider the other situation, where children are fixating
on a familiar object and hear a word that immediately mismatches with
the name of that familiar object. On the basis of the first segment,
children have information that supports switching to another image. But
as the rest of the word unfolds, they hear a syllable rime that supports
staying.

Figure \@ref(fig:fam-initial-mp-trials) shows the growth curve averages
for trials starting on the familiar image. The looking patterns show a
sharp fall towards .5 which is chance-level performance. Behaviorally,
children on average move quickly to look at both images equally. They
rush into maximum uncertainty, especially at age 4. Patterns are
somewhat more restrained at age 5. Here, the average of the growth
curves never dips below .5, and in fact, it shows a late rise to .6
looking probability. At this age, children are overall more likely to
stay on the familiar object. Finally, at age-3, the curve begins to fall
later than the other curves, reflecting a slower change from the
starting probability.

<!-- One possible interpretation of this pattern is that the children making  -->
<!-- brief confirmatory looks to the novel image; they checking out -->
<!-- the novel image. But this cannot be right because the growth curve never -->
<!-- dips much below .5 (certainly not below .4). So there is more likely a -->
<!-- mix of behaviors, with children staying put on some trials and -->
<!-- considering the novel object on some trials. -->


(ref:fam-initial-mp-trials) Average looks to familiar image for mispronunciation trials starting on the familiar image at each age. Lines represent 100 posterior predictions of the group average (the average of participants' individual growth curves). 

(ref:fam-initial-mp-trials-scap) Average looks to familiar image for mispronunciation trials starting on the familiar image at each age.

```{r fam-initial-mp-trials, fig.scap = "(ref:fam-initial-mp-trials-scap)", fig.cap = "(ref:fam-initial-mp-trials)", fig.width = 5, fig.height = 4, out.width = out_tex80_else66}
f_newdata <- d_f %>% 
  distinct(Study, ResearchID, Time, ot1, ot2, ot3) %>% 
  mutate(Target = 0, Trials = 30)

m_f_new_fits_each <- augment_linpred(
  mp_fam, f_newdata, nsamples = 100, allow_new_levels = TRUE) %>% 
  mutate(Study = convert_study_to_age(Study)) 
  
m_f_new_fits <- m_f_new_fits_each %>% 
  group_by(Study, .draw, Time) %>% 
  summarise(Prop = mean(plogis(.posterior_value))) %>% 
  group_by(Study, .draw)

df_f_label <- tibble::tribble(
  ~Study, ~Time, ~Prop,
  "Age 3", 650, .80,
  "Age 4", 1000, .41,
  "Age 5", 1400, .66)

df_f_plotting <- d_f %>% 
  mutate(Study = convert_study_to_age(Study)) 

ggplot(df_f_plotting) + 
  aes(x = Time, y = Prop, color = Study) + 
  geom_hline(yintercept = .5, size = 2, color = "white") +
  stat_summary(fun.data = mean_se, geom = "pointrange") + 
  geom_line(aes(group = .group), data = m_f_new_fits, alpha = .05) +
  geom_text(
    aes(label = label),
    data = data_frame(
      Time = 410, 
      Prop = .93, 
      label = constants$note_mp_fam),
    size = 3.5, 
    hjust = 0,
    color = constants$col_off_black,
    family = "Lato") +
  geom_text(
    aes(label = Study),
    data = df_f_label,
    size = 5, 
    family = "Lato Semibold") +
  scale_color_study() + 
  expand_limits(y = .38) +
  guides(color = FALSE) +
  labs(
    x = constants$x_time,
    y = constants$y_prop_fam,
    caption = constants$cap_emp_and_draw)
```

In other analyses, growth curves rise and plateau, and age-related
effects appear in how quickly the curves rise or the height at which
they plateau. In those cases, it is straightforward to interpret how the
intercept and linear time effects contribute to the curve's shape over
development. For this model, the curves *fall* and plateau, and there is
not an obvious developmental, year-over-year change among the curves.
Thus, more effort is required to interpret the model parameters and how
they combine to form the growth curve shape.

Figure \@ref(fig:mp-fam-gca-features) visualizes how the growth curve
features are weighted at each year and how they contribute to the
overall growth curve shape. At age 3, the intercept feature, or average
proportion of looks to the familiar image, was `r props$b_Age3`. The
feature is less meaningful in this situation because the curves all
start at a high probability which inflates the average value. That said,
comparisons remain useful. At age 4, the average probability decreased
by `r props$neg_d_Age4` to `r props$b_Age4`, and at age 5 the average
probability returns to age-3 levels, `r props$b_Age5`. This intercept
effect contributes to how the age-4 curve dips below the others and
indeed briefly crosses the .5 probability threshold.


(ref:mp-fam-gca-features) Weighted growth curve features. For the first four panels, the *y* axes are scaled to the same range. This scaling highlights how the cubic time component contributes less to the overall shape than the other features.

```{r mp-fam-gca-features, fig.cap = "(ref:mp-fam-gca-features)", eval = TRUE, fig.width = 7, fig.height = 3, out.width = "100%"}
draws <- mp_fam_fixef %>% 
  tibble::rowid_to_column(".draw") %>% 
  sample_n(200) 

by_study <- df_f_plotting %>% 
  mutate(Intercept = 1) %>% 
  distinct(Study, Time, Intercept, ot1, ot2, ot3) %>% 
  tidyr::crossing(.draw = unique(draws$.draw)) %>% 
  left_join(draws) %>% 
  split(.$Study)

by_study$`Age 3`  <- by_study$`Age 3` %>% 
  mutate(
    b_Intercept = Intercept * b_Intercept_Age3,
    b_ot1  = ot1 * b_ot1_Age3,
    b_ot2  = ot2 * b_ot2_Age3,
    b_ot3  = ot3 * b_ot3_Age3)

by_study$`Age 4`  <- by_study$`Age 4` %>% 
  mutate(
    b_Intercept = Intercept * b_Intercept_Age4,
    b_ot1  = ot1 * b_ot1_Age4,
    b_ot2  = ot2 * b_ot2_Age4,
    b_ot3  = ot3 * b_ot3_Age4)

by_study$`Age 5`  <- by_study$`Age 5` %>% 
  mutate(
    b_Intercept = Intercept * b_Intercept_Age5,
    b_ot1  = ot1 * b_ot1_Age5,
    b_ot2  = ot2 * b_ot2_Age5,
    b_ot3  = ot3 * b_ot3_Age5)

feature_draws <- bind_rows(by_study) %>% 
  mutate(b_sum = b_Intercept + b_ot1 + b_ot2 + b_ot3) %>% 
  distinct(.draw, Study, Time, b_Intercept, b_ot1, b_ot2, b_ot3, b_sum) %>% 
  tidyr::gather("Feature", "Value", b_Intercept:b_sum) 

p <- feature_draws %>% 
  mutate(
    Feature = factor(
      Feature, 
      levels = c("b_Intercept", "b_ot1", "b_ot2", "b_ot3", "b_sum"),
      labels = c("Intercept", "Time^1", "Time^2", "Time^3", "Total"))) %>% 
  group_by(Study, Feature, .draw) %>% 
  ggplot() + 
    aes(x = Time, y = Value, color = Study) + 
    geom_hline(color = "white", size = 1.5, yintercept = 0) + 
    geom_line(aes(group = .group), alpha = .05) + 
    facet_wrap(
      facets = "Feature", 
      nrow = 1, 
      labeller = label_parsed, 
      scales = "free_y") +
    scale_color_study() + 
    guides(color = FALSE) +
    geom_text(
      aes(label = Study, hjust = hjust),
      data = data_frame(
        Study = c("Age 3", "Age 4", "Age 5", "Age 5", "Age 5"),
        Time = c(650, 900, 300, 900, 1400),
        Value = c(1.1, .20, 0, 0, .9),
        hjust = c(0, .5, 0, .5, 1),
        Feature = c("Time^1", "Intercept", "Time^1", "Time^2", "Total")), 
      size = 4,
      family = "Lato Semibold") + 
    expand_limits(y = range(by_study$`Age 3`$b_ot1)) +
  labs(
    x = constants$x_time, 
    y = "Growth curve feature (log-odds)",
    caption = "200 posterior samples of population-average (fixed) effects")
p
```


For the linear time feature, the slope becomes flatter year over year,
decreasing by `r time1$neg_per_d_ot1_Age4` from age 3 to age 4 and
decreasing by `r time1$neg_per_d_ot1_Age5` from age 4 to age 5. For
these curves, however, the starting location is the highest value on the
curve, so the linear time feature in this case mostly works to set the
starting location of the curves. When the features are combined in
Figure \@ref(fig:mp-fam-gca-features), the age-3 curve, which has the
steepest linear time feature, starts at a higher value than the others.

There was a credible change in the quadratic time feature at
age 5. One way to think of a positive quadratic trend is like a weight
hanging on a string: It pulls and bends the whole curve downwards. At
age 5, the quadratic feature is `r time2$neg_per_d_ot2_Age5` smaller than at
age 4, meaning that the age-5 curve has slightly less bend downwards.
Finally, there were no credible differences in the cubic time feature.
Compared to the other features, the cubic trend contributes only a small
amount to the overall shape of the curves.

The combination of these effects shows in the final panel of
Figure \@ref(fig:mp-fam-gca-features). The age-4 curve dips down
furthest beneath 0 log-odds (.5 probability)---this is driven by in the
intercept feature. The age-5 curve stays above 0 log-odds and eventually
starts to rise away from its minimum value, owning to the dampened
linear and quadratic features.

**Summary**. The shape of the average growth curves changed with each
year of the study. Given the interplay of the curve features, I will
avoid assigning a developmental interpretation to individual features.
There are two main noticeable developmental trends at play however.
First, the age-3 curve starts to fall from its baseline probability a
little later than the other curves. Second, the age-5 curve stays above
.5 probability and starts to rise at the end of the trial. At age 5,
children were more likely to stay looking at the familiar object than look
at both images equally.


### Child-level predictors and different listening behaviors

In other word recognition analyses, I derived a growth curve "peak"
value as a measure of maximum looking probability or minimum word
recognition uncertainty. For these trials, I asked whether analogous
growth curve "valleys" provided a meaningful feature for looking
behavior when children start a trial fixated on the familiar image. This
value was defined as the median of the five smallest values of a growth
curve. Intuitively, it reflects the maximum degree to which the novel
image is considered as a referent for the mispronunciation.

Figure \@ref(fig:fam-peaks-by-age) shows the posterior means of
participants' growth curve valleys. Note that there is considerable
variability at each age, with the 0--1 interval nearly covered at age 4.
The median value is closer to .5 at age 5, and this difference is
consistent with the growth curve trajectories where the average age-5
curve did not dip as low as the other curves.

(ref:fam-peaks-by-age) Growth curve valleys by age for mispronunciation trials starting on the familiar image.

(ref:fam-peaks-by-age-scap) Growth curve valleys by age for mispronunciation trials starting on the familiar image.


```{r fam-peaks-by-age, fig.cap = "(ref:fam-peaks-by-age)", fig.width = 4, fig.height = 3, out.width = out_tex80_else50}
study_peak_counts <- fam_peaks %>%
  distinct(Study, ResearchID) %>%
  mutate(
    StudyCounts = Study %>% fct_add_counts()) %>%
  distinct(Study, StudyCounts)

x_levels <- setNames(
  as.character(study_peak_counts$StudyCounts), 
  as.character(study_peak_counts$Study))

fam_peaks %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(Valley_Prop), mean, na.rm = TRUE) %>% 
    ggplot() + 
      aes(x = Study, y = Valley_Prop) + 
      geom_hline(yintercept = .5, size = 2, color = "white") + 
      geom_boxplot(width = .4, fill = NA, outlier.alpha = 0) +
      geom_point(
        position = position_jitter(width = .2), alpha = .3, shape = 1) + 
      labs(
        title = "Growth curve valleys",
        subtitle = constants$note_mp_fam,
        x = NULL,
        y = NULL,
        caption = "Points: Participant posterior means.") + 
    scale_x_discrete(labels = x_levels) +
    theme(plot.subtitle = element_text(size = rel(.9)))
```

The wide range of values for the growth curve valleys suggests that
there are a few different listening behaviors that are being averaged
over in the above analyses. The valleys above .6, for example, indicate
that some children on average stay with the familiar image, and the
valleys below .4 indicate children who favor the unfamiliar image. 

To explore individual listening behaviors, I visualized children's
individual growth curves based on their growth curve valleys. Within
each year, I grouped children into sextiles based on the posterior mean
of their valleys and plotted their individual growth
curves. Figure \@ref(fig:age3-valley-curves) shows the results from
age 3. The final two bins show children who stayed with the
familiar image throughout the mispronunciation trials. The first two bins
mostly contain children who switched to the unfamiliar image and stayed
there. These are also children whose curves show a pronounced u-shaped
trajectory. Specifically, the curves with the highest ending points in
the first three bins highlight children with u-shaped trajectories. In
these curves, the probability of fixating on the familiar image briefly
decreases, as the child considers the other image.

(ref:age3-valley-curves) Growth curves for mispronunciations trials starting on the familiar object at age 3. Children were grouped into sextiles based on the posterior mean of their growth curve valleys---that is, the lowest point on the growth curve. Ten lines are drawn per child to visualize uncertainty. Children were assigned colors arbitrarily. On the right side of each panel are "rugs" which mark the valleys in that panel.

(ref:age3-valley-curves-scap) Growth curves for mispronunciations trials starting on the familiar object at age 3 with children binned by growth curve valley.

```{r age3-valley-curves, fig.cap = "(ref:age3-valley-curves)", fig.scap = "(ref:age3-valley-curves-scap)", width = 6, height = 6, out.width=out_tex100_else80}
feature_means <- fam_peaks %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(
    vars(
      Valley_Prop, RiseAfterValley_Prop, PeakAfterValley_Prop, 
      Prop_Intercept:Logit_ot3), 
    mean, na.rm = TRUE) %>% 
  ungroup()

ends <- m_f_new_fits_each %>% 
  group_by(Study, ResearchID, .draw) %>% 
  top_n(5, Time) %>% 
  summarise(End = median(plogis(.posterior_value))) %>% 
  ungroup()

feature_means <- feature_means %>% 
  left_join(
    ends %>% group_by(Study, ResearchID) %>% summarise(End = mean(End))) %>% 
  mutate(WeightedProp_ot2 = Prop_ot2 * End)

valley_groups <- feature_means %>% 
  group_by(Study) %>% 
  mutate(
    ntile = factor(ntile(Valley_Prop, 6)),
    num = ntile %>% 
      fct_add_counts(first_fmt = "{levels} ({counts} children)") %>% 
      as.character()) %>% 
  distinct(Study, ResearchID, Valley_Prop, ntile, num)

set.seed(20180713)

to_plot <- m_f_new_fits_each %>% 
  sample_n_of(10, .draw) %>% 
  left_join(valley_groups, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 3") %>% 
  group_by(ResearchID, Study, .draw)

minima <- to_plot %>% 
  summarise(
    num = unique(num), 
    min = min(plogis(.posterior_value)), 
    Time = max(Time)) %>% 
  group_by(ResearchID, Study, .draw)

ggplot(to_plot) + 
  aes(x = Time, y = plogis(.posterior_value), color = ResearchID) + 
  geom_hline(size = 2, yintercept = .5, color = "white") + 
  geom_rug(
    aes(group = .group, y = min),
    sides = "r", 
    data = minima, 
    alpha = .1, 
    color = "grey20") +
  geom_line(aes(group = .group), alpha = .1) +
  facet_wrap("num") + 
  guides(color = FALSE) + 
  labs(
    x = constants$x_time,
    y = constants$y_prop_fam,
    title = "Age 3 children binned by valley",
    caption = "10 posterior samples per child. Right rugs: Valleys in panel.")

# # This looks at whether age 3 valley predicts later vocab
# valley_groups %>%
#   ungroup() %>%
#   filter(Study == "Age 3") %>%
#   select(-Study) %>%
#   inner_join(scores) %>%
#   ggplot() +
#   aes(x = Peak, y = EVT_Standard, color = Study) +
#   geom_point() +
#   stat_smooth(method = "lm")
```

```{r evt-vs-mp-valley, include = FALSE}
# Extract a model coefficient and optionally multiply it a value
pull_effect <- function(model, index, scale = 1) {
  coef(model)[index] * scale
}

valley_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  lm(Valley_Prop ~ scale(EVT_Standard) * Study, .) %>% 
  summary()

valley_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 3") %>% 
  lm(Valley_Prop ~ scale(EVT_Standard), .) %>% 
  summary()

valley_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 4") %>% 
  lm(Valley_Prop ~ scale(EVT_Standard), .) %>% 
  summary()

valley_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 5") %>% 
  lm(Valley_Prop ~ scale(EVT_Standard), .) %>% 
  summary()

m_fam_valley_evt_age3 <- valley_groups %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 3") %>% 
  lm(Valley_Prop ~ scale(EVT_Standard, scale = FALSE), .)
summary(m_fam_valley_evt_age3)

# Small effect
neg_valley_delta_by_evt15 <- m_fam_valley_evt_age3 %>% 
  pull_effect("scale(EVT_Standard, scale = FALSE)", -15) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

r2_valley_evt <- m_fam_valley_evt_age3 %>% 
  broom::glance() %>% 
  pull(r.squared) %>%
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()




```

```{r minp-vs-mp-valley, include = FALSE}
# minp <- readr::read_csv(file = "./data-raw/age3-minpair-fits.csv") %>%
#   filter(Model == "base + age + ppvt") %>%
#   mutate(Study = "Age 3") %>% 
#   select(ResearchID, Study, MinPair_Ability = coef)

m_fam_valley_prop_age3 <- valley_groups %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 3") %>% 
  lm(Valley_Prop ~ scale(MinPair_ProportionCorrect, scale = FALSE), .)
summary(m_fam_valley_prop_age3)

# Small effect
neg_valley_delta_by_minp1 <- m_fam_valley_prop_age3 %>% 
  pull_effect("scale(MinPair_ProportionCorrect, scale = FALSE)", -.1) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

r2_valley_minp <- m_fam_valley_prop_age3 %>% 
  broom::glance() %>% 
  pull(r.squared) %>%
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()
```

```{r evt-x-minp-vs-mp-valley, include = FALSE}
evt_minp_age3 <- valley_groups %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 3") %>% 
  filter(!is.na(MinPair_ProportionCorrect), !is.na(EVT_Standard))

m_fam_valley_evt_minp_age3 <- 
  lm(
    scale(Valley_Prop, scale = FALSE) ~ 
      scale(MinPair_ProportionCorrect, scale = FALSE) * 
      scale(EVT_Standard, scale = FALSE), 
    evt_minp_age3)
summary(m_fam_valley_evt_minp_age3)

m_fam_valley_evt_minp_age3_raw <- lm(
  Valley_Prop ~ MinPair_ProportionCorrect * EVT_Standard, 
  evt_minp_age3)
summary(m_fam_valley_evt_minp_age3_raw)

# jtools::sim_slopes(
#   m_fam_valley_evt_minp_age3_raw,
#   pred = MinPair_ProportionCorrect,
#   modx = EVT_Standard,
#   jnplot = TRUE)

# jtools::interact_plot(
#   m_fam_valley_evt_minp_age3_raw,
#   pred = MinPair_ProportionCorrect,
#   modx = EVT_Standard,
#   plot.points = TRUE)
# jtools::interact_plot(
#   m_fam_valley_evt_minp_age3_raw,
#   pred = EVT_Standard,
#   modx = MinPair_ProportionCorrect,
#   plot.points = TRUE)

minp_cutpoint <- m_fam_valley_evt_minp_age3_raw %>% 
  jtools::johnson_neyman(
    pred = EVT_Standard, 
    modx = MinPair_ProportionCorrect) %>% 
  getElement("bounds") %>% 
  getElement("Lower") %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()
  
evt_cutpoint <- m_fam_valley_evt_minp_age3_raw %>% 
  jtools::johnson_neyman(
    pred = MinPair_ProportionCorrect, 
    modx = EVT_Standard) %>% 
  getElement("bounds") %>% 
  getElement("Lower") %>% 
  round()

evt_cutpoint_tile <- 
  round(ecdf(evt_minp_age3$EVT_Standard)(evt_cutpoint), 2) * 100

minp_cutpoint_tile <- 
  round(ecdf(evt_minp_age3$MinPair_ProportionCorrect)(minp_cutpoint), 2) * 100

neg_evt_minp_valley_delta_by_minp1 <- m_fam_valley_evt_minp_age3 %>% 
  pull_effect("scale(MinPair_ProportionCorrect, scale = FALSE)", -.1) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

neg_evt_minp_valley_delta_by_evt15 <- m_fam_valley_evt_minp_age3 %>% 
  pull_effect("scale(EVT_Standard, scale = FALSE)", -15) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

r2_valley_evt_minp <- m_fam_valley_evt_minp_age3 %>% 
  broom::glance() %>% 
  pull(r.squared) %>%
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()
```

```{r, eval = FALSE}
# This code checks over whether any regression effects held between MinPair/EVT
# and GCA.
regressions <- fam_peaks %>% 
  mutate(WeightedProp_ot2_alt = Prop_ot2 * PeakAfterValley_Prop) %>% 
  sample_n_of(100, .draw) %>% 
  select(
    .draw, Study, ResearchID, Valley_Prop, RiseAfterValley_Prop, 
    PeakAfterValley_Prop, Peak_Prop, Prop_Intercept:Prop_ot3,
    WeightedProp_ot2_alt) %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>%
  tidyr::gather(
    "Feature", "Value", Valley_Prop, RiseAfterValley_Prop, 
    PeakAfterValley_Prop, Peak_Prop, Prop_Intercept:Prop_ot3,
    WeightedProp_ot2_alt) %>% 
  tidyr::gather(
    "Predictor", "Score", 
    EVT_Standard, MinPair_ProportionCorrect) %>% 
  anti_join(
    data_frame(
      Study = c("Age 4", "Age 5"), 
      Predictor = c("MinPair_ProportionCorrect", "MinPair_ProportionCorrect")),
    by = c("Study", "Predictor")) %>% 
  tidyr::nest(-.draw, -Study, -Feature, -Predictor) %>% 
  mutate(
    results = data %>% 
      purrr::map(~ lm(Value ~ Score, .x)) %>% 
      purrr::map(broom::tidy)) %>% 
  select(-data) %>% 
  tidyr::unnest(results) %>% 
  filter(term != "(Intercept)")

# Just quickly eyeball/confirm that EVT Standard predicted age 3
# reliability/accuracy feature. It's bad practice to look at p-values like this
# but I need a quick piece of code to run/re-run to verify my claim in the prose
# that the only effects held on age 3 x evt standard x intercept/peak.
ggplot(regressions %>% group_by(Study, Feature, Predictor)) +
  aes(x = Feature, y = p.value, color = Study) +
  stat_summary(
    aes(group = .group), 
    fun.data = median_hilow, 
    position = position_dodge(width = .4)) +
  geom_hline(yintercept = .05) + 
  facet_wrap("Predictor") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0))

# These things tend to be super correlated
feature_means %>% 
  group_by(Study) %>% 
  select(
    Study, ResearchID, Valley_Prop, RiseAfterValley_Prop, 
    PeakAfterValley_Prop, Prop_Intercept:Prop_ot3) %>% 
  tidy_correlation(
    Valley_Prop, RiseAfterValley_Prop, 
    PeakAfterValley_Prop, Prop_Intercept:Prop_ot3)
```


I asked whether any child-level factors predicted children's looking
behaviors. I first regressed growth curve valleys on EVT-2 standard
score. There was a small effect at age 3, *R*^2^ =
`r r2_valley_evt`, *n* = `r nobs(m_fam_valley_evt_age3)`. A 15-point
increase in expressive vocabulary predicted decrease in growth curve
valley of `r neg_valley_delta_by_evt15`. At the other ages, the effects are
negligibly small, as shown in Figure \@ref(fig:mp-fam-valley-evt).

(ref:mp-fam-valley-evt) Relationship between expressive vocabulary and growth curve valleys for mispronunciation trials starting on the familiar image. Valleys were computed on 100 draws of the posterior distribution. Points represent the mean and standard error of the valleys. Lines represent the fit of the regression in each draw. Although the slopes of age-4 and age-5 lines are noticeably different from the age-3 one, they cover a tiny amount of the *y* axis so they represent a negligible effect.

(ref:mp-fam-valley-evt-scap) Relationship between expressive vocabulary and growth curve valleys for mispronunciation trials starting on the familiar image.

```{r mp-fam-valley-evt, fig.cap = "(ref:mp-fam-valley-evt)", fig.cap = "(ref:mp-fam-valley-evt-scap)", out.width = out_tex80_else50, fig.width = 4.25, fig.height = 4}
# Get 100 samples of peaks to model
to_model <- fam_peaks %>% 
  sample_n_of(100, .draw) %>% 
  left_join(scores) 

# Given a df with a EVT_Standard column, make a grid for ploting based on that
# df.
make_grid <- function(df) {
  modelr::data_grid(df, EVT_Standard = modelr::seq_range(EVT_Standard, 80))
}

# Fit 100 regressions
lines <- to_model %>% 
  tidyr::nest(-Study, -.draw) %>% 
  mutate(
    model = data %>% 
      purrr::map(~ lm(Valley_Prop ~ EVT_Standard, .x)),
    grid = data %>% purrr::map(make_grid),
    grid = purrr:::map2(grid, model, modelr::add_predictions)) %>% 
  select(Study, .draw, grid) %>% 
  tidyr::unnest()

to_model %>% 
  filter(!is.na(EVT_Standard)) %>% 
  ggplot() + 
    aes(x = EVT_Standard, y = Valley_Prop, color = Study) + 
    geom_hline(size = 2, color = "white", yintercept = .5) +
    stat_summary(fun.y = mean, geom = "point") + 
    stat_summary(fun.data = mean_se, geom = "linerange") + 
    geom_line(
      aes(y = pred, group = interaction(.draw, Study)), 
      data = lines, 
      alpha = .1)  +
    geom_text(
      aes(label = Study),
      data = data_frame(
        EVT_Standard = c(55, 72),
        Study = c("Age 3", "Age 5"),
        Valley_Prop = c(.70, .36)),
        size = 5, 
       family = "Lato Semibold") +
    scale_color_study() +
    guides(color = FALSE) +
    labs(
      x = "EVT-2 standard score",
      y = "Growth curve valley",
      title = "Vocabulary weakly predicts valleys at age 3",
      caption = "Lines: Regressions on 100 posterior samples of valleys")
```


I regressed age-3 valleys onto expressive vocabulary, minimal-pair
discrimination accuracy, and their interaction. The two main effects and
their interaction were all statistically significant, *R*^2^ =
`r r2_valley_evt_minp`, *n* = `r nobs(m_fam_valley_evt_minp_age3)`. The
effects of vocabulary and minimal-pair discrimination were both
negative, so that higher scores on these measures predicted lower growth
curve valleys---that is, a greater maximum probability of fixating on
the unfamiliar image. For an average participant, a 15-point increase in
expressive vocabulary predicted a decrease of
`r neg_evt_minp_valley_delta_by_evt15`, and an increase of minimal pair
accuracy of .1 predicted a decrease in valley of
`r neg_evt_minp_valley_delta_by_minp1`. The interaction term, however,
was positive, meaning that increasing one of the predictors
simultaneously weakens the effect of the other. As one of the
predictors increases, it can push the effect of the other closer to zero
so that its simple effect is "no longer" statistically significant. In
this case, the simple effect of expressive vocabulary was not
significant when minimal pair accuracy was `r minp_cutpoint` or greater
(that is, at the `r minp_cutpoint_tile`-percentile or greater).
Conversely, the simple effect of minimal pair discrimination accuracy
was not significant when expressive vocabulary standard score was
`r evt_cutpoint` or greater (at the `r minp_cutpoint_tile`-percentile or
greater). In summary, at age 3, both expressive vocabulary and minimal
pair discrimination each predicted greater consideration of the
unfamiliar image. But these effects also interacted so that a large
change in one predictor would weaken the effect of the other. 

```{r compute-weighted-quadratic}
ends <- m_f_new_fits_each %>% 
  group_by(Study, ResearchID, .draw) %>% 
  top_n(5, Time) %>% 
  summarise(End = median(plogis(.posterior_value)))

end_means <- ends %>% 
  summarise(End = mean(End))

feature_means <- feature_means %>% 
  left_join(end_means) %>% 
  mutate(WeightedProp_ot2 = Prop_ot2 * End)

prop_ot2_groups <- feature_means %>% 
  group_by(Study) %>% 
  mutate(
    ntile = factor(ntile(WeightedProp_ot2, 6)),
    num = ntile %>% 
      fct_add_counts(first_fmt = "{levels} ({counts} children)") %>% 
      as.character()) %>% 
  distinct(Study, ResearchID, WeightedProp_ot2, ntile, num)

cor_prop_valley <- cor(feature_means$Prop_ot2, feature_means$Valley_Prop) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero() %>% 
  printy::fmt_minus_sign()

cor_wprop_valley <- feature_means$WeightedProp_ot2 %>% 
  cor(feature_means$Valley_Prop) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero() %>% 
  printy::fmt_minus_sign()

cor_wprop_prop <- feature_means$WeightedProp_ot2 %>% 
  cor(feature_means$Prop_ot2) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero() %>% 
  printy::fmt_minus_sign()
```

The growth curve valley feature measures the maximum extent to which the novel
object is considered as the referent on these trials. But the u-shaped
growth curves in Figure \@ref(fig:age3-valley-curves) suggest another
listening response on this task: Confirmatory looks to the unfamiliar
object. In these u-shaped curves, a child's probability of fixating on
the familiar object temporarily decreases as the novel object is
considered, and the probability rises as that interpretation is
rejected. To quantify this tendency, I computed each child's growth
curve on the probability scale and re-estimated the quadratic trends in
these curves. Exploratory visualization showed that children with higher
values on this quadratic trend were more likely to have a u-shape curve.
This feature, however, also favored sigmoid or z-shaped curves that
rapidly fell and plateaued. To avoid these kinds of curves, I weighted
the quadratic trend using the median of the final five points of the
curve. The weighted quadratic feature penalized curves that have a
strong quadratic trend but end on a low probability.
Figure \@ref(fig:mp-fam-prop-ot2-bins) shows growth curves of age-5
children binned using this feature. The bottom row of panels illustrates
how the u-shaped feature becomes stronger in each bin. The weighted
quadratic feature was weakly correlated with the growth curve valleys,
*r* = `r cor_wprop_valley`, and the lack of correlation appears in the
figure by how the curves in each panel reach different valleys.

(ref:mp-fam-prop-ot2-bins) Growth curves for mispronunciations trials starting on the familiar object at age 5. Children were grouped into sextiles based on the posterior mean of their curves quadratic trend weighted by the height of the curve in the final time bins. Ten lines are drawn per child to visualize uncertainty. Children were assigned colors arbitrarily. 

(ref:mp-fam-prop-ot2-bins-scap) Growth curves for mispronunciations trials starting on the familiar object at age 5 with children binned using the weighted quadratic trend.

```{r mp-fam-prop-ot2-bins, fig.cap = "(ref:mp-fam-prop-ot2-bins)", fig.scap = "(ref:mp-fam-prop-ot2-bins-scap)", width = 6, height = 6, out.width=out_tex100_else80}
set.seed(20180713)

prop_ot2_to_plot <- m_f_new_fits_each %>% 
  sample_n_of(10, .draw) %>% 
  left_join(prop_ot2_groups, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 5") %>% 
  group_by(ResearchID, Study, .draw)

ggplot(prop_ot2_to_plot) + 
  aes(x = Time, y = plogis(.posterior_value), color = ResearchID) + 
  geom_hline(size = 2, yintercept = .5, color = "white") + 
  geom_line(aes(group = .group), alpha = .1) +
  facet_wrap("num") + 
  guides(color = FALSE) + 
  labs(
    x = constants$x_time,
    y = constants$y_prop_fam,
    title = "Age 5 children binned by weighted quadratic trend",
    caption = "10 posterior samples per child.")

# bottom_fifth <- function(xs) {
#   xs <= quantile(xs, .2)
# }
# ggplot(prop_ot2_to_plot %>% inner_join(scores)) + 
#   aes(x = Time, y = plogis(.posterior_value), color = bottom_fifth(EVT_Standard)) + 
#   geom_hline(size = 2, yintercept = .5, color = "white") + 
#   geom_line(aes(group = .group), alpha = .1) +
#   facet_wrap("num") + 
#   guides(color = FALSE) + 
#   scale_color_manual(values = c("grey50", constants$col_blue_highlight)) +
#   labs(
#     x = constants$x_time,
#     y = constants$y_prop_fam,
#     title = "Age 5 children binned by weighted quadratic trend",
#     caption = "10 posterior samples per child.")
```


```{r, include = FALSE}
prop_ot2_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  lm(WeightedProp_ot2 ~ scale(EVT_Standard) * Study, .) %>% 
  summary()

prop_ot2_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 3") %>% 
  lm(WeightedProp_ot2 ~ scale(MinPair_ProportionCorrect), .) %>% 
  summary()

prop_ot2_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 3") %>% 
  lm(WeightedProp_ot2 ~ scale(EVT_Standard), .) %>% 
  summary()

prop_ot2_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 4") %>% 
  lm(WeightedProp_ot2 ~ scale(EVT_Standard), .) %>% 
  summary()

prop_ot2_groups %>% 
  ungroup() %>% 
  inner_join(scores) %>% 
  filter(Study == "Age 5") %>% 
  tidy_correlation(EVT_Standard, WeightedProp_ot2)

m_fam_wot2_evt_age5 <- prop_ot2_groups %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>% 
  filter(Study == "Age 5") %>% 
  lm(WeightedProp_ot2 ~ scale(EVT_Standard, scale = FALSE), .)
summary(m_fam_wot2_evt_age5)

# Small effect
r2_wot2_evt <- m_fam_wot2_evt_age5 %>% 
  broom::glance() %>% 
  pull(r.squared) %>%
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

prop_ot2_groups %>% 
  left_join(scores, by = c("Study", "ResearchID")) %>% 
  ggplot() + 
    aes(x = EVT_Standard, y = WeightedProp_ot2, color = Study) + 
    geom_point() + 
    stat_smooth(method = "lm")
```

I regressed the u-shaped curve feature onto expressive vocabulary
standard score at each age and onto minimal pair discrimination for
age 3. There was a tiny yet significant effect of vocabulary at
age 5, *R*^2^ = `r r2_wot2_evt`, where children with lower vocabularies
had a slightly stronger u-shaped trend in their growth curve. This
effect, however, is so small as to be negligible. None of the effects were 
significant.

**Summary**. At age 3, children with larger expressive vocabularies or
better minimal pair discrimination had lower growth curve valleys---that
is, they looked more to the unfamiliar object when they heard a
mispronunciation while fixated on an image of the mispronounced word.
These two child-level measures significantly interacted so that
increasing both measures simultaneously had diminishing returns. I
devised a measure of the how u-shaped the growth curves were, but there
were not any meaningful effects of vocabulary or expressive vocabulary
on this measure.

## Looking behaviors and word learning

At age 5, we tested children's retention of the novel objects paired
with the mispronunciations and nonwords. Children saw the two novel
objects and heard either the mispronunciation or the nonword, and they
had to point to the objects that went with the image. All six nonwords
and mispronunciations were tested. 

Table \@ref(tab:mp-norming-table)
shows the results for each item. Overall, children performed better on
the nonwords than the real words. Children performed decidedly better on
the nonwords than the mispronunciations on four of the pairs and performed
about equally well on the remaining two (*gake*-*pumm*, *wice*-*bape*).

```{r mp-norming-table}
se_prop <- littlelisteners::se_prop

mp_norming <- readr::read_csv("./data-raw/age5-mp-norming.csv") %>% 
  mutate(Study = convert_study_to_age(Study))  %>% 
  rename(
    ItemType = MPNorm_Type, 
    Item = MPNorm_Item,
    Correct = MPNorm_Correct)

# mp_norming %>% 
#   group_by(ResearchID, ItemType) %>% 
#   summarise(Proportion = mean(Correct)) %>% 
#   ggplot() + 
#     aes(x = Proportion, fill = ItemType) + 
#     geom_histogram(position = position_dodge())

mpn_items <- mp_norming %>% 
  group_by(WordGroup, ItemType, Item) %>% 
  summarise(
    NCorrect = sum(Correct),
    NTrials = n(),
    Percent = mean(Correct) %>% round(2) %>% scales::percent(),
    SE = se_prop(mean(Correct), NTrials) %>% round(3))

mpn_items_all <- mp_norming %>% 
  mutate(WordGroup = "(all)", Item = "&nbsp;") %>% 
  group_by(WordGroup, ItemType, Item) %>% 
  summarise(
    NCorrect = sum(Correct),
    NTrials = n(),
    Percent = mean(Correct) %>% round(2) %>% scales::percent(),
    SE = se_prop(mean(Correct), NTrials) %>% round(3))

both <- bind_rows(mpn_items, mpn_items_all)

both$Percent <- both %>% 
  glue::glue_data("{Percent} &plusmn; {SE * 100}") 

both$Correct <- both %>% 
  glue::glue_data(
    "{stringr::str_pad(NCorrect, width = 3, side = 'left', pad = ' ')} / {NTrials}") %>% 
  as.character()
  
both <- both %>%
  ungroup() %>% 
  mutate(
    WordGroup = tjmisc::replace_if_same_as_last(WordGroup, "&nbsp;")) %>% 
  select(
    `Word Group` = WordGroup,
    `Type` = ItemType,
    `Item` = Item,
    `Trials Correct` = Correct,
    `Percent Correct` = Percent) 

both %>% 
  knitr::kable(
    align = "lllrr", 
    booktabs = TRUE, 
    caption = "Results for the item retention tests.")
```


```{r}
set.seed(20180715)
peaks <- readr::read_rds("./data/aim2-real-vs-nw-all-peaks.rds.gz")
peaks <- peaks %>% 
  group_by(Study, ResearchID) %>% 
  rename(nonword = nonsense) %>% 
  summarise_at(vars(nonword, real), funs(mean, sd)) %>% 
  ungroup() %>% 
  mutate(Study = convert_study_to_age(Study))

by_cond_peaks <- unfam_peaks %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(Peak), funs(mean, sd), na.rm = TRUE) %>% 
  ungroup() %>% 
  rename(mispronunciation_mean = mean, mispronunciation_sd = sd) %>% 
  right_join(peaks) %>% 
  select(-real_mean, -real_sd) %>% 
  filter(Study == "Age 5") %>% 
  tidyr::gather(stat, value, mispronunciation_mean:nonword_sd) %>% 
  tidyr::separate(stat, c("ItemType", "stat")) %>% 
  tidyr::spread(stat, value) %>% 
  rename(peak_mean = mean, peak_sd = sd)

# by_cond_peaks2 <- fam_peaks %>%
#   group_by(Study, ResearchID) %>%
#   summarise_at(vars(Valley_Prop), mean, na.rm = TRUE) %>%
#   ungroup() %>%
#   rename(mp = Valley_Prop) %>%
#   right_join(peaks) %>%
#   rename(mispronunciation = mp, nonword = nonsense) %>%
#   select(-real) %>%
#   filter(Study == "Age 5") %>%
#   tidyr::gather(ItemType, Peak, mispronunciation, nonword)

mp_norming_peaks <- by_cond_peaks %>% 
  inner_join(mp_norming)

d_centered_peaks <- mp_norming_peaks %>% 
  distinct(Study, ResearchID, ItemType, peak_mean) %>% 
  group_by(ItemType) %>% 
  mutate(
    mean = mean(peak_mean, na.rm = TRUE), 
    sd = sd(peak_mean, na.rm = TRUE),
    # unit change represents change of .1 from mean
    c_peak_10 = (peak_mean - mean) * 10) %>% 
  ungroup() 

mp_norming_peaks <- mp_norming_peaks %>% 
  left_join(d_centered_peaks)

n_peaks <- mp_norming_peaks %>% 
  distinct(ResearchID) %>% 
  nrow()

readr::write_csv(mp_norming_peaks, "./data/mp-norming-data.csv.gz")

m_norm <- readr::read_rds("./data/mp-norming-m2.rds.gz")

mean_se_prop <- function(x) {
  x <- stats::na.omit(x)
  m <- mean(x)
  n <- length(x)
  se <- se_prop(m, n)
  data.frame(y = m, ymin = m - se, ymax = m + se)
}

new_data <- mp_norming_peaks %>% 
  split(.$ItemType) %>% 
  lapply(
    modelr::data_grid, 
    c_peak_10 = modelr::seq_range(c_peak_10, 200),
    mean = mean,
    sd = sd,
    ResearchID = "Average",
    Item = "ignore",
    WordGroup = "ignore",
    ItemType = unique(ItemType)) %>% 
  bind_rows() %>% 
  mutate(
    peak_mean = (c_peak_10 / 10) + mean)

aaa <- augment_linpred(
  m_norm, 
  data = new_data, 
  transform = TRUE,
  all_new_levels = TRUE,
  re_formula = NA)

means <- mp_norming_peaks %>% 
  group_by(ItemType) %>% 
  summarise(
    m_value = unique(mean),
    sd_value = unique(sd),
    peak = mean(c_peak_10, na.rm = TRUE),
    sd = sd(c_peak_10, na.rm = TRUE),
    peak_upsd = peak + sd) %>% 
  split(.$ItemType)

norm_fixef <- m_norm %>% 
  posterior_samples(pars = "b_") %>% 
  as_tibble() %>% 
  transmute(
    b_mispronunciation = b_Intercept,
    b_nonword = b_Intercept + b_ItemTypenonword,
        
    b_peak_mispronunciation = b_c_peak_10,
    b_peak_nonword = b_c_peak_10 + `b_ItemTypenonword:c_peak_10`,
    
    b_mean_mispronunciation = b_mispronunciation + 
      means$mispronunciation$peak * b_peak_mispronunciation,
    b_mean_nonword = b_nonword + 
      means$nonword$peak * b_peak_nonword,
    
    b_mean_upsd_mispronunciation = b_mispronunciation + 
      means$mispronunciation$peak_upsd * b_peak_mispronunciation,
    b_mean_upsd_nonword = b_nonword + 
      means$nonword$peak_upsd * b_peak_nonword,
    
    b_mean_upsd_mispronunciation_prop = plogis(b_mean_upsd_mispronunciation),
    b_mean_upsd_nonword_prop = plogis(b_mean_upsd_nonword),
    
    b_mean_mispronunciation_prop = plogis(b_mean_mispronunciation),
    b_mean_nonword_prop = plogis(b_mean_nonword),
  
    d_mean_upsd_mispronunciation_prop =  
      b_mean_upsd_mispronunciation_prop - b_mean_mispronunciation_prop,
    d_mean_upsd_nonword_prop = b_mean_upsd_nonword_prop - b_mean_nonword_prop) 

props <- norm_fixef %>% 
  mcmc_intervals_data(
    pars = c("b_mean_nonword_prop", "b_mean_mispronunciation_prop")) %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  add_ui_slug_to_first("90% UI: ") %>% 
  lapply(fmt_remove_leading_zeros_in_text)

props_sd <- norm_fixef %>% 
  mcmc_intervals_data(
    regex_pars = c("upsd")) %>% 
  split(.$parameter) %>% 
  fmt_inline_median_interval() %>% 
  lapply(fmt_remove_leading_zeros_in_text)

# sjPlot::tab_model(m_norm)

mean_mp_peak <- means$mispronunciation$m_value %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

mean_nw_peak <- means$nonword$m_value %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

sd_mp_peak <- means$mispronunciation$sd_value %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()

sd_nw_peak <- means$nonword$sd_value %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero()
```

I performed an item-response analysis using a mixed-effects logistic
regression model. [Appendix \@ref(aim2-gca-models)](#aim2-gca-models) reports the code used to specify the
model. The model included varying intercepts for child, child × item
type, item, and word-group. The first two effects capture
information about a child's general ability and their ability on each
type of item. The second two effects capture information about an item's
difficulty and difficulty of object-pairs. I also asked whether growth
curve peaks predicted novel word recognition accuracy, so I included
growth curve peaks from each condition in the model. For the nonwords, I
used the age-5 peak proportion of looks to the novel image for trials
that started on the familiar object. For the mispronunciations, I used
the peak looks to the familiar object on trials that started on the
unfamiliar object. I chose those peaks based on the conclusion that
children were reliably treating the mispronunciations as imperfect
productions of the familiar word. The model included data from
`r n_peaks` children.

The model confirmed that children were much more successful on the
nonword trials. For a child with an average mispronunciation peak
(`r mean_mp_peak`), the predicted proportion correct on the
mispronunciation retention trials was
`r props$b_mean_mispronunciation_prop`. A 1-SD (`r sd_mp_peak`) increase
in the mispronunciation peak predicted a change in proportion correct of
`r props_sd$d_mean_upsd_mispronunciation_prop`. Children who looked more
to the familiar object on these mispronunciation trials were less
successful during the retention trials. For a child with an average peak
on the nonword trials (`r mean_nw_peak`), the predicted proportion
correct on the nonword retention trials was
`r props$b_mean_nonword_prop`. A 1-SD increase (`r sd_nw_peak` to 1.00)
in nonword peaks predicted a change in proportion correct of
`r props_sd$d_mean_upsd_nonword_prop`. The uncertainty interval here
includes positive and negative values. It is uncertain whether the
effect is positive or negative, so I conclude that there was not a
reliable effect in the nonword case.

Figure \@ref(fig:mp-norm-trials-by-peak) visualizes the model results.
The difference in height between the two curves reflects the
general advantage in the nonword condition. The negative slope for the
mispronunciation line captures the effect of growth curve peaks. A
change in mispronunciation growth curve peak from .5 to 1 roughly
predicts a change from 4/6 to 3/6 mispronunciation items correct. The
nonword line hovers around 5/6 items correct: There is not enough
information in the peaks or in the number of retention trials for a
reliable effect to emerge.

(ref:mp-norm-trials-by-peak) Effect of growth curve peaks on children's accuracy on retention trials. For the mispronunciations, I used the peak looks to the familiar image on trials where the child started on the unfamiliar image, so it represents, say, how much a child looked at *shoes* given "suze". Thus, more permissive listeners looked performed more poorly on the retention trials. For the nonwords, I used the peak look to the unfamiliar image on trials where the child started on the familiar image.
Points were jittered by 1% to avoid overplotting. There were six trials per condition which is why the points fall into 6 bands.

(ref:mp-norm-trials-by-peak-scap) Effect of growth curve peaks on children's accuracy on retention trials.

```{r mp-norm-trials-by-peak, fig.cap = "(ref:mp-norm-trials-by-peak)", fig.scap = "(ref:mp-norm-trials-by-peak-scap)", fig.width=5, fig.height=3.5, out.width=out_tex80_else66}
aaa %>% 
  group_by(ItemType, .draw) %>% 
  ggplot() + 
    aes(x = peak_mean, y = .posterior_value, color = ItemType) + 
  geom_hline(yintercept = .5, size = 2, color = "white") +
      stat_summary(
      aes(y = Correct),
      data = mp_norming_peaks,
      fun.data = mean_se_prop,
      geom = "point",
      position = position_jitter(.01, .01), shape = 1)  + 
    stat_summary(
      aes(fill = ItemType),
      fun.data = median_hilow,
      fun.args = list(conf.int = .9),
      geom = "ribbon", 
      alpha = .25, color = NA)  + 
    stat_summary(
      aes(fill = ItemType),
      fun.data = median_hilow,
      fun.args = list(conf.int = .5),
      geom = "ribbon", 
      alpha = .3, 
      color = NA) + 
    stat_summary(
      aes(fill = ItemType),
      fun.data = median_hilow,
      fun.args = list(conf.int = .05),
      geom = "ribbon", 
      alpha = .4, 
      color = NA) + 
    geom_text(
      aes(label = label),
      data = data_frame(
        peak_mean = c(.2, .9), 
        label = c("mispronunciations", "nonwords"),
        ItemType = c("mispronunciation", "nonword"),
        .posterior_value = c(.55, .93)), 
      size = 4, 
      family = "Lato Semibold") +
    scale_color_manual(values = c("cyan4",  "#f7882f")) + 
    scale_fill_manual(values = c("cyan4", "#f7882f")) + 
  labs(
    x = "Growth curve peaks",
    y = "Proportion trials correct",
    caption = "Ribbons: 90%, 50%, 5% uncertainty intervals.") +
    guides(color = FALSE, fill = FALSE) 

```

**Summary**. When 5-year-olds were tested on their retention of the
unfamiliar images used on the mispronunciation and nonword trials,
children were much more accurate for the nonwords than the
mispronunciations. Children's accuracy on the mispronunciations was
related to their looking behaviors: Children who looked more to the familiar
image during mispronunciation trials had a lower accuracy on the
mispronunciation retention trials.

```{r include = FALSE}
set.seed(20180715)
peaks <- readr::read_rds("./data/aim2-real-vs-nw-all-peaks.rds.gz")
peaks <- peaks %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(nonsense, real), mean) %>% 
  ungroup() %>% 
  mutate(Study = convert_study_to_age(Study))

peaks_all <- unfam_peaks %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(Peak), mean, na.rm = TRUE) %>% 
  ungroup() %>% 
  rename(mp = Peak) %>% 
  right_join(peaks)

peaks_all <- unfam_peaks %>% 
  group_by(Study, ResearchID) %>% 
  summarise_at(vars(Peak), mean, na.rm = TRUE) %>% 
  ungroup() %>% 
  rename(mp = Peak) %>% 
  right_join(peaks) %>% 
  mutate(penalty = mp - real, advantage = real - mp)





condition_means <- peaks_all %>% 
  select(-nonsense, -penalty, -advantage) %>% 
  filter(!is.na(mp), !is.na(real)) %>% 
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  ungroup()


study_peak_counts <- condition_means %>%
  distinct(Study, ResearchID) %>%
  mutate(StudyCounts = Study %>% fct_add_counts()) %>%
  distinct(Study, StudyCounts)

x_levels <- setNames(
  as.character(study_peak_counts$StudyCounts), 
  as.character(study_peak_counts$Study))

p_mp_real <- ggplot(condition_means) + 
  aes(x = Study, y = Peak, color = Condition) + 
    geom_hline(yintercept = .5, size = 2, color = "white") + 
  geom_text(
    aes(label = label),
    data = data_frame(
      Peak = 1.06, 
      label = c("mispronunciations", " "),
      Condition = c("mp", "real"),
      Study = c("Age 3", "Age 3")), 
    position = position_dodge(width = .75), 
    size = 3, 
    family = "Lato Medium") +
  geom_text(
    aes(label = label),
    data = data_frame(
      Peak = 1.06, 
      label = c(" ", "real words"),
      Condition = c("mp", "real"),
      Study = c("Age 4", "Age 4")), 
    position = position_dodge(width = 1.15), 
    size = 3, 
    family = "Lato Medium") +
  geom_point(
    position = position_jitterdodge(jitter.width = 0.25, dodge.width = 1.05), 
    alpha = .5, 
    shape = 1) +
  geom_boxplot(
    width = .2, 
    position = position_dodge(width = .3), 
    outlier.alpha = 0)  +
  guides(color = FALSE) +
  labs(
    title = "Mispronunciation penalty",
    x = NULL,
    y = NULL,
    subtitle = "Peaks for trials starting on unfamiliar image",
    caption = "Points: Participant posterior means.") + 
  scale_x_discrete(labels = x_levels) +
  scale_y_continuous(
    minor_breaks = c(.1, .3, .5, .7, .9),
    breaks = c(0, .2, .4, .6, .8, 1)) +
  scale_color_manual(values = c("cyan4", "#6b7a8f", "#f7882f"))  +
  theme(plot.subtitle = element_text(size = rel(.9)))
```


## Discussion

In the lab, when preschoolers are looking at a novel object and hear the
name of a different familiar object, albeit mispronounced, they look to
the familiar object. Children do this reliably at age 3 and even more
reliably at age 5. Thus, children recognized these mispronunciations as
productions of familiar words, but this recognition was not without a
penalty. They looked much less to the familiar object under these
conditions, compared to trials where they hear a correct production of
the familiar object---see Figure \@ref(fig:mp-vs-real-peaks)---or when
they hear a nonword in a context that supports fast-referent selection. 
Therefore, preschoolers are unquestionably sensitive to
mispronunciations of familiar words, as they show more uncertainty when
hearing a mispronunciation.

(ref:mp-vs-real-peaks) Comparison of growth curve peaks for the real words and mispronunciations.

(ref:mp-vs-real-peaks-scap) Comparison of growth curve peaks for the real words and mispronunciations.

```{r mp-vs-real-peaks, fig.cap = "(ref:mp-vs-real-peaks)", fig.scap = "(ref:mp-vs-real-peaks-scap)", fig.width=4, fig.height=3, out.width=out_tex80_else50}
p_mp_real
```

Child-level measures generally did not predict how well children
tolerated mispronunciations. There was a very small effect of expressive
vocabulary at age 3 such that children with larger vocabularies looked
more the familiar image on these trials. Although children differed in
their tendency to look to a familiar image when given a
mispronunciation, these differences could not be pinned to any
child-level measures.

I also analyzed trials where children started on the familiar word and
heard a mispronunciation. In this situation, there is no one clear
strategy for referent selection, and children exhibit a few different
patterns. Some listeners stay with the familiar image. Some reliably
switch to the novel image. Some look at both equally. On average, the
growth curve averages rush to .5---equal looking to both images and
maximum uncertainty. At age 5, the curve does not reach quite as far
down as the other curves, so they never demonstrate this degree of
uncertainty. These sets of analyses mainly demonstrate that when
children start on a familiar image and hear a mispronunciation, they
have a few options for how to proceed. 

Child-level predictors only were predictive at age 3 for curve valley. In
this case, children with larger vocabularies or better minimal pair
discrimination showed more consideration of the nonword object. I
speculate that in this situation, the effect reflects that children with
better abilities in these areas were more sensitive to the
mispronunciation. These children were better at recognizing the mismatch
from partial information and thus allocated more credibility to the
alternative image.

One strategy to resolve the uncertainty in this situation would be to
verify and reject the other image. Therefore, I also defined a weighted
quadratic growth curve feature that measured how u-shaped the curves
were. Such curves would reflect a child temporarily decreasing looks to
the familiar image as a confirmatory looking behavior. The u-shaped
curve features were not reliably related to any child-level factors,
outside of negligibly small effect of expressive vocabulary at age 5.

Children demonstrated different looking behaviors based on their initial
fixation location. For unfamiliar-initial trials, the growth curves show
a reliable shift to the familiar image and we infer that the children
treat the mispronunciation as passable production of the familiar word.
For the familiar-initial trials, the children show much more uncertainty
and a reliable advantage for the familiar word only begins to appear by
age 5. 

What are children doing in this situation? I initially thought that some
children might "be finished" with the trial when they hear the word.
That is, the child fixates on the familiar word, hears the
mispronunciation prompt, notices that they have already found the image,
and then looks to other parts of the screen. The problem with this
possibility is that it does not happen in other conditions. For the
nonword and real
word conditions, when children start on the named image, they stick with
the target. The average empirical growth curves in
Figure \@ref(fig:aim2-real-word-spaghetti) and
Figure \@ref(fig:aim2-nonword-spaghetti) tend to stay around 70--80%
looking to the target image. Rather than reflecting disengagement from
the task, the looking patterns indicate increased uncertainty in these
trials.

Another possibility is that children show increased uncertainty because
the mispronunciation effect is greater when the child is fixating on the
familiar word. That is, children who fixated on the familiar image might
have internally named the object and built up the word's resting
activation. The mispronunciation directly conflicts with the child's
pre-naming expectations for the word's name, thus inducing more
uncertainty after the word is named. For the unfamiliar-initial trials,
on the other hand, a child's attention is on the novel object and they
have a less potent expectation about the words they might hear.

Visual attention did seem to influence how children retained information
from the mispronunciation trials. At age 5, we tested children's
retention of the mispronunciations and nonwords. Children were much more
likely to recall which unfamiliar object appeared on the nonword trials
than the mispronunciation trials. This difference is not unexpected. In
the nonword trials, children looked to an unfamiliar object when given
an unambiguous novel word for a label. Thus, each trial worked to build
an association between a new word and an unfamiliar object. But children
generally treated the mispronunciations as productions of the familiar
words. For the unfamiliar-initial trials, they looked more to the
familiar object, a result that held at all three ages. Rather than
developing a new object-label mapping, children are working on resolving
an ambiguous and uncertain production on these trials. This idea is
consistent with the effect of growth curve peaks on retention accuracy:
Children who looked less to the unfamiliar object on mispronunciation
trials were less likely to recall that unfamiliar object during
retention testing.



```{r advantage-predictions, include = FALSE}
# Quantify an advantage
ggplot(peaks_all) + 
  aes(x = Study, y = advantage) + 
  geom_hline(yintercept = 0, size = 2, color = "white") +
  geom_point(
    position = position_jitter(width = 0.25), 
    alpha = .5, 
    shape = 1) +
  geom_boxplot(
    width = .2, fill = NA,
    outlier.alpha = 0) + 
  labs(y = "real word advantage")

# No relationships between advantage and vocab
peaks_all %>% 
  left_join(scores) %>% 
  ggplot() + 
    aes(x = EVT_Standard, y = advantage, color = Study) + 
    geom_point() +
    stat_smooth(method = "lm") +
    labs(
      y = "real word advantage",
      title = "no within age effects")

peaks_all %>% 
  filter(Study == "Age 3") %>% 
  inner_join(scores) %>% 
  ggplot() + 
    aes(x = MinPair_ProportionCorrect, y = advantage) + 
    geom_point() +
    stat_smooth(method = "lm") +
    labs(y = "real word advantage")

# tiny effect
peaks_all %>% 
  filter(Study == "Age 3") %>% 
  inner_join(scores) %>% 
  lm(advantage ~ MinPair_ProportionCorrect, .) %>% summary()


peaks_all %>% 
  filter(Study == "Age 3") %>% 
  inner_join(scores) %>% 
  lm(cbind(nonsense, mp, real) ~ EVT_Standard, .) %>% 
  broom::tidy()

peaks_all %>% 
  filter(Study == "Age 4") %>% 
  inner_join(scores) %>% 
  lm(cbind(nonsense, mp, real) ~ EVT_Standard, .) %>% 
  broom::tidy()

peaks_all %>% 
  filter(Study == "Age 5") %>% 
  inner_join(scores) %>% 
  lm(cbind(nonsense, mp, real) ~ EVT_Standard, .) %>% 
  broom::tidy()

# tiny effect
peaks_all %>% 
  filter(Study == "Age 3") %>% 
  inner_join(scores) %>% 
  lm(cbind(nonsense, mp, real) ~ MinPair_ProportionCorrect, .) %>% 
  broom::tidy()


peaks_all %>% 
  filter(Study == "Age 3") %>% 
  inner_join(
    scores %>% 
      filter(Study == "Age 5") %>% 
      select(ResearchID, EVT_Standard)) %>% 
  ggplot() + 
  aes(x = advantage, y = EVT_Standard) + 
  geom_point() +
  stat_smooth(method = "lm") +
  labs(
    title = "no predictive effects",
    x = "real word advantage (age 3)", 
    y = "EVT Standard (age 5)")

```

```{r advantage-correlations, include = FALSE}
# Advantages are not well correlated with other peaks

by_year <- peaks_all %>% 
  select(Study, ResearchID, real, mp, nonsense, advantage) %>% 
  filter(!is.na(mp), !is.na(real)) %>% 
  tidyr::gather("Condition", "Peak", -Study, -ResearchID) %>%
  ungroup()

by_type <- by_year %>% 
  mutate(Study = stringr::str_replace(Study, " ", "")) %>% 
  tidyr::unite(Study, Study, Condition) %>% 
  tidyr::spread(Study, Peak)  

ggplot(by_type) + 
  aes(x = `Age3_advantage`, y = `Age4_advantage`) + 
  geom_point() +
  stat_smooth(method = "lm") 

ggplot(by_type) + 
  aes(x = `Age4_advantage`, y = `Age5_advantage`) + 
  geom_point() +
  stat_smooth(method = "lm") 

ggplot(by_type) + 
  aes(x = `Age3_nonsense`, y = `Age4_nonsense`) + 
  geom_point() +
  stat_smooth(method = "lm") 

ggplot(by_type) + 
  aes(x = `Age3_real`, y = `Age4_real`) + 
  geom_point() +
  stat_smooth(method = "lm") 

ggplot(by_type) + 
  aes(x = `Age3_real`, y = `Age3_nonsense`) + 
  geom_point() +
  stat_smooth(method = "lm") 

ggplot(by_type) + 
  aes(x = `Age3_mp`, y = `Age3_nonsense`) + 
  geom_point() +
  stat_smooth(method = "lm") 

ggplot(by_type) + 
  aes(x = `Age4_mp`, y = `Age4_nonsense`) + 
  geom_point() +
  stat_smooth(method = "lm") 

ggplot(by_type) + 
  aes(x = `Age5_mp`, y = `Age5_nonsense`) + 
  geom_point() +
  stat_smooth(method = "lm") 

by_type %>% 
  select(-ResearchID, -ends_with("advantage")) %>% 
  cor(use = "pairwise.complete.obs") %>% 
  round(2)
```
