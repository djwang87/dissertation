# Visualize looks to each image type

```{r include = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
```

```{r helpers, include = FALSE}
```

```{r aim1-gam-load-looks, message = FALSE, warnings = FALSE, echo = FALSE}
# Earlier we cleaned the data to remove trials with excessive missing data 
# and blocks of trials with too few trials. Read in that data.
data <- readr::read_csv("./data/aim1-screened.csv.gz")

recode_studies <- tibble::tribble(
  ~S,           ~S2,          ~Study,       ~Age,
  "TimePoint1", "TimePoint1", "TimePoint1", "Age 3",
  "TimePoint2", "TimePoint2", "TimePoint2", "Age 4",
  "TimePoint3", "TimePoint3", "TimePoint3", "Age 5",
)

convert_study_to_age <- function(xs) {
  factor(
    xs, 
    levels = c("TimePoint1", "TimePoint2", "TimePoint3"), 
    labels = c("Age 3", "Age 4", "Age 5"))
}

# How to aggregate data the looking labels
resp_def <- create_response_def(
  primary = "Target",
  others = c("PhonologicalFoil", "SemanticFoil", "Unrelated"),
  elsewhere = "tracked",
  missing = NA
)

defs <- cycle_response_def(resp_def)

semy_defs <- defs %>% 
  purrr::keep(~ .x$primary %in% c("Target", "SemanticFoil"))

phon_defs <- defs %>% 
  purrr::keep(~ .x$primary %in% c("Target", "PhonologicalFoil"))
```


```{r separate-strong-vs-weak-foils, message = FALSE, echo = FALSE}
# In @RWLPaper, we ignored trials for certain items where we didn't think the
# phonological or semantic similarity was strong enough.

trial_info <- bind_rows(
  readr::read_csv("data-raw/rwl_timepoint1_trials.csv.gz"),
  readr::read_csv("data-raw/rwl_timepoint2_trials.csv.gz"),
  readr::read_csv("data-raw/rwl_timepoint3_trials.csv.gz")) %>% 
  select(
    TrialID, 
    Target = WordTarget, 
    PhonologicalFoil = WordPhonologicalFoil,
    SemanticFoil = WordSemanticFoil, 
    Unrelated = WordUnrelated)

good_phono <- c("bear", "bee", "bell", "dress", "drum", "flag", "fly", 
                "heart", "horse", "pan", "pear", "pen", "vase")

good_semy <- c("bear", "bee", "bell", "bread", "cheese", "dress", 
               "drum", "fly", "horse", "pan", "pear", "shirt", "spoon")

words <- trial_info %>% 
  distinct(Target, PhonologicalFoil, SemanticFoil, Unrelated)

phono_foils <- split(words, words$Target %in% good_phono) %>% 
  lapply(arrange, Target) %>% 
  setNames(c("weak_foil", "strong_foil"))

semy_foils <- split(words, words$Target %in% good_semy) %>% 
  lapply(arrange, Target) %>% 
  setNames(c("weak_foil", "strong_foil"))

strong_phon_looks <- trial_info %>% 
  semi_join(phono_foils$strong_foil) %>% 
  inner_join(data) %>% 
  mutate(PhonFoil = "Strong")

strong_semy_looks <- trial_info %>% 
  semi_join(semy_foils$strong_foil) %>% 
  inner_join(data) %>% 
  mutate(SemyFoil = "Strong")

n_phon <- phono_foils$strong_foil$Target %>% unique() %>% length()
n_semy <- semy_foils$strong_foil$Target %>% unique() %>% length()

# Keeping this commented out code around until it can be ported to an appendix

# phono_foils$strong_foil %>% 
#   knitr::kable(caption = "Trials with strong phonological foils.")
# 
# phono_foils$weak_foil %>% 
#   knitr::kable(caption = "Trials with weak phonological foils.")

# semy_foils$strong_foil %>% 
#   knitr::kable(caption = "Trials with strong semantic foils.")
# 
# semy_foils$weak_foil %>% 
#   knitr::kable(caption = "Trials with weak semantic foils.")
```




```{r gam-modeling-options, echo = FALSE, results = "hide"}
opts_model <- list(
  bin_width = 3,
  phon_start_time = 250,
  phon_end_time = 1500,
  semy_start_time = 250,
  semy_end_time = 1800)

opts_model$bin_length <- round(opts_model$bin_width * 16.67, -1)

message("Modeling options: ")
message(str(opts_model))
```

## Looks to the phonological foil

```{r create-phon-data, include = FALSE}
data <- strong_phon_looks %>% 
  select(Study, ResearchID, TrialID:GazeByImageAOI) %>% 
  assign_bins(bin_width = opts_model$bin_width, Time, TrialID)

# Compute time at center of each bin
bin_times <- data %>% 
  distinct(Time, .bin) %>% 
  group_by(.bin) %>% 
  mutate(BinTime = round(median(Time), -1)) %>% 
  ungroup()

# Attach bin times
binned <- data %>% 
  left_join(bin_times, by = c("Time", ".bin")) %>% 
  ungroup() %>% 
  select(-Time) %>% 
  rename(Time = BinTime) 

d <- binned %>% 
  aggregate_looks(phon_defs, Study + ResearchID + Time ~ GazeByImageAOI)

phon_d <- d %>% 
  filter(
    opts_model$phon_start_time <= Time, 
    Time <= opts_model$phon_end_time) %>% 
  rename(Focus = .response_def)

phon_d <- phon_d %>% 
  mutate(
    S = factor(Study, c("TimePoint2", "TimePoint1", "TimePoint3")),
    R = as.factor(ResearchID),
    SR = interaction(S, R),
    elog = lookr::empirical_logit(PhonologicalFoil, Unrelated))

# Include intercepts and smooths for studies
phon_d$S2 <- as.ordered(phon_d$S) 
contrasts(phon_d$S2) <- "contr.treatment"
contrasts(phon_d$S2)
```

```{r create-semy-data, include = FALSE}
semy_data <- strong_semy_looks %>% 
  select(Study, ResearchID, TrialID:GazeByImageAOI) %>% 
  assign_bins(bin_width = opts_model$bin_width, Time, TrialID)

# Compute time at center of each bin
bin_times <- semy_data %>% 
  distinct(Time, .bin) %>% 
  group_by(.bin) %>% 
  mutate(BinTime = round(median(Time), -1)) %>% 
  ungroup()

# Attach bin times
binned <- semy_data %>% 
  left_join(bin_times, by = c("Time", ".bin")) %>% 
  ungroup() %>% 
  select(-Time) %>% 
  rename(Time = BinTime) 

semy_d <- binned %>% 
  aggregate_looks(semy_defs, Study + ResearchID + Time ~ GazeByImageAOI)

semy_d <- semy_d %>% 
  filter(
    opts_model$semy_start_time <= Time, 
    Time <= opts_model$semy_end_time) %>%
  rename(Focus = .response_def)

semy_d <- semy_d %>% 
  mutate(
    S = factor(Study, c("TimePoint2", "TimePoint1", "TimePoint3")),
    R = as.factor(ResearchID),
    SR = interaction(S, R),
    elog = lookr::empirical_logit(SemanticFoil, Unrelated))

# Include intercepts and smooths for studies
semy_d$S2 <- as.ordered(semy_d$S) 
contrasts(semy_d$S2) <- "contr.treatment"
contrasts(semy_d$S2)
```

Next, I asked how children's sensitivity to the phonological foils
changed over developmental time. Following what we did in [@RWLPaper],
I only examined trials for which the phonological foil and the noun
shared the same syllable onset. For example, this criterion included
trials with *dress*–*drum*, *fly*–*flag*, or *horse*–*heart*, but it
excluded trials *kite*–*gift* (feature difference), *bear*–*bread*
(onset difference), and *ring*–*swing* (rimes). I kept `r n_phon` of
the 24 trials.

The outcome measure for these analyses was the log-odds of fixating on
the phonological foil versus the unrelated image. Because children
looked more to the target word with each year of the study, they
necessarily looked less to the distractors each year.
Figure \@ref(fig:declining-phon-props) illustrates how the proportions
of looks to the phonological foils declined each year. Therefore, I
examined the effect of the phonological foil in comparison to the
unrelated foil. For example, on the trials where the target is *fly*, we
can study the effect of the phonological foil *flag* by looking at when
and to what to degree the children fixate on *flag* more than the
unrelated image *pen*. If a window of time of shows a consistent
advantage for the phonological foil over the unrelated image, we can
conclude that the children were sensitive to the phonological foil. By
studying the time course of fixations to the phonological foil versus
the unrelated image, we can identify when the phonological foil affected
word recognition most significantly.

<!-- Note time window for semantic foils. -->

As in the previous models, I downsampled the data into
`r opts_model$bin_length`-ms (`r opts_model$bin_width`-frame) bins in
order to smooth the data. I modeled the looks from
`r opts_model$start_time` to `r opts_model$end_time` ms. Lastly, I
aggregated looks by child, study and time.

(ref:declining-phon-props) Because children looked more to the target as
they grew older, they numerically looked less the foils too. This effect
is why we evaluate the phonological and semantic foils by comparing them
against the unrelated image.

```{r declining-phon-props, fig.cap = "(ref:declining-phon-props)", echo = FALSE, message = FALSE, out.width = "50%", fig.width = 5, fig.height = 3.5}
phon_d %>% 
  mutate(
    Focus = factor(
      Focus, c("Target", "PhonologicalFoil"), 
      c("Target", "Phonological foil")),
    Study = convert_study_to_age(Study)) %>% 
  ggplot() + 
    aes(x = Time, y = Prop, color = Study) + 
    geom_hline(yintercept = .25, color = "white", size = 2) +
    stat_summary(fun.y = "mean", geom = "line", size = 1) +
    facet_wrap("Focus") +
    labs(
      x = "Time after target onset [ms]",
      y = "Mean proportion looking to image") +
    theme_grey() +
    theme(
      legend.position = c(0.95, 0.95), 
      legend.justification = c(1, 1))
```

To account for the sparseness of the data, I used the empirical log-odds
(or empirical logit) transformation [@Barr2008]. This transformation
adds .5 to the looking counts. For example, a time-frame with 4 looks to
the phonological foil and 1 look to the unrelated image has a
conventional log-odds of log(4/1) = 1.39 and empirical log-odds of
log(4.5/1.5) = 1.10. This transformation fills in 0 values, and it
dampens the extremeness of some probabilities that arise in sparse count
data.

```{r, echo = FALSE, message = FALSE, include = FALSE, out.width = "80%", fig.width = 6}
library(mgcv)
library(itsadug)

# Base model with no study effect
b2n <- bam(
  elog ~ s(Time), 
  data = phon_d, 
  method = "REML")
# summary(b2n)

# b2 <- bam(
#   elog ~ S + s(Time) + s(Time, by = S), 
#   data = phon_d, 
#   method = "REML")
# # summary(b2)

# b2r <- bam(
#   elog ~ S2 + s(Time) + s(Time, by = S2) + s(Time, R, bs = "fs", m = 1, k = 5),
#   data = phon_d)

# readr::write_rds(b2r, "./data/aim1-phon-random-smooths.rds.gz")
b2r <- readr::read_rds("./data/aim1-phon-random-smooths.rds.gz")
summary(b2r)
# plot(b2r, pages = 1)
# report <- itsadug::report_stats(b2r)
# report[3, 2]
```

I fit a generalized additive model with fast restricted maximum
likelihood estimation [@Wood2017; @Soskuthy2017 for a tutorial for
linguists]. Box 1 provides a brief overview of these models. I used the
R package `mgcv` [vers. `r packageVersion("mgcv")`; @Wood2017] with
support from the tools in the `itsadug` package [vers.
`r packageVersion("itsadug")`; @itsadug].





\Begin{infobox}
<div class = "infobox">

**Box 1: The Intuition Behind Generalized Additive Models**.

In these analyses, the outcome of interest is a value that changes over
time in a nonlinear way. We model these time series by building a set of
features to represent time values. In the growth curve analyses of
familiar word recognition, I used a set of polynomial features which
expressed time as the weighted sum of a linear trend, a quadratic trend
and cubic trend. That is:

$$
\text{log-odds}(\mathit{looking}) = 
  \alpha + \beta_1 * \textit{Time}^1 +
           \beta_2 * \textit{Time}^2 +
           \beta_3 * \textit{Time}^3
$$

But another way to think about the polynomial terms is as *basis
functions*: A set of features that combine to approximate some nonlinear
function of time. Under this framework, the model can be expressed as:

$$
\text{log-odds}(\mathit{looking}) = 
  \alpha + f(\textit{Time})
$$
  
This is the idea behind generalized additive models and their *smooth
terms*. These smooths fit nonlinear functions of data by weighting and
adding simple functions together. The figures below show 9 basis
functions from a "thin-plate spline" and how they can be weighted and
summed to fit a growth curve.

```{r infobox-1-figs, message = FALSE, echo = FALSE, out.width = "66%", fig.width = 6, fig.height = 3, fig.align = "center"}
library(mgcv)
library(ggplot2)
library(dplyr)

t1_fam <- structure(
  list(
    Time = c(
      250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 
      950, 1000, 1050, 1100, 1150, 1200, 1250, 1300, 1350, 1400, 1450, 1500), 
    Prop = c(
      0.252, 0.255, 0.257, 0.261, 0.265, 0.275, 0.286, 0.298, 0.311, 0.315, 
      0.329, 0.342, 0.365, 0.392, 0.407, 0.422, 0.446, 0.464, 0.479, 0.497, 
      0.514, 0.524, 0.532, 0.545, 0.549, 0.555)), 
  .Names = c("Time", "Prop"), 
  class = c("tbl_df", "tbl", "data.frame"), 
  row.names = c(NA, -26L))

times <- modelr::seq_range(t1_fam$Time, 80)
newdata <- data.frame(Time = times)
t1_gam <- gam(Prop ~ s(Time), data = t1_fam)

t1_gam <- gam(Prop ~ s(Time, bs = "tp", k = 10), data = t1_fam)
basis_matrix <- predict(t1_gam, newdata, type = "lpmatrix")[, 2:10]

basis <- polypoly::poly_melt(basis_matrix) %>% 
  mutate(observation = as.numeric(observation)) %>% 
  left_join(
    data.frame(Time = times, observation = seq_along(times)), 
    by = "observation")

t1_poly <- lm(Prop ~ poly(Time, 3), data = t1_fam)

poly_basis <- polypoly::poly_melt(poly(t1_fam$Time, 3)) %>% 
  mutate(observation = as.numeric(observation)) %>% 
  left_join(
    data.frame(Time = times, observation = seq_along(times)), 
    by = "observation")

p1 <- ggplot(basis) + 
  aes(x = Time, y = value) + 
  geom_line(aes(color = degree)) + 
  ylim(c(-2, 2)) + 
  guides(color = FALSE) + 
  ggtitle("Basis functions (time features)") + 
  labs(y = NULL) +
  theme_grey(base_size = 9) + 
  theme(
    plot.background = element_rect(fill = "#eef7fa", colour = "#eef7fa"),
    panel.background = element_rect(fill = "#E5EAEF"))

p1_poly <- ggplot(poly_basis) + 
  aes(x = Time, y = value) + 
  geom_line(aes(color = degree)) + 
  # ylim(c(-2, 2)) + 
  guides(color = FALSE) + 
  ggtitle("Basis functions (time features)") + 
  labs(y = NULL) +
  theme_grey(base_size = 9)

weighted <- (basis_matrix %*% diag(coef(t1_gam)[-1])) %>% 
  polypoly::poly_melt() %>% 
  mutate(observation = as.numeric(observation)) %>% 
  left_join(
    data.frame(Time = times, observation = seq_along(times)), 
    by = "observation")

poly_weighted <- (poly(t1_fam$Time, 3) %*% diag(coef(t1_poly)[-1])) %>% 
  polypoly::poly_melt() %>% 
  mutate(observation = as.numeric(observation)) %>% 
  left_join(
    data.frame(Time = times, observation = seq_along(times)), 
    by = "observation")

p2 <- ggplot(weighted) + 
  aes(x = Time, y = value) + 
  geom_line(aes(color = factor(degree))) + 
  stat_summary(fun.y = sum, color = "#0074D9", geom = "line", size = 1.25) + 
  ylim(c(-.2, .2)) + 
  guides(color = FALSE) + 
  ggtitle("Weighted basis functions") + 
  labs(y = NULL) +
  theme_grey(base_size = 9)  + 
  theme(
    plot.background = element_rect(fill = "#eef7fa", colour = "#eef7fa"),
    panel.background = element_rect(fill = "#E5EAEF"))

p2_poly <- ggplot(poly_weighted) + 
  aes(x = Time, y = value) + 
  geom_line(aes(color = factor(degree))) + 
  stat_summary(fun.y = sum, color = "#0074D9", geom = "line", size = 1.25) + 
  ylim(c(-.2, .2)) + 
  guides(color = FALSE) + 
  ggtitle("Weighted basis functions") + 
  labs(y = NULL) +
  theme_grey(base_size = 9) 

p3 <- cowplot::plot_grid(p1, p2)
p3_poly <- cowplot::plot_grid(p1_poly, p2_poly)
print(p3)
# ggsave("./misc/basis-raw.png", p1,  width = 3, height = 3)
# ggsave("./misc/basis-weighted.png", p2, width = 3, height = 3)
# cowplot::ggsave("./misc/basis-both.png", p3, width = 6, height = 3)
# cowplot::ggsave("./misc/basis-both.png", p3, width = 6, height = 3)
```

Each of these basis functions is weighted by a model coefficient, but
the individual basis functions are not a priori meaningful. Rather, it
is the whole set of functions that approximate the curvature of the
data---i.e., *f*(Time))---so we statistically evaluate the whole batch
of coefficients simultaneously. This joint testing is similar to how one
might test a batch of effects in an ANOVA. If the batch of effects
jointly improve model fit, we infer that there is a significant smooth
or shape effect.

Smooth terms come with an estimated degrees of freedom (EDF). These
values provide a sense of how many degrees of freedom the smooth
consumed. An EDF of 1 is a perfectly straight line, indicating no
smoothing. Higher EDF values indicate that the smooth term captured more
curvature from the data.

<!-- The other important thing to know about generalized additive models is that -->
<!-- wigglyness is penalized. With so many functions, one might worry about -->
<!-- overfitting the data and including incidental wiggliness into *f*(Time). These -->
<!-- models, however, include a smoothing parameter that -->
</div>
\End{infobox}




The model included main effects of study year. These *parametric* terms
work like conventional regression effects and determined the growth
curve's average values. The model used age 4 as the reference year, so
the model's intercept represented the average looking probability at
age 4. The model's year effects therefore represented differences
between age 4 vs. age 3 and age 4 vs. age 5.

The model also included *smooth* terms to represent the time course of
the data. As with the parametric effects, age 4 served as the reference
year. The model estimated a smooth for age 4 and it estimated
*difference smooths* to capture how the curvature at age 3 and age 5
differed from the age 4 curvature. Each of these study-level smooths
used 10 knots (9 basis functions). I also included child-level *random
smooths* to represent child-level variation in growth curve shapes.
Because there is much as less data at the child level than at the study
level, these random smooths only included 5 knots (4 basis functions).
We can think of these simpler splines as coarse adjustments in growth
curve shape to capture child-level variation from limited data.
Altogether, the model contained the following terms:

`r insert_html_math()`
\begin{align*}
   \text{emp. log-odds}(\mathit{phonological\ vs.\ unrelated}) =\    
   & \alpha + \beta_1\text{Age3} + \beta_2\text{Age5} +\ &\text{[growth curve averages]} \\
   & f_1(\text{Time}, \text{Age4})\ +                    &\text{[reference smooth]} \\ 
   & f_2(\text{Time}, \text{Age4} - \text{Age3})\ +      &\text{[difference smooths]} \\ 
   & f_3(\text{Time}, \text{Age4} - \text{Age5})\ +      & \\ 
   & f_i(\text{Time}, \text{Child}_i)                    &\text{[by-child random smooths]} \\
\end{align*}
`r insert_html_math()`

```{r, echo = FALSE}
# prints p-value in markdown as "*p* < .001" or "*p* = [whatever]" 
format_p_value <- function(p, digits = 3) {
  formatted <- printy::fmt_p_value(p, digits)
  less_than <- stringr::str_detect(formatted, "<")
  if (less_than) {
    paste0("*p*&nbsp;", formatted)
  } else {
    paste0("*p*&nbsp;= ", formatted)
  }
}

b2r_summary <- summary.gam(b2r)

para <- b2r_summary$p.table %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column("term") %>% 
  rename(estimate = Estimate, p.value = `Pr(>|t|)`)

tp2 <- para %>% 
  filter(term == "(Intercept)") %>% 
  pull(estimate) %>% 
  printy::fmt_fix_digits(2)

tp2_prop <- para %>% 
  filter(term == "(Intercept)") %>% 
  pull(estimate) %>% 
  plogis() %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero() 

tp1_p <- para %>% 
  filter(term == "S2TimePoint1") %>% 
  pull(p.value) %>% 
  format_p_value(digits = 2)

tp2_est <- para %>% 
  filter(term == "(Intercept)") %>% 
  pull(estimate) 

tp3_est <- para %>% 
  filter(term == "S2TimePoint3") %>% 
  pull(estimate) 

tp3_prop <- (tp2_est + tp3_est) %>% 
  plogis() %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero() 

tp3 <- (tp2_est + tp3_est) %>% 
  printy::fmt_fix_digits(2)

tp3_p <- para %>% 
  filter(term == "S2TimePoint3") %>% 
  pull(p.value) %>% 
  format_p_value()


# itsadug::report_stats(b2r, b2r_summary)
smooths <- b2r_summary$s.table %>% 
  as.data.frame() %>% 
  setNames(c("edf", "Ref.df", "F", "p.value")) %>% 
  tibble::rownames_to_column("term")

s_tp2_p <- smooths %>% 
  filter(term == "s(Time)") %>% 
  pull(p.value) %>% 
  format_p_value()

s_tp2_edf <- smooths %>% 
  filter(term == "s(Time)") %>% 
  pull(edf) %>% 
  printy::fmt_fix_digits(2)

s_tp1_edf <- smooths %>% 
  filter(term == "s(Time):S2TimePoint1") %>% 
  pull(edf) %>% 
  printy::fmt_fix_digits(2)

s_tp1_p <- smooths %>% 
  filter(term == "s(Time):S2TimePoint1") %>% 
  pull(p.value) %>% 
  format_p_value()

s_tp3_edf <- smooths %>% 
  filter(term == "s(Time):S2TimePoint3") %>% 
  pull(edf) %>% 
  printy::fmt_fix_digits(2)

s_tp3_p <- smooths %>% 
  filter(term == "s(Time):S2TimePoint3") %>% 
  pull(p.value) %>% 
  format_p_value()
```

The model’s fitted values are shown in
Figure \@ref(fig:phon-vs-unre-fits). These are the average empirical
log-odds of fixating on the phonological foil versus the unrelated image
for each year of the study. The model captured the trend for increased
looks to the competitor image with each year of the study. At age 4 and
age 5, the shape rises from a baseline to the peak around 800 ms. These
curves slope downwards and eventually fall beneath the initial baseline.
The shape at age 3 does not have a steady rise from baseline and shows a
very small peak around 800 ms.

(ref:phon-vs-unre-fits) With each year of the study, children looked
more to the phonological foil, relative to unrelated image, during and
after the target noun. the target noun. Both figures show means for each
year estimated by the generalized additive model. The left compares
model estimates to observed means and standard errors, and the right
visualizes estimated means and their 95% confidence intervals.

```{r phon-vs-unre-fits, fig.cap = "(ref:phon-vs-unre-fits)", echo = FALSE, warning = FALSE, message = FALSE, out.width = "80%", fig.width = 6, fig.height = 4, results = "hide"}
# phon_d$fitted_elogit <- predict.gam(b2r)

avg <- b2r %>% 
  get_predictions(
    cond = list(
      Time = unique(phon_d$Time), 
      S2 = unique(phon_d$S2)),
    rm.ranef = TRUE) %>% 
  left_join(recode_studies, by = c("S2")) 

p1 <- phon_d %>% 
  left_join(recode_studies, by = c("Study", "S", "S2")) %>% 
  ggplot() +
    aes(x = Time, y = fitted_elogit, color = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    stat_summary(aes(y = elog), alpha = .7) +
    geom_line(aes(y = fit), data = avg, size = 1) + 
    # stat_summary(fun.y = "mean", geom = "line", size = 1) +
    coord_cartesian(ylim = c(-.35, .85)) +
    labs(
      x = "Time after target onset [ms]",
      y = "Emp. log-odds(Phon. vs. Unrelated)",
      caption = "Lines: Model fits. Points: Obs. means ± SE") +
    theme_grey(base_size = 10) +
    guides(color = FALSE) 

p2 <- b2r %>% 
  get_predictions(
    cond = list(
      Time = unique(phon_d$Time), 
      S2 = unique(phon_d$S2)),
    rm.ranef = TRUE) %>% 
  left_join(recode_studies) %>% 
  ggplot() + 
    aes(x = Time, y = fit, fill = Age) + 
    geom_hline(size = 2, yintercept = 0, color = "white") +
    geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
    geom_line(aes(color = Age), size = 1) + 
    coord_cartesian(ylim = c(-.35, .85)) +
    labs(
      color = "Study",
      fill = "Study",
      x = "Time after target onset [ms]",
      y = NULL,
      caption = "Fitted means with 95% interval") + 
    theme_grey(base_size = 10) + 
    theme(
      legend.position = c(0.975, 0.975), 
      legend.justification = c(1, 1)) 

p3 <- cowplot::plot_grid(p1, p2)
print(p3)
```

The average looks to the phonological foil over the unrelated for age 4
was `r tp2` emp. log-odds, `r tp2_prop` proportion units. The averages
for age 3 and age 4 did not significantly differ, `r tp1_p` but the
average value was significantly greater at age 5, `r tp3` emp. log-odds,
`r tp3_prop` proportion units, `r tp3_p`. Visually, this effect shows up
in the almost constant height difference between the age-4 and the age-5
curves.

(ref:phon-diff-curves) Differences in the average looks to the
phonological foil versus the unrelated image between age 4 and the other
ages. Plotted line is estimated difference and the shaded region is
the 95% confidence around that difference. Blue boxes highlight regions
where the 95% interval excludes zero. From age 3 to age 4, children
become more sensitive to the phonological foil during and after the
target noun. The curves for age 3 and age 4 have largely the same shape,
but they steadily diverge over time.

```{r phon-diff-curves, fig.cap = "(ref:phon-diff-curves)", echo = FALSE, message = FALSE, out.width = "80%", fig.width = 5, fig.height = 3, results = "hide"}
age5_age4 <- b2r %>% 
  get_difference(
    comp = list(S2 = c("TimePoint3", "TimePoint2")), 
    cond = list(Time = unique(phon_d$Time)), 
    rm.ranef = TRUE) %>% 
  mutate(comparison = "Age 5 − Age 4")
  
age4_age3 <- b2r %>% 
  get_difference(
    comp = list(S2 = c("TimePoint2", "TimePoint1")), 
    cond = list(Time = unique(phon_d$Time)), 
    rm.ranef = TRUE) %>% 
  mutate(comparison = "Age 4 − Age 3")  

rle_lengths <- function(xs) rle(xs)[["lengths"]]

differences <- bind_rows(age5_age4, age4_age3) %>% 
  rename(fit = difference) %>% 
  mutate(
    upper = fit + CI, 
    lower = fit - CI,
    no_zero = 0 > upper | 0 < lower) %>% 
  group_by(comparison) %>% 
  arrange(comparison, Time) %>% 
  mutate(
    streak = rep(seq_along(rle_lengths(no_zero)), rle_lengths(no_zero))) %>% 
  ungroup()

sig_regions <- differences %>% 
  filter(no_zero) %>% 
  group_by(comparison, streak) %>% 
  summarize(min = min(Time), max = max(Time)) %>% 
  ungroup()

ggplot(differences) + 
  aes(x = Time, y = fit) + 
  geom_hline(size = 2, yintercept = 0, color = "white") +
  geom_vline(
    aes(xintercept = min), data = sig_regions, 
    color = "blue", alpha = .5, linetype = "dashed") +
  geom_vline(
    aes(xintercept = max), data = sig_regions, 
    color = "blue", alpha = .5, linetype = "dashed") +
  geom_segment(
      aes(x = min, xend = max, group = streak), y = -Inf, yend = -Inf,
      data = sig_regions, color = "blue",  alpha = .5, size = 1) + 
  geom_segment(
      aes(x = min, xend = max, group = streak), y = Inf, yend = Inf,
      data = sig_regions, color = "blue",  alpha = .5, size = 1.1) + 
  geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
  geom_line(size = 1) +
  labs(
    color = "Study",
    fill = "Study",
    x = "Time after target onset [ms]",
    y = "Diff. in emp. log-odds (phonological)",
    caption = "Estimated difference with 95% interval") + 
  facet_wrap("comparison")
```

There was a significant smooth term for time at age&nbsp;4, estimated degrees
of freedom (EDF) = `r s_tp2_edf`, `r s_tp2_p`.
Figure \@ref(fig:phon-diff-curves) visualizes how and when the smooths
from other studies differed from the age-4 smooth.

The age-3 and age-4 significantly differed, EDF = `r s_tp1_edf`,
`r s_tp1_p`. In particular, the curves are significantly different
from 500 to 1050 ms. This result confirms that the looks to the
phonological foil increased from age 3 and age 4 during the time window
immediately following presentation of the noun. The similarity between
the phonological foil and the target occurs early in the trial. Given
the 150--300 ms time required to execute an eye movement in response to
speech, the time window for these differences indicates that children
became more sensitive to the phonological similarities between the foil
and the target from age 3 to age 4.

The age-3 and age-4 curves also differed significantly after 1250 ms.
The effect reflects how the looks to phonological foil decreased as the
trial progresses. After an incorrect look to the foil, the children on
average corrected their gaze and looked even less to the phonological
foil. We do not observe this degree of correction during age 3
presumably because children hardly looked to the phonological foil early
on.

The age-4 and age-5 smooths also significantly differed, EDF =
`r s_tp3_edf`, `r s_tp3_p`, although the low EDF values indicates that
the shape of the difference was a flat line. Thus, the difference
between the age-4 and age-5 smooths is driven primarily by the intercept
difference and a linear diverging trend---that is, the distance between
the two grows slightly over time. The same general curvature was
observed for the two studies, reflecting the same general looking
behavior at both time points. Children showed an early increase in looks
to the phonological foil relative to the unrelated image but after
receiving disqualifying information from the rest of the word, the looks
to the phonological foil rapidly decrease. The primary difference
between age-4 and age-5 is that the foil effect becomes more pronounced
at age 5.

Talking points:

  - Children increased their relative looks to the phonological foil with each
    year of the study. Although they looked to the target more quickly and more
    reliably with each of the study, the advantage of the phonological foil over
    the unrelated image increased with each year. Thus, the children became more
    sensitive to the phonological cohort words as they grew older.
  - There is hardly an effect of the phonological foil during timepoint 1. There
    are a few ways to interpret this finding. The first may be artefactual. The
    stimuli were re-recorded at timepoint 2 so the timepoint 1 stimuli were
    somewhat longer on average (around 800 ms at TP1 vs. 550--800ms later on).
    However, with slower stimuli, we would still expect an inflection in looks
    to the foil as children have more time to activate the phonological
    representations to the cohort. In other words, with more time to respond,
    there could plausibly be an even greater effect of early phonological
    information.
  - Alternatively, the children in timepoint 1 may not be using the early
    similarity of words during word recognition. That is, instead of immediate
    incremental activation of lexical cohorts, the children may not be
    activating the cohorts as reliably. This would imply that further study is
    required on the evidence for when young children begin to show immediate
    activation of cohorts.
  - The children at timepoint1 may not be incrementally activating the cohorts.
    The children in timepoint 2 and 3 certainly are.
  - Incremental activation and early commitments to partial information goes up 
    with age.


## Looks to the semantic foil

Next, I asked how children's sensitivity to the semantic foils changed
as they grew older. As in [@RWLPaper], I only examined trials for
which the semantic foil and the noun were part of the same category. For
example, I included trials with *bee*–*fly*, *shirt*–*dress*, and
*spoon*–*pan*, but I excluded trials where the similarity was perceptual
(*sword*–*pen*) or too abstract (*swan*–*bee*). This criterion kept
`r n_semy` of the 24 trials.

```{r semy-models, echo = FALSE, message = FALSE, results = "hide"}
# Base model with no study effect
s2n <- bam(
  elog ~ s(Time), 
  data = semy_d)
# summary(b2n)

# Include intercepts and smooths for studies
s2 <- bam(
  elog ~ S2 + s(Time) + s(Time, by = S2), 
  data = semy_d)
summary(s2)
# plot(s2, pages = 1)

# s2r <- bam(
#   elog ~ S2 + s(Time) + s(Time, by = S2) + s(Time, R, bs = "fs", m = 1, k = 5),
#   data = semy_d)
# summary(s2r)
# plot(s2r, pages = 1)
# readr::write_rds(s2r, "./data/aim1-semy-random-smooths.rds.gz")
s2r <- readr::read_rds("./data/aim1-semy-random-smooths.rds.gz")

# AIC(s2r, s2n, s2)
```

```{r, echo = FALSE}
s2r_summary <- summary.gam(s2r)

sem_para <- s2r_summary$p.table %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column("term") %>% 
  rename(estimate = Estimate, p.value = `Pr(>|t|)`)

sem_tp2 <- sem_para %>% 
  filter(term == "(Intercept)") %>% 
  pull(estimate) %>% 
  printy::fmt_fix_digits(2)

sem_tp2_prop <- sem_para %>% 
  filter(term == "(Intercept)") %>% 
  pull(estimate) %>% 
  plogis() %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero() 

sem_tp2_est <- sem_para %>% 
  filter(term == "(Intercept)") %>% 
  pull(estimate) 

sem_tp1_est <- sem_para %>% 
  filter(term == "S2TimePoint1") %>% 
  pull(estimate) 

sem_tp1_elog <- (sem_tp2_est + sem_tp1_est) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero() 

sem_tp1_prop <- (sem_tp2_est + sem_tp1_est) %>% 
  plogis() %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero() 

sem_tp1_p <- sem_para %>% 
  filter(term == "S2TimePoint1") %>% 
  pull(p.value) %>% 
  format_p_value(digits = 2)

sem_tp3_est <- sem_para %>% 
  filter(term == "S2TimePoint3") %>% 
  pull(estimate) 

sem_tp3_elog <- (sem_tp2_est + sem_tp3_est) %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero() 

sem_tp3_prop <- (sem_tp2_est + sem_tp3_est) %>% 
  plogis() %>% 
  printy::fmt_fix_digits(2) %>% 
  printy::fmt_leading_zero() 

sem_tp3 <- (sem_tp2_est + sem_tp3_est) %>% 
  printy::fmt_fix_digits(2)

sem_tp3_p <- sem_para %>% 
  filter(term == "S2TimePoint3") %>% 
  pull(p.value) %>% 
  format_p_value()


# itsadug::report_stats(b2r, b2r_summary)
sem_smooths <- s2r_summary$s.table %>% 
  as.data.frame() %>% 
  setNames(c("edf", "Ref.df", "F", "p.value")) %>% 
  tibble::rownames_to_column("term")

sem_s_tp2_p <- sem_smooths %>% 
  filter(term == "s(Time)") %>% 
  pull(p.value) %>% 
  format_p_value()

sem_s_tp2_edf <- sem_smooths %>% 
  filter(term == "s(Time)") %>% 
  pull(edf) %>% 
  printy::fmt_fix_digits(2)

sem_s_tp1_edf <- sem_smooths %>% 
  filter(term == "s(Time):S2TimePoint1") %>% 
  pull(edf) %>% 
  printy::fmt_fix_digits(2)

sem_s_tp1_p <- sem_smooths %>% 
  filter(term == "s(Time):S2TimePoint1") %>% 
  pull(p.value) %>% 
  format_p_value()

sem_s_tp3_edf <- sem_smooths %>% 
  filter(term == "s(Time):S2TimePoint3") %>% 
  pull(edf) %>% 
  printy::fmt_fix_digits(2)

sem_s_tp3_p <- sem_smooths %>% 
  filter(term == "s(Time):S2TimePoint3") %>% 
  pull(p.value) %>% 
  format_p_value()
```

The model’s fitted values are shown in Figure \@ref(fig:semy-vs-unre-fits). The
average empirical log-odds of fixating on the semantic foil versus the unrelated
image increased with each year of the study. All three years show the same
general time course of effects: Looks begin to increase from a baseline around
750 ms and peak around 1300 ms. The peaks of the curves increased as children
grew older. The semantic foil shows a clear advantage over the unrelated image
at age 3, which was not the case for the phonological foil at age 3.

(ref:semy-vs-unre-fits) With each year of the study, children looked more to the
semantic foil, relative to the unrelated image, with peak looking occurring after
the target noun. Both figures show means for each year estimated by the
generalized additive model. The left compares model estimates to observed means
and standard errors, and the right visualizes estimated means and their 95%
confidence intervals.

```{r semy-vs-unre-fits, fig.cap = "(ref:semy-vs-unre-fits)", echo = FALSE, warning = FALSE, message = FALSE, out.width = "80%", fig.width = 6, fig.height = 4, results = "hide"}
# semy_d$fitted_elogit <- predict.gam(s2r)

avg <- s2r %>% 
  get_predictions(
    cond = list(
      Time = unique(semy_d$Time), 
      S2 = unique(semy_d$S2)),
    rm.ranef = TRUE) %>% 
  left_join(recode_studies, by = c("S2")) 

p1 <- semy_d %>% 
  left_join(recode_studies, by = c("Study", "S", "S2")) %>% 
  ggplot() +
    aes(x = Time, y = fitted_elogit, color = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    stat_summary(aes(y = elog), alpha = .7) +
    geom_line(aes(y = fit), data = avg, size = 1) + 
    coord_cartesian(ylim = c(-.25, 1.1)) +
    labs(
      color = "Study",
      fill = "Study",
      x = "Time after target onset [ms]",
      y = "Emp. log-odds(Sem. vs. Unrelated)",
      caption = "Lines: Model fits. Points: Obs. means ± SE") +
    theme_grey(base_size = 10) +
    theme(
      legend.position = c(0.025, 0.975), 
      legend.justification = c(0, 1)) 

p2 <- s2r %>% 
  get_predictions(
    cond = list(
      Time = unique(semy_d$Time), 
      S2 = unique(semy_d$S2)),
    rm.ranef = TRUE) %>% 
  left_join(recode_studies) %>% 
  ggplot() + 
    aes(x = Time, y = fit, fill = Age) + 
    geom_hline(size = 2, yintercept = 0, color = "white") +
    geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
    geom_line(aes(color = Age), size = 1) + 
    coord_cartesian(ylim = c(-.25, 1.1)) +
    labs(
      color = "Study",
      fill = "Study",
      x = "Time after target onset [ms]",
      y = NULL,
      caption = "Fitted means with 95% interval") + 
    theme_grey(base_size = 10) + 
    guides(color = FALSE, fill = FALSE) 

p3 <- cowplot::plot_grid(p1, p2)
print(p3)

semy_peaks <- s2r %>% 
  get_predictions(
    cond = list(
      Time = unique(semy_d$Time), 
      S2 = unique(semy_d$S2)),
    rm.ranef = TRUE) %>% 
  group_by(S2) %>% 
  top_n(5, fit) %>% 
  summarise(
    fit = median(fit),
    fit_prop = plogis(fit) %>% 
      printy::fmt_fix_digits(2) %>% 
      printy::fmt_leading_zero()) %>% 
  split(.$S2)
```

The average looks to the semantic foil over the unrelated for age 4 was
`r sem_tp2` emp. log-odds, `r sem_tp2_prop` proportion units. Children looked
significantly less to the semantic foil on average at age 3, `r sem_tp1_elog`
emp. log-odds, `r sem_tp1_prop` proportion units, `r sem_tp1_p`, and they looked
significantly more to the semantic foil at age 5, `r sem_tp3_elog` emp.
log-odds, `r sem_tp3_prop` proportion units, `r sem_tp3_p`. The peaks of the
growth curves, in proportion units, were `r semy_peaks$TimePoint1$fit_prop`at
age 3, `r semy_peaks$TimePoint2$fit_prop` at age 4, and
`r semy_peaks$TimePoint3$fit_prop`.

There was a significant smooth term for time at age 4, estimated degrees
of freedom (EDF) = `r sem_s_tp2_edf`, `r sem_s_tp2_p`.
Figure \@ref(fig:semy-diff-curves) visualizes the time course of the
differences between the smooths from each study.

(ref:semy-diff-curves) Differences in the average looks to the semantic foil
versus the unrelated image between age 4 and the other ages. Plotted line is
estimated difference and the shaded region is the 95% confidence around that
difference. Blue boxes highlight regions where the 95% interval excludes zero.
The flat line on the left reflects how the shape of the growth curves remained
the same from age 3 to age 4 and only differed in average height. From age 4 to
age 5, the lines quickly diverge and the age-5 curve reaches a higher peak
value.

```{r semy-diff-curves, fig.cap = "(ref:semy-diff-curves)", echo = FALSE, message = FALSE, out.width = "80%", fig.width = 5, fig.height = 3, results = "hide"}
age5_age4 <- s2r %>% 
  get_difference(
    comp = list(S2 = c("TimePoint3", "TimePoint2")), 
    cond = list(Time = unique(semy_d$Time)), 
    rm.ranef = TRUE) %>% 
  mutate(comparison = "Age 5 − Age 4")
  
age4_age3 <- s2r %>% 
  get_difference(
    comp = list(S2 = c("TimePoint2", "TimePoint1")), 
    cond = list(Time = unique(semy_d$Time)), 
    rm.ranef = TRUE) %>% 
  mutate(comparison = "Age 4 − Age 3")  

rle_lengths <- function(xs) rle(xs)[["lengths"]]

differences <- bind_rows(age5_age4, age4_age3) %>% 
  rename(fit = difference) %>% 
  mutate(
    upper = fit + CI, 
    lower = fit - CI,
    no_zero = 0 > upper | 0 < lower) %>% 
  group_by(comparison) %>% 
  arrange(comparison, Time) %>% 
  mutate(
    streak = rep(seq_along(rle_lengths(no_zero)), rle_lengths(no_zero))) %>% 
  ungroup()

sig_regions <- differences %>% 
  filter(no_zero) %>% 
  group_by(comparison, streak) %>% 
  summarize(min = min(Time), max = max(Time)) %>% 
  ungroup()

ggplot(differences) + 
  aes(x = Time, y = fit) + 
  geom_hline(size = 2, yintercept = 0, color = "white") +
  geom_vline(
    aes(xintercept = min), data = sig_regions, 
    color = "blue", alpha = .5, linetype = "dashed") +
  geom_vline(
    aes(xintercept = max), data = sig_regions, 
    color = "blue", alpha = .5, linetype = "dashed") +
  geom_segment(
      aes(x = min, xend = max, group = streak), y = -Inf, yend = -Inf,
      data = sig_regions, color = "blue",  alpha = .5, size = 1) + 
  geom_segment(
      aes(x = min, xend = max, group = streak), y = Inf, yend = Inf,
      data = sig_regions, color = "blue",  alpha = .5, size = 1.1) + 
  geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
  geom_line(size = 1) +
  labs(
    x = "Time after target onset [ms]",
    y = "Diff. in emp. log-odds (semantic)",
    caption = "Estimated difference with 95% interval") + 
  facet_wrap("comparison")
```

The shapes of the age-3 and age-4 curves did not significantly differ, EDF =
`r sem_s_tp1_edf`, `r sem_s_tp1_p`. The age-3 curve begins to rise about 100 ms
later, and it reaches a shallower peak value than the age-4 curve. These two
features create a nearly constant height difference between the two curves, and
thus, the two curves show the same overall shape.

The age-4 and age-5 smooths significantly differed, EDF = `r s_tp3_edf`,
`r s_tp3_p`. The differences are greatest after the end of the target noun, in
the window from 750 to 1500 ms. The two curves start from a similar baseline but
quickly diverge as the age-5 curve reaches a higher peak value. After 1500 ms,
the age-5 turns downwards to overlap with the age-4 curve. Thus, children look
more to the semantic foil relative to the unrelated image, but they are also
quicker to correct and look away from it.

**Summary.** Children became more sensitivity to the semantic foil with each
year of the study. Unlike with the phonological foils, the semantic foils
clearly influenced looking patterns at age 3. The semantic foil effect occurs
when we would expect it too: After the end of the target noun, after activation
of the target noun and its neighbors. That the effect of the foil increases each
year indicates that the semantic representations of words have strengthened. 

  - Is inhibition coming online at age 5?
  - If children were just confused between bear/horse, fly/bee, goat/sheep,
    etc., they should be confused more at younger ages when they know much less
    about the world. So if it were confusion or guess, the semantic foil should
    be stronger at age 3. But they are also slower at word recognition in
    general at younger ages, so maybe these things cancel each other out?








## Individual differences in competitor sensitivity

I asked whether children differed reliably in their sensitivity to the
phonological and semantic foils based on speech perception and
vocabulary measures.

As a measure of speech perception, I used scores from a minimal
discrimination task administered during the first year of the study.
[citations] The task is essentially an ABX discrimination task: A
picture of a familar object is shown and labeled (e.g., "car"), another
object is shown and labeled ("jar"), and then both images are shown and
one of the two is named. The child then indicated which word they heard
by tapping on the image on a touch-screen. 

I derived speech perception by fitting a hierarchical item-response
model. This logistic-regression model estimates the probability of child
*i* correctly choosing word *j* on word-pair *k*. See equation below for
term-by-term description of the model. The model's intercept term
represents the average participant's probability of correctly answering
for an average item. By-child random intercepts capture a child's
deviation from the overall average, so they estimate the child's
*ability*. By-word and by-word-in-pair random intercepts capture the
relative difficulty of particular items on the experiment. The
by-word-in-pair effects were necessary because four words appeared in
more than one word pair (e.g., *juice*--*goose* and *juice*--*moose*).
The model also controlled for the children's ages and receptive
vocabulary scores (PPVT-4 growth scale values). These predictors were
transformed to have mean 0 and standard deviation 1, so the the model's
intercept reflected a child with average age and average vocabulary. The
by-child intercepts therefore reflect a child's ability after
controlling for age and receptive vocabulary.

`r insert_html_math()`
\begin{align*}
   \text{log-odds}(\mathit{choosing\ correct\ word}) =\    
   & \alpha\ +                  &\text{[average participant ability]} \\
   & \alpha_i\ +                &\text{[difference of participant}\ i
                                       \text{'s ability from average]} \\ 
   & \alpha_j\ +                &\text{[word}\ j\text{'s difficulty]} \\
   & \alpha_{j,k}\ +            &\text{[word}\ j
                                       \text{'s difficulty in word-pair}\ k] \\
   & \beta_{1}\text{Age}\ +     &\text{[participant-level predictors]} \\ 
   & \beta_{2}\text{Vocabulary} & \\
\end{align*}
`r insert_html_math()`

I tested whether phonemic discrimination ability at age-3 predicted
looks to the phonological foil over the unrelated image by modifying the
generalized additive model from earlier. In particular, I included a
smooth term for the phonemic discrimination ability score and a "smooth
interaction" between the smooth of time and phonemic ability. These
smooth interaction terms are analogous to interaction terms in linear
models. In this case, the interaction term allows the ability score to
change the shape of the time trend. The model was therefore:

$$
\begin{align*}
   \text{emp. log-odds}(\mathit{phonological\ vs.\ unrelated}) =\    
   & \alpha +\ &\text{[growth curve average]} \\
   & f_1(\text{Time})\ +                    &\text{[time smooth]} \\ 
   & f_2(\text{Ability})\ +                 &\text{[ability smooth]} \\ 
   & f_3(\text{Time} * \text{Ability})\ +   &\text{[interaction smooth]} \\
   & f_i(\text{Time}, \text{Child}_i)       &\text{[by-child random smooths]} \\
\end{align*}
$$

```{r fit-phon-minp-model}
ppvt <- readr::read_csv(file = "./data-raw/test_scores.csv") %>% 
  filter(Study == "TimePoint1") %>% 
  select(ResearchID, PPVT_Age, PPVT_GSV, EVT_Age, PPVT_GSV) 

minp <- readr::read_csv(file = "./data-raw/age3-minpair-fits.csv") %>% 
  filter(Model == "base + age + ppvt") %>% 
  left_join(ppvt) %>% 
  mutate(PPVT_Age = ifelse(is.na(PPVT_Age), MinPair_Age, PPVT_Age))

minp <- minp %>% 
  modelr::add_residuals(
    model = lm(PPVT_GSV ~ PPVT_Age + fitted, .),
    var = "PPVT_GSV_Adj")

# ggplot(minp) + 
#   aes(x = coef, y = PPVT_GSV) + 
#   geom_point()
# 
# ggplot(minp) + 
#   aes(x = fitted, y = PPVT_GSV_Adj) + 
#   geom_point()

phon_d_minp <- phon_d %>% 
  filter(S == "TimePoint1") %>% 
  inner_join(minp, by = "ResearchID") %>% 
  mutate(
    ability = as.vector(scale(coef)), 
    ppvt = as.vector(scale(PPVT_GSV_Adj)))

b2_age3 <- bam(
  elog ~ s(Time) + s(Time, R, bs = "fs", m = 1, k = 5),
  data = phon_d_minp)
summary(b2_age3)
# plot(b2_age3, pages = 1)

b2_age3_minp <- bam(
  elog ~ s(Time) + 
    s(ability) + 
    ti(Time, ability) + 
    s(Time, R, bs = "fs", m = 1, k = 5),
  data = phon_d_minp)



summary(b2_age3_ppvt)

plot(b2_age3_ppvt, pages = 1, scale = FALSE)
# compareML(b2_age3, b2_age3_ppvt)




n_phon_minp <- phon_d_minp %>% pull(ResearchID) %>% unique() %>% length()
# summary(b2_age3_minp)
# # plot(b2_age3_minp, pages = 1, scale = FALSE)
# b2_age3_minp


# anova(b2_age3, b2_age3_minp)
# AIC(b2_age3, b2_age3_minp)
comparison <- compareML(b2_age3, b2_age3_minp, print.output = FALSE)

format_chi_squared <- function(comparison) {
  comp_df <- levels(comparison$table$Df)[2] %>% 
    as.numeric() %>% 
    round(2)
  
  comp_diff <- levels(comparison$table$Difference)[2] %>% 
    as.numeric() %>% 
    round(2)
  
  comp_p <- levels(comparison$table$p.value)[2] %>% 
    as.numeric() %>% 
    format_p_value()
  
  sprintf("_&chi;_<sup>2</sup>(%s)&nbsp;= %s, %s", 
          comp_df, comp_diff, comp_p)
}

chi_phon <- format_chi_squared(comparison)
# compareML(b2_age3, b2_age3_minp,  suggest.report = TRUE)
# plot(b2_age3_minp, pages = 1)
# summary(b2_age3_minp)
```

The model included data from `r n_phon_minp` participants; these were
children with eyetracking data, receptive vocabulary and phonological
discrimination data age 3. There was not a significant smooth effect for
phonological discrimination ability, [edf], [p]. The interaction
smooth between time and ability was significant, [edf], [p]. Model
comparison between the model and a reduced model (without the Ability
and Ability × Time effects) supported inclusion of the predictor,
`r chi_phon`.

To examine the contribution of the interaction term, I visualized
model-predicted growth curves for an average participant at different
phonological ability scores. Figure X shows how looks to phonological
foil apparently increased with discrimination ability. The left panel
shows how early looking to the phonological foil become more pronounced
as phonological discrimination increases. This nonlinear interaction,
however, becomes more unstable at extreme values. In particular,
children with very low phonological discrimination abilities (2 SD below
average) showed roughly the same estimated growth curves as children
with above average (+1 SD) discrimination scores. For the middle 68% of
children, we observe a sensible and interpretable effect, but this
effect term is poorly behaved at very low abilities scores. In
particular, children with low phonemic discrimination are predicted to
be especially sensitive to the phonological foil. Such a finding
contradicts my prior expectation that phonological discrimination would
be related to processing of word onsets, so I interpret as a modeling
artefact. A conservative conclusion from this model would be that
differences in phonological discrimination predicted early looks to the
phonological foil, but the direction of this effect was not consistent
at low ability scores.

```{r}
smooth_times <- modelr::seq_range(unique(phon_d_minp$Time), 100)
pp <- get_predictions(
  b2_age3_minp, 
  cond = list(
    ability = c(-2, -1, 0, 1, 2),
    Time = smooth_times), 
  rm.ranef = TRUE) 

pp %>% 
  mutate(
    panel = ifelse(ability %in% c(-2, 2), "Very low or very high", "Typical"),
    ability = factor(
      ability, labels = c("-2 SD", "-1 SD", "Mean", "+1 SD", "+2 SD"))) %>% 
  ggplot() + 
    aes(x = Time, y = fit, color = ability, fill = ability) + 
    geom_hline(yintercept = 0, size = 2, color = "white") +
    geom_line() + 
    labs(color = "Phonological\ndiscrimination") + 
  facet_wrap("panel")
```


```{r}
b2_age3_ppvt <- bam(
  elog ~ s(Time) + 
    s(ppvt) + 
    ti(Time, ppvt) + 
    s(Time, R, bs = "fs", m = 1, k = 5),
  data = phon_d_minp)
summary(b2_age3_ppvt)

# b2_age3_ppvt_0 <- bam(
#   elog ~ ppvt + s(Time) + s(Time, R, bs = "fs", m = 1, k = 5),
#   data = phon_d_minp)
# summary(b2_age3_ppvt_0)
# 
# b2_age3_ppvt_1 <- bam(
#   elog ~ ability + s(Time) + s(Time, R, bs = "fs", m = 1, k = 5),
#   data = phon_d_minp)
# summary(b2_age3_ppvt_1)

# b2_age3_minp_a -> b2_age3_minp
```

To test the role of receptive vocabulary, I also fit analogous models
using growth scale value scores from the PPVT-4, a receptive vocabulary
test. I first adjusted these scores in a regression model to control
for--that is, partial out the effects of---age and predicted accuracy on
the phonological discrimination task.




```{r, eval = FALSE, out.width = "100%", echo = FALSE}

  
plot_error(pp$Time, pp$fit, pp$CI, shade=TRUE, xpd=TRUE)


ggplot(phon_d_minp) + aes(x = ability) + geom_histogram()

predict
plot_smooth(b2_age3_minp, view="Time", cond=list(coef=c(-1,0,1)), rm.ranef=TRUE)

predict(b2_age3_minp, )

phon_d %>% 
  filter(Focus == "PhonologicalFoil") %>% 
  left_join(minp) %>% 
  ggplot() + 
    aes(x = Time, y = plogis(empirical_logit(PhonologicalFoil, Unrelated))) + 
    geom_line(aes(group = ResearchID), alpha = .2) +
    stat_smooth(aes(color = MinP), se = FALSE) +
    facet_grid(. ~ Study)  + 
    ggtitle("To phon foil by minimal pairs")


# ggplot(phon_d %>% filter(Focus == "PhonologicalFoil")) + 
#   aes(x = Time, y = empirical_logit(PhonologicalFoil, Unrelated)) + 
#   geom_line(aes(group = ResearchID), alpha = .2) + 
#   stat_smooth() +
#   facet_grid(. ~ Study)
# 
# ggplot(phon_d %>% filter(Focus == "PhonologicalFoil")) + 
#   aes(x = Time, y = empirical_logit(PhonologicalFoil, Unrelated)) + 
#   geom_line(aes(group = interaction(ResearchID, Study)), alpha = .2) + 
#   stat_smooth(aes(color = Study)) 
# 
# phon_d %>%
#   filter(Focus == "PhonologicalFoil") %>% 
#   sample_n_of(9, ResearchID) %>%
#   ggplot() + 
#     aes(x = Time, y = empirical_logit(PhonologicalFoil, Unrelated)) + 
#     geom_line(aes(group = interaction(ResearchID, Study)), alpha = .2) + 
#     stat_smooth(aes(color = Study)) +
#   facet_wrap("ResearchID")
# 
minp1 <- readr::read_csv("./data-raw/test_scores.csv") %>% 
  select(Study, ResearchID, MinPair_ProportionCorrect) %>% 
  filter(Study == "TimePoint1") %>% 
  mutate(
    MinP = ntile(MinPair_ProportionCorrect, 4),
    Cut = cut(MinPair_ProportionCorrect, c(0, .6, .8, 1))) %>% 
  select(-Study)

# table(minp1$Cut)
 
phon_d %>% 
  filter(Focus == "PhonologicalFoil") %>% 
  left_join(minp1) %>% 
  ggplot() + 
    aes(x = Time, y = plogis(empirical_logit(PhonologicalFoil, Unrelated))) + 
    geom_line(aes(group = ResearchID), alpha = .2) +
    stat_smooth(aes(color = Cut), se = FALSE) +
    facet_grid(. ~ Study)  + 
    ggtitle("To phon foil by minimal pairs")

phon_d %>% 
  filter(Focus == "Target") %>% 
  left_join(minp1) %>% 
  ggplot() + 
    aes(x = Time, y = Prop) + 
    geom_line(aes(group = ResearchID), alpha = .2) +
    stat_smooth(aes(color = Cut), se = FALSE) +
    facet_grid(. ~ Study) + 
   ggtitle("Prop to target by minimal pairs")

# phon_d %>% 
#   filter(Focus == "Target") %>% 
#   left_join(minp1) %>% 
#   ggplot() + 
#     aes(x = Time, y = plogis(empirical_logit(Target, Unrelated))) + 
#     geom_line(aes(group = ResearchID), alpha = .2) +
#     stat_smooth(aes(color = Cut), se = FALSE) +
#     facet_grid(. ~ Study)

# phon_d %>% 
#   filter(Focus == "PhonologicalFoil") %>% 
#   left_join(minp1) %>% 
#   ggplot() + 
#     aes(x = Time) + 
#     # geom_line(aes(group = ResearchID), alpha = .2) +
#     stat_smooth(
#       aes(color = Cut, y = plogis(empirical_logit(Target, PhonologicalFoil))), 
#       se = FALSE) +
#     stat_smooth(
#       aes(color = Cut, y = plogis(empirical_logit(Target, Unrelated))), 
#       se = FALSE, linetype = "dashed") +
#     facet_grid(Cut ~ Study)

# phon_d %>% 
#   filter(Focus == "Target") %>% 
#   left_join(minp1) %>% 
#   ggplot() + 
#     aes(x = Time, y = Prop) + 
#     geom_line(aes(group = ResearchID), alpha = .2) +
#     stat_smooth(aes(color = Cut), se = FALSE) +
#     facet_grid(. ~ Study)


evt1 <- readr::read_csv("./data-raw/test_scores.csv") %>% 
  select(Study, ResearchID, EVT_Standard) %>% 
  filter(Study == "TimePoint1") %>% 
  mutate(EVT = ntile(EVT_Standard, 4)) %>% 
  select(-Study)

# gfta1 <- readr::read_csv("./data-raw/scores_for_participant_summary.csv") %>% 
#   select(Study, ResearchID, GFTA_Standard) %>% 
#   filter(Study == "TimePoint1") %>% 
#   mutate(GFTA = ntile(GFTA_Standard, 4)) %>% 
#   select(-Study)


phon_d %>% 
  filter(Focus == "PhonologicalFoil") %>% 
  left_join(evt1) %>% 
  ggplot() + 
    aes(x = Time, y = empirical_logit(PhonologicalFoil, Unrelated)) + 
    geom_line(aes(group = ResearchID), alpha = .2) + 
    stat_smooth(aes(color = factor(EVT)), se = FALSE) +
    facet_grid(. ~ Study)

# phon_d %>% 
#   filter(Focus == "PhonologicalFoil") %>% 
#   left_join(gfta1) %>% 
#   ggplot() + 
#     aes(x = Time, y = empirical_logit(PhonologicalFoil, Unrelated)) + 
#     geom_line(aes(group = ResearchID), alpha = .2) + 
#     stat_smooth(aes(color = factor(GFTA)), se = FALSE) +
#     facet_grid(. ~ Study)



semy_d %>% 
  filter(Focus == "SemanticFoil") %>% 
  left_join(evt1) %>% 
  ggplot() + 
    aes(x = Time, y = empirical_logit(SemanticFoil, Unrelated)) + 
    geom_line(aes(group = ResearchID), alpha = .2) + 
    stat_smooth(aes(color = factor(EVT)), se = FALSE) +
    facet_grid(. ~ Study)

semy_d %>% 
  filter(Focus == "SemanticFoil") %>% 
  left_join(minp1) %>% 
  ggplot() + 
    aes(x = Time, y = empirical_logit(SemanticFoil, Unrelated)) + 
    geom_line(aes(group = ResearchID), alpha = .2) + 
    stat_smooth(aes(color = Cut), se = FALSE) +
    facet_grid(. ~ Study)

# m <- glmer(
#   cbind(PhonologicalFoil, Unrelated) ~ 
#     (ot1 + ot2 + ot3) * Study + 
#     (ot1 + ot2 + ot3 | ResearchID), 
#   family = binomial,
#   data = d_m)
# summary(m)
```





<!-- What's going on here: -->

<!--   - The weak phonological foils are indeed weaker than the strong foils. -->
<!--   - The strong semantic foils appear stronger than the weak ones. The -->
<!--     strong foils show a growth curve pattern of increasing looks away -->
<!--     from baseline and there a developmental difference among the growth -->
<!--     curves for each time point. -->
<!--   - Children have a lower advantage for the target (vs unrelated) in -->
<!--     weak foil trials because... why? My reading is that if the semantic -->
<!--     or phonological foil is effective, children will look at it instead -->
<!--     of the unrelated image. Conversely, if the semantic or phonological -->
<!--     foil are less effective, children will look more to the unrelated -->
<!--     image, which pulls down the ratio of looks to target versus the -->
<!--     unrelated image. -->


```{r by-aoi-logit, out.width = "100%", fig.height = 2.5, fig.width = 6, echo = FALSE, message = FALSE, eval = FALSE}
# ggplot(looks_by_aoi %>% filter(AOI != "Unrelated")) + 
#   aes(x = Time, y = log(Primary / Unrelated), color = Study) + 
#   geom_hline(size = 2, color = "white", yintercept = 0) +
#   stat_smooth(method = "gam", formula = y ~ s(x)) + 
#   facet_grid( ~ AOI) + 
#   labs(
#     x = "Time after target onset [ms]",
#     y = "Log odds looking to word vs. unrelated word",
#     caption = "GAM smooth") +
#   theme_grey(base_size = 9) +
#   theme(
#     legend.position = c(0.95, 0.95), 
#     legend.justification = c(1, 1))
```


<!-- Each curve is the log odds of looking to the target, phonological foil, and -->
<!-- semantic foil versus the unrelated word. Positive values mean more looks to an -->
<!-- image type than the unrelated. If you think of the _y_ axis as the image's -->
<!-- _relatedness_ to the target, you can see a time course of relatedness in each -->
<!-- panel: Here early phonological effects meaning early relatedness and later, -->
<!-- flatter semantic effects meaning late relatedness. (These effects make even more -->
<!-- sense sense if phonological representations affect processing before semantic -->
<!-- ones.) -->

<!-- This plot suggests an important finding: Children becoming more sensitive to the -->
<!-- phonological and semantic foils as they grow older. (I use the verb *suggest* -->
<!-- because this is still a preliminary, unmodeled finding.) Jan and I had made -->
<!-- opposite predictions about whether this would happen. Her argument, I think, was -->
<!-- that children become better at word recognition by becoming better able to -->
<!-- inhibit interference from competing words. This plot would suggest that they -->
<!-- show increased sensitive to the target and foils words by looking less to the -->
<!-- unrelated word as they age and reapportioning those looks to the other three -->
<!-- lexically relevant words. -->
