Effects of phonological and semantic competitors
=======================================================================

```{r include = FALSE, warning = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
```

```{r helpers, include = FALSE}
```

```{r aim1-gam-load-looks, message = FALSE}
data <- readr::read_csv("./data/aim1-screened.csv.gz")

constants$cap_model_mean_data_mean_se <-
  "Lines: Model fits. Points: Obs. means ± SE"

# How to aggregate looks to the images
resp_def <- create_response_def(
  primary = "Target",
  others = c("PhonologicalFoil", "SemanticFoil", "Unrelated"),
  elsewhere = "tracked",
  missing = NA
)

# Create alternative aggregation rules for the two foils
semy_defs <- cycle_response_def(resp_def) %>%
  purrr::keep(~ .x$primary %in% c("Target", "SemanticFoil"))

phon_defs <- cycle_response_def(resp_def) %>%
  purrr::keep(~ .x$primary %in% c("Target", "PhonologicalFoil"))
```

```{r separate-strong-vs-weak-foils, message = FALSE, echo = FALSE}
# In @RWLPaper, we ignored trials for certain items where we didn't think the
# phonological or semantic similarity was strong enough.

trial_info <- bind_rows(
  readr::read_csv("data-raw/rwl_timepoint1_trials.csv.gz"),
  readr::read_csv("data-raw/rwl_timepoint2_trials.csv.gz"),
  readr::read_csv("data-raw/rwl_timepoint3_trials.csv.gz")) %>%
  select(
    Study,
    TrialID,
    Target = WordTarget,
    PhonologicalFoil = WordPhonologicalFoil,
    SemanticFoil = WordSemanticFoil,
    Unrelated = WordUnrelated)

## There was a block at year one where the wrong unrelated was used.
## See the items with 15 trials each. We will exclude them.
trials_to_drop <- trial_info %>%
  count(Study, Target, PhonologicalFoil, SemanticFoil, Unrelated) %>%
  filter(n <= 15)

words <- trial_info %>%
  distinct(Target, PhonologicalFoil, SemanticFoil, Unrelated) %>%
  anti_join(
    trials_to_drop,
     by = c("Target", "PhonologicalFoil", "SemanticFoil", "Unrelated"))

# aim1_stim$good_phon is a constant defined in helpers.R
phono_foils <- split(words, words$Target %in% aim1_stim$good_phon) %>%
  lapply(arrange, Target) %>%
  setNames(c("weak_foil", "strong_foil"))

# aim1_stim$good_semy is a constant defined in helpers.R
semy_foils <- split(words, words$Target %in% aim1_stim$good_semy) %>%
  lapply(arrange, Target) %>%
  setNames(c("weak_foil", "strong_foil"))

strong_phon_looks <- trial_info %>%
  semi_join(phono_foils$strong_foil) %>%
  inner_join(data) %>%
  mutate(PhonFoil = "Strong")

strong_semy_looks <- trial_info %>%
  semi_join(semy_foils$strong_foil) %>%
  inner_join(data) %>%
  mutate(SemyFoil = "Strong")

n_phon <- phono_foils$strong_foil$Target %>%
  unique() %>%
  length()

n_semy <- semy_foils$strong_foil$Target %>%
  unique() %>%
  length()

# Keeping this commented out code around until it can be ported to an appendix

# phono_foils$strong_foil %>%
#   knitr::kable(caption = "Trials with strong phonological foils.")

# phono_foils$weak_foil %>%
#   knitr::kable(caption = "Trials with weak phonological foils.")

# semy_foils$strong_foil %>%
#   knitr::kable(caption = "Trials with strong semantic foils.")
#
# semy_foils$weak_foil %>%
#   knitr::kable(caption = "Trials with weak semantic foils.")
```

```{r gam-modeling-options, echo = FALSE, results = "hide"}
opts_model <- list(
  bin_width = 3,
  phon_start_time = 0,
  phon_end_time = 1500,
  semy_start_time = 250,
  semy_end_time = 1800)

opts_model$bin_length <- round(opts_model$bin_width * 16.67, -1)
opts_model$semy_longer <- opts_model$semy_end_time - opts_model$phon_end_time
```




Looks to the phonological competitor
------------------------------------------------------------------------

```{r create-phon-data, include = FALSE}
data <- strong_phon_looks %>%
  select(Study, ResearchID, TrialID:GazeByImageAOI) %>%
  assign_bins(bin_width = opts_model$bin_width, Time, TrialID)

# Compute time at center of each bin
bin_times <- data %>%
  distinct(Time, .bin) %>%
  group_by(.bin) %>%
  mutate(BinTime = round(median(Time), -1)) %>%
  ungroup()

# Attach bin times
binned <- data %>%
  left_join(bin_times, by = c("Time", ".bin")) %>%
  ungroup() %>%
  select(-Time) %>%
  rename(Time = BinTime)

d <- binned %>%
  aggregate_looks(phon_defs, Study + ResearchID + Time ~ GazeByImageAOI)

phon_d <- d %>%
  filter(
    opts_model$phon_start_time <= Time,
    Time <= opts_model$phon_end_time) %>%
  rename(Focus = .response_def)

phon_d <- phon_d %>%
  mutate(
    S = factor(Study, c("TimePoint2", "TimePoint1", "TimePoint3")),
    R = as.factor(ResearchID),
    SR = interaction(S, R),
    elog = lookr::empirical_logit(PhonologicalFoil, Unrelated))

# Include intercepts and smooths for studies
phon_d$S2 <- as.ordered(phon_d$S)
contrasts(phon_d$S2) <- "contr.treatment"
contrasts(phon_d$S2)
```

```{r create-semy-data, include = FALSE}
semy_data <- strong_semy_looks %>%
  select(Study, ResearchID, TrialID:GazeByImageAOI) %>%
  assign_bins(bin_width = opts_model$bin_width, Time, TrialID)

# Compute time at center of each bin
bin_times <- semy_data %>%
  distinct(Time, .bin) %>%
  group_by(.bin) %>%
  mutate(BinTime = round(median(Time), -1)) %>%
  ungroup()

# Attach bin times
binned <- semy_data %>%
  left_join(bin_times, by = c("Time", ".bin")) %>%
  ungroup() %>%
  select(-Time) %>%
  rename(Time = BinTime)

semy_d <- binned %>%
  aggregate_looks(semy_defs, Study + ResearchID + Time ~ GazeByImageAOI)

semy_d <- semy_d %>%
  filter(
    opts_model$semy_start_time <= Time,
    Time <= opts_model$semy_end_time) %>%
  rename(Focus = .response_def)

semy_d <- semy_d %>%
  mutate(
    S = factor(Study, c("TimePoint2", "TimePoint1", "TimePoint3")),
    R = as.factor(ResearchID),
    SR = interaction(S, R),
    elog = lookr::empirical_logit(SemanticFoil, Unrelated))

# Include intercepts and smooths for studies
semy_d$S2 <- as.ordered(semy_d$S)
contrasts(semy_d$S2) <- "contr.treatment"
contrasts(semy_d$S2)
```

Next, I asked how children's sensitivity to the phonological foils
changed over developmental time. Following our approach in [@RWLPaper],
I only examined trials for which the phonological foil and the noun
shared the same syllable onset. For example, this criterion included
trials with *dress*–*drum*, *fly*–*flag*, or *horse*–*heart*, but it
excluded trials *kite*–*gift* (feature difference), *bear*–*bread*
(onset difference), and *ring*–*swing* (rimes). I kept `r n_phon` of
the 24 trials.
[Appendix \@ref(vw-experiment-items)](#vw-experiment-items) provides a
complete list of trials used.

The outcome measure for these analyses was the log-odds of fixating on
the phonological foil versus the unrelated image. Because children
looked more to the target word with each year of the study, they
necessarily looked less to the distractors each year. 
Figure \@ref(fig:declining-phon-props) illustrates how the proportions
of looks to the phonological foils declined each year. Therefore, I
examined the effect of the phonological foil in comparison to the
unrelated foil. For example, on the trials where the target is *fly*, we
can study the effect of the phonological foil *flag* by looking at when
and to what to degree the children fixate on *flag* more than the
unrelated image *pen*. If a window of time of shows a consistent
advantage for the phonological foil over the unrelated image, we can
conclude that the children were sensitive to the phonological foil. By
studying the time course of fixations to the phonological foil versus
the unrelated image, we can identify when the phonological foil affected
word recognition most significantly.

As in the previous models, I downsampled the data into
`r opts_model$bin_length`-ms (`r opts_model$bin_width`-frame) bins in
order to smooth the data. I modeled the looks
from `r opts_model$start_time` to `r opts_model$end_time` ms. Lastly, I
aggregated looks by child, study and time.

(ref:declining-phon-props) Because children looked more to the target as
they grew older, they numerically looked less the foils too. This effect
is why I evaluated the phonological and semantic foils by comparing them
against the unrelated image.

```{r declining-phon-props, fig.cap = "(ref:declining-phon-props)", echo = FALSE, message = FALSE, out.width = "60%", fig.width = 5, fig.height = 3.5}
data_labs <- tibble::tribble(
  ~Focus, ~Time, ~Prop, ~Study,
  "Target", 1400, .8, "Age 5",
  "Target", 1400, .7, "Age 4",
  "Target", 1400, .575, "Age 3",
  "PhonologicalFoil", 1180, .04, "Age 5",
  "PhonologicalFoil", 1400, .18, "Age 3",
) %>% 
  mutate(
    Focus = factor(
      Focus, c("Target", "PhonologicalFoil"),
      c("Target", "Phonological foil"))) 
  

phon_d %>%
  mutate(
    Focus = factor(
      Focus, c("Target", "PhonologicalFoil"),
      c("Target", "Phonological foil")),
    Study = convert_study_to_age(Study)) %>%
  ggplot() +
    aes(x = Time, y = Prop, color = Study) +
    geom_hline(yintercept = .25, color = "white", size = 2) +
    stat_summary(fun.y = "mean", geom = "line", size = 1) +
    geom_text(aes(label = Study), data = data_labs, size = 3.5) +
    facet_wrap("Focus") +
    labs(
      x = "Time after target onset [ms]",
      y = "Mean proportion looking to image") +
    theme_grey() +
    guides(color = FALSE)
```

To account for the sparseness of the data, I used the empirical log-odds
(or empirical logit) transformation [@Barr2008]. This transformation
adds .5 to the looking counts. For example, a time-frame with 4 looks to
the phonological foil and 1 look to the unrelated image has a
conventional log-odds of log(4/1) = 1.39 and empirical log-odds of
log(4.5/1.5) = 1.10. This transformation fills in 0 counts, and it
dampens the extremeness of some probabilities that arise in sparse count
data.

```{r load-phon-model, echo = FALSE, message = FALSE, include = FALSE, out.width = "80%", fig.width = 6}
library(mgcv)
library(itsadug)

phon_by_year <- "./data/aim1-phon-random-smooths.rds.gz"

if (file.exists(phon_by_year)) {
  b2r <- readr::read_rds(phon_by_year)
} else {
  b2r <- bam(
    elog ~ S2 +
      s(Time) + s(Time, by = S2) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = phon_d)
  readr::write_rds(b2r, phon_by_year)
}
```

To model these data, I fit a generalized additive model with fast
restricted maximum likelihood estimation [@Wood2017; @Soskuthy2017 for
a tutorial for linguists]. Box 1 provides a brief overview of these
models. I used the mgcv R package [vers. `r packageVersion("mgcv")`;
@Wood2017] with support from the tools in the itsadug R package
[vers. `r packageVersion("itsadug")`; @itsadug].[^gca-fail]

[^gca-fail]: Initially, I tried to use Bayesian polynomial growth
  curve models, as in the earlier analysis of the looks to the target
  image. These models however did not converge, even when strong priors
  were placed on the parameters.





\Begin{infobox}
<div class = "infobox">

**Box 1: The Intuition Behind Generalized Additive Models**.

In these analyses, the outcome of interest is a value that changes over
time in a nonlinear way. We model these time series by building a set of
features to represent time values. In the growth curve analyses of
familiar word recognition, I used a set of polynomial features which
expressed time as the weighted sum of a linear trend, a quadratic trend
and cubic trend. That is:

$$
\text{log-odds}(\mathit{looking}) =
  \alpha + \beta_1 * \textit{Time}^1 +
           \beta_2 * \textit{Time}^2 +
           \beta_3 * \textit{Time}^3
$$

But another way to think about the polynomial terms is as *basis
functions*: A set of features that combine to approximate some nonlinear
function of time. Under this framework, the model can be expressed as:

$$
\text{log-odds}(\mathit{looking}) =
  \alpha + f(\textit{Time})
$$

This is the idea behind generalized additive models and their *smooth
terms*. These smooths fit nonlinear functions of data by weighting and
adding simple functions together. The figures below show 9 basis
functions from a "thin-plate spline" and how they can be weighted and
summed to fit a growth curve.

```{r infobox-1-figs, message = FALSE, echo = FALSE, out.width = "66%", fig.width = 6, fig.height = 3, fig.align = "center"}
t1_fam <- structure(
  list(
    Time = c(
      250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900,
      950, 1000, 1050, 1100, 1150, 1200, 1250, 1300, 1350, 1400, 1450, 1500),
    Prop = c(
      0.252, 0.255, 0.257, 0.261, 0.265, 0.275, 0.286, 0.298, 0.311, 0.315,
      0.329, 0.342, 0.365, 0.392, 0.407, 0.422, 0.446, 0.464, 0.479, 0.497,
      0.514, 0.524, 0.532, 0.545, 0.549, 0.555)),
  .Names = c("Time", "Prop"),
  class = c("tbl_df", "tbl", "data.frame"),
  row.names = c(NA, -26L))

times <- modelr::seq_range(t1_fam$Time, 80)
newdata <- data.frame(Time = times)
t1_gam <- gam(Prop ~ s(Time), data = t1_fam)

t1_gam <- gam(Prop ~ s(Time, bs = "tp", k = 10), data = t1_fam)
basis_matrix <- predict(t1_gam, newdata, type = "lpmatrix")[, 2:10]

basis <- polypoly::poly_melt(basis_matrix) %>%
  mutate(observation = as.numeric(observation)) %>%
  left_join(
    data.frame(Time = times, observation = seq_along(times)),
    by = "observation")

p1 <- ggplot(basis) +
  aes(x = Time, y = value) +
  geom_line(aes(color = degree)) +
  ylim(c(-2, 2)) +
  guides(color = FALSE) +
  ggtitle("Basis functions (time features)") +
  labs(
    x = constants$x_time,
    y = NULL) +
  theme_grey(base_size = 9) +
  theme(
    plot.background = element_rect(
      fill = constants$col_infobox_blue,
      colour = constants$col_infobox_blue),
    panel.background = element_rect(fill = constants$col_infobox_plot_bg))

weighted <- (basis_matrix %*% diag(coef(t1_gam)[-1])) %>%
  polypoly::poly_melt() %>%
  mutate(observation = as.numeric(observation)) %>%
  left_join(
    data.frame(Time = times, observation = seq_along(times)),
    by = "observation")

p2 <- ggplot(weighted) +
  aes(x = Time, y = value) +
  geom_line(aes(color = factor(degree))) +
  stat_summary(
    fun.y = sum,
    color = constants$col_blue_highlight,
    geom = "line",
    size = 1.25) +
  annotate("text",
    label = "sum", 
    x = 1350, 
    y = .175, 
    color = constants$col_blue_highlight,
    size = 3,
    ) +
  ylim(c(-.2, .2)) +
  guides(color = FALSE) +
  ggtitle("Weighted basis functions") +
  labs(
    x = constants$x_time,
    y = NULL) +
  theme_grey(base_size = 9)  +
  theme(
    plot.background = element_rect(
      fill = constants$col_infobox_blue,
      colour = constants$col_infobox_blue),
    panel.background = element_rect(fill = constants$col_infobox_plot_bg))


## Analagous plot for GCA polynomials

# t1_poly <- lm(Prop ~ poly(Time, 3), data = t1_fam)
#
# poly_basis <- polypoly::poly_melt(poly(t1_fam$Time, 3)) %>%
#   mutate(observation = as.numeric(observation)) %>%
#   left_join(
#     data.frame(Time = times, observation = seq_along(times)),
#     by = "observation")

# p1_poly <- ggplot(poly_basis) +
#   aes(x = Time, y = value) +
#   geom_line(aes(color = degree)) +
#   # ylim(c(-2, 2)) +
#   guides(color = FALSE) +
#   ggtitle("Basis functions (time features)") +
#   labs(
#     x = constants$x_time,
#     y = NULL) +
#   theme_grey(base_size = 9)

# poly_weighted <- (poly(t1_fam$Time, 3) %*% diag(coef(t1_poly)[-1])) %>%
#   polypoly::poly_melt() %>%
#   mutate(observation = as.numeric(observation)) %>%
#   left_join(
#     data.frame(Time = times, observation = seq_along(times)),
#     by = "observation")

# p2_poly <- ggplot(poly_weighted) +
#   aes(x = Time, y = value) +
#   geom_line(aes(color = factor(degree))) +
#   stat_summary(
#     fun.y = sum,
#     color = constants$col_blue_highlight,
#     geom = "line",
#     size = 1.25) +
#   ylim(c(-.2, .2)) +
#   guides(color = FALSE) +
#   ggtitle("Weighted basis functions") +
#   labs(
#     x = constants$x_time,
#     y = NULL) +
#   theme_grey(base_size = 9)
#
# p3_poly <- cowplot::plot_grid(p1_poly, p2_poly)

p3 <- cowplot::plot_grid(p1, p2)
print(p3)
# ggsave("./misc/basis-raw.png", p1,  width = 3, height = 3)
# ggsave("./misc/basis-weighted.png", p2, width = 3, height = 3)
# cowplot::ggsave("./misc/basis-both.png", p3, width = 6, height = 3)
# cowplot::ggsave("./misc/basis-both.png", p3, width = 6, height = 3)
```

Each of these basis functions is weighted by a model coefficient, but
the individual basis functions are not a priori meaningful. Rather, it
is the whole set of functions that approximate the curvature of the
data---i.e., *f*(Time))---so we statistically evaluate the whole batch
of coefficients simultaneously. This joint testing is similar to how one
might test a batch of effects in an ANOVA. If the batch of effects
jointly improve model fit, we infer that there is a significant smooth
or shape effect.

Smooth terms come with an estimated degrees of freedom (EDF). These
values provide a sense of how many degrees of freedom the smooth
consumed. An EDF of 1 is a perfectly straight line, indicating no
smoothing. Higher EDF values indicate that the smooth term captured more
curvature from the data.

<!-- The other important thing to know about generalized additive models is that -->
<!-- wigglyness is penalized. With so many functions, one might worry about -->
<!-- overfitting the data and including incidental wiggliness into *f*(Time). These -->
<!-- models, however, include a smoothing parameter that -->
</div>
\End{infobox}




The model included main effects of study year. These *parametric* terms
work like conventional regression effects and determined the growth
curve's average values. The model used age 4 as the reference year, so
the intercept represented the average looking probability at
age 4. The model's year effects therefore represented differences
between age 4 vs. age 3 and age 4 vs. age 5.

The model also included *smooth* terms to represent the time course of
the data. As with the parametric effects, age 4 served as the reference
year. The model estimated a smooth for age 4 and it estimated
*difference smooths* to capture how the curvature at age 3 and age 5
differed from the age-4 curvature. Each of these study-level smooths
used 10 knots (9 basis functions). I also included child-level *random
smooths* to represent child-level variation in growth curve shapes.
Because there is much as less data at the child level than at the study
level, these random smooths only included 5 knots (4 basis functions).
We can think of these simpler splines as coarse adjustments in growth
curve shape to capture child-level variation from limited data.
Altogether, the model contained the following terms:

`r insert_html_math()`
\small
\begin{align*}
   \text{emp. log-odds}(\mathit{phon.\ vs.\ unrelated}) =\
   & \alpha + \beta_1\text{Age3} + \beta_2\text{Age5} +\ &\text{[growth curve averages]} \\
   & f_1(\text{Time}, \text{Age4})\ +                    &\text{[reference smooth]} \\
   & f_2(\text{Time}, \text{Age4} - \text{Age3})\ +      &\text{[difference smooths]} \\
   & f_3(\text{Time}, \text{Age4} - \text{Age5})\ +      & \\
   & f_i(\text{Time}, \text{Child}_i)                    &\text{[by-child random smooths]} \\
\end{align*}
`r insert_html_math()`

```{r stats-from-phon-gamms}
b2r_summary <- summary.gam(b2r)

tp2_est <- get_para_estimate(b2r_summary, "(Intercept)")
tp3_est <- get_para_estimate(b2r_summary, "S2TimePoint3")

tp2 <- tp2_est %>%
  printy::fmt_fix_digits(2)

tp3 <- (tp2_est + tp3_est) %>%
  printy::fmt_fix_digits(2)

tp2_prop <- tp2_est %>%
  plogis() %>%
  printy::fmt_fix_digits(2) %>%
  printy::fmt_leading_zero()

tp3_prop <- (tp2_est + tp3_est) %>%
  plogis() %>%
  printy::fmt_fix_digits(2) %>%
  printy::fmt_leading_zero()

tp1_p <- get_para_pvalue(b2r_summary, "S2TimePoint1", digits = 2)
tp3_p <- get_para_pvalue(b2r_summary, "S2TimePoint3")

# # itsadug::report_stats(b2r, b2r_summary)
# smooths <- b2r_summary$s.table %>%
#   as.data.frame() %>%
#   setNames(c("edf", "Ref.df", "F", "p.value")) %>%
#   tibble::rownames_to_column("term")

s_tp2_edf <- get_smooth_edf(b2r_summary, term = "s(Time)")
s_tp1_edf <- get_smooth_edf(b2r_summary, term = "s(Time):S2TimePoint1")
s_tp3_edf <- get_smooth_edf(b2r_summary, term = "s(Time):S2TimePoint3")

s_tp2_p <- get_smooth_pvalue(b2r_summary, "s(Time)")
s_tp1_p <- get_smooth_pvalue(b2r_summary, "s(Time):S2TimePoint1")
s_tp3_p <- get_smooth_pvalue(b2r_summary, "s(Time):S2TimePoint3")
```

The model’s fitted values are shown in
Figure \@ref(fig:phon-vs-unre-fits). These are the average empirical
log-odds of fixating on the phonological foil versus the unrelated image
for each year of the study. The model captured the trend for increased
looks to the competitor image with each year of the study. At age 4 and
age 5, the shape rises from a baseline to the peak around 800 ms. These
curves slope downwards and eventually fall beneath the initial baseline.
The shape at age 3 does not have a steady rise from baseline and shows a
very small peak around 800 ms.

(ref:phon-vs-unre-fits) With each year of the study, children looked
more to the phonological foil, relative to unrelated image, during and
after the target noun. the target noun. Both figures show means for each
year estimated by the generalized additive model. The left compares
model estimates to observed means and standard errors, and the right
visualizes estimated means and their 95% confidence intervals.

```{r phon-vs-unre-fits, fig.cap = "(ref:phon-vs-unre-fits)", warning = FALSE, message = FALSE, out.width = "80%", fig.width = 6, fig.height = 4, results = "hide"}
avg <- b2r %>%
  get_predictions(
    cond = list(
      Time = unique(phon_d$Time),
      S2 = unique(phon_d$S2)),
    rm.ranef = TRUE,
    print.summary = FALSE) %>%
  left_join(recode_studies, by = c("S2"))

labs_fit_obs <- labs(
  color = constants$lab_study,
  fill = constants$lab_study,
  x = constants$x_time,
  caption = constants$cap_model_mean_data_mean_se)

# Data for direct labeling of lines
study_labs <- data.frame(
  Age = c("Age 3", "Age 4", "Age 5"),
  x = c(775, NA, 750),
  y = c(.17, NA, .78)
)

p1 <- phon_d %>%
  left_join(recode_studies, by = c("Study", "S", "S2")) %>%
  ggplot() +
    aes(x = Time, y = fitted_elogit, color = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    stat_summary(aes(y = elog), fun.data = mean_se, alpha = .7) +
    geom_line(aes(y = fit), data = avg, size = 1) +
    geom_text(aes(label = Age, x = x, y = y), data = study_labs) +
    coord_cartesian(ylim = c(-.35, .85)) +
    labs_fit_obs +
    labs(y = constants$y_elog_phon) +
    guides(color = FALSE)


labs_model_ci <- labs(
  color = constants$lab_study,
  fill = constants$lab_study,
  x = constants$x_time,
  y = NULL,
  caption = constants$cap_mean_95)

p2 <- b2r %>%
  get_predictions(
    cond = list(
      Time = unique(phon_d$Time),
      S2 = unique(phon_d$S2)),
    rm.ranef = TRUE) %>%
  left_join(recode_studies) %>%
  ggplot() +
    aes(x = Time, y = fit, fill = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
    geom_line(aes(color = Age), size = 1) +
    geom_text(aes(label = Age, color = Age, x = x, y = y), data = study_labs) +
    coord_cartesian(ylim = c(-.35, .85)) +
    labs_model_ci +
    guides(color = FALSE, fill = FALSE)

p3 <- cowplot::plot_grid(p1, p2)
print(p3)
```

The average looks to the phonological foil over the unrelated for age 4
was `r tp2` emp. log-odds, `r tp2_prop` proportion units. The averages
for age 3 and age 4 did not significantly differ, `r tp1_p` but the
average value was significantly greater at age 5, `r tp3` emp. log-odds,
`r tp3_prop` proportion units, `r tp3_p`. Visually, this effect shows up
in the almost constant height difference between the age-4 and the age-5
curves.

(ref:phon-diff-curves) Differences in the average looks to the
phonological foil versus the unrelated image between age 4 and the other
ages. Plotted line is estimated difference and the shaded region is
the 95% confidence interval around that difference. Blue boxes highlight
regions where the 95% interval excludes zero. From age 3 to age 4,
children become more sensitive to the phonological foil during and after
the target noun. The curves for age 3 and age 4 have largely the same
shape, but they steadily diverge over time.

```{r phon-diff-curves, fig.cap = "(ref:phon-diff-curves)", message = FALSE, out.width = "80%", fig.width = 5, fig.height = 3, results = "hide"}
age5_age4 <- b2r %>%
  get_difference(
    comp = list(S2 = c("TimePoint3", "TimePoint2")),
    cond = list(Time = unique(phon_d$Time)),
    rm.ranef = TRUE) %>%
  mutate(comparison = "Age 5 − Age 4")

age4_age3 <- b2r %>%
  get_difference(
    comp = list(S2 = c("TimePoint2", "TimePoint1")),
    cond = list(Time = unique(phon_d$Time)),
    rm.ranef = TRUE) %>%
  mutate(comparison = "Age 4 − Age 3")

rle_lengths <- function(xs) rle(xs)[["lengths"]]

differences <- bind_rows(age5_age4, age4_age3) %>%
  rename(fit = difference) %>%
  mutate(
    upper = fit + CI,
    lower = fit - CI,
    no_zero = 0 > upper | 0 < lower) %>%
  group_by(comparison) %>%
  arrange(comparison, Time) %>%
  mutate(
    streak = rep(seq_along(rle_lengths(no_zero)), rle_lengths(no_zero))) %>%
  ungroup()

sig_regions <- differences %>%
  filter(no_zero) %>%
  group_by(comparison, streak) %>%
  summarize(min = min(Time), max = max(Time)) %>%
  ungroup()

ggplot(differences) +
  aes(x = Time, y = fit) +
  geom_hline(size = 2, yintercept = 0, color = "white") +
  geom_vline(
    aes(xintercept = min), data = sig_regions,
    color = constants$col_blue_highlight, linetype = "dashed") +
  geom_vline(
    aes(xintercept = max), data = sig_regions,
    color = constants$col_blue_highlight ,linetype = "dashed") +
  geom_segment(
      aes(x = min, xend = max, group = streak), y = -Inf, yend = -Inf,
      data = sig_regions, color = constants$col_blue_highlight,
      size = 1) +
  geom_segment(
      aes(x = min, xend = max, group = streak), y = Inf, yend = Inf,
      data = sig_regions, color = constants$col_blue_highlight,
      size = 1.1) +
  geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
  geom_line(size = 1) +
  labs(
    color = constants$lab_study,
    fill = constants$lab_study,
    x = constants$x_time,
    y = constants$y_elog_diff_phon,
    caption = constants$cap_diff_95) +
  facet_wrap("comparison")
```

There was a significant smooth term for time at age&nbsp;4, estimated degrees
of freedom (EDF) = `r s_tp2_edf`, `r s_tp2_p`.
Figure \@ref(fig:phon-diff-curves) visualizes how and when the smooths
from other studies differed from the age-4 smooth.

The age-3 and age-4 significantly differed, EDF = `r s_tp1_edf`,
`r s_tp1_p`. In particular, the curves are significantly different
from 500 to 1050 ms. This result confirms that the looks to the
phonological foil increased from age 3 and age 4 during the time window
immediately following presentation of the noun. The similarity between
the phonological foil and the target occurs early in the trial. Given
the 150--300 ms time required to execute an eye movement in response to
speech, the time window for these differences indicates that children
became more sensitive to the phonological similarities between the foil
and the target from age 3 to age 4.

The age-3 and age-4 curves also differed significantly after 1250 ms.
The effect reflects how the looks to phonological foil decreased as the
trial progresses. After an incorrect look to the foil, the children on
average corrected their gaze and looked even less to the phonological
foil. We do not observe this degree of correction during age 3,
presumably because children at age 3 hardly looked to the phonological
foil early on.

The age-4 and age-5 smooths also significantly differed, EDF =
`r s_tp3_edf`, `r s_tp3_p`, although the low EDF values indicates that
the shape of the difference was a flat line. Thus, the difference
between the age-4 and age-5 smooths is driven primarily by the intercept
difference and a linear diverging trend---that is, the distance between
the two grows slightly over time. The same general curvature was
observed for the two studies, reflecting the same general looking
behavior at both time points. Children showed an early increase in looks
to the phonological foil relative to the unrelated image but after
receiving disqualifying information from the rest of the word, the looks
to the phonological foil rapidly decrease. The primary difference
between age-4 and age-5 is that the foil effect becomes more pronounced
at age 5.

**Summary**. Children looked more the phonological competitor than the
unrelated image early in the trials. The advantage of the phonological
competitor peaked on average around 800 ms after target onset. This peak
was very small at age 3 but increased in height with each year of the
study. Thus, children became more sensitive to the phonological cohort
competitors as they grew older.




Looks to the semantic competitor
------------------------------------------------------------------------

I asked how children's sensitivity to the semantic competitor changed
as they grew older. As in [@RWLPaper], I only examined trials for
which the semantic foil and the noun were part of the same category. For
example, I included trials with *bee*–*fly*, *shirt*–*dress*, and
*spoon*–*pan*, but I excluded trials where the similarity was perceptual
(*sword*–*pen*) or too abstract (*swan*–*bee*). This criterion kept
`r n_semy` of the 24 trials.
[Appendix \@ref(vw-experiment-items)](#vw-experiment-items) provides a
complete list of trials used.

For these trials, I used the same modeling technique as the one used for
phonological competitor: Generalized additive models with study effects
and a time smooth, time-by-study difference smooths, and time-by-child
random smooths. I modeled the looks from
from `r opts_model$semy_start_time` to `r opts_model$semy_end_time` ms.
This window was `r opts_model$semy_longer` ms longer than the one used
for the phonological competitors in order to capture late-occurring
semantic effects.

```{r semy-models, message = FALSE, results = "hide"}
semy_by_year <- "./data/aim1-semy-random-smooths.rds.gz"

if (file.exists(semy_by_year)) {
  s2r <- readr::read_rds(semy_by_year)
} else {
  s2r <- bam(
    elog ~ S2 +
      s(Time) + s(Time, by = S2) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = semy_d)
  readr::write_rds(s2r, semy_by_year)
}
```

```{r stats-from-semy-gamms}
s2r_summary <- summary.gam(s2r)

sem_para <- s2r_summary$p.table %>%
  as.data.frame() %>%
  tibble::rownames_to_column("term") %>%
  rename(estimate = Estimate, p.value = `Pr(>|t|)`)

sem_tp2_est <- get_para_estimate(s2r_summary, "(Intercept)")
sem_tp1_est <- get_para_estimate(s2r_summary, "S2TimePoint1")
sem_tp3_est <- get_para_estimate(s2r_summary, "S2TimePoint3")

sem_tp2 <- sem_tp2_est %>%
  printy::fmt_fix_digits(2)

sem_tp2_prop <- sem_tp2_est %>%
  plogis() %>%
  printy::fmt_fix_digits(2) %>%
  printy::fmt_leading_zero()

sem_tp1_elog <- (sem_tp2_est + sem_tp1_est) %>%
  printy::fmt_fix_digits(2)

sem_tp1_prop <- (sem_tp2_est + sem_tp1_est) %>%
  plogis() %>%
  printy::fmt_fix_digits(2) %>%
  printy::fmt_leading_zero()

sem_tp3_elog <- (sem_tp2_est + sem_tp3_est) %>%
  printy::fmt_fix_digits(2)

sem_tp3_prop <- (sem_tp2_est + sem_tp3_est) %>%
  plogis() %>%
  printy::fmt_fix_digits(2) %>%
  printy::fmt_leading_zero()

sem_tp1_p <- get_para_pvalue(s2r_summary, "S2TimePoint1", digits = 3)
sem_tp3_p <- get_para_pvalue(s2r_summary, "S2TimePoint3", digits = 3)


## itsadug::report_stats(b2r, b2r_summary)
# sem_smooths <- s2r_summary$s.table %>%
#   as.data.frame() %>%
#   setNames(c("edf", "Ref.df", "F", "p.value")) %>%
#   tibble::rownames_to_column("term")

sem_s_tp2_edf <- get_smooth_edf(s2r_summary, term = "s(Time)")
sem_s_tp1_edf <- get_smooth_edf(s2r_summary, term = "s(Time):S2TimePoint1")
sem_s_tp3_edf <- get_smooth_edf(s2r_summary, term = "s(Time):S2TimePoint3")

sem_s_tp2_p <- get_smooth_pvalue(s2r_summary, "s(Time)")
sem_s_tp1_p <- get_smooth_pvalue(s2r_summary, "s(Time):S2TimePoint1")
sem_s_tp3_p <- get_smooth_pvalue(s2r_summary, "s(Time):S2TimePoint3")
```

The model’s fitted values are shown in
Figure \@ref(fig:semy-vs-unre-fits). The average empirical log-odds of
fixating on the semantic foil versus the unrelated image increased with
each year of the study. All three years show the same general time
course of effects: Looks begin to increase from a baseline around 750 ms
and peak around 1300 ms. The peaks of the curves increased as children
grew older. The semantic foil shows a clear advantage over the unrelated
image at age 3, which was not the case for the phonological foil at
age 3.

(ref:semy-vs-unre-fits) With each year of the study, children looked
more to the semantic foil, relative to the unrelated image, with peak
looking occurring after the target noun. Both figures show means for
each year estimated by the generalized additive model. The left compares
model estimates to observed means and standard errors, and the right
visualizes estimated means and their 95% confidence intervals.

```{r semy-vs-unre-fits, fig.cap = "(ref:semy-vs-unre-fits)", warning = FALSE, message = FALSE, out.width = "80%", fig.width = 6, fig.height = 4, results = "hide"}
avg <- s2r %>%
  get_predictions(
    cond = list(
      Time = unique(semy_d$Time),
      S2 = unique(semy_d$S2)),
    rm.ranef = TRUE) %>%
  left_join(recode_studies, by = c("S2"))

# Data for direct labeling of lines
study_labs <- data.frame(
  Age = c("Age 3", "Age 4", "Age 5"),
  x = c(1400, NA, 1330),
  y = c(.42, NA, 1.1)
)

p1 <- semy_d %>%
  left_join(recode_studies, by = c("Study", "S", "S2")) %>%
  ggplot() +
    aes(x = Time, y = fitted_elogit, color = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    stat_summary(aes(y = elog), fun.data = mean_se, alpha = .7) +
    geom_line(aes(y = fit), data = avg, size = 1) +
    geom_text(aes(x = x, y = y, label = Age), data = study_labs) +
    coord_cartesian(ylim = c(-.25, 1.1)) +
    guides(color = FALSE) + 
    labs_fit_obs +
    labs(y = constants$y_elog_semy) +
    theme_grey()

p2 <- s2r %>%
  get_predictions(
    cond = list(
      Time = unique(semy_d$Time),
      S2 = unique(semy_d$S2)),
    rm.ranef = TRUE) %>%
  left_join(recode_studies) %>%
  ggplot() +
    aes(x = Time, y = fit, fill = Age) +
    geom_hline(size = 2, yintercept = 0, color = "white") +
    geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
    geom_line(aes(color = Age), size = 1) +
    geom_text(aes(x = x, y = y, color = Age, label = Age), data = study_labs) +
    coord_cartesian(ylim = c(-.25, 1.1)) +
    labs_model_ci +
    theme_grey(base_size = 10) +
    guides(color = FALSE, fill = FALSE)

p3 <- cowplot::plot_grid(p1, p2)
print(p3)

semy_peaks <- s2r %>%
  get_predictions(
    cond = list(
      Time = unique(semy_d$Time),
      S2 = unique(semy_d$S2)),
    rm.ranef = TRUE) %>%
  group_by(S2) %>%
  top_n(5, fit) %>%
  summarise(
    fit = median(fit),
    fit_prop = plogis(fit) %>%
      printy::fmt_fix_digits(2) %>%
      printy::fmt_leading_zero()) %>%
  split(.$S2)
```

The average looks to the semantic foil over the unrelated for age 4 was
`r sem_tp2` emp. log-odds, `r sem_tp2_prop` proportion units. Children
looked significantly less to the semantic foil on average at age 3,
`r sem_tp1_elog` emp. log-odds, `r sem_tp1_prop` proportion units,
`r sem_tp1_p`, and they looked significantly more to the semantic foil
at age 5, `r sem_tp3_elog` emp. log-odds, `r sem_tp3_prop` proportion
units, `r sem_tp3_p`. The peaks of the growth curves, in proportion
units, were `r semy_peaks$TimePoint1$fit_prop` at age 3,
`r semy_peaks$TimePoint2$fit_prop` at age 4, and
`r semy_peaks$TimePoint3$fit_prop` at age 5.

There was a significant smooth term for time at age 4, estimated degrees
of freedom (EDF) = `r sem_s_tp2_edf`, `r sem_s_tp2_p`.
Figure \@ref(fig:semy-diff-curves) visualizes the time course of the
differences between the smooths from each study.

(ref:semy-diff-curves) Differences in the average looks to the semantic
foil versus the unrelated image between age 4 and the other ages.
Plotted line is estimated difference and the shaded region is the 95%
confidence interval around that difference. Blue boxes highlight regions
where the 95% interval excludes zero. The flat line on the left reflects
how the shape of the growth curves remained the same from age 3 to age 4
and only differed in average height. From age 4 to age 5, the lines
quickly diverge and the age-5 curve reaches a higher peak value.

```{r semy-diff-curves, fig.cap = "(ref:semy-diff-curves)", out.width = "80%", fig.width = 5, fig.height = 3}
age5_age4 <- s2r %>%
  get_difference(
    comp = list(S2 = c("TimePoint3", "TimePoint2")),
    cond = list(Time = unique(semy_d$Time)),
    rm.ranef = TRUE,
    print.summary = FALSE) %>%
  mutate(comparison = "Age 5 − Age 4")

age4_age3 <- s2r %>%
  get_difference(
    comp = list(S2 = c("TimePoint2", "TimePoint1")),
    cond = list(Time = unique(semy_d$Time)),
    rm.ranef = TRUE) %>%
  mutate(comparison = "Age 4 − Age 3")

rle_lengths <- function(xs) rle(xs)[["lengths"]]

differences <- bind_rows(age5_age4, age4_age3) %>%
  rename(fit = difference) %>%
  mutate(
    upper = fit + CI,
    lower = fit - CI,
    no_zero = 0 > upper | 0 < lower) %>%
  group_by(comparison) %>%
  arrange(comparison, Time) %>%
  mutate(
    streak = rep(seq_along(rle_lengths(no_zero)), rle_lengths(no_zero))) %>%
  ungroup()

sig_regions <- differences %>%
  filter(no_zero) %>%
  group_by(comparison, streak) %>%
  summarize(min = min(Time), max = max(Time)) %>%
  ungroup()

ggplot(differences) +
  aes(x = Time, y = fit) +
  geom_hline(size = 2, yintercept = 0, color = "white") +
  geom_vline(
    aes(xintercept = min), data = sig_regions,
    color = constants$col_blue_highlight, linetype = "dashed") +
  geom_vline(
    aes(xintercept = max), data = sig_regions,
    color = constants$col_blue_highlight ,linetype = "dashed") +
  geom_segment(
      aes(x = min, xend = max, group = streak), y = -Inf, yend = -Inf,
      data = sig_regions, color = constants$col_blue_highlight,
      size = 1) +
  geom_segment(
      aes(x = min, xend = max, group = streak), y = Inf, yend = Inf,
      data = sig_regions, color = constants$col_blue_highlight,
      size = 1.1) +
  geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI), alpha = .2) +
  geom_line(size = 1) +
  labs(
    color = constants$lab_study,
    fill = constants$lab_study,
    x = constants$x_time,
    y = constants$y_elog_diff_semy,
    caption = constants$cap_diff_95) +
  facet_wrap("comparison")
```

The shapes of the age-3 and age-4 curves did not significantly differ,
EDF = `r sem_s_tp1_edf`, `r sem_s_tp1_p`. The age-3 curve begins to rise
about 100 ms later, and it reaches a shallower peak value than the age-4
curve. These two features create a nearly constant height difference
between the two curves, and thus, the two curves show the same overall
shape.

The age-4 and age-5 smooths significantly differed, EDF = `r s_tp3_edf`,
`r s_tp3_p`. The differences are greatest after the end of the target
noun, in the window from 750 to 1500 ms. The two curves start from a
similar baseline but quickly diverge as the age-5 curve reaches a higher
peak value. After 1500 ms, the age-5 curve turns downwards to overlap
with the age-4 curve. Thus, children looked more to the semantic foil
relative to the unrelated image, but they were also quicker to correct
and look away from it.

**Summary.** Children became more sensitive to the semantic competitor,
compared to the unrelated image, with each year of the study. The
semantic foils clearly influenced looking patterns at age 3, in contrast
to the muted effect observed for the phonological foils. The semantic
effect also occurred when we would expect: After the end of the target
noun, following activation of the target noun and its semantic
neighbors. 




Differences in competitor sensitivity at age 3
------------------------------------------------------------------------

Next, I asked whether children differed reliably in their sensitivity to
the phonological and semantic foils based on speech perception and
vocabulary measures collected at age 3

As a measure of speech perception, I used scores from a minimal pair
discrimination experiment administered during the first year of the
study. [citations] The task is essentially an ABX discrimination task:
A picture of a familiar object is shown and labeled (e.g., "car"),
another object is shown and labeled ("jar"), and then both images are
shown and one of the two is named. The child then indicated which word
they heard by tapping on the image on a touch-screen.

I derived speech perception scores by fitting a hierarchical
item-response model. This logistic regression model estimates the
probability of child *i* correctly choosing word *j* on word-pair *k*.
The equation below provides a term-by-term description of the model. The
model's intercept term represents the average participant's probability
of correctly answering for an average item. By-child random intercepts
capture a child's deviation from the overall average, so they estimate
the child's *ability*. By-word and by-word-in-pair random intercepts
capture the relative difficulty of particular items on the experiment.
The by-word-in-pair effects were necessary because four words appeared
in more than one word pair (e.g., *juice*--*goose* and
*juice*--*moose*). The model also controlled for the children's ages and
receptive vocabulary scores (PPVT-4 growth scale values). These
predictors were transformed to have mean 0 and standard deviation 1, so
the the model's intercept reflected a child of an average age and an
average vocabulary level. Put differently, the by-child intercepts
reflect a child's ability after controlling for age and receptive
vocabulary.

`r insert_html_math()`
\small
\begin{align*}
   \text{log-odds}(\mathit{choosing\ correct\ word}) =\
   & \alpha\ +                  &\text{[average participant ability]} \\
   & \alpha_i\ +                &\text{[difference of participant}\ i
                                       \text{'s ability from average]} \\
   & \alpha_j\ +                &\text{[word}\ j\text{'s difficulty]} \\
   & \alpha_{j,k}\ +            &\text{[word}\ j
                                       \text{'s difficulty in word-pair}\ k] \\
   & \beta_{1}\text{Age}\ +     &\text{[participant-level predictors]} \\
   & \beta_{2}\text{Vocabulary} & \\
\end{align*}
`r insert_html_math()`

I tested whether phonemic discrimination ability at age-3 predicted
looks to the phonological foil over the unrelated image by modifying the
generalized additive model from earlier. In particular, I included a
smooth term for the phonemic discrimination ability score and a "smooth
interaction" between the smooth of time and phonemic ability. These
smooth interaction terms are analogous to interaction terms in linear
models. In this case, the interaction term allows the ability score to
change the shape of the time trend. The additive model was therefore:

`r insert_html_math()`
\small
\begin{align*}
   \text{emp. log-odds}(\mathit{phon.\ vs.\ unrelated}) =\
   & \alpha +\ &\text{[growth curve average]} \\
   & f_1(\text{Time})\ +                    &\text{[time smooth]} \\
   & f_2(\text{Ability})\ +                 &\text{[ability smooth]} \\
   & f_3(\text{Time} * \text{Ability})\ +   &\text{[interaction smooth]} \\
   & f_i(\text{Time}, \text{Child}_i)       &\text{[by-child random smooths]} \\
\end{align*}
`r insert_html_math()`

```{r load-test-scores, include = FALSE}
ppvt <- readr::read_csv(file = "./data-raw/test_scores.csv") %>%
  filter(Study == "TimePoint1") %>%
  select(ResearchID, PPVT_Age, PPVT_GSV, EVT_Age, PPVT_GSV)

minp <- readr::read_csv(file = "./data-raw/age3-minpair-fits.csv") %>%
  filter(Model == "base + age + ppvt") %>%
  left_join(ppvt) %>%
  mutate(PPVT_Age = ifelse(is.na(PPVT_Age), MinPair_Age, PPVT_Age))

minp <- minp %>%
  modelr::add_residuals(
    model = lm(PPVT_GSV ~ PPVT_Age + fitted, .),
    var = "PPVT_GSV_Adj")

phon_d_minp <- phon_d %>%
  filter(S == "TimePoint1") %>%
  inner_join(minp, by = "ResearchID") %>%
  mutate(
    ability = as.vector(scale(coef)),
    ppvt = as.vector(scale(PPVT_GSV_Adj)))

semy_d_minp <- semy_d %>%
  filter(S == "TimePoint1") %>%
  inner_join(minp, by = "ResearchID") %>%
  mutate(
    ability = as.vector(scale(coef)),
    ppvt = as.vector(scale(PPVT_GSV_Adj)))
```

```{r fit-phon-minp-model}
phon_base <- "./data/aim1-phon-gamm-age3-base.rds.gz"
phon_minp <- "./data/aim1-phon-gamm-age3-minp.rds.gz"
phon_ppvt <- "./data/aim1-phon-gamm-age3-ppvt.rds.gz"
phon_ppvt_para <- "./data/aim1-phon-gamm-age3-ppvt-para.rds.gz"

b2_age3 <- if (file.exists(phon_base)) {
  readr::read_rds(phon_base)
} else {
  bam(
    elog ~ s(Time) + s(Time, R, bs = "fs", m = 1, k = 5),
    data = phon_d_minp) %>%
  readr::write_rds(phon_base)
}

b2_age3_minp <- if (file.exists(phon_minp)) {
  readr::read_rds(phon_minp)
} else {
  bam(
    elog ~ s(Time) +
      s(ability) +
      ti(Time, ability) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = phon_d_minp) %>%
  readr::write_rds(phon_minp)
}

b2_age3_ppvt <- if (file.exists(phon_ppvt)) {
  readr::read_rds(phon_ppvt)
} else {
  bam(
    elog ~ s(Time) +
      s(ppvt) +
      ti(Time, ppvt) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = phon_d_minp) %>%
  readr::write_rds(phon_ppvt)
}

b2_age3_ppvt_0 <- if (file.exists(phon_ppvt_para)) {
  readr::read_rds(phon_ppvt_para)
} else {
  bam(
    elog ~ ppvt +
      s(Time) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = phon_d_minp) %>%
  readr::write_rds(phon_ppvt_para)
}

n_phon_minp <- phon_d_minp %>%
  pull(ResearchID) %>%
  unique() %>%
  length()

minp_summary <- summary(b2_age3_minp)
phon_minp_edf <- get_smooth_edf(minp_summary, "s(ability)")
phon_minp_p <- get_smooth_pvalue(minp_summary, "s(ability)")

phon_minp_time_edf <- get_smooth_edf(minp_summary, "ti(Time,ability)")
phon_minp_time_p <- get_smooth_pvalue(minp_summary, "ti(Time,ability)")

ppvt_summary <- summary(b2_age3_ppvt)
phon_ppvt_edf <- get_smooth_edf(ppvt_summary, "s(ppvt)")
phon_ppvt_p <- get_smooth_pvalue(ppvt_summary, "s(ppvt)")

phon_ppvt_time_edf <- get_smooth_edf(ppvt_summary, "ti(Time,ppvt)")
phon_ppvt_time_p <- get_smooth_pvalue(ppvt_summary, "ti(Time,ppvt)")

comparison <- compareML(b2_age3, b2_age3_minp, print.output = FALSE)
chi_phon <- format_chi_squared(comparison)
# compareML(b2_age3, b2_age3_minp,  suggest.report = TRUE)
```

The model included data from `r n_phon_minp` participants; these were
children with eyetracking data, receptive vocabulary and phonological
discrimination data at age 3. There was not a significant smooth effect
for phonological discrimination ability, EDF = `r phon_minp_edf`,
`r phon_minp_p` or for an interaction smooth between time and ability, EDF = `r phon_minp_time_edf`, `r phon_minp_time_p`.

```{r fit-semy-minp-model, echo = FALSE}
semy_base <- "./data/aim1-semy-gamm-age3-base.rds.gz"
semy_ppvt <- "./data/aim1-semy-gamm-age3-ppvt.rds.gz"
semy_minp <- "./data/aim1-semy-gamm-age3-minp.rds.gz"
semy_ppvt_para <- "./data/aim1-semy-gamm-age3-ppvt-para.rds.gz"
semy_minp_para <- "./data/aim1-semy-gamm-age3-minp-para.rds.gz"

semy_age3 <- if (file.exists(semy_base)) {
  readr::read_rds(semy_base)
} else {
  bam(
    elog ~ s(Time) + s(Time, R, bs = "fs", m = 1, k = 5),
    data = semy_d_minp) %>%
  readr::write_rds(semy_base)
}

semy_age3_ppvt <- if (file.exists(semy_ppvt)) {
  readr::read_rds(semy_ppvt)
} else {
  bam(
    elog ~ s(Time) +
      s(ppvt) +
      ti(Time, ppvt) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = semy_d_minp) %>%
  readr::write_rds(semy_ppvt)
}

semy_age3_minp <- if (file.exists(semy_minp)) {
  readr::read_rds(semy_minp)
} else {
  bam(
    elog ~ s(Time) +
      s(ability) +
      ti(Time, ability) +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = semy_d_minp) %>%
  readr::write_rds(semy_minp)
}

# parametric ppvt effect
semy_age3_ppvt_0 <- if (file.exists(semy_ppvt_para)) {
  readr::read_rds(semy_ppvt_para)
} else {
  bam(
    elog ~ s(Time) +
      ppvt +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = semy_d_minp) %>%
  readr::write_rds(semy_ppvt_para)
}

# parametric minpair effect
semy_age3_minp_0 <- if (file.exists(semy_minp_para)) {
  readr::read_rds(semy_minp_para)
} else {
  bam(
    elog ~ s(Time) +
      ability +
      s(Time, R, bs = "fs", m = 1, k = 5),
    data = semy_d_minp) %>%
  readr::write_rds(semy_minp_para)
}
```

To test the role of receptive vocabulary, I also fit analogous models
using growth scale value scores from the PPVT-4, a receptive vocabulary
test. I first adjusted these scores in a regression model to control
for--that is, to partial out the effects of---age and predicted accuracy
on the phonological discrimination task. There was not a significant
smooth effect for receptive vocabulary, EDF = `r phon_ppvt_edf`,
`r phon_ppvt_p`, or a significant interaction smooth between time and
receptive vocabulary, EDF = `r phon_ppvt_time_edf`,
`r phon_ppvt_time_p`. Receptive vocabulary therefore was not related to
looks to the phonological foil at age 3.

I tested the same two predictors on looks to the semantic foil at age 3.
These child-level factors did not show any significant parametric
effects, smooth effects or smooth interactions with time. Thus,
children's looks to the semantic foil were not reliably related to
phonological discrimination or receptive vocabulary.

**Summary**. These models tested whether two child-level
factors---minimal-pair discrimination ability and receptive
vocabulary---predicted looks to the phonological and semantic
competitors at age 3. No significant effects were observed for 
all cases. 




Discussion
------------------------------------------------------------------------

In the preceding analyses, I examined children's fixation patterns to
the phonological and semantic competitors and how these fixation
patterns changed over developmental time. With each year of the study,
children looked more to the target overall, so they consequently looked
less to the competitor images each year. To account for this fact, these
analyses modeled the ratio of looks to the competitors versus the
unrelated image used in each trial. This ratio measured the relative
advantage of a competitor over the unrelated image. 


<!-- If we imagine a pie-chart of looks to the four images, the target piece -->
<!-- increases in size each year, overtaking area from the other three looks. -->

<!-- describe general patterns, time course and increase -->

### Immediate activation of phonological neighbors

Developmentally, children became more sensitive to the phonological
competitors with each year of the study. These words shared the same
syllable onset as the target noun---for example, the pairs
*dress*–*drum* or *fly*–*flag*. The competitors affected word
recognition early on, with relative looks to the phonological foils
peaking around 800 ms. The target nouns were approximately 800 ms long
at age 3 and 550--800 ms for later ages. Assuming an 150–300 ms overhead
for executing an eye movement in response to speed, this timing means
that children on average shifted their gaze, immediately, based on partial
information.

At ages 4 and 5, these early peaks of looks to the phonological competitor were followed by a steep decrease in looks: Children rejected their initial interpretation of the word and considered other images. (At age 3, the pattern showed more wiggliness, which suggests greater uncertainty.) _Say something about inhibition?_

_At age&nbsp;3 the effect of the phonological competitor was very small compared.
The early advantage of the phonological foil was observed to a more
limited degree in the age 3 study, but still there._

Young children used information in an incremental fashion. This fact
agrees with previous findings....

<!-- Our results showed that children's activation of the target and its phonological neighbors increased with age. Children were more able to use partial information during word recognition. I had described this earlier as children becoming "more sensitive" to the phonological competitors. -->

@Rigler2015 provides an interesting comparison. They compared 9-
and 16-year-olds on a visual-world word recognition experiment with
cohort and rime competitors. The younger children in that study were
slower to look to the target image and showed more looks to the
competitor images. The implications are that children's lexical
processing is still developing in late childhood and that in particular,
children's inhibition of lexical competitors increases with age.

The current results with 3-, 4-, and 5-year-olds followed a different
pattern: Relative looks to the competitor images increased with age.
Taken together, the results suggest an interesting progression for the
development of lexical processing. From the earliest stages, children's
word recognition demonstrates incremental processing. [cite cite]
During the preschool years, children learn many, many words, and they
establish phonological and semantic connections between words. These
connections support immediate activation of neighborhoods of words. For
these experiments, children became more sensitive to the phonological
foils because the phonological competitor achieved greater activation.
Late childhood, based on the @Rigler2015 findings, would be a time for
refinement of those connections, so that sensitivity to the competitors
decreases. This refinement could follow from more selective activation 
channels, increased lexical inhibition, or likely a combination of both.




I also asked whether child-level factors predicted sensitivity to the
phonological competitors. They did not at age 3. In particular, children
who can more reliably discriminate minimal pairs did not show increased
sensitive to the phonological foil. This finding suggests that
sensitivity to the phonological foil is somewhat removed from speech
perception. PPVT: vocabulary not a factor either. Early activation
dynamics different from speech perception or number of words.

Limitations: Change in recorded stimuli. Inclusion of two competitors on
every trial.



<!-- Talking points: -->

<!--   - There is hardly an effect of the phonological foil during timepoint 1. There -->
<!--     are a few ways to interpret this finding. The first may be artefactual. The -->
<!--     stimuli were re-recorded at timepoint 2 so the timepoint 1 stimuli were -->
<!--     somewhat longer on average (). -->
<!--     However, with slower stimuli, we would still expect an inflection in looks -->
<!--     to the foil as children have more time to activate the phonological -->
<!--     representations to the cohort. In other words, with more time to respond, -->
<!--     there could plausibly be an even greater effect of early phonological -->
<!--     information. -->
<!--   - Alternatively, the children in timepoint 1 may not be using the early -->
<!--     similarity of words during word recognition. That is, instead of immediate -->
<!--     incremental activation of lexical cohorts, the children may not be -->
<!--     activating the cohorts as reliably. This would imply that further study is -->
<!--     required on the evidence for when young children begin to show immediate -->
<!--     activation of cohorts. -->



### Late activation of semantic neighbors

The semantic competitors were from the same category as the target noun.
They showed late effects. *bee*–*fly* or *shirt*–*dress*


describe lexical dynamics for semantic foil

describe lack of individual differences at age 3




## General discussion

Children became more successful listerners. When they erred, they erred
on the side of the phonologically or semantically plausible word.


<!-- Phon looks scraps. -->





<!-- semantic scraps: -->

<!-- The looking patterns---that is, the shapes of the growth curves---were largely the same for each year. The main differences were that the age-3 curve was about 100&nbsp;ms slower to rise than the age-4 curve and that the age-5 curve -->

<!--   - That the effect of the foil increases each year indicates that the -->
<!--     semantic representations of words have strengthened. -->
<!--   - Is inhibition coming online at age 5? -->
<!--   - If children were just confused between bear/horse, fly/bee, -->
<!--     goat/sheep, etc., they should be confused more at younger ages when -->
<!--     they know much less about the world. So if it were confusion or -->
<!--     guess, the semantic foil should be stronger at age 3. But they are -->
<!--     also slower at word recognition in general at younger ages, so maybe -->
<!--     these things cancel each other out? -->


<!-- Talking points : -->

<!-- * I tested whether two child-level features predicted looks to the competitor image at age 3. -->
<!-- * One a priori expectation was that looks to the phonological foil would relate to phonological discrimination ability, because children who can reliably discriminate one-feature phonetic differences between words would have richer phonological or phonetic representations that supported word recognition. -->

<!-- * The other a prior expectation was that looks to semantic foil would relate to looks to the receptive vocabulary. However, neither predicted related to looks the semantic foil. -->





<!-- What's going on here: -->

<!--   - The weak phonological foils are indeed weaker than the strong foils. -->
<!--   - The strong semantic foils appear stronger than the weak ones. The -->
<!--     strong foils show a growth curve pattern of increasing looks away -->
<!--     from baseline and there a developmental difference among the growth -->
<!--     curves for each time point. -->
<!--   - Children have a lower advantage for the target (vs unrelated) in -->
<!--     weak foil trials because... why? My reading is that if the semantic -->
<!--     or phonological foil is effective, children will look at it instead -->
<!--     of the unrelated image. Conversely, if the semantic or phonological -->
<!--     foil are less effective, children will look more to the unrelated -->
<!--     image, which pulls down the ratio of looks to target versus the -->
<!--     unrelated image. -->


```{r by-aoi-logit, out.width = "100%", fig.height = 2.5, fig.width = 6, echo = FALSE, message = FALSE, eval = FALSE}
# ggplot(looks_by_aoi %>% filter(AOI != "Unrelated")) +
#   aes(x = Time, y = log(Primary / Unrelated), color = Study) +
#   geom_hline(size = 2, color = "white", yintercept = 0) +
#   stat_smooth(method = "gam", formula = y ~ s(x)) +
#   facet_grid( ~ AOI) +
#   labs(
#     x = "Time after target onset [ms]",
#     y = "Log odds looking to word vs. unrelated word",
#     caption = "GAM smooth") +
#   theme_grey(base_size = 9) +
#   theme(
#     legend.position = c(0.95, 0.95),
#     legend.justification = c(1, 1))
```


<!-- Each curve is the log odds of looking to the target, phonological foil, and -->
<!-- semantic foil versus the unrelated word. Positive values mean more looks to an -->
<!-- image type than the unrelated. If you think of the _y_ axis as the image's -->
<!-- _relatedness_ to the target, you can see a time course of relatedness in each -->
<!-- panel: Here early phonological effects meaning early relatedness and later, -->
<!-- flatter semantic effects meaning late relatedness. (These effects make even more -->
<!-- sense sense if phonological representations affect processing before semantic -->
<!-- ones.) -->

<!-- This plot suggests an important finding: Children becoming more sensitive to the -->
<!-- phonological and semantic foils as they grow older. (I use the verb *suggest* -->
<!-- because this is still a preliminary, unmodeled finding.) Jan and I had made -->
<!-- opposite predictions about whether this would happen. Her argument, I think, was -->
<!-- that children become better at word recognition by becoming better able to -->
<!-- inhibit interference from competing words. This plot would suggest that they -->
<!-- show increased sensitive to the target and foils words by looking less to the -->
<!-- unrelated word as they age and reapportioning those looks to the other three -->
<!-- lexically relevant words. -->
