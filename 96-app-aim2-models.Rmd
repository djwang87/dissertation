Computational details for Study 2 {#aim2-gca-models}
========================================================================

```{r, include = FALSE}
knitr::read_chunk("./helpers.R")
if (interactive()) source("./helpers.R")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r helpers, message = FALSE, warning = FALSE}
```


Real words versus nonwords growth curves
------------------------------------------------------------------------

These models were fit in R [vers. 3.5.0; @R-base] with the brms package
[vers. 2.3.1; @brms].

The orthogonal polynomial features for Time, they were scaled as in
Study 1, so that the linear feature ranged from −.5 to .5. Under
this scaling a unit change in Time^1^ was equal to change from the start
to the end of the analysis window.

The model formula used to specify the model with brms is printed below.
The variables `ot1`, `ot2`, and `ot3` are the polynomial time features,
`ResearchID` identifies children, and `Condition` identifies the
experimental condition (either, the nonword or real word condition).
`Target` counts the number of looks to the target image at each time
bin; `trials()` is a flag that tells brms the number of trials for the
binomial process. Here, it is the variable `Trials`, which is equal to
the number of looks to target and distractor in each bin. 
The syntax `(1 + ot1 + ot2 + ot3) * Condition` specifies a Time x
Condition interaction; it says to estimate an intercept and the three
time feature effects for each condition.
The line `(ot1 + ot2 + ot3 | ResearchID/Condition)` describes the
random-effect structure of the model with the `/` indicating that data
from each `Condition` is nested within each `ResearchID`.

```{r, eval = FALSE, echo = TRUE}
library(brms)

# Fit a hierarchical logistic regression model
formula <- bf(
  Target | trials(Trials) ~ 
    (1 + ot1 + ot2 + ot3) * Condition + 
    (1 + ot1 + ot2 + ot3 | ResearchID/Condition), 
  family = binomial)
```

The priors for the model are specified below. The regression effects
(`class = "b"`) have a prior of Normal(0, 1). Because most of the action
in the growth curves is a sharp rise, the linear time effect `ot1` has a
slightly wider prior of Normal(0, 2). These priors are uninformative in
terms of direction--both positive and negative effects are equally
likely--but they are informative in terms of magnitude. A weakly
informative LKJ(2) prior is put on the random-effect correlations. I
review the role of the LKJ prior in 
[Appendix \@ref(aim1-gca-models)](#aim1-gca-models). A weakly informative
prior is put on the random-effect standard deviations
Student-*t*([df] 7, [mean] 0, [sd] 3). The Student-*t*
distribution is like the normal distribution but it provides slightly
thicker tails which allow extreme or outlying values.

```{r, eval = FALSE, echo = TRUE}
priors <- c(
  # Population-average intercept
  set_prior(class = "Intercept", "normal(0, 1)"),
  # Population-average slopes
  set_prior(class = "b", "normal(0, 1)"),
  # ... expect somewhat larger range of effects for linear time
  set_prior(class = "b", coef = "ot1", "normal(0, 2)"),
  # Correlations for random effect terms
  set_prior(class = "cor", "lkj(2)"),
  # Standard deviation of the distribution from
  # which random-intercepts are drawn
  set_prior(class = "sd", "student_t(7, 0, 3)"))
```

I originally tried a single model containing all three years with
corresponding year effects, year × time interactions, and
year × condition × time interactions, but this model took 30 hours to
run and did not converge. Therefore, I fit separate models for
each year of the study using syntax like the following. 

```{r, eval = FALSE, echo = TRUE}
m_age3 <- brm(
  formula = formula,
  data = d_age3,
  prior = priors,
  chains = 4,
  iter = 2000,
  cores = 4,
  control = list(adapt_delta = .99))

# Save the output
readr::write_rds(m_age3, "age3_mp.rds.gz")
```

This code fits the model using four sampling `chains` in parallel over
four processing `cores`. Early attempts at the model produced warnings,
so I increased the `adapt_delta` control option to make the sampling
more robust and eliminate the warnings.

Model summary for real words versus nonwords at age 3:

```{r, echo = FALSE}
intercept_summary <- function(...) {
  print_out <- purrr::quietly(print)(summary(...))
  lines <- print_out$output %>% 
    stringr::str_split("\n") %>% 
    unlist()
  lines
}

# indent all elements but first
str_exdent <- function(xs, width = 0) {
  indent <- stringr::str_pad("", width = width, side = "left", pad = " ")
  c(xs[1], paste0(indent, xs[-1]))
}

# add a prefix to all strings that are missing it
str_prefix_if_needed <- function(xs, comment = "") {
  to_fix <- !stringr::str_detect(xs, paste0("^", comment))
  xs[to_fix] <- paste0(comment, xs[to_fix])
  xs
}

# wrap the formula line from a brms summary
wrap_brms_formula <- function(lines, indent = 2, comment = "") {
  formula_line_no <- lines %>% 
    stringr::str_which("Formula:") %>% 
    head(1)
  
  formula_indent <- lines[formula_line_no] %>% 
    stringr::str_locate("Formula: ") %>% 
    as.list() %>% 
    getElement(2)
  
  formula_indent <- formula_indent - nchar(comment)
  
  lines[formula_line_no] <- lines[formula_line_no] %>% 
    stringr::str_replace(" ~ ", " ~ \n") %>% 
    stringr::str_replace(" [+] [(]", " + \n(") %>% 
    stringr::str_split("\n") %>%
    unlist() %>%
    str_exdent(formula_indent + indent) %>% 
    str_prefix_if_needed(comment) %>% 
    paste0(collapse = "\n")
  
  paste0(lines, collapse = "\n")
}
```

```{r custom-hook, echo = FALSE}
# store original processor
hook_output <- knitr::knit_hooks$get('output')

# if brms_wrap, intercept output and wrap formula line. run processor
knitr::knit_hooks$set(output = function(x, options) {
  if (is.null(options$brms_wrap)) { 
    options$brms_wrap <- FALSE
  }
  
  if (options$brms_wrap) { 
    x <- knitr:::split_lines(x)
    x <- wrap_brms_formula(x, indent = 2, comment = options$comment)
  } 
  
  hook_output(x, options)
})
```

```{r, echo = TRUE, brms_wrap = TRUE}
m1 <- readr::read_rds("./data/aim2-real-vs-nw-tp1.rds.gz")
summary(m1, priors = TRUE, prob = .9)
```

Model summary for real words versus nonwords at age 4:

```{r, echo = TRUE, brms_wrap = TRUE}
m2 <- readr::read_rds("./data/aim2-real-vs-nw-tp2.rds.gz")
summary(m2, priors = TRUE, prob = .9)
```

Model summary for real words versus nonwords at age 5:

```{r, echo = TRUE, brms_wrap = TRUE}
m3 <- readr::read_rds("./data/aim2-real-vs-nw-tp3.rds.gz")
summary(m3, priors = TRUE, prob = .9)
```



Mispronunciation growth curves
------------------------------------------------------------------------

Like the models above, these ones are Bayesian mixed-effects logistic
regression growth curve models fit with brms. I used two separate
models, one for unfamiliar-initial trials and familiar-initial trials.
Each model included data from all three years of the study. The code is
essentially the same syntax with a `Study` variable replacing the
`Condition` variable.

```{r, eval = FALSE, echo = TRUE}
library(brms)

# Fit a hierarchical logistic regression model
formula <- bf(
  Target | trials(Trials) ~ 
    (1 + ot1 + ot2 + ot3) * Study + 
    (1 + ot1 + ot2 + ot3 | ResearchID/Study), 
  family = binomial)

priors <- c(
  set_prior(class = "Intercept", "normal(0, 1)"),
  set_prior(class = "b", "normal(0, 1)"),
  set_prior(class = "b", coef = "ot1", "normal(0, 2)"),
  set_prior(class = "cor", "lkj(2)"),
  set_prior(class = "sd", "student_t(7, 0, 2)"))

mp_unfam <- brm(
  formula = formula,
  data = d_u,
  prior = priors,
  chains = 4,
  cores = 4,
  # Run extra iterations to get a higher effective sample size
  iter = 3000,
  control = list(
    adapt_delta = .995, 
    max_treedepth = 15))

# Save the output
readr::write_rds(mp_unfam, "./data/aim2-mp-unfam.rds.gz")

mp_fam <- brm(
  formula = formula,
  data = d_f,
  prior = priors,
  chains = 4,
  cores = 4,
  control = list(
    adapt_delta = .99, 
    max_treedepth = 15))

# Save the output
readr::write_rds(mp_fam, "./data/aim2-mp-fam.rds.gz")
```

The priors for this model are the same, except for a tighter prior on
scale/standard deviations for the random effect distributions. The model
had difficulty obtaining an effective number of samples for these
parameters. Initially, I tried to tell the model to do more work on each
sampling step (`adapt_delta = .995` and `max_treedepth = 15`) and run
the chains for 50% longer (`iter = 3000`). These changes did not solve
the problem. By using a tighter prior, the model had a smaller search
space meaning it could obtain samples more efficiently. 

The revised prior was still weakly informative. Figure
\@ref(fig:student-t-priors) illustrates the differences in the prior
densities---that is, which values are plausible before seeing the data.
It also shows posterior densities from the model and how those values
are easily enclosed by the prior densities.

```{r, include = FALSE}
library(tidyverse)
library(brms)

mp_unfam <- readr::read_rds("./data/aim2-mp-unfam.rds.gz")
mp_fam <- readr::read_rds("./data/aim2-mp-fam.rds.gz")

densities <- mp_unfam %>% 
  posterior_samples(pars = "sd") %>% 
  as_tibble() %>% 
  bayesplot:::mcmc_areas_data(prob = 1, n_dens = 5000) %>% 
  filter(interval == "inner")


# densities2 <- mp_unfam %>% 
#   posterior_samples(pars = "sd") %>% 
#   as_tibble() %>% 
#   tidyr::gather("var", "value")
# 
# ggplot(densities2) + 
#   aes(x = value, color = var) + 
#   stat_density(position = "identity") 

p2 <- ggplot(densities) + 
  aes(x = x, y = density) + 
  annotate(
    "rect", xmin =  -Inf, xmax = Inf,
    ymin = -Inf, ymax = Inf, 
    alpha = .25, fill = "lightskyblue1") +
  geom_line(aes(group = parameter)) + 
  guides(color = FALSE) + 
  labs(
    x = "SD value", y = "Posterior density") 
  
  

p1 <- ggplot(data_frame(x = 0:15)) + 
  aes(x = x) + 
  annotate(
    "rect", 
    xmin =  -Inf, 
    xmax = max(densities$x),
    ymin = -Inf, ymax = Inf, 
    alpha = .25, fill = "lightskyblue1") +
  stat_function(
    # aes(color = "student_t(7, 0, 2)"), 
    fun = dstudent_t, args = list(df = 7, mu = 0, sigma = 2),
    size = 1, 
    color = "lightpink4") + 
  stat_function(
    fun = dstudent_t, args = list(df = 7, mu = 0, sigma = 3),
    size = 1,
     color = "slateblue4") + 
  geom_text(
    aes(label = label, y = y),
    data = data_frame(
      color = "student_t(7, 0, 3)",
      label =  "student_t(7, 0, 3) \nhas a fatter tail",
      x = 6, 
      y = .04),
    family = "Lato Semibold",
    hjust = 0,
    color = "slateblue4") + 
  geom_text(
    aes(label = label, y = y),
    data = data_frame(
      color = "student_t(7, 0, 2)",
      label =  "student_t(7, 0, 2) \nfavors values up to 7.5",
      x = 2.0, 
      y = .16),
    hjust = 0,
    family = "Lato Semibold",
    color = "lightpink4") + 
  geom_text(
    aes(label = label, y = y),
    data = data_frame(
      color = "student_t(7, 0, 3)",
      label =  "range of\nposterior\ndensities",
      x = 0, 
      y = .02),
    family = "Lato Medium",
    hjust = 0,
    color = "lightskyblue4",
    size = 3) + 
  guides(color = FALSE) + 
  labs(
    x = "SD value", y = "Prior density")
  
library(patchwork)
```

(ref:student-t-priors) Prior densities (*left*) versus posterior densities (*right*) for the random-effect standard deviations. I changed the prior to be tighter, so that it favor values up to 7.5. This prior still turned out to be very conservative, given that the posterior samples for these values are all less than 3.

(ref:student-t-priors-scap) Prior densities versus posterior densities for the random-effect standard deviations.

```{r student-t-priors, echo = FALSE, fig.cap = "(ref:student-t-priors)", fig.scap = "(ref:student-t-priors-scap)", fig.width = 6, fig.height = 2.75, out.width = "100%"}
p1 + p2
```

Model summary for unfamiliar-initial mispronunciation trials:

```{r, echo = TRUE, brms_wrap = TRUE}
summary(mp_unfam, priors = TRUE, prob = .9)
```

Model summary for familiar-initial mispronunciation trials:

```{r, echo = TRUE, brms_wrap = TRUE}
summary(mp_fam, priors = TRUE, prob = .9)
```



Item-response analysis for novel word retention
------------------------------------------------------------------------

This is an item-response analysis carried out using a Bayesian
mixed-effects logistic regression model. These models were fit in R
[vers. 3.5.0; @R-base] with the brms package [vers. 2.3.1; @brms]. I
used weakly informative priors.

The linear model `Correct ~ ItemType * c_peak_10` says to
estimate the log-odds of answering correctly using on mispronunciations
(intercept) using the growth curve peaks (`c_peak_10`), adjust it for
nonwords (`ItemType`) and for the nonword × peak interaction. The peaks
were mean-centered within each type and multiplied by 10 so that the
slope represents the effect of change of .1 from the mean peak value.
The model includes four random intercepts: general child ability and
child × condition ability adjustments (simultaneously requested using 
`1 | ResearchID/ItemType`, i.e., `ResearchID` levels have `ItemType` levels
nested under `/` them), plus specific item-level difficulties (`1 | Item`)
and item-pair level difficulties (`1 | WordGroup`).

```{r, eval = FALSE, echo = TRUE}
d <- readr::read_csv("./data/mp-norming-data.csv.gz")

priors <- c(
  # Population-average intercept
  set_prior(class = "Intercept", "normal(0, 1)"),
  # Population-average slopes
  set_prior(class = "b", "normal(0, 1)"),
  # Standard deviation of the distribution from
  # which random-intercepts are drawn
  set_prior(class = "sd", "student_t(7, 0, 2)"))

m_norm <- brm(
  Correct ~ ItemType * c_peak_10 +
    (1 | ResearchID/ItemType) +
    (1 | WordGroup) +
    (1 | Item),
  prior = priors,
  family = bernoulli,
  chains = 4,
  iter = 2000,
  cores = 4,
  control = list(adapt_delta = .99),
  data = d)

readr::write_rds(m_norm, "./data/mp-norming-m2.rds.gz") 
```


```{r, eval = FALSE, include = FALSE}
# Code to fit a model without the peaks
m_norm1 <- update(
  m_norm, . ~ ItemType +
    (1 | ResearchID/ItemType) +
    (1 | WordGroup) +
    (1 | Item))

readr::write_rds(m_norm1, "./data/mp-norming-m1.rds.gz")
readr::write_rds(m_norm, "./data/mp-norming-m2.rds.gz")
```

Model summary for retention trials at age 5:

```{r, include = FALSE}
m_norm <- readr::read_rds("./data/mp-norming-m2.rds.gz")
```

```{r, echo = TRUE, R.options = list(width = 71), brms_wrap = TRUE}
summary(m_norm, priors = TRUE, prob = .9)
```
